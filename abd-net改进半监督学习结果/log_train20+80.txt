==========
Args:Namespace(abd_dan=['cam', 'pam'], abd_dan_no_head=False, abd_dim=1024, abd_np=2, adam_beta1=0.9, adam_beta2=0.999, arch='resnet50', branches=['global', 'abd'], compatibility=False, criterion='htri', cuhk03_classic_split=False, cuhk03_labeled=False, dan_dan=[], dan_dan_no_head=False, dan_dim=1024, data_augment=['crop', 'random-erase'], dropout=0, eval_freq=-1, evaluate=False, fixbase=False, fixbase_epoch=10, flip_eval=True, gamma=0.1, global_dim=1024, global_max_pooling=False, gpu_devices='0', height=384, htri_only=False, label_smooth=True, lambda_htri=0.1, lambda_xent=1, load_weights='', lr=0.0003, margin=1.2, max_epoch=80, momentum=0.9, np_dim=1024, np_max_pooling=False, np_np=2, np_with_global=False, num_instances=4, of_beta=1e-06, of_position=['before', 'after', 'cam', 'pam', 'intermediate'], of_start_epoch=23, open_layers=['classifier'], optim='adam', ow_beta=0.001, pool_tracklet_features='avg', print_freq=10, resume='', rmsprop_alpha=0.99, root='data', sample_method='evenly', save_dir='path/to/dir/jpf20', seed=1, seq_len=15, sgd_dampening=0, sgd_nesterov=False, shallow_cam=True, source_names=['market1501'], split_id=0, start_epoch=0, start_eval=0, stepsize=[20, 40], target_names=['market1501'], test_batch_size=100, train_batch_size=8, train_sampler='', use_avai_gpus=False, use_cpu=False, use_metric_cuhk03=False, use_of=True, use_ow=True, visualize_ranks=False, weight_decay=0.0005, width=128, workers=0)
==========
Currently using GPU 0
Initializing image data manager
Using augmentation: {'random-erase', 'crop'}
Using transform: Compose(
    <torchreid.transforms.Random2DTranslation object at 0x000001E5F1C913C8>
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <torchreid.transforms.RandomErasing object at 0x000001E5F1C91400>
)
=> Initializing TRAIN (source) datasets
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  label_train    |   150 |     2967 |         6
  unlabel_train    |   601 |     9969 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------
!!! Using RandomIdentitySampler !!!
=> Initializing TEST (target) datasets
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  label_train    |   150 |     2967 |         6
  unlabel_train    |   601 |     9969 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------


  **************** Summary ****************
  train names      : ['market1501']
  # train datasets : 1
  # train ids      : 150
  # label_train images   : 2967
  # unlabel_train images   : 9969
  # train cameras  : 6
  test names       : ['market1501']
  *****************************************


Initializing model: resnet50
Initialized model with pretrained weights from https://download.pytorch.org/models/resnet50-19c8e357.pth
MultiBranchResNet(
  (common_branch): ResNetCommonBranch(
    (backbone1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (shallow_cam): ShallowCAM(
      (_cam_module): CAM_Module(
        (softmax): Softmax(dim=-1)
      )
    )
    (backbone2): Sequential(
      (0): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
  )
  (branches): ModuleList(
    (0): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): ABDBranch(
        (reduction): Sequential(
          (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (before_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): Identity()
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (cam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): CAM_Module(
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (pam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): PAM_Module(
            (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (sum_conv): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifiers): ModuleList(
          (0): Linear(in_features=1024, out_features=150, bias=True)
          (1): Linear(in_features=1024, out_features=150, bias=True)
        )
      )
    )
    (1): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): GlobalBranch(
        (fc): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Dropout(p=0, inplace=False)
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifier): Linear(in_features=1024, out_features=150, bias=True)
      )
    )
  )
)
Model size: 67.327 M
Initialized model with pretrained weights from https://download.pytorch.org/models/resnet50-19c8e357.pth
MultiBranchResNet(
  (common_branch): ResNetCommonBranch(
    (backbone1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (shallow_cam): ShallowCAM(
      (_cam_module): CAM_Module(
        (softmax): Softmax(dim=-1)
      )
    )
    (backbone2): Sequential(
      (0): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
  )
  (branches): ModuleList(
    (0): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): ABDBranch(
        (reduction): Sequential(
          (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (before_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): Identity()
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (cam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): CAM_Module(
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (pam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): PAM_Module(
            (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (sum_conv): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifiers): ModuleList(
          (0): Linear(in_features=1024, out_features=150, bias=True)
          (1): Linear(in_features=1024, out_features=150, bias=True)
        )
      )
    )
    (1): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): GlobalBranch(
        (fc): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Dropout(p=0, inplace=False)
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifier): Linear(in_features=1024, out_features=150, bias=True)
      )
    )
  )
)
ema_Model size: 67.327 M
==> Start training
Train ['classifier'] for 10 epochs while keeping other layers frozen
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
F:\新建文件夹\ABD-Net-master\torchreid\losses\hard_mine_triplet_loss.py:58: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ..\torch\csrc\utils\python_arg_parser.cpp:766.)
  dist.addmm_(1, -2, inputs, inputs.t())
label_Epoch: [1][10/345]	Time 0.328 (2.447)	Data 0.0000 (0.0000)	Loss 6.3966 (6.5753)	
label_Epoch: [1][20/345]	Time 0.359 (1.395)	Data 0.0000 (0.0000)	Loss 5.9906 (6.4221)	
label_Epoch: [1][30/345]	Time 0.328 (1.043)	Data 0.0000 (0.0000)	Loss 5.9606 (6.3373)	
label_Epoch: [1][40/345]	Time 0.328 (0.868)	Data 0.0000 (0.0000)	Loss 6.3508 (6.3681)	
label_Epoch: [1][50/345]	Time 0.359 (0.763)	Data 0.0000 (0.0000)	Loss 6.3005 (6.3799)	
label_Epoch: [1][60/345]	Time 0.344 (0.693)	Data 0.0000 (0.0000)	Loss 5.9421 (6.3696)	
label_Epoch: [1][70/345]	Time 0.328 (0.643)	Data 0.0000 (0.0000)	Loss 6.0474 (6.3680)	
label_Epoch: [1][80/345]	Time 0.344 (0.604)	Data 0.0000 (0.0000)	Loss 5.9430 (6.3507)	
label_Epoch: [1][90/345]	Time 0.328 (0.574)	Data 0.0000 (0.0000)	Loss 6.0532 (6.3202)	
label_Epoch: [1][100/345]	Time 0.359 (0.550)	Data 0.0000 (0.0000)	Loss 5.8480 (6.2632)	
label_Epoch: [1][110/345]	Time 0.344 (0.531)	Data 0.0000 (0.0000)	Loss 6.3376 (6.2567)	
label_Epoch: [1][120/345]	Time 0.344 (0.515)	Data 0.0000 (0.0000)	Loss 6.0204 (6.2566)	
label_Epoch: [1][130/345]	Time 0.344 (0.502)	Data 0.0000 (0.0000)	Loss 6.4975 (6.2367)	
label_Epoch: [1][140/345]	Time 0.328 (0.490)	Data 0.0000 (0.0000)	Loss 6.7622 (6.2004)	
label_Epoch: [1][150/345]	Time 0.344 (0.480)	Data 0.0000 (0.0000)	Loss 5.9118 (6.1798)	
label_Epoch: [1][160/345]	Time 0.329 (0.471)	Data 0.0000 (0.0000)	Loss 5.8840 (6.1687)	
label_Epoch: [1][170/345]	Time 0.359 (0.464)	Data 0.0000 (0.0000)	Loss 5.4586 (6.1416)	
label_Epoch: [1][180/345]	Time 0.360 (0.457)	Data 0.0000 (0.0000)	Loss 5.5162 (6.1144)	
label_Epoch: [1][190/345]	Time 0.344 (0.451)	Data 0.0000 (0.0000)	Loss 5.4517 (6.0851)	
label_Epoch: [1][200/345]	Time 0.344 (0.446)	Data 0.0000 (0.0000)	Loss 5.5456 (6.0666)	
label_Epoch: [1][210/345]	Time 0.312 (0.441)	Data 0.0000 (0.0000)	Loss 5.9643 (6.0423)	
label_Epoch: [1][220/345]	Time 0.344 (0.437)	Data 0.0000 (0.0000)	Loss 5.5081 (6.0266)	
label_Epoch: [1][230/345]	Time 0.375 (0.433)	Data 0.0000 (0.0000)	Loss 5.6535 (5.9938)	
label_Epoch: [1][240/345]	Time 0.344 (0.429)	Data 0.0000 (0.0000)	Loss 5.5812 (5.9664)	
label_Epoch: [1][250/345]	Time 0.344 (0.425)	Data 0.0000 (0.0000)	Loss 5.2555 (5.9459)	
label_Epoch: [1][260/345]	Time 0.328 (0.422)	Data 0.0000 (0.0000)	Loss 4.4036 (5.9194)	
label_Epoch: [1][270/345]	Time 0.328 (0.419)	Data 0.0000 (0.0000)	Loss 5.3859 (5.8949)	
label_Epoch: [1][280/345]	Time 0.312 (0.415)	Data 0.0000 (0.0000)	Loss 4.3671 (5.8700)	
label_Epoch: [1][290/345]	Time 0.344 (0.413)	Data 0.0000 (0.0000)	Loss 4.7464 (5.8387)	
label_Epoch: [1][300/345]	Time 0.328 (0.410)	Data 0.0000 (0.0000)	Loss 5.3807 (5.8003)	
label_Epoch: [1][310/345]	Time 0.312 (0.408)	Data 0.0000 (0.0000)	Loss 4.8666 (5.7685)	
label_Epoch: [1][320/345]	Time 0.328 (0.406)	Data 0.0000 (0.0000)	Loss 4.9821 (5.7342)	
label_Epoch: [1][330/345]	Time 0.375 (0.404)	Data 0.0000 (0.0000)	Loss 4.5753 (5.6959)	
label_Epoch: [1][340/345]	Time 0.344 (0.402)	Data 0.0000 (0.0000)	Loss 4.3182 (5.6505)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [2][10/345]	Time 0.330 (2.303)	Data 0.0000 (0.0000)	Loss 5.8233 (6.1582)	
label_Epoch: [2][20/345]	Time 0.344 (1.326)	Data 0.0000 (0.0000)	Loss 5.6163 (5.9950)	
label_Epoch: [2][30/345]	Time 0.328 (0.997)	Data 0.0000 (0.0000)	Loss 4.8480 (5.8746)	
label_Epoch: [2][40/345]	Time 0.344 (0.833)	Data 0.0000 (0.0000)	Loss 4.8472 (5.7592)	
label_Epoch: [2][50/345]	Time 0.344 (0.735)	Data 0.0000 (0.0000)	Loss 6.0263 (5.6913)	
label_Epoch: [2][60/345]	Time 0.344 (0.671)	Data 0.0000 (0.0000)	Loss 5.6551 (5.6134)	
label_Epoch: [2][70/345]	Time 0.359 (0.624)	Data 0.0000 (0.0000)	Loss 5.2901 (5.5950)	
label_Epoch: [2][80/345]	Time 0.375 (0.591)	Data 0.0000 (0.0000)	Loss 4.9153 (5.5732)	
label_Epoch: [2][90/345]	Time 0.328 (0.563)	Data 0.0000 (0.0000)	Loss 5.2303 (5.5152)	
label_Epoch: [2][100/345]	Time 0.439 (0.543)	Data 0.0000 (0.0000)	Loss 4.7206 (5.4691)	
label_Epoch: [2][110/345]	Time 0.375 (0.525)	Data 0.0000 (0.0000)	Loss 5.4315 (5.4811)	
label_Epoch: [2][120/345]	Time 0.359 (0.510)	Data 0.0000 (0.0000)	Loss 5.6779 (5.4635)	
label_Epoch: [2][130/345]	Time 0.312 (0.497)	Data 0.0000 (0.0000)	Loss 5.4646 (5.4676)	
label_Epoch: [2][140/345]	Time 0.344 (0.486)	Data 0.0000 (0.0000)	Loss 4.9515 (5.4549)	
label_Epoch: [2][150/345]	Time 0.422 (0.476)	Data 0.0000 (0.0000)	Loss 5.1896 (5.4371)	
label_Epoch: [2][160/345]	Time 0.328 (0.468)	Data 0.0000 (0.0000)	Loss 5.5799 (5.4189)	
label_Epoch: [2][170/345]	Time 0.344 (0.461)	Data 0.0000 (0.0000)	Loss 4.3608 (5.3865)	
label_Epoch: [2][180/345]	Time 0.328 (0.455)	Data 0.0000 (0.0000)	Loss 4.9358 (5.3575)	
label_Epoch: [2][190/345]	Time 0.329 (0.449)	Data 0.0000 (0.0000)	Loss 4.7401 (5.3352)	
label_Epoch: [2][200/345]	Time 0.328 (0.443)	Data 0.0000 (0.0000)	Loss 5.7621 (5.3096)	
label_Epoch: [2][210/345]	Time 0.328 (0.438)	Data 0.0000 (0.0000)	Loss 5.0740 (5.2891)	
label_Epoch: [2][220/345]	Time 0.328 (0.434)	Data 0.0000 (0.0000)	Loss 4.6244 (5.2735)	
label_Epoch: [2][230/345]	Time 0.328 (0.429)	Data 0.0000 (0.0000)	Loss 4.8680 (5.2544)	
label_Epoch: [2][240/345]	Time 0.344 (0.426)	Data 0.0000 (0.0000)	Loss 5.0278 (5.2395)	
label_Epoch: [2][250/345]	Time 0.328 (0.422)	Data 0.0000 (0.0000)	Loss 4.4316 (5.2143)	
label_Epoch: [2][260/345]	Time 0.344 (0.419)	Data 0.0000 (0.0000)	Loss 4.7595 (5.1930)	
label_Epoch: [2][270/345]	Time 0.344 (0.416)	Data 0.0000 (0.0000)	Loss 3.9483 (5.1733)	
label_Epoch: [2][280/345]	Time 0.344 (0.414)	Data 0.0000 (0.0000)	Loss 3.4265 (5.1380)	
label_Epoch: [2][290/345]	Time 0.328 (0.412)	Data 0.0000 (0.0000)	Loss 4.9643 (5.1189)	
label_Epoch: [2][300/345]	Time 0.359 (0.409)	Data 0.0000 (0.0000)	Loss 5.3417 (5.0973)	
label_Epoch: [2][310/345]	Time 0.328 (0.407)	Data 0.0000 (0.0000)	Loss 4.0921 (5.0709)	
label_Epoch: [2][320/345]	Time 0.344 (0.405)	Data 0.0000 (0.0000)	Loss 2.7902 (5.0331)	
label_Epoch: [2][330/345]	Time 0.360 (0.403)	Data 0.0000 (0.0000)	Loss 3.4015 (4.9984)	
label_Epoch: [2][340/345]	Time 0.313 (0.401)	Data 0.0000 (0.0000)	Loss 3.5122 (4.9557)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [3][10/345]	Time 0.312 (2.152)	Data 0.0000 (0.0000)	Loss 5.7669 (5.7384)	
label_Epoch: [3][20/345]	Time 0.344 (1.248)	Data 0.0000 (0.0000)	Loss 5.2353 (5.7385)	
label_Epoch: [3][30/345]	Time 0.344 (0.946)	Data 0.0000 (0.0000)	Loss 5.6073 (5.6169)	
label_Epoch: [3][40/345]	Time 0.359 (0.794)	Data 0.0000 (0.0000)	Loss 5.7020 (5.5563)	
label_Epoch: [3][50/345]	Time 0.375 (0.705)	Data 0.0000 (0.0000)	Loss 4.8008 (5.4981)	
label_Epoch: [3][60/345]	Time 0.359 (0.646)	Data 0.0000 (0.0000)	Loss 5.6617 (5.4560)	
label_Epoch: [3][70/345]	Time 0.360 (0.601)	Data 0.0000 (0.0000)	Loss 4.6032 (5.3973)	
label_Epoch: [3][80/345]	Time 0.375 (0.570)	Data 0.0000 (0.0000)	Loss 4.3116 (5.3357)	
label_Epoch: [3][90/345]	Time 0.344 (0.544)	Data 0.0000 (0.0000)	Loss 5.0621 (5.3182)	
label_Epoch: [3][100/345]	Time 0.360 (0.525)	Data 0.0000 (0.0000)	Loss 5.2703 (5.2935)	
label_Epoch: [3][110/345]	Time 0.359 (0.509)	Data 0.0000 (0.0000)	Loss 4.9081 (5.2501)	
label_Epoch: [3][120/345]	Time 0.344 (0.495)	Data 0.0000 (0.0000)	Loss 5.0870 (5.2345)	
label_Epoch: [3][130/345]	Time 0.344 (0.483)	Data 0.0000 (0.0000)	Loss 4.3435 (5.2013)	
label_Epoch: [3][140/345]	Time 0.359 (0.473)	Data 0.0000 (0.0000)	Loss 5.0520 (5.1798)	
label_Epoch: [3][150/345]	Time 0.344 (0.464)	Data 0.0000 (0.0000)	Loss 5.1632 (5.1540)	
label_Epoch: [3][160/345]	Time 0.328 (0.456)	Data 0.0000 (0.0000)	Loss 4.0866 (5.1377)	
label_Epoch: [3][170/345]	Time 0.328 (0.449)	Data 0.0000 (0.0000)	Loss 5.1419 (5.1066)	
label_Epoch: [3][180/345]	Time 0.328 (0.444)	Data 0.0000 (0.0000)	Loss 5.2532 (5.0773)	
label_Epoch: [3][190/345]	Time 0.359 (0.439)	Data 0.0000 (0.0000)	Loss 4.5407 (5.0651)	
label_Epoch: [3][200/345]	Time 0.328 (0.433)	Data 0.0000 (0.0000)	Loss 4.2612 (5.0373)	
label_Epoch: [3][210/345]	Time 0.344 (0.429)	Data 0.0000 (0.0000)	Loss 5.7179 (5.0108)	
label_Epoch: [3][220/345]	Time 0.344 (0.425)	Data 0.0000 (0.0000)	Loss 4.7149 (4.9949)	
label_Epoch: [3][230/345]	Time 0.344 (0.422)	Data 0.0000 (0.0000)	Loss 4.9141 (4.9826)	
label_Epoch: [3][240/345]	Time 0.328 (0.419)	Data 0.0000 (0.0000)	Loss 5.2812 (4.9692)	
label_Epoch: [3][250/345]	Time 0.328 (0.415)	Data 0.0000 (0.0000)	Loss 4.2350 (4.9536)	
label_Epoch: [3][260/345]	Time 0.360 (0.412)	Data 0.0000 (0.0000)	Loss 3.5866 (4.9360)	
label_Epoch: [3][270/345]	Time 0.312 (0.409)	Data 0.0000 (0.0000)	Loss 3.8963 (4.9111)	
label_Epoch: [3][280/345]	Time 0.312 (0.407)	Data 0.0000 (0.0000)	Loss 4.0604 (4.8922)	
label_Epoch: [3][290/345]	Time 0.345 (0.405)	Data 0.0000 (0.0000)	Loss 3.7965 (4.8565)	
label_Epoch: [3][300/345]	Time 0.344 (0.403)	Data 0.0000 (0.0000)	Loss 3.9295 (4.8262)	
label_Epoch: [3][310/345]	Time 0.344 (0.401)	Data 0.0000 (0.0000)	Loss 3.9768 (4.7973)	
label_Epoch: [3][320/345]	Time 0.359 (0.399)	Data 0.0000 (0.0000)	Loss 2.9298 (4.7544)	
label_Epoch: [3][330/345]	Time 0.375 (0.398)	Data 0.0000 (0.0000)	Loss 2.5377 (4.7112)	
label_Epoch: [3][340/345]	Time 0.328 (0.396)	Data 0.0000 (0.0000)	Loss 3.1349 (4.6705)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [4][10/345]	Time 0.314 (2.043)	Data 0.0000 (0.0000)	Loss 5.8932 (5.5168)	
label_Epoch: [4][20/345]	Time 0.330 (1.190)	Data 0.0000 (0.0000)	Loss 5.2045 (5.3919)	
label_Epoch: [4][30/345]	Time 0.328 (0.906)	Data 0.0000 (0.0000)	Loss 5.1196 (5.3553)	
label_Epoch: [4][40/345]	Time 0.328 (0.765)	Data 0.0000 (0.0000)	Loss 4.8376 (5.2560)	
label_Epoch: [4][50/345]	Time 0.344 (0.679)	Data 0.0000 (0.0000)	Loss 5.6463 (5.2095)	
label_Epoch: [4][60/345]	Time 0.312 (0.622)	Data 0.0000 (0.0000)	Loss 4.5437 (5.1689)	
label_Epoch: [4][70/345]	Time 0.359 (0.582)	Data 0.0000 (0.0000)	Loss 5.3485 (5.1712)	
label_Epoch: [4][80/345]	Time 0.344 (0.553)	Data 0.0000 (0.0000)	Loss 5.4470 (5.1646)	
label_Epoch: [4][90/345]	Time 0.328 (0.529)	Data 0.0000 (0.0000)	Loss 4.5828 (5.1130)	
label_Epoch: [4][100/345]	Time 0.344 (0.510)	Data 0.0000 (0.0000)	Loss 4.1865 (5.0811)	
label_Epoch: [4][110/345]	Time 0.312 (0.494)	Data 0.0000 (0.0000)	Loss 4.8390 (5.0370)	
label_Epoch: [4][120/345]	Time 0.359 (0.482)	Data 0.0000 (0.0000)	Loss 5.2602 (5.0269)	
label_Epoch: [4][130/345]	Time 0.344 (0.472)	Data 0.0000 (0.0000)	Loss 4.8930 (5.0031)	
label_Epoch: [4][140/345]	Time 0.328 (0.463)	Data 0.0000 (0.0000)	Loss 4.5418 (4.9706)	
label_Epoch: [4][150/345]	Time 0.328 (0.455)	Data 0.0000 (0.0000)	Loss 4.6101 (4.9375)	
label_Epoch: [4][160/345]	Time 0.375 (0.448)	Data 0.0000 (0.0000)	Loss 4.9570 (4.9336)	
label_Epoch: [4][170/345]	Time 0.361 (0.442)	Data 0.0000 (0.0000)	Loss 5.2141 (4.9028)	
label_Epoch: [4][180/345]	Time 0.328 (0.437)	Data 0.0000 (0.0000)	Loss 5.7630 (4.9029)	
label_Epoch: [4][190/345]	Time 0.328 (0.432)	Data 0.0000 (0.0000)	Loss 3.9175 (4.8807)	
label_Epoch: [4][200/345]	Time 0.375 (0.427)	Data 0.0000 (0.0000)	Loss 3.9820 (4.8696)	
label_Epoch: [4][210/345]	Time 0.359 (0.423)	Data 0.0000 (0.0000)	Loss 4.6858 (4.8551)	
label_Epoch: [4][220/345]	Time 0.328 (0.420)	Data 0.0000 (0.0000)	Loss 4.7377 (4.8325)	
label_Epoch: [4][230/345]	Time 0.328 (0.416)	Data 0.0000 (0.0000)	Loss 4.5673 (4.8167)	
label_Epoch: [4][240/345]	Time 0.328 (0.413)	Data 0.0000 (0.0000)	Loss 4.4229 (4.7989)	
label_Epoch: [4][250/345]	Time 0.328 (0.410)	Data 0.0000 (0.0000)	Loss 6.2714 (4.7799)	
label_Epoch: [4][260/345]	Time 0.328 (0.408)	Data 0.0000 (0.0000)	Loss 3.5530 (4.7626)	
label_Epoch: [4][270/345]	Time 0.328 (0.406)	Data 0.0000 (0.0000)	Loss 4.0010 (4.7499)	
label_Epoch: [4][280/345]	Time 0.328 (0.403)	Data 0.0000 (0.0000)	Loss 3.8148 (4.7307)	
label_Epoch: [4][290/345]	Time 0.344 (0.401)	Data 0.0000 (0.0000)	Loss 3.6421 (4.7146)	
label_Epoch: [4][300/345]	Time 0.359 (0.399)	Data 0.0000 (0.0000)	Loss 2.8941 (4.6735)	
label_Epoch: [4][310/345]	Time 0.344 (0.397)	Data 0.0000 (0.0000)	Loss 4.0942 (4.6390)	
label_Epoch: [4][320/345]	Time 0.375 (0.395)	Data 0.0000 (0.0000)	Loss 3.4116 (4.6030)	
label_Epoch: [4][330/345]	Time 0.344 (0.394)	Data 0.0000 (0.0000)	Loss 4.0737 (4.5688)	
label_Epoch: [4][340/345]	Time 0.359 (0.392)	Data 0.0000 (0.0000)	Loss 2.8561 (4.5378)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [5][10/345]	Time 0.312 (2.083)	Data 0.0000 (0.0000)	Loss 5.4350 (5.3379)	
label_Epoch: [5][20/345]	Time 0.344 (1.211)	Data 0.0000 (0.0000)	Loss 4.9159 (5.2472)	
label_Epoch: [5][30/345]	Time 0.344 (0.921)	Data 0.0000 (0.0000)	Loss 5.2213 (5.1857)	
label_Epoch: [5][40/345]	Time 0.328 (0.774)	Data 0.0000 (0.0000)	Loss 4.3642 (5.1549)	
label_Epoch: [5][50/345]	Time 0.328 (0.688)	Data 0.0000 (0.0000)	Loss 4.5729 (5.0786)	
label_Epoch: [5][60/345]	Time 0.359 (0.630)	Data 0.0000 (0.0000)	Loss 4.3770 (5.0325)	
label_Epoch: [5][70/345]	Time 0.345 (0.589)	Data 0.0000 (0.0000)	Loss 5.2665 (5.0262)	
label_Epoch: [5][80/345]	Time 0.328 (0.558)	Data 0.0000 (0.0000)	Loss 3.7611 (4.9644)	
label_Epoch: [5][90/345]	Time 0.344 (0.536)	Data 0.0000 (0.0000)	Loss 4.3941 (4.9550)	
label_Epoch: [5][100/345]	Time 0.344 (0.516)	Data 0.0000 (0.0000)	Loss 4.2528 (4.9468)	
label_Epoch: [5][110/345]	Time 0.360 (0.502)	Data 0.0000 (0.0000)	Loss 5.4182 (4.9177)	
label_Epoch: [5][120/345]	Time 0.328 (0.489)	Data 0.0000 (0.0000)	Loss 4.5309 (4.9072)	
label_Epoch: [5][130/345]	Time 0.359 (0.478)	Data 0.0000 (0.0000)	Loss 4.0765 (4.8733)	
label_Epoch: [5][140/345]	Time 0.344 (0.468)	Data 0.0000 (0.0000)	Loss 3.1191 (4.8456)	
label_Epoch: [5][150/345]	Time 0.328 (0.460)	Data 0.0000 (0.0000)	Loss 3.9035 (4.8118)	
label_Epoch: [5][160/345]	Time 0.359 (0.453)	Data 0.0000 (0.0000)	Loss 3.6703 (4.7895)	
label_Epoch: [5][170/345]	Time 0.328 (0.446)	Data 0.0000 (0.0000)	Loss 5.1695 (4.7555)	
label_Epoch: [5][180/345]	Time 0.328 (0.440)	Data 0.0000 (0.0000)	Loss 4.2889 (4.7272)	
label_Epoch: [5][190/345]	Time 0.328 (0.435)	Data 0.0000 (0.0000)	Loss 4.3965 (4.6958)	
label_Epoch: [5][200/345]	Time 0.359 (0.431)	Data 0.0000 (0.0000)	Loss 3.2050 (4.6691)	
label_Epoch: [5][210/345]	Time 0.328 (0.426)	Data 0.0000 (0.0000)	Loss 3.8898 (4.6470)	
label_Epoch: [5][220/345]	Time 0.313 (0.423)	Data 0.0000 (0.0000)	Loss 4.0911 (4.6252)	
label_Epoch: [5][230/345]	Time 0.328 (0.419)	Data 0.0000 (0.0000)	Loss 4.7936 (4.6138)	
label_Epoch: [5][240/345]	Time 0.359 (0.416)	Data 0.0000 (0.0000)	Loss 3.8462 (4.5975)	
label_Epoch: [5][250/345]	Time 0.375 (0.413)	Data 0.0000 (0.0000)	Loss 4.2157 (4.5764)	
label_Epoch: [5][260/345]	Time 0.344 (0.410)	Data 0.0000 (0.0000)	Loss 2.9262 (4.5595)	
label_Epoch: [5][270/345]	Time 0.359 (0.408)	Data 0.0000 (0.0000)	Loss 4.1055 (4.5548)	
label_Epoch: [5][280/345]	Time 0.344 (0.406)	Data 0.0000 (0.0000)	Loss 3.7746 (4.5347)	
label_Epoch: [5][290/345]	Time 0.344 (0.404)	Data 0.0000 (0.0000)	Loss 3.6992 (4.5139)	
label_Epoch: [5][300/345]	Time 0.328 (0.402)	Data 0.0000 (0.0000)	Loss 4.3053 (4.4932)	
label_Epoch: [5][310/345]	Time 0.344 (0.400)	Data 0.0000 (0.0000)	Loss 3.4997 (4.4680)	
label_Epoch: [5][320/345]	Time 0.328 (0.398)	Data 0.0000 (0.0000)	Loss 3.3514 (4.4393)	
label_Epoch: [5][330/345]	Time 0.359 (0.396)	Data 0.0000 (0.0000)	Loss 3.2333 (4.3997)	
label_Epoch: [5][340/345]	Time 0.375 (0.395)	Data 0.0000 (0.0000)	Loss 1.8177 (4.3572)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [6][10/345]	Time 0.345 (2.131)	Data 0.0000 (0.0000)	Loss 6.2488 (5.7980)	
label_Epoch: [6][20/345]	Time 0.328 (1.237)	Data 0.0000 (0.0000)	Loss 3.8656 (5.3054)	
label_Epoch: [6][30/345]	Time 0.344 (0.940)	Data 0.0000 (0.0000)	Loss 4.4897 (5.1696)	
label_Epoch: [6][40/345]	Time 0.328 (0.790)	Data 0.0000 (0.0000)	Loss 5.1659 (5.1031)	
label_Epoch: [6][50/345]	Time 0.359 (0.700)	Data 0.0000 (0.0000)	Loss 4.2172 (5.0323)	
label_Epoch: [6][60/345]	Time 0.344 (0.641)	Data 0.0000 (0.0000)	Loss 5.0570 (4.9936)	
label_Epoch: [6][70/345]	Time 0.368 (0.600)	Data 0.0000 (0.0000)	Loss 4.4673 (4.9350)	
label_Epoch: [6][80/345]	Time 0.359 (0.568)	Data 0.0000 (0.0000)	Loss 5.0896 (4.9022)	
label_Epoch: [6][90/345]	Time 0.328 (0.542)	Data 0.0000 (0.0000)	Loss 4.1233 (4.8946)	
label_Epoch: [6][100/345]	Time 0.359 (0.522)	Data 0.0000 (0.0000)	Loss 4.8040 (4.8793)	
label_Epoch: [6][110/345]	Time 0.313 (0.506)	Data 0.0000 (0.0000)	Loss 4.1138 (4.8386)	
label_Epoch: [6][120/345]	Time 0.344 (0.492)	Data 0.0000 (0.0000)	Loss 3.9258 (4.8252)	
label_Epoch: [6][130/345]	Time 0.344 (0.480)	Data 0.0000 (0.0000)	Loss 4.7619 (4.7930)	
label_Epoch: [6][140/345]	Time 0.328 (0.471)	Data 0.0000 (0.0000)	Loss 4.2167 (4.7691)	
label_Epoch: [6][150/345]	Time 0.344 (0.461)	Data 0.0000 (0.0000)	Loss 4.9358 (4.7343)	
label_Epoch: [6][160/345]	Time 0.359 (0.454)	Data 0.0000 (0.0000)	Loss 4.1097 (4.7120)	
label_Epoch: [6][170/345]	Time 0.328 (0.447)	Data 0.0000 (0.0000)	Loss 4.2066 (4.6764)	
label_Epoch: [6][180/345]	Time 0.328 (0.441)	Data 0.0000 (0.0000)	Loss 4.5211 (4.6648)	
label_Epoch: [6][190/345]	Time 0.344 (0.436)	Data 0.0000 (0.0000)	Loss 4.0494 (4.6385)	
label_Epoch: [6][200/345]	Time 0.344 (0.431)	Data 0.0000 (0.0000)	Loss 3.6915 (4.6019)	
label_Epoch: [6][210/345]	Time 0.328 (0.427)	Data 0.0000 (0.0000)	Loss 4.0207 (4.5911)	
label_Epoch: [6][220/345]	Time 0.345 (0.423)	Data 0.0000 (0.0000)	Loss 5.0952 (4.5806)	
label_Epoch: [6][230/345]	Time 0.345 (0.420)	Data 0.0000 (0.0000)	Loss 3.6215 (4.5581)	
label_Epoch: [6][240/345]	Time 0.359 (0.417)	Data 0.0000 (0.0000)	Loss 3.5496 (4.5453)	
label_Epoch: [6][250/345]	Time 0.313 (0.414)	Data 0.0000 (0.0000)	Loss 4.1885 (4.5224)	
label_Epoch: [6][260/345]	Time 0.328 (0.411)	Data 0.0000 (0.0000)	Loss 3.5463 (4.5090)	
label_Epoch: [6][270/345]	Time 0.328 (0.408)	Data 0.0000 (0.0000)	Loss 3.2385 (4.4846)	
label_Epoch: [6][280/345]	Time 0.375 (0.406)	Data 0.0000 (0.0000)	Loss 3.7004 (4.4640)	
label_Epoch: [6][290/345]	Time 0.391 (0.405)	Data 0.0000 (0.0000)	Loss 5.4227 (4.4439)	
label_Epoch: [6][300/345]	Time 0.328 (0.403)	Data 0.0000 (0.0000)	Loss 5.0768 (4.4188)	
label_Epoch: [6][310/345]	Time 0.328 (0.400)	Data 0.0000 (0.0000)	Loss 3.0713 (4.3877)	
label_Epoch: [6][320/345]	Time 0.328 (0.398)	Data 0.0000 (0.0000)	Loss 3.3109 (4.3478)	
label_Epoch: [6][330/345]	Time 0.359 (0.397)	Data 0.0000 (0.0000)	Loss 3.4919 (4.3134)	
label_Epoch: [6][340/345]	Time 0.344 (0.396)	Data 0.0000 (0.0000)	Loss 3.1225 (4.2639)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [7][10/345]	Time 0.360 (2.188)	Data 0.0000 (0.0000)	Loss 5.1437 (5.2883)	
label_Epoch: [7][20/345]	Time 0.328 (1.267)	Data 0.0000 (0.0000)	Loss 3.7546 (5.1382)	
label_Epoch: [7][30/345]	Time 0.328 (0.959)	Data 0.0000 (0.0000)	Loss 4.7546 (4.9839)	
label_Epoch: [7][40/345]	Time 0.344 (0.805)	Data 0.0000 (0.0000)	Loss 4.9006 (4.9518)	
label_Epoch: [7][50/345]	Time 0.328 (0.713)	Data 0.0000 (0.0000)	Loss 4.1347 (4.9008)	
label_Epoch: [7][60/345]	Time 0.375 (0.651)	Data 0.0000 (0.0000)	Loss 4.4416 (4.8703)	
label_Epoch: [7][70/345]	Time 0.344 (0.607)	Data 0.0000 (0.0000)	Loss 3.9340 (4.7814)	
label_Epoch: [7][80/345]	Time 0.328 (0.574)	Data 0.0000 (0.0000)	Loss 3.8148 (4.7539)	
label_Epoch: [7][90/345]	Time 0.328 (0.549)	Data 0.0000 (0.0000)	Loss 4.5489 (4.7213)	
label_Epoch: [7][100/345]	Time 0.375 (0.530)	Data 0.0000 (0.0000)	Loss 3.6262 (4.6409)	
label_Epoch: [7][110/345]	Time 0.328 (0.513)	Data 0.0000 (0.0000)	Loss 5.0762 (4.6277)	
label_Epoch: [7][120/345]	Time 0.359 (0.499)	Data 0.0000 (0.0000)	Loss 4.4704 (4.6296)	
label_Epoch: [7][130/345]	Time 0.406 (0.488)	Data 0.0000 (0.0000)	Loss 5.4745 (4.6030)	
label_Epoch: [7][140/345]	Time 0.344 (0.477)	Data 0.0000 (0.0000)	Loss 3.9768 (4.5857)	
label_Epoch: [7][150/345]	Time 0.328 (0.468)	Data 0.0000 (0.0000)	Loss 4.6836 (4.5706)	
label_Epoch: [7][160/345]	Time 0.328 (0.461)	Data 0.0000 (0.0000)	Loss 3.6025 (4.5521)	
label_Epoch: [7][170/345]	Time 0.344 (0.454)	Data 0.0000 (0.0000)	Loss 3.4142 (4.5351)	
label_Epoch: [7][180/345]	Time 0.359 (0.448)	Data 0.0000 (0.0000)	Loss 4.7276 (4.5063)	
label_Epoch: [7][190/345]	Time 0.312 (0.442)	Data 0.0000 (0.0000)	Loss 4.3183 (4.4990)	
label_Epoch: [7][200/345]	Time 0.328 (0.437)	Data 0.0000 (0.0000)	Loss 3.2917 (4.4680)	
label_Epoch: [7][210/345]	Time 0.328 (0.433)	Data 0.0000 (0.0000)	Loss 3.4991 (4.4433)	
label_Epoch: [7][220/345]	Time 0.344 (0.428)	Data 0.0000 (0.0000)	Loss 3.8652 (4.4206)	
label_Epoch: [7][230/345]	Time 0.375 (0.425)	Data 0.0000 (0.0000)	Loss 4.6423 (4.4069)	
label_Epoch: [7][240/345]	Time 0.328 (0.421)	Data 0.0000 (0.0000)	Loss 4.5694 (4.3981)	
label_Epoch: [7][250/345]	Time 0.344 (0.418)	Data 0.0000 (0.0000)	Loss 3.8130 (4.3815)	
label_Epoch: [7][260/345]	Time 0.344 (0.415)	Data 0.0000 (0.0000)	Loss 4.3677 (4.3648)	
label_Epoch: [7][270/345]	Time 0.328 (0.412)	Data 0.0000 (0.0000)	Loss 3.5058 (4.3483)	
label_Epoch: [7][280/345]	Time 0.344 (0.410)	Data 0.0000 (0.0000)	Loss 4.7351 (4.3391)	
label_Epoch: [7][290/345]	Time 0.328 (0.407)	Data 0.0000 (0.0000)	Loss 3.3351 (4.3175)	
label_Epoch: [7][300/345]	Time 0.328 (0.405)	Data 0.0000 (0.0000)	Loss 3.4429 (4.2929)	
label_Epoch: [7][310/345]	Time 0.406 (0.403)	Data 0.0000 (0.0000)	Loss 3.4095 (4.2560)	
label_Epoch: [7][320/345]	Time 0.328 (0.401)	Data 0.0000 (0.0000)	Loss 3.2803 (4.2242)	
label_Epoch: [7][330/345]	Time 0.328 (0.399)	Data 0.0000 (0.0000)	Loss 2.7277 (4.1904)	
label_Epoch: [7][340/345]	Time 0.328 (0.397)	Data 0.0000 (0.0000)	Loss 2.3333 (4.1484)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [8][10/345]	Time 0.328 (2.067)	Data 0.0000 (0.0000)	Loss 5.0700 (5.1630)	
label_Epoch: [8][20/345]	Time 0.359 (1.206)	Data 0.0000 (0.0000)	Loss 4.9368 (4.8912)	
label_Epoch: [8][30/345]	Time 0.344 (0.917)	Data 0.0000 (0.0000)	Loss 4.5766 (4.8173)	
label_Epoch: [8][40/345]	Time 0.328 (0.772)	Data 0.0000 (0.0000)	Loss 5.2407 (4.8417)	
label_Epoch: [8][50/345]	Time 0.328 (0.686)	Data 0.0000 (0.0000)	Loss 5.0085 (4.7809)	
label_Epoch: [8][60/345]	Time 0.328 (0.629)	Data 0.0000 (0.0000)	Loss 4.7603 (4.7486)	
label_Epoch: [8][70/345]	Time 0.328 (0.587)	Data 0.0000 (0.0000)	Loss 4.4298 (4.6900)	
label_Epoch: [8][80/345]	Time 0.328 (0.556)	Data 0.0000 (0.0000)	Loss 5.6028 (4.6719)	
label_Epoch: [8][90/345]	Time 0.344 (0.532)	Data 0.0000 (0.0000)	Loss 4.8470 (4.6397)	
label_Epoch: [8][100/345]	Time 0.328 (0.513)	Data 0.0000 (0.0000)	Loss 3.6106 (4.6078)	
label_Epoch: [8][110/345]	Time 0.328 (0.497)	Data 0.0000 (0.0000)	Loss 3.4249 (4.5546)	
label_Epoch: [8][120/345]	Time 0.328 (0.484)	Data 0.0000 (0.0000)	Loss 3.7824 (4.5303)	
label_Epoch: [8][130/345]	Time 0.328 (0.473)	Data 0.0000 (0.0000)	Loss 4.2529 (4.5463)	
label_Epoch: [8][140/345]	Time 0.344 (0.463)	Data 0.0000 (0.0000)	Loss 5.0705 (4.5133)	
label_Epoch: [8][150/345]	Time 0.328 (0.455)	Data 0.0000 (0.0000)	Loss 3.2760 (4.4774)	
label_Epoch: [8][160/345]	Time 0.344 (0.448)	Data 0.0000 (0.0000)	Loss 4.6445 (4.4555)	
label_Epoch: [8][170/345]	Time 0.328 (0.442)	Data 0.0000 (0.0000)	Loss 3.9431 (4.4118)	
label_Epoch: [8][180/345]	Time 0.312 (0.437)	Data 0.0000 (0.0000)	Loss 3.6661 (4.4152)	
label_Epoch: [8][190/345]	Time 0.344 (0.432)	Data 0.0000 (0.0000)	Loss 4.3618 (4.4038)	
label_Epoch: [8][200/345]	Time 0.359 (0.428)	Data 0.0000 (0.0000)	Loss 3.4357 (4.3835)	
label_Epoch: [8][210/345]	Time 0.314 (0.423)	Data 0.0000 (0.0000)	Loss 3.9436 (4.3673)	
label_Epoch: [8][220/345]	Time 0.359 (0.419)	Data 0.0000 (0.0000)	Loss 3.4184 (4.3436)	
label_Epoch: [8][230/345]	Time 0.344 (0.416)	Data 0.0000 (0.0000)	Loss 3.8245 (4.3219)	
label_Epoch: [8][240/345]	Time 0.328 (0.413)	Data 0.0000 (0.0000)	Loss 3.3221 (4.3014)	
label_Epoch: [8][250/345]	Time 0.328 (0.410)	Data 0.0000 (0.0000)	Loss 2.6446 (4.2791)	
label_Epoch: [8][260/345]	Time 0.344 (0.407)	Data 0.0000 (0.0000)	Loss 2.8994 (4.2593)	
label_Epoch: [8][270/345]	Time 0.328 (0.405)	Data 0.0000 (0.0000)	Loss 2.9638 (4.2393)	
label_Epoch: [8][280/345]	Time 0.344 (0.402)	Data 0.0000 (0.0000)	Loss 3.8190 (4.2137)	
label_Epoch: [8][290/345]	Time 0.344 (0.400)	Data 0.0000 (0.0000)	Loss 4.1228 (4.1919)	
label_Epoch: [8][300/345]	Time 0.360 (0.398)	Data 0.0000 (0.0000)	Loss 2.4086 (4.1752)	
label_Epoch: [8][310/345]	Time 0.343 (0.397)	Data 0.0000 (0.0000)	Loss 3.7957 (4.1470)	
label_Epoch: [8][320/345]	Time 0.360 (0.395)	Data 0.0000 (0.0000)	Loss 4.1641 (4.1179)	
label_Epoch: [8][330/345]	Time 0.328 (0.393)	Data 0.0000 (0.0000)	Loss 2.5997 (4.0891)	
label_Epoch: [8][340/345]	Time 0.328 (0.392)	Data 0.0000 (0.0000)	Loss 2.0247 (4.0478)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [9][10/345]	Time 0.344 (2.238)	Data 0.0000 (0.0000)	Loss 3.8184 (4.9560)	
label_Epoch: [9][20/345]	Time 0.328 (1.292)	Data 0.0000 (0.0000)	Loss 4.6655 (4.7474)	
label_Epoch: [9][30/345]	Time 0.344 (0.976)	Data 0.0000 (0.0000)	Loss 4.7014 (4.7409)	
label_Epoch: [9][40/345]	Time 0.375 (0.822)	Data 0.0000 (0.0000)	Loss 5.0410 (4.7345)	
label_Epoch: [9][50/345]	Time 0.344 (0.726)	Data 0.0000 (0.0000)	Loss 4.3091 (4.6865)	
label_Epoch: [9][60/345]	Time 0.329 (0.663)	Data 0.0000 (0.0000)	Loss 4.4747 (4.6590)	
label_Epoch: [9][70/345]	Time 0.344 (0.618)	Data 0.0000 (0.0000)	Loss 4.5375 (4.6260)	
label_Epoch: [9][80/345]	Time 0.344 (0.584)	Data 0.0000 (0.0000)	Loss 4.1904 (4.5728)	
label_Epoch: [9][90/345]	Time 0.406 (0.560)	Data 0.0000 (0.0000)	Loss 3.8712 (4.5640)	
label_Epoch: [9][100/345]	Time 0.328 (0.538)	Data 0.0000 (0.0000)	Loss 3.6687 (4.5326)	
label_Epoch: [9][110/345]	Time 0.344 (0.520)	Data 0.0000 (0.0000)	Loss 4.0781 (4.5321)	
label_Epoch: [9][120/345]	Time 0.328 (0.506)	Data 0.0000 (0.0000)	Loss 3.8150 (4.4694)	
label_Epoch: [9][130/345]	Time 0.361 (0.494)	Data 0.0000 (0.0000)	Loss 4.5668 (4.4477)	
label_Epoch: [9][140/345]	Time 0.328 (0.482)	Data 0.0000 (0.0000)	Loss 3.2403 (4.4060)	
label_Epoch: [9][150/345]	Time 0.360 (0.473)	Data 0.0000 (0.0000)	Loss 3.4798 (4.3765)	
label_Epoch: [9][160/345]	Time 0.344 (0.464)	Data 0.0000 (0.0000)	Loss 5.1927 (4.3595)	
label_Epoch: [9][170/345]	Time 0.328 (0.457)	Data 0.0000 (0.0000)	Loss 4.0752 (4.3402)	
label_Epoch: [9][180/345]	Time 0.359 (0.451)	Data 0.0000 (0.0000)	Loss 3.3520 (4.3264)	
label_Epoch: [9][190/345]	Time 0.344 (0.446)	Data 0.0000 (0.0000)	Loss 3.9919 (4.2990)	
label_Epoch: [9][200/345]	Time 0.344 (0.441)	Data 0.0000 (0.0000)	Loss 4.5952 (4.2753)	
label_Epoch: [9][210/345]	Time 0.359 (0.436)	Data 0.0000 (0.0000)	Loss 3.2135 (4.2614)	
label_Epoch: [9][220/345]	Time 0.328 (0.432)	Data 0.0000 (0.0000)	Loss 3.6918 (4.2305)	
label_Epoch: [9][230/345]	Time 0.359 (0.428)	Data 0.0000 (0.0000)	Loss 4.3265 (4.2232)	
label_Epoch: [9][240/345]	Time 0.344 (0.425)	Data 0.0000 (0.0000)	Loss 2.7005 (4.1894)	
label_Epoch: [9][250/345]	Time 0.328 (0.421)	Data 0.0000 (0.0000)	Loss 4.3676 (4.1706)	
label_Epoch: [9][260/345]	Time 0.359 (0.418)	Data 0.0000 (0.0000)	Loss 3.1274 (4.1502)	
label_Epoch: [9][270/345]	Time 0.344 (0.416)	Data 0.0000 (0.0000)	Loss 4.0989 (4.1329)	
label_Epoch: [9][280/345]	Time 0.328 (0.413)	Data 0.0000 (0.0000)	Loss 3.9203 (4.1153)	
label_Epoch: [9][290/345]	Time 0.328 (0.411)	Data 0.0000 (0.0000)	Loss 3.4359 (4.0896)	
label_Epoch: [9][300/345]	Time 0.344 (0.409)	Data 0.0000 (0.0000)	Loss 2.8314 (4.0668)	
label_Epoch: [9][310/345]	Time 0.391 (0.407)	Data 0.0000 (0.0000)	Loss 4.0770 (4.0414)	
label_Epoch: [9][320/345]	Time 0.328 (0.405)	Data 0.0000 (0.0000)	Loss 2.5285 (4.0117)	
label_Epoch: [9][330/345]	Time 0.359 (0.403)	Data 0.0000 (0.0000)	Loss 2.5025 (3.9727)	
label_Epoch: [9][340/345]	Time 0.360 (0.402)	Data 0.0000 (0.0000)	Loss 2.1428 (3.9244)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [10][10/345]	Time 0.344 (2.170)	Data 0.0000 (0.0000)	Loss 5.3213 (4.8680)	
label_Epoch: [10][20/345]	Time 0.375 (1.263)	Data 0.0000 (0.0000)	Loss 4.5005 (4.6703)	
label_Epoch: [10][30/345]	Time 0.313 (0.954)	Data 0.0000 (0.0000)	Loss 4.8061 (4.6369)	
label_Epoch: [10][40/345]	Time 0.328 (0.800)	Data 0.0000 (0.0000)	Loss 3.5389 (4.5819)	
label_Epoch: [10][50/345]	Time 0.375 (0.711)	Data 0.0000 (0.0000)	Loss 4.5434 (4.5519)	
label_Epoch: [10][60/345]	Time 0.359 (0.649)	Data 0.0000 (0.0000)	Loss 4.0988 (4.5136)	
label_Epoch: [10][70/345]	Time 0.344 (0.606)	Data 0.0000 (0.0000)	Loss 4.6421 (4.4940)	
label_Epoch: [10][80/345]	Time 0.312 (0.574)	Data 0.0000 (0.0000)	Loss 4.4987 (4.4628)	
label_Epoch: [10][90/345]	Time 0.328 (0.548)	Data 0.0000 (0.0000)	Loss 5.3018 (4.4147)	
label_Epoch: [10][100/345]	Time 0.344 (0.527)	Data 0.0000 (0.0000)	Loss 3.1098 (4.3990)	
label_Epoch: [10][110/345]	Time 0.375 (0.511)	Data 0.0000 (0.0000)	Loss 4.6280 (4.3560)	
label_Epoch: [10][120/345]	Time 0.344 (0.496)	Data 0.0000 (0.0000)	Loss 3.9016 (4.3191)	
label_Epoch: [10][130/345]	Time 0.359 (0.485)	Data 0.0000 (0.0000)	Loss 5.1750 (4.3303)	
label_Epoch: [10][140/345]	Time 0.359 (0.475)	Data 0.0000 (0.0000)	Loss 3.8930 (4.3026)	
label_Epoch: [10][150/345]	Time 0.328 (0.466)	Data 0.0000 (0.0000)	Loss 4.0740 (4.2904)	
label_Epoch: [10][160/345]	Time 0.329 (0.458)	Data 0.0000 (0.0000)	Loss 4.2984 (4.2767)	
label_Epoch: [10][170/345]	Time 0.328 (0.451)	Data 0.0000 (0.0000)	Loss 4.1464 (4.2494)	
label_Epoch: [10][180/345]	Time 0.328 (0.445)	Data 0.0000 (0.0000)	Loss 4.2953 (4.2239)	
label_Epoch: [10][190/345]	Time 0.375 (0.440)	Data 0.0000 (0.0000)	Loss 3.1291 (4.1999)	
label_Epoch: [10][200/345]	Time 0.359 (0.435)	Data 0.0000 (0.0000)	Loss 4.5315 (4.1934)	
label_Epoch: [10][210/345]	Time 0.360 (0.431)	Data 0.0000 (0.0000)	Loss 3.7050 (4.1677)	
label_Epoch: [10][220/345]	Time 0.344 (0.427)	Data 0.0000 (0.0000)	Loss 3.8176 (4.1463)	
label_Epoch: [10][230/345]	Time 0.344 (0.423)	Data 0.0000 (0.0000)	Loss 3.2712 (4.1175)	
label_Epoch: [10][240/345]	Time 0.328 (0.420)	Data 0.0000 (0.0000)	Loss 3.0594 (4.0969)	
label_Epoch: [10][250/345]	Time 0.360 (0.417)	Data 0.0000 (0.0000)	Loss 4.1481 (4.0747)	
label_Epoch: [10][260/345]	Time 0.344 (0.414)	Data 0.0000 (0.0000)	Loss 4.0096 (4.0612)	
label_Epoch: [10][270/345]	Time 0.344 (0.412)	Data 0.0000 (0.0000)	Loss 3.1517 (4.0317)	
label_Epoch: [10][280/345]	Time 0.359 (0.409)	Data 0.0000 (0.0000)	Loss 2.7492 (4.0002)	
label_Epoch: [10][290/345]	Time 0.328 (0.407)	Data 0.0000 (0.0000)	Loss 2.6420 (3.9892)	
label_Epoch: [10][300/345]	Time 0.313 (0.405)	Data 0.0000 (0.0000)	Loss 4.1257 (3.9717)	
label_Epoch: [10][310/345]	Time 0.346 (0.403)	Data 0.0000 (0.0000)	Loss 2.5574 (3.9427)	
label_Epoch: [10][320/345]	Time 0.328 (0.401)	Data 0.0000 (0.0000)	Loss 3.3017 (3.9221)	
label_Epoch: [10][330/345]	Time 0.328 (0.399)	Data 0.0000 (0.0000)	Loss 2.3478 (3.8875)	
label_Epoch: [10][340/345]	Time 0.344 (0.397)	Data 0.0000 (0.0000)	Loss 1.7561 (3.8448)	
Done. All layers are open to train for 80 epochs
0
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [1][10/345]	Time 0.609 (2.552)	Data 0.0000 (0.0000)	Loss 5.3582 (5.7999)	
label_Epoch: [1][20/345]	Time 0.609 (1.588)	Data 0.0000 (0.0000)	Loss 5.5690 (5.5561)	
label_Epoch: [1][30/345]	Time 0.625 (1.265)	Data 0.0000 (0.0000)	Loss 5.2440 (5.5801)	
label_Epoch: [1][40/345]	Time 0.611 (1.104)	Data 0.0000 (0.0000)	Loss 5.6573 (5.5545)	
label_Epoch: [1][50/345]	Time 0.609 (1.008)	Data 0.0000 (0.0000)	Loss 5.0405 (5.4359)	
label_Epoch: [1][60/345]	Time 0.609 (0.944)	Data 0.0000 (0.0000)	Loss 5.9481 (5.4212)	
label_Epoch: [1][70/345]	Time 0.594 (0.897)	Data 0.0000 (0.0000)	Loss 4.8661 (5.3739)	
label_Epoch: [1][80/345]	Time 0.625 (0.864)	Data 0.0000 (0.0000)	Loss 5.5772 (5.3742)	
label_Epoch: [1][90/345]	Time 0.627 (0.838)	Data 0.0000 (0.0000)	Loss 5.8332 (5.3300)	
label_Epoch: [1][100/345]	Time 0.625 (0.817)	Data 0.0000 (0.0000)	Loss 4.8468 (5.3311)	
label_Epoch: [1][110/345]	Time 0.625 (0.799)	Data 0.0000 (0.0000)	Loss 4.9883 (5.3160)	
label_Epoch: [1][120/345]	Time 0.609 (0.784)	Data 0.0000 (0.0000)	Loss 5.3492 (5.3069)	
label_Epoch: [1][130/345]	Time 0.609 (0.772)	Data 0.0000 (0.0000)	Loss 5.4343 (5.2846)	
label_Epoch: [1][140/345]	Time 0.625 (0.761)	Data 0.0000 (0.0000)	Loss 4.0580 (5.2431)	
label_Epoch: [1][150/345]	Time 0.625 (0.752)	Data 0.0000 (0.0000)	Loss 3.5191 (5.2058)	
label_Epoch: [1][160/345]	Time 0.625 (0.744)	Data 0.0000 (0.0000)	Loss 4.7377 (5.1718)	
label_Epoch: [1][170/345]	Time 0.609 (0.737)	Data 0.0000 (0.0000)	Loss 4.8418 (5.1454)	
label_Epoch: [1][180/345]	Time 0.640 (0.731)	Data 0.0000 (0.0000)	Loss 4.7342 (5.1355)	
label_Epoch: [1][190/345]	Time 0.640 (0.726)	Data 0.0000 (0.0000)	Loss 4.1413 (5.1176)	
label_Epoch: [1][200/345]	Time 0.625 (0.720)	Data 0.0000 (0.0000)	Loss 4.9850 (5.0918)	
label_Epoch: [1][210/345]	Time 0.611 (0.716)	Data 0.0000 (0.0000)	Loss 5.2873 (5.0702)	
label_Epoch: [1][220/345]	Time 0.610 (0.711)	Data 0.0000 (0.0000)	Loss 3.8447 (5.0406)	
label_Epoch: [1][230/345]	Time 0.625 (0.708)	Data 0.0000 (0.0000)	Loss 4.8534 (5.0207)	
label_Epoch: [1][240/345]	Time 0.625 (0.704)	Data 0.0000 (0.0000)	Loss 4.2522 (5.0002)	
label_Epoch: [1][250/345]	Time 0.641 (0.701)	Data 0.0000 (0.0000)	Loss 4.4674 (4.9734)	
label_Epoch: [1][260/345]	Time 0.625 (0.698)	Data 0.0000 (0.0000)	Loss 3.5357 (4.9384)	
label_Epoch: [1][270/345]	Time 0.610 (0.695)	Data 0.0000 (0.0000)	Loss 4.0182 (4.9047)	
label_Epoch: [1][280/345]	Time 0.625 (0.692)	Data 0.0000 (0.0000)	Loss 3.8557 (4.8656)	
label_Epoch: [1][290/345]	Time 0.625 (0.690)	Data 0.0000 (0.0000)	Loss 4.9573 (4.8270)	
label_Epoch: [1][300/345]	Time 0.609 (0.688)	Data 0.0000 (0.0000)	Loss 3.1581 (4.7975)	
label_Epoch: [1][310/345]	Time 0.625 (0.685)	Data 0.0000 (0.0000)	Loss 4.0554 (4.7789)	
label_Epoch: [1][320/345]	Time 0.625 (0.683)	Data 0.0000 (0.0000)	Loss 3.4379 (4.7579)	
label_Epoch: [1][330/345]	Time 0.625 (0.682)	Data 0.0000 (0.0000)	Loss 3.6586 (4.7204)	
label_Epoch: [1][340/345]	Time 0.609 (0.680)	Data 0.0000 (0.0000)	Loss 2.1255 (4.6628)	
1
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [2][10/345]	Time 0.641 (2.397)	Data 0.0000 (0.0000)	Loss 5.8192 (6.0094)	
label_Epoch: [2][20/345]	Time 0.625 (1.509)	Data 0.0000 (0.0000)	Loss 5.2095 (5.6400)	
label_Epoch: [2][30/345]	Time 0.657 (1.216)	Data 0.0000 (0.0000)	Loss 4.4377 (5.4093)	
label_Epoch: [2][40/345]	Time 0.609 (1.068)	Data 0.0000 (0.0000)	Loss 4.7999 (5.3266)	
label_Epoch: [2][50/345]	Time 0.625 (0.979)	Data 0.0000 (0.0000)	Loss 5.4181 (5.2152)	
label_Epoch: [2][60/345]	Time 0.609 (0.919)	Data 0.0000 (0.0000)	Loss 4.8070 (5.1288)	
label_Epoch: [2][70/345]	Time 0.625 (0.876)	Data 0.0000 (0.0000)	Loss 4.8348 (5.0710)	
label_Epoch: [2][80/345]	Time 0.609 (0.845)	Data 0.0000 (0.0000)	Loss 4.5142 (5.0188)	
label_Epoch: [2][90/345]	Time 0.609 (0.820)	Data 0.0000 (0.0000)	Loss 4.5863 (4.9875)	
label_Epoch: [2][100/345]	Time 0.609 (0.800)	Data 0.0000 (0.0000)	Loss 4.8531 (4.9728)	
label_Epoch: [2][110/345]	Time 0.609 (0.784)	Data 0.0000 (0.0000)	Loss 4.6263 (4.9438)	
label_Epoch: [2][120/345]	Time 0.609 (0.771)	Data 0.0000 (0.0000)	Loss 5.4818 (4.9062)	
label_Epoch: [2][130/345]	Time 0.625 (0.759)	Data 0.0000 (0.0000)	Loss 4.6788 (4.8771)	
label_Epoch: [2][140/345]	Time 0.640 (0.749)	Data 0.0000 (0.0000)	Loss 4.5439 (4.8469)	
label_Epoch: [2][150/345]	Time 0.626 (0.741)	Data 0.0000 (0.0000)	Loss 3.6601 (4.7898)	
label_Epoch: [2][160/345]	Time 0.640 (0.734)	Data 0.0000 (0.0000)	Loss 4.4222 (4.7753)	
label_Epoch: [2][170/345]	Time 0.625 (0.727)	Data 0.0000 (0.0000)	Loss 3.9991 (4.7543)	
label_Epoch: [2][180/345]	Time 0.609 (0.721)	Data 0.0000 (0.0000)	Loss 4.9603 (4.7331)	
label_Epoch: [2][190/345]	Time 0.609 (0.716)	Data 0.0000 (0.0000)	Loss 4.6874 (4.6992)	
label_Epoch: [2][200/345]	Time 0.625 (0.711)	Data 0.0000 (0.0000)	Loss 4.3192 (4.6744)	
label_Epoch: [2][210/345]	Time 0.625 (0.707)	Data 0.0000 (0.0000)	Loss 3.9066 (4.6314)	
label_Epoch: [2][220/345]	Time 0.594 (0.703)	Data 0.0000 (0.0000)	Loss 3.4485 (4.5939)	
label_Epoch: [2][230/345]	Time 0.609 (0.699)	Data 0.0000 (0.0000)	Loss 4.2288 (4.5710)	
label_Epoch: [2][240/345]	Time 0.641 (0.696)	Data 0.0000 (0.0000)	Loss 2.7824 (4.5455)	
label_Epoch: [2][250/345]	Time 0.640 (0.694)	Data 0.0000 (0.0000)	Loss 3.5987 (4.5113)	
label_Epoch: [2][260/345]	Time 0.609 (0.691)	Data 0.0000 (0.0000)	Loss 3.0636 (4.4890)	
label_Epoch: [2][270/345]	Time 0.627 (0.688)	Data 0.0000 (0.0000)	Loss 2.9309 (4.4577)	
label_Epoch: [2][280/345]	Time 0.609 (0.686)	Data 0.0000 (0.0000)	Loss 3.1382 (4.4245)	
label_Epoch: [2][290/345]	Time 0.625 (0.684)	Data 0.0000 (0.0000)	Loss 3.8481 (4.3931)	
label_Epoch: [2][300/345]	Time 0.610 (0.682)	Data 0.0000 (0.0000)	Loss 2.9466 (4.3630)	
label_Epoch: [2][310/345]	Time 0.625 (0.680)	Data 0.0000 (0.0000)	Loss 2.3032 (4.3200)	
label_Epoch: [2][320/345]	Time 0.612 (0.678)	Data 0.0000 (0.0000)	Loss 2.0991 (4.2718)	
label_Epoch: [2][330/345]	Time 0.609 (0.676)	Data 0.0000 (0.0000)	Loss 2.8584 (4.2253)	
label_Epoch: [2][340/345]	Time 0.640 (0.675)	Data 0.0000 (0.0000)	Loss 1.8916 (4.1731)	
2
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [3][10/345]	Time 0.625 (2.378)	Data 0.0000 (0.0000)	Loss 5.5896 (5.6121)	
label_Epoch: [3][20/345]	Time 0.594 (1.498)	Data 0.0000 (0.0000)	Loss 4.6113 (5.3048)	
label_Epoch: [3][30/345]	Time 0.609 (1.207)	Data 0.0000 (0.0000)	Loss 4.9764 (5.2686)	
label_Epoch: [3][40/345]	Time 0.625 (1.060)	Data 0.0000 (0.0000)	Loss 4.0265 (5.1007)	
label_Epoch: [3][50/345]	Time 0.640 (0.971)	Data 0.0000 (0.0000)	Loss 4.3922 (4.9527)	
label_Epoch: [3][60/345]	Time 0.625 (0.913)	Data 0.0000 (0.0000)	Loss 4.4541 (4.8555)	
label_Epoch: [3][70/345]	Time 0.594 (0.871)	Data 0.0000 (0.0000)	Loss 4.6993 (4.8384)	
label_Epoch: [3][80/345]	Time 0.625 (0.840)	Data 0.0000 (0.0000)	Loss 3.7378 (4.7984)	
label_Epoch: [3][90/345]	Time 0.640 (0.815)	Data 0.0000 (0.0000)	Loss 3.6053 (4.7264)	
label_Epoch: [3][100/345]	Time 0.609 (0.797)	Data 0.0000 (0.0000)	Loss 4.1540 (4.6727)	
label_Epoch: [3][110/345]	Time 0.625 (0.780)	Data 0.0000 (0.0000)	Loss 5.0599 (4.6547)	
label_Epoch: [3][120/345]	Time 0.625 (0.767)	Data 0.0000 (0.0000)	Loss 3.6751 (4.6045)	
label_Epoch: [3][130/345]	Time 0.609 (0.756)	Data 0.0000 (0.0000)	Loss 5.1136 (4.5768)	
label_Epoch: [3][140/345]	Time 0.625 (0.746)	Data 0.0000 (0.0000)	Loss 4.4497 (4.5452)	
label_Epoch: [3][150/345]	Time 0.625 (0.738)	Data 0.0000 (0.0000)	Loss 4.3499 (4.5362)	
label_Epoch: [3][160/345]	Time 0.626 (0.730)	Data 0.0000 (0.0000)	Loss 4.2797 (4.5134)	
label_Epoch: [3][170/345]	Time 0.625 (0.724)	Data 0.0000 (0.0000)	Loss 5.3844 (4.5129)	
label_Epoch: [3][180/345]	Time 0.625 (0.718)	Data 0.0000 (0.0000)	Loss 3.8228 (4.4921)	
label_Epoch: [3][190/345]	Time 0.640 (0.713)	Data 0.0000 (0.0000)	Loss 4.0167 (4.4819)	
label_Epoch: [3][200/345]	Time 0.609 (0.709)	Data 0.0000 (0.0000)	Loss 3.2238 (4.4501)	
label_Epoch: [3][210/345]	Time 0.625 (0.705)	Data 0.0000 (0.0000)	Loss 3.5479 (4.4350)	
label_Epoch: [3][220/345]	Time 0.641 (0.701)	Data 0.0000 (0.0000)	Loss 5.1760 (4.4235)	
label_Epoch: [3][230/345]	Time 0.640 (0.697)	Data 0.0000 (0.0000)	Loss 3.7357 (4.3975)	
label_Epoch: [3][240/345]	Time 0.625 (0.694)	Data 0.0000 (0.0000)	Loss 3.4239 (4.3673)	
label_Epoch: [3][250/345]	Time 0.610 (0.691)	Data 0.0000 (0.0000)	Loss 4.2768 (4.3356)	
label_Epoch: [3][260/345]	Time 0.609 (0.689)	Data 0.0000 (0.0000)	Loss 3.2359 (4.3036)	
label_Epoch: [3][270/345]	Time 0.625 (0.687)	Data 0.0000 (0.0000)	Loss 3.6800 (4.2644)	
label_Epoch: [3][280/345]	Time 0.611 (0.684)	Data 0.0000 (0.0000)	Loss 3.5070 (4.2462)	
label_Epoch: [3][290/345]	Time 0.625 (0.682)	Data 0.0000 (0.0000)	Loss 3.5816 (4.2284)	
label_Epoch: [3][300/345]	Time 0.610 (0.680)	Data 0.0000 (0.0000)	Loss 3.2706 (4.1962)	
label_Epoch: [3][310/345]	Time 0.625 (0.678)	Data 0.0000 (0.0000)	Loss 3.2228 (4.1602)	
label_Epoch: [3][320/345]	Time 0.625 (0.677)	Data 0.0000 (0.0000)	Loss 3.2886 (4.1198)	
label_Epoch: [3][330/345]	Time 0.625 (0.675)	Data 0.0000 (0.0000)	Loss 2.8136 (4.0746)	
label_Epoch: [3][340/345]	Time 0.625 (0.673)	Data 0.0000 (0.0000)	Loss 4.0132 (4.0434)	
3
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [4][10/345]	Time 0.609 (2.367)	Data 0.0000 (0.0000)	Loss 4.0754 (5.1900)	
label_Epoch: [4][20/345]	Time 0.609 (1.492)	Data 0.0000 (0.0000)	Loss 5.2996 (5.1242)	
label_Epoch: [4][30/345]	Time 0.609 (1.200)	Data 0.0000 (0.0000)	Loss 4.6319 (4.9678)	
label_Epoch: [4][40/345]	Time 0.625 (1.054)	Data 0.0000 (0.0000)	Loss 5.2018 (4.8764)	
label_Epoch: [4][50/345]	Time 0.611 (0.968)	Data 0.0000 (0.0000)	Loss 4.4420 (4.8411)	
label_Epoch: [4][60/345]	Time 0.609 (0.909)	Data 0.0000 (0.0000)	Loss 5.2953 (4.7639)	
label_Epoch: [4][70/345]	Time 0.641 (0.868)	Data 0.0000 (0.0000)	Loss 3.7657 (4.7229)	
label_Epoch: [4][80/345]	Time 0.609 (0.837)	Data 0.0000 (0.0000)	Loss 3.8309 (4.6617)	
label_Epoch: [4][90/345]	Time 0.609 (0.813)	Data 0.0000 (0.0000)	Loss 4.8499 (4.6196)	
label_Epoch: [4][100/345]	Time 0.609 (0.793)	Data 0.0000 (0.0000)	Loss 4.1847 (4.6015)	
label_Epoch: [4][110/345]	Time 0.640 (0.778)	Data 0.0000 (0.0000)	Loss 5.0481 (4.5998)	
label_Epoch: [4][120/345]	Time 0.634 (0.765)	Data 0.0000 (0.0000)	Loss 5.3860 (4.6248)	
label_Epoch: [4][130/345]	Time 0.612 (0.754)	Data 0.0000 (0.0000)	Loss 4.4759 (4.6049)	
label_Epoch: [4][140/345]	Time 0.615 (0.744)	Data 0.0000 (0.0000)	Loss 5.0385 (4.5587)	
label_Epoch: [4][150/345]	Time 0.616 (0.736)	Data 0.0000 (0.0000)	Loss 3.6242 (4.5379)	
label_Epoch: [4][160/345]	Time 0.615 (0.728)	Data 0.0000 (0.0000)	Loss 3.7880 (4.5028)	
label_Epoch: [4][170/345]	Time 0.605 (0.721)	Data 0.0000 (0.0000)	Loss 4.3671 (4.4724)	
label_Epoch: [4][180/345]	Time 0.626 (0.716)	Data 0.0000 (0.0000)	Loss 4.7865 (4.4423)	
label_Epoch: [4][190/345]	Time 0.627 (0.711)	Data 0.0000 (0.0000)	Loss 4.0508 (4.4131)	
label_Epoch: [4][200/345]	Time 0.608 (0.706)	Data 0.0000 (0.0000)	Loss 4.0725 (4.3836)	
label_Epoch: [4][210/345]	Time 0.623 (0.702)	Data 0.0000 (0.0000)	Loss 4.4503 (4.3647)	
label_Epoch: [4][220/345]	Time 0.643 (0.698)	Data 0.0000 (0.0000)	Loss 2.6393 (4.3326)	
label_Epoch: [4][230/345]	Time 0.605 (0.694)	Data 0.0000 (0.0000)	Loss 3.0995 (4.3039)	
label_Epoch: [4][240/345]	Time 0.604 (0.691)	Data 0.0000 (0.0000)	Loss 3.5998 (4.2887)	
label_Epoch: [4][250/345]	Time 0.618 (0.688)	Data 0.0000 (0.0000)	Loss 2.5095 (4.2596)	
label_Epoch: [4][260/345]	Time 0.612 (0.685)	Data 0.0000 (0.0000)	Loss 3.2355 (4.2339)	
label_Epoch: [4][270/345]	Time 0.620 (0.683)	Data 0.0000 (0.0000)	Loss 2.5804 (4.1993)	
label_Epoch: [4][280/345]	Time 0.601 (0.681)	Data 0.0000 (0.0000)	Loss 3.2376 (4.1634)	
label_Epoch: [4][290/345]	Time 0.605 (0.678)	Data 0.0000 (0.0000)	Loss 2.8281 (4.1301)	
label_Epoch: [4][300/345]	Time 0.623 (0.676)	Data 0.0000 (0.0000)	Loss 3.0150 (4.0979)	
label_Epoch: [4][310/345]	Time 0.645 (0.675)	Data 0.0000 (0.0000)	Loss 3.1855 (4.0643)	
label_Epoch: [4][320/345]	Time 0.623 (0.673)	Data 0.0000 (0.0000)	Loss 2.3882 (4.0284)	
label_Epoch: [4][330/345]	Time 0.625 (0.671)	Data 0.0000 (0.0000)	Loss 2.0562 (3.9858)	
label_Epoch: [4][340/345]	Time 0.636 (0.669)	Data 0.0000 (0.0000)	Loss 1.8657 (3.9470)	
4
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [5][10/345]	Time 0.610 (2.499)	Data 0.0000 (0.0000)	Loss 5.1306 (5.3759)	
label_Epoch: [5][20/345]	Time 0.612 (1.558)	Data 0.0000 (0.0000)	Loss 5.1798 (4.9504)	
label_Epoch: [5][30/345]	Time 0.597 (1.244)	Data 0.0000 (0.0000)	Loss 4.6990 (4.8162)	
label_Epoch: [5][40/345]	Time 0.625 (1.087)	Data 0.0000 (0.0000)	Loss 4.2864 (4.7376)	
label_Epoch: [5][50/345]	Time 0.611 (0.993)	Data 0.0000 (0.0000)	Loss 3.6978 (4.6526)	
label_Epoch: [5][60/345]	Time 0.637 (0.931)	Data 0.0000 (0.0000)	Loss 4.0728 (4.5085)	
label_Epoch: [5][70/345]	Time 0.604 (0.886)	Data 0.0000 (0.0000)	Loss 3.9295 (4.4683)	
label_Epoch: [5][80/345]	Time 0.610 (0.853)	Data 0.0000 (0.0000)	Loss 2.7449 (4.4182)	
label_Epoch: [5][90/345]	Time 0.637 (0.827)	Data 0.0000 (0.0000)	Loss 4.6022 (4.3639)	
label_Epoch: [5][100/345]	Time 0.638 (0.806)	Data 0.0000 (0.0000)	Loss 4.2773 (4.3271)	
label_Epoch: [5][110/345]	Time 0.615 (0.789)	Data 0.0000 (0.0000)	Loss 4.0378 (4.2891)	
label_Epoch: [5][120/345]	Time 0.627 (0.775)	Data 0.0000 (0.0000)	Loss 4.1206 (4.2795)	
label_Epoch: [5][130/345]	Time 0.608 (0.763)	Data 0.0000 (0.0000)	Loss 3.0699 (4.2341)	
label_Epoch: [5][140/345]	Time 0.605 (0.752)	Data 0.0000 (0.0000)	Loss 3.5471 (4.2023)	
label_Epoch: [5][150/345]	Time 0.619 (0.743)	Data 0.0000 (0.0000)	Loss 3.7040 (4.1750)	
label_Epoch: [5][160/345]	Time 0.627 (0.735)	Data 0.0000 (0.0000)	Loss 3.3809 (4.1475)	
label_Epoch: [5][170/345]	Time 0.626 (0.728)	Data 0.0000 (0.0000)	Loss 3.3745 (4.1237)	
label_Epoch: [5][180/345]	Time 0.610 (0.722)	Data 0.0000 (0.0000)	Loss 4.1002 (4.0763)	
label_Epoch: [5][190/345]	Time 0.612 (0.717)	Data 0.0000 (0.0000)	Loss 4.1309 (4.0638)	
label_Epoch: [5][200/345]	Time 0.611 (0.712)	Data 0.0000 (0.0000)	Loss 4.3674 (4.0410)	
label_Epoch: [5][210/345]	Time 0.632 (0.707)	Data 0.0000 (0.0000)	Loss 3.5076 (4.0195)	
label_Epoch: [5][220/345]	Time 0.630 (0.703)	Data 0.0000 (0.0000)	Loss 5.4527 (3.9964)	
label_Epoch: [5][230/345]	Time 0.611 (0.700)	Data 0.0000 (0.0000)	Loss 4.3371 (3.9806)	
label_Epoch: [5][240/345]	Time 0.609 (0.696)	Data 0.0000 (0.0000)	Loss 3.5107 (3.9510)	
label_Epoch: [5][250/345]	Time 0.607 (0.693)	Data 0.0000 (0.0000)	Loss 4.2347 (3.9194)	
label_Epoch: [5][260/345]	Time 0.623 (0.690)	Data 0.0000 (0.0000)	Loss 3.0189 (3.8978)	
label_Epoch: [5][270/345]	Time 0.625 (0.688)	Data 0.0000 (0.0000)	Loss 2.8846 (3.8611)	
label_Epoch: [5][280/345]	Time 0.618 (0.685)	Data 0.0000 (0.0000)	Loss 2.6058 (3.8237)	
label_Epoch: [5][290/345]	Time 0.623 (0.682)	Data 0.0000 (0.0000)	Loss 2.9842 (3.8001)	
label_Epoch: [5][300/345]	Time 0.605 (0.680)	Data 0.0000 (0.0000)	Loss 2.8900 (3.7725)	
label_Epoch: [5][310/345]	Time 0.618 (0.679)	Data 0.0000 (0.0000)	Loss 2.3270 (3.7333)	
label_Epoch: [5][320/345]	Time 0.617 (0.677)	Data 0.0000 (0.0000)	Loss 2.4317 (3.6920)	
label_Epoch: [5][330/345]	Time 0.609 (0.675)	Data 0.0000 (0.0000)	Loss 1.8651 (3.6472)	
label_Epoch: [5][340/345]	Time 0.614 (0.673)	Data 0.0000 (0.0000)	Loss 2.1711 (3.6026)	
5
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [6][10/345]	Time 0.620 (2.458)	Data 0.0000 (0.0000)	Loss 4.0891 (4.3467)	
label_Epoch: [6][20/345]	Time 0.620 (1.538)	Data 0.0000 (0.0000)	Loss 4.9968 (4.3723)	
label_Epoch: [6][30/345]	Time 0.617 (1.232)	Data 0.0000 (0.0000)	Loss 5.2740 (4.4247)	
label_Epoch: [6][40/345]	Time 0.634 (1.079)	Data 0.0000 (0.0000)	Loss 3.2506 (4.3051)	
label_Epoch: [6][50/345]	Time 0.634 (0.987)	Data 0.0000 (0.0000)	Loss 3.5107 (4.3399)	
label_Epoch: [6][60/345]	Time 0.639 (0.925)	Data 0.0000 (0.0000)	Loss 4.0927 (4.2645)	
label_Epoch: [6][70/345]	Time 0.653 (0.882)	Data 0.0000 (0.0000)	Loss 3.3646 (4.2102)	
label_Epoch: [6][80/345]	Time 0.643 (0.849)	Data 0.0000 (0.0000)	Loss 3.3942 (4.1666)	
label_Epoch: [6][90/345]	Time 0.612 (0.823)	Data 0.0000 (0.0000)	Loss 3.9208 (4.1200)	
label_Epoch: [6][100/345]	Time 0.610 (0.803)	Data 0.0000 (0.0000)	Loss 4.5155 (4.1138)	
label_Epoch: [6][110/345]	Time 0.623 (0.786)	Data 0.0000 (0.0000)	Loss 2.1095 (4.0484)	
label_Epoch: [6][120/345]	Time 0.612 (0.772)	Data 0.0000 (0.0000)	Loss 4.6722 (4.0216)	
label_Epoch: [6][130/345]	Time 0.613 (0.760)	Data 0.0000 (0.0000)	Loss 2.9712 (4.0137)	
label_Epoch: [6][140/345]	Time 0.626 (0.749)	Data 0.0000 (0.0000)	Loss 4.4916 (3.9930)	
label_Epoch: [6][150/345]	Time 0.622 (0.741)	Data 0.0000 (0.0000)	Loss 3.8584 (3.9815)	
label_Epoch: [6][160/345]	Time 0.614 (0.733)	Data 0.0000 (0.0000)	Loss 4.3785 (3.9401)	
label_Epoch: [6][170/345]	Time 0.633 (0.726)	Data 0.0000 (0.0000)	Loss 2.9799 (3.8974)	
label_Epoch: [6][180/345]	Time 0.615 (0.720)	Data 0.0000 (0.0000)	Loss 2.7833 (3.8548)	
label_Epoch: [6][190/345]	Time 0.634 (0.714)	Data 0.0000 (0.0000)	Loss 3.7713 (3.8504)	
label_Epoch: [6][200/345]	Time 0.613 (0.709)	Data 0.0000 (0.0000)	Loss 3.4611 (3.8297)	
label_Epoch: [6][210/345]	Time 0.630 (0.705)	Data 0.0000 (0.0000)	Loss 3.2801 (3.8091)	
label_Epoch: [6][220/345]	Time 0.636 (0.701)	Data 0.0000 (0.0000)	Loss 2.4924 (3.7730)	
label_Epoch: [6][230/345]	Time 0.621 (0.698)	Data 0.0000 (0.0000)	Loss 4.0333 (3.7543)	
label_Epoch: [6][240/345]	Time 0.618 (0.694)	Data 0.0000 (0.0000)	Loss 3.4903 (3.7176)	
label_Epoch: [6][250/345]	Time 0.618 (0.691)	Data 0.0000 (0.0000)	Loss 3.4252 (3.6868)	
label_Epoch: [6][260/345]	Time 0.649 (0.688)	Data 0.0000 (0.0000)	Loss 3.1157 (3.6690)	
label_Epoch: [6][270/345]	Time 0.615 (0.686)	Data 0.0000 (0.0000)	Loss 3.4872 (3.6387)	
label_Epoch: [6][280/345]	Time 0.626 (0.683)	Data 0.0000 (0.0000)	Loss 1.9607 (3.6101)	
label_Epoch: [6][290/345]	Time 0.611 (0.681)	Data 0.0000 (0.0000)	Loss 2.3857 (3.5760)	
label_Epoch: [6][300/345]	Time 0.626 (0.679)	Data 0.0000 (0.0000)	Loss 2.2565 (3.5465)	
label_Epoch: [6][310/345]	Time 0.605 (0.677)	Data 0.0000 (0.0000)	Loss 2.1729 (3.5154)	
label_Epoch: [6][320/345]	Time 0.617 (0.675)	Data 0.0000 (0.0000)	Loss 1.8958 (3.4797)	
label_Epoch: [6][330/345]	Time 0.620 (0.673)	Data 0.0000 (0.0000)	Loss 2.9413 (3.4457)	
label_Epoch: [6][340/345]	Time 0.607 (0.671)	Data 0.0000 (0.0000)	Loss 1.6611 (3.4064)	
6
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [7][10/345]	Time 0.607 (2.462)	Data 0.0000 (0.0000)	Loss 4.9904 (4.4976)	
label_Epoch: [7][20/345]	Time 0.619 (1.541)	Data 0.0000 (0.0000)	Loss 4.7576 (4.4314)	
label_Epoch: [7][30/345]	Time 0.619 (1.233)	Data 0.0000 (0.0000)	Loss 5.2151 (4.4202)	
label_Epoch: [7][40/345]	Time 0.627 (1.079)	Data 0.0000 (0.0000)	Loss 3.6101 (4.2708)	
label_Epoch: [7][50/345]	Time 0.617 (0.986)	Data 0.0000 (0.0000)	Loss 4.4799 (4.2523)	
label_Epoch: [7][60/345]	Time 0.628 (0.925)	Data 0.0000 (0.0000)	Loss 3.9352 (4.1996)	
label_Epoch: [7][70/345]	Time 0.613 (0.881)	Data 0.0000 (0.0000)	Loss 3.7920 (4.2160)	
label_Epoch: [7][80/345]	Time 0.626 (0.848)	Data 0.0000 (0.0000)	Loss 3.2106 (4.1564)	
label_Epoch: [7][90/345]	Time 0.620 (0.823)	Data 0.0000 (0.0000)	Loss 4.1243 (4.1043)	
label_Epoch: [7][100/345]	Time 0.613 (0.803)	Data 0.0000 (0.0000)	Loss 3.1996 (4.0813)	
label_Epoch: [7][110/345]	Time 0.609 (0.786)	Data 0.0000 (0.0000)	Loss 2.8960 (4.0068)	
label_Epoch: [7][120/345]	Time 0.607 (0.771)	Data 0.0000 (0.0000)	Loss 3.5153 (3.9493)	
label_Epoch: [7][130/345]	Time 0.603 (0.759)	Data 0.0000 (0.0000)	Loss 3.8683 (3.9170)	
label_Epoch: [7][140/345]	Time 0.645 (0.750)	Data 0.0000 (0.0000)	Loss 3.0039 (3.8720)	
label_Epoch: [7][150/345]	Time 0.629 (0.741)	Data 0.0000 (0.0000)	Loss 2.8856 (3.8252)	
label_Epoch: [7][160/345]	Time 0.630 (0.733)	Data 0.0000 (0.0000)	Loss 3.9433 (3.7983)	
label_Epoch: [7][170/345]	Time 0.608 (0.726)	Data 0.0000 (0.0000)	Loss 2.7607 (3.7560)	
label_Epoch: [7][180/345]	Time 0.618 (0.720)	Data 0.0000 (0.0000)	Loss 2.3944 (3.7278)	
label_Epoch: [7][190/345]	Time 0.611 (0.715)	Data 0.0000 (0.0000)	Loss 3.5322 (3.7096)	
label_Epoch: [7][200/345]	Time 0.619 (0.710)	Data 0.0000 (0.0000)	Loss 2.2637 (3.6763)	
label_Epoch: [7][210/345]	Time 0.617 (0.705)	Data 0.0000 (0.0000)	Loss 3.4276 (3.6564)	
label_Epoch: [7][220/345]	Time 0.613 (0.701)	Data 0.0000 (0.0000)	Loss 3.3145 (3.6386)	
label_Epoch: [7][230/345]	Time 0.632 (0.698)	Data 0.0000 (0.0000)	Loss 2.2416 (3.6142)	
label_Epoch: [7][240/345]	Time 0.645 (0.694)	Data 0.0000 (0.0000)	Loss 2.7831 (3.5948)	
label_Epoch: [7][250/345]	Time 0.597 (0.691)	Data 0.0000 (0.0000)	Loss 2.4427 (3.5611)	
label_Epoch: [7][260/345]	Time 0.622 (0.688)	Data 0.0000 (0.0000)	Loss 1.9632 (3.5264)	
label_Epoch: [7][270/345]	Time 0.614 (0.685)	Data 0.0000 (0.0000)	Loss 2.8831 (3.5032)	
label_Epoch: [7][280/345]	Time 0.630 (0.683)	Data 0.0000 (0.0000)	Loss 4.1351 (3.4802)	
label_Epoch: [7][290/345]	Time 0.616 (0.681)	Data 0.0000 (0.0000)	Loss 2.3991 (3.4455)	
label_Epoch: [7][300/345]	Time 0.614 (0.679)	Data 0.0000 (0.0000)	Loss 2.6652 (3.4175)	
label_Epoch: [7][310/345]	Time 0.600 (0.676)	Data 0.0000 (0.0000)	Loss 1.8026 (3.3843)	
label_Epoch: [7][320/345]	Time 0.634 (0.675)	Data 0.0000 (0.0000)	Loss 1.6180 (3.3480)	
label_Epoch: [7][330/345]	Time 0.618 (0.673)	Data 0.0000 (0.0000)	Loss 2.2989 (3.3129)	
label_Epoch: [7][340/345]	Time 0.642 (0.671)	Data 0.0000 (0.0000)	Loss 2.1116 (3.2738)	
7
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [8][10/345]	Time 0.615 (2.523)	Data 0.0000 (0.0000)	Loss 4.4791 (4.8754)	
label_Epoch: [8][20/345]	Time 0.606 (1.572)	Data 0.0000 (0.0000)	Loss 5.6054 (4.6265)	
label_Epoch: [8][30/345]	Time 0.623 (1.253)	Data 0.0000 (0.0000)	Loss 3.9283 (4.2669)	
label_Epoch: [8][40/345]	Time 0.614 (1.095)	Data 0.0000 (0.0000)	Loss 3.2528 (4.1917)	
label_Epoch: [8][50/345]	Time 0.634 (1.000)	Data 0.0000 (0.0000)	Loss 3.7260 (4.1194)	
label_Epoch: [8][60/345]	Time 0.621 (0.937)	Data 0.0000 (0.0000)	Loss 3.9351 (4.0606)	
label_Epoch: [8][70/345]	Time 0.616 (0.892)	Data 0.0000 (0.0000)	Loss 3.0634 (4.0235)	
label_Epoch: [8][80/345]	Time 0.605 (0.858)	Data 0.0000 (0.0000)	Loss 3.5331 (3.9952)	
label_Epoch: [8][90/345]	Time 0.623 (0.831)	Data 0.0000 (0.0000)	Loss 4.2588 (3.9603)	
label_Epoch: [8][100/345]	Time 0.613 (0.810)	Data 0.0000 (0.0000)	Loss 2.8643 (3.9595)	
label_Epoch: [8][110/345]	Time 0.644 (0.793)	Data 0.0000 (0.0000)	Loss 3.2071 (3.9123)	
label_Epoch: [8][120/345]	Time 0.616 (0.778)	Data 0.0000 (0.0000)	Loss 3.2981 (3.8427)	
label_Epoch: [8][130/345]	Time 0.604 (0.766)	Data 0.0000 (0.0000)	Loss 3.2169 (3.8408)	
label_Epoch: [8][140/345]	Time 0.613 (0.755)	Data 0.0000 (0.0000)	Loss 3.0433 (3.7872)	
label_Epoch: [8][150/345]	Time 0.646 (0.747)	Data 0.0000 (0.0000)	Loss 3.0244 (3.7789)	
label_Epoch: [8][160/345]	Time 0.628 (0.739)	Data 0.0000 (0.0000)	Loss 4.3435 (3.7554)	
label_Epoch: [8][170/345]	Time 0.618 (0.732)	Data 0.0000 (0.0000)	Loss 2.9840 (3.7234)	
label_Epoch: [8][180/345]	Time 0.621 (0.726)	Data 0.0000 (0.0000)	Loss 2.8741 (3.6882)	
label_Epoch: [8][190/345]	Time 0.607 (0.720)	Data 0.0000 (0.0000)	Loss 2.3530 (3.6435)	
label_Epoch: [8][200/345]	Time 0.610 (0.715)	Data 0.0000 (0.0000)	Loss 3.0546 (3.6059)	
label_Epoch: [8][210/345]	Time 0.598 (0.710)	Data 0.0000 (0.0000)	Loss 2.4953 (3.5788)	
label_Epoch: [8][220/345]	Time 0.612 (0.706)	Data 0.0000 (0.0000)	Loss 3.5401 (3.5505)	
label_Epoch: [8][230/345]	Time 0.618 (0.702)	Data 0.0000 (0.0000)	Loss 3.2419 (3.5247)	
label_Epoch: [8][240/345]	Time 0.619 (0.699)	Data 0.0000 (0.0000)	Loss 2.3117 (3.4948)	
label_Epoch: [8][250/345]	Time 0.601 (0.695)	Data 0.0000 (0.0000)	Loss 3.8987 (3.4724)	
label_Epoch: [8][260/345]	Time 0.616 (0.692)	Data 0.0000 (0.0000)	Loss 3.0099 (3.4531)	
label_Epoch: [8][270/345]	Time 0.630 (0.690)	Data 0.0000 (0.0000)	Loss 2.9626 (3.4283)	
label_Epoch: [8][280/345]	Time 0.609 (0.687)	Data 0.0000 (0.0000)	Loss 2.1689 (3.3906)	
label_Epoch: [8][290/345]	Time 0.627 (0.685)	Data 0.0000 (0.0000)	Loss 2.9248 (3.3687)	
label_Epoch: [8][300/345]	Time 0.606 (0.682)	Data 0.0000 (0.0000)	Loss 2.7614 (3.3328)	
label_Epoch: [8][310/345]	Time 0.601 (0.680)	Data 0.0000 (0.0000)	Loss 2.2548 (3.3049)	
label_Epoch: [8][320/345]	Time 0.631 (0.678)	Data 0.0000 (0.0000)	Loss 2.5602 (3.2758)	
label_Epoch: [8][330/345]	Time 0.619 (0.676)	Data 0.0000 (0.0000)	Loss 3.0511 (3.2512)	
label_Epoch: [8][340/345]	Time 0.633 (0.675)	Data 0.0000 (0.0000)	Loss 2.4224 (3.2142)	
8
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [9][10/345]	Time 0.642 (2.393)	Data 0.0000 (0.0000)	Loss 5.1601 (4.5700)	
label_Epoch: [9][20/345]	Time 0.617 (1.504)	Data 0.0000 (0.0000)	Loss 5.8612 (4.4818)	
label_Epoch: [9][30/345]	Time 0.620 (1.209)	Data 0.0000 (0.0000)	Loss 3.9634 (4.2244)	
label_Epoch: [9][40/345]	Time 0.621 (1.060)	Data 0.0000 (0.0000)	Loss 4.3248 (4.0892)	
label_Epoch: [9][50/345]	Time 0.605 (0.973)	Data 0.0000 (0.0000)	Loss 4.6932 (4.0714)	
label_Epoch: [9][60/345]	Time 0.618 (0.913)	Data 0.0000 (0.0000)	Loss 4.2287 (3.9746)	
label_Epoch: [9][70/345]	Time 0.604 (0.870)	Data 0.0000 (0.0000)	Loss 4.3877 (3.9676)	
label_Epoch: [9][80/345]	Time 0.621 (0.838)	Data 0.0000 (0.0000)	Loss 4.1750 (3.9120)	
label_Epoch: [9][90/345]	Time 0.609 (0.813)	Data 0.0000 (0.0000)	Loss 2.7824 (3.8771)	
label_Epoch: [9][100/345]	Time 0.644 (0.794)	Data 0.0000 (0.0000)	Loss 3.0949 (3.8024)	
label_Epoch: [9][110/345]	Time 0.630 (0.778)	Data 0.0000 (0.0000)	Loss 5.5121 (3.7940)	
label_Epoch: [9][120/345]	Time 0.625 (0.764)	Data 0.0000 (0.0000)	Loss 3.5161 (3.7693)	
label_Epoch: [9][130/345]	Time 0.614 (0.753)	Data 0.0000 (0.0000)	Loss 3.9677 (3.7335)	
label_Epoch: [9][140/345]	Time 0.619 (0.743)	Data 0.0000 (0.0000)	Loss 3.2681 (3.7001)	
label_Epoch: [9][150/345]	Time 0.601 (0.734)	Data 0.0000 (0.0000)	Loss 4.0643 (3.6588)	
label_Epoch: [9][160/345]	Time 0.611 (0.727)	Data 0.0000 (0.0000)	Loss 2.1321 (3.6076)	
label_Epoch: [9][170/345]	Time 0.619 (0.721)	Data 0.0000 (0.0000)	Loss 2.6740 (3.5861)	
label_Epoch: [9][180/345]	Time 0.625 (0.715)	Data 0.0000 (0.0000)	Loss 2.1889 (3.5395)	
label_Epoch: [9][190/345]	Time 0.623 (0.710)	Data 0.0000 (0.0000)	Loss 2.9780 (3.5077)	
label_Epoch: [9][200/345]	Time 0.611 (0.705)	Data 0.0000 (0.0000)	Loss 2.3172 (3.4891)	
label_Epoch: [9][210/345]	Time 0.638 (0.701)	Data 0.0000 (0.0000)	Loss 3.7509 (3.4781)	
label_Epoch: [9][220/345]	Time 0.628 (0.698)	Data 0.0000 (0.0000)	Loss 3.1670 (3.4508)	
label_Epoch: [9][230/345]	Time 0.657 (0.695)	Data 0.0000 (0.0000)	Loss 3.1649 (3.4172)	
label_Epoch: [9][240/345]	Time 0.639 (0.692)	Data 0.0000 (0.0000)	Loss 2.7228 (3.3891)	
label_Epoch: [9][250/345]	Time 0.620 (0.689)	Data 0.0000 (0.0000)	Loss 2.2108 (3.3745)	
label_Epoch: [9][260/345]	Time 0.625 (0.686)	Data 0.0000 (0.0000)	Loss 2.7882 (3.3459)	
label_Epoch: [9][270/345]	Time 0.604 (0.684)	Data 0.0000 (0.0000)	Loss 2.4785 (3.3208)	
label_Epoch: [9][280/345]	Time 0.619 (0.681)	Data 0.0000 (0.0000)	Loss 1.7505 (3.2965)	
label_Epoch: [9][290/345]	Time 0.601 (0.679)	Data 0.0000 (0.0000)	Loss 2.9965 (3.2730)	
label_Epoch: [9][300/345]	Time 0.644 (0.677)	Data 0.0000 (0.0000)	Loss 2.4907 (3.2509)	
label_Epoch: [9][310/345]	Time 0.634 (0.676)	Data 0.0000 (0.0000)	Loss 2.4195 (3.2235)	
label_Epoch: [9][320/345]	Time 0.646 (0.674)	Data 0.0000 (0.0000)	Loss 2.1477 (3.1925)	
label_Epoch: [9][330/345]	Time 0.617 (0.672)	Data 0.0000 (0.0000)	Loss 1.6910 (3.1669)	
label_Epoch: [9][340/345]	Time 0.633 (0.671)	Data 0.0000 (0.0000)	Loss 2.6956 (3.1301)	
9
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [10][10/345]	Time 0.618 (2.502)	Data 0.0000 (0.0000)	Loss 2.6244 (4.6563)	
label_Epoch: [10][20/345]	Time 0.607 (1.556)	Data 0.0000 (0.0000)	Loss 2.4062 (4.2987)	
label_Epoch: [10][30/345]	Time 0.606 (1.244)	Data 0.0000 (0.0000)	Loss 2.8483 (4.0022)	
label_Epoch: [10][40/345]	Time 0.609 (1.089)	Data 0.0000 (0.0000)	Loss 2.7646 (4.0050)	
label_Epoch: [10][50/345]	Time 0.626 (0.995)	Data 0.0000 (0.0000)	Loss 4.4950 (3.9903)	
label_Epoch: [10][60/345]	Time 0.608 (0.932)	Data 0.0000 (0.0000)	Loss 4.0119 (3.9503)	
label_Epoch: [10][70/345]	Time 0.620 (0.888)	Data 0.0000 (0.0000)	Loss 2.6504 (3.9045)	
label_Epoch: [10][80/345]	Time 0.614 (0.855)	Data 0.0000 (0.0000)	Loss 2.5384 (3.8088)	
label_Epoch: [10][90/345]	Time 0.639 (0.829)	Data 0.0000 (0.0000)	Loss 3.7035 (3.7875)	
label_Epoch: [10][100/345]	Time 0.617 (0.808)	Data 0.0000 (0.0000)	Loss 2.6284 (3.7121)	
label_Epoch: [10][110/345]	Time 0.618 (0.791)	Data 0.0000 (0.0000)	Loss 3.0661 (3.6700)	
label_Epoch: [10][120/345]	Time 0.630 (0.778)	Data 0.0000 (0.0000)	Loss 3.2123 (3.6226)	
label_Epoch: [10][130/345]	Time 0.623 (0.765)	Data 0.0000 (0.0000)	Loss 3.4657 (3.5942)	
label_Epoch: [10][140/345]	Time 0.613 (0.755)	Data 0.0000 (0.0000)	Loss 2.8808 (3.5648)	
label_Epoch: [10][150/345]	Time 0.625 (0.746)	Data 0.0000 (0.0000)	Loss 3.6475 (3.5286)	
label_Epoch: [10][160/345]	Time 0.622 (0.739)	Data 0.0000 (0.0000)	Loss 3.4151 (3.4904)	
label_Epoch: [10][170/345]	Time 0.613 (0.731)	Data 0.0000 (0.0000)	Loss 2.3347 (3.4555)	
label_Epoch: [10][180/345]	Time 0.612 (0.724)	Data 0.0000 (0.0000)	Loss 1.9609 (3.4357)	
label_Epoch: [10][190/345]	Time 0.652 (0.719)	Data 0.0000 (0.0000)	Loss 1.8558 (3.4006)	
label_Epoch: [10][200/345]	Time 0.627 (0.713)	Data 0.0000 (0.0000)	Loss 1.9652 (3.3601)	
label_Epoch: [10][210/345]	Time 0.601 (0.709)	Data 0.0000 (0.0000)	Loss 3.3405 (3.3560)	
label_Epoch: [10][220/345]	Time 0.619 (0.704)	Data 0.0000 (0.0000)	Loss 1.8226 (3.3317)	
label_Epoch: [10][230/345]	Time 0.609 (0.700)	Data 0.0000 (0.0000)	Loss 2.8854 (3.3029)	
label_Epoch: [10][240/345]	Time 0.616 (0.697)	Data 0.0000 (0.0000)	Loss 2.1857 (3.2761)	
label_Epoch: [10][250/345]	Time 0.636 (0.694)	Data 0.0000 (0.0000)	Loss 2.6209 (3.2563)	
label_Epoch: [10][260/345]	Time 0.610 (0.691)	Data 0.0000 (0.0000)	Loss 1.6677 (3.2441)	
label_Epoch: [10][270/345]	Time 0.617 (0.688)	Data 0.0000 (0.0000)	Loss 1.3980 (3.2273)	
label_Epoch: [10][280/345]	Time 0.611 (0.686)	Data 0.0000 (0.0000)	Loss 2.4047 (3.2100)	
label_Epoch: [10][290/345]	Time 0.621 (0.684)	Data 0.0000 (0.0000)	Loss 2.5568 (3.1874)	
label_Epoch: [10][300/345]	Time 0.607 (0.682)	Data 0.0000 (0.0000)	Loss 2.1845 (3.1574)	
label_Epoch: [10][310/345]	Time 0.645 (0.680)	Data 0.0000 (0.0000)	Loss 2.2069 (3.1300)	
label_Epoch: [10][320/345]	Time 0.603 (0.678)	Data 0.0000 (0.0000)	Loss 1.8848 (3.0957)	
label_Epoch: [10][330/345]	Time 0.609 (0.676)	Data 0.0000 (0.0000)	Loss 1.5415 (3.0608)	
label_Epoch: [10][340/345]	Time 0.598 (0.674)	Data 0.0000 (0.0000)	Loss 1.8489 (3.0358)	
10
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [11][10/345]	Time 0.630 (2.575)	Data 0.0000 (0.0000)	Loss 4.4381 (3.9005)	
label_Epoch: [11][20/345]	Time 0.612 (1.596)	Data 0.0000 (0.0000)	Loss 3.6939 (3.9212)	
label_Epoch: [11][30/345]	Time 0.609 (1.268)	Data 0.0000 (0.0000)	Loss 4.5047 (3.8767)	
label_Epoch: [11][40/345]	Time 0.598 (1.104)	Data 0.0000 (0.0000)	Loss 3.9991 (3.9322)	
label_Epoch: [11][50/345]	Time 0.608 (1.006)	Data 0.0000 (0.0000)	Loss 3.6678 (3.8586)	
label_Epoch: [11][60/345]	Time 0.624 (0.941)	Data 0.0000 (0.0000)	Loss 2.3308 (3.7615)	
label_Epoch: [11][70/345]	Time 0.616 (0.895)	Data 0.0000 (0.0000)	Loss 2.6049 (3.7533)	
label_Epoch: [11][80/345]	Time 0.617 (0.860)	Data 0.0000 (0.0000)	Loss 2.8038 (3.6730)	
label_Epoch: [11][90/345]	Time 0.614 (0.833)	Data 0.0000 (0.0000)	Loss 3.0452 (3.6050)	
label_Epoch: [11][100/345]	Time 0.614 (0.811)	Data 0.0000 (0.0000)	Loss 3.2280 (3.5575)	
label_Epoch: [11][110/345]	Time 0.625 (0.793)	Data 0.0000 (0.0000)	Loss 3.7149 (3.5335)	
label_Epoch: [11][120/345]	Time 0.602 (0.778)	Data 0.0000 (0.0000)	Loss 3.0996 (3.5250)	
label_Epoch: [11][130/345]	Time 0.607 (0.765)	Data 0.0000 (0.0000)	Loss 3.4234 (3.5126)	
label_Epoch: [11][140/345]	Time 0.611 (0.755)	Data 0.0000 (0.0000)	Loss 3.0992 (3.4695)	
label_Epoch: [11][150/345]	Time 0.603 (0.745)	Data 0.0000 (0.0000)	Loss 2.7038 (3.4437)	
label_Epoch: [11][160/345]	Time 0.618 (0.737)	Data 0.0000 (0.0000)	Loss 3.5043 (3.4148)	
label_Epoch: [11][170/345]	Time 0.635 (0.730)	Data 0.0000 (0.0000)	Loss 2.6910 (3.3962)	
label_Epoch: [11][180/345]	Time 0.616 (0.724)	Data 0.0000 (0.0000)	Loss 2.6527 (3.3896)	
label_Epoch: [11][190/345]	Time 0.620 (0.718)	Data 0.0000 (0.0000)	Loss 2.2417 (3.3728)	
label_Epoch: [11][200/345]	Time 0.609 (0.713)	Data 0.0000 (0.0000)	Loss 2.8091 (3.3495)	
label_Epoch: [11][210/345]	Time 0.615 (0.708)	Data 0.0000 (0.0000)	Loss 2.5106 (3.3213)	
label_Epoch: [11][220/345]	Time 0.632 (0.704)	Data 0.0000 (0.0000)	Loss 2.5211 (3.2900)	
label_Epoch: [11][230/345]	Time 0.612 (0.700)	Data 0.0000 (0.0000)	Loss 3.2759 (3.2577)	
label_Epoch: [11][240/345]	Time 0.610 (0.697)	Data 0.0000 (0.0000)	Loss 2.9223 (3.2245)	
label_Epoch: [11][250/345]	Time 0.630 (0.693)	Data 0.0000 (0.0000)	Loss 2.3728 (3.1962)	
label_Epoch: [11][260/345]	Time 0.613 (0.691)	Data 0.0000 (0.0000)	Loss 2.5323 (3.1703)	
label_Epoch: [11][270/345]	Time 0.647 (0.688)	Data 0.0000 (0.0000)	Loss 2.6696 (3.1511)	
label_Epoch: [11][280/345]	Time 0.617 (0.686)	Data 0.0000 (0.0000)	Loss 3.1735 (3.1307)	
label_Epoch: [11][290/345]	Time 0.613 (0.683)	Data 0.0000 (0.0000)	Loss 3.3164 (3.1072)	
label_Epoch: [11][300/345]	Time 0.630 (0.681)	Data 0.0000 (0.0000)	Loss 2.3256 (3.0882)	
label_Epoch: [11][310/345]	Time 0.610 (0.679)	Data 0.0000 (0.0000)	Loss 1.8593 (3.0537)	
label_Epoch: [11][320/345]	Time 0.621 (0.677)	Data 0.0000 (0.0000)	Loss 2.1417 (3.0196)	
label_Epoch: [11][330/345]	Time 0.628 (0.676)	Data 0.0000 (0.0000)	Loss 2.0685 (2.9845)	
label_Epoch: [11][340/345]	Time 0.638 (0.674)	Data 0.0000 (0.0000)	Loss 1.5724 (2.9463)	
11
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [12][10/345]	Time 0.639 (2.470)	Data 0.0000 (0.0000)	Loss 3.3466 (4.1117)	
label_Epoch: [12][20/345]	Time 0.642 (1.557)	Data 0.0000 (0.0000)	Loss 3.6697 (3.9887)	
label_Epoch: [12][30/345]	Time 0.622 (1.251)	Data 0.0000 (0.0000)	Loss 2.9767 (3.8649)	
label_Epoch: [12][40/345]	Time 0.661 (1.099)	Data 0.0000 (0.0000)	Loss 3.6237 (3.7504)	
label_Epoch: [12][50/345]	Time 0.656 (1.009)	Data 0.0000 (0.0000)	Loss 3.6153 (3.6810)	
label_Epoch: [12][60/345]	Time 0.643 (0.947)	Data 0.0000 (0.0000)	Loss 3.5747 (3.6643)	
label_Epoch: [12][70/345]	Time 0.612 (0.901)	Data 0.0000 (0.0000)	Loss 2.3440 (3.5956)	
label_Epoch: [12][80/345]	Time 0.636 (0.868)	Data 0.0000 (0.0000)	Loss 3.9389 (3.5956)	
label_Epoch: [12][90/345]	Time 0.659 (0.843)	Data 0.0000 (0.0000)	Loss 3.9161 (3.5483)	
label_Epoch: [12][100/345]	Time 0.655 (0.822)	Data 0.0000 (0.0000)	Loss 3.4681 (3.5099)	
label_Epoch: [12][110/345]	Time 0.641 (0.806)	Data 0.0000 (0.0000)	Loss 2.8514 (3.4809)	
label_Epoch: [12][120/345]	Time 0.625 (0.792)	Data 0.0000 (0.0000)	Loss 3.5202 (3.4400)	
label_Epoch: [12][130/345]	Time 0.661 (0.781)	Data 0.0000 (0.0000)	Loss 2.0507 (3.4078)	
label_Epoch: [12][140/345]	Time 0.644 (0.772)	Data 0.0000 (0.0000)	Loss 3.1251 (3.4043)	
label_Epoch: [12][150/345]	Time 0.631 (0.763)	Data 0.0000 (0.0000)	Loss 1.9765 (3.3783)	
label_Epoch: [12][160/345]	Time 0.597 (0.755)	Data 0.0000 (0.0000)	Loss 2.9476 (3.3589)	
label_Epoch: [12][170/345]	Time 0.623 (0.747)	Data 0.0000 (0.0000)	Loss 2.4101 (3.3145)	
label_Epoch: [12][180/345]	Time 0.626 (0.741)	Data 0.0000 (0.0000)	Loss 2.8179 (3.2737)	
label_Epoch: [12][190/345]	Time 0.612 (0.734)	Data 0.0000 (0.0000)	Loss 2.8724 (3.2503)	
label_Epoch: [12][200/345]	Time 0.621 (0.728)	Data 0.0000 (0.0000)	Loss 2.8969 (3.2367)	
label_Epoch: [12][210/345]	Time 0.601 (0.723)	Data 0.0000 (0.0000)	Loss 2.7133 (3.2180)	
label_Epoch: [12][220/345]	Time 0.621 (0.719)	Data 0.0000 (0.0000)	Loss 1.7522 (3.1958)	
label_Epoch: [12][230/345]	Time 0.629 (0.715)	Data 0.0000 (0.0000)	Loss 2.8597 (3.1770)	
label_Epoch: [12][240/345]	Time 0.611 (0.711)	Data 0.0000 (0.0000)	Loss 3.4950 (3.1685)	
label_Epoch: [12][250/345]	Time 0.616 (0.707)	Data 0.0000 (0.0000)	Loss 2.3683 (3.1523)	
label_Epoch: [12][260/345]	Time 0.635 (0.704)	Data 0.0000 (0.0000)	Loss 1.9674 (3.1263)	
label_Epoch: [12][270/345]	Time 0.620 (0.701)	Data 0.0000 (0.0000)	Loss 1.6829 (3.1032)	
label_Epoch: [12][280/345]	Time 0.627 (0.698)	Data 0.0000 (0.0000)	Loss 2.3900 (3.0693)	
label_Epoch: [12][290/345]	Time 0.619 (0.695)	Data 0.0000 (0.0000)	Loss 1.8339 (3.0401)	
label_Epoch: [12][300/345]	Time 0.604 (0.692)	Data 0.0000 (0.0000)	Loss 1.7879 (3.0126)	
label_Epoch: [12][310/345]	Time 0.609 (0.690)	Data 0.0000 (0.0000)	Loss 2.0141 (2.9812)	
label_Epoch: [12][320/345]	Time 0.615 (0.688)	Data 0.0000 (0.0000)	Loss 2.3183 (2.9501)	
label_Epoch: [12][330/345]	Time 0.613 (0.685)	Data 0.0000 (0.0000)	Loss 1.7807 (2.9214)	
label_Epoch: [12][340/345]	Time 0.624 (0.684)	Data 0.0000 (0.0000)	Loss 1.9885 (2.8885)	
12
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [13][10/345]	Time 0.608 (2.425)	Data 0.0000 (0.0000)	Loss 5.4347 (4.3972)	
label_Epoch: [13][20/345]	Time 0.603 (1.522)	Data 0.0000 (0.0000)	Loss 4.0355 (4.1802)	
label_Epoch: [13][30/345]	Time 0.626 (1.221)	Data 0.0000 (0.0000)	Loss 2.5307 (3.9883)	
label_Epoch: [13][40/345]	Time 0.608 (1.070)	Data 0.0000 (0.0000)	Loss 4.5625 (3.7674)	
label_Epoch: [13][50/345]	Time 0.604 (0.978)	Data 0.0000 (0.0000)	Loss 3.4287 (3.6602)	
label_Epoch: [13][60/345]	Time 0.623 (0.918)	Data 0.0000 (0.0000)	Loss 3.6628 (3.6294)	
label_Epoch: [13][70/345]	Time 0.620 (0.876)	Data 0.0000 (0.0000)	Loss 2.6549 (3.5714)	
label_Epoch: [13][80/345]	Time 0.665 (0.852)	Data 0.0000 (0.0000)	Loss 2.5685 (3.5132)	
label_Epoch: [13][90/345]	Time 0.643 (0.831)	Data 0.0000 (0.0000)	Loss 3.5025 (3.4623)	
label_Epoch: [13][100/345]	Time 0.750 (0.814)	Data 0.0000 (0.0000)	Loss 1.9887 (3.4223)	
label_Epoch: [13][110/345]	Time 0.642 (0.798)	Data 0.0000 (0.0000)	Loss 2.7324 (3.3893)	
label_Epoch: [13][120/345]	Time 0.649 (0.787)	Data 0.0000 (0.0000)	Loss 2.5315 (3.3779)	
label_Epoch: [13][130/345]	Time 0.655 (0.779)	Data 0.0000 (0.0000)	Loss 3.1950 (3.3480)	
label_Epoch: [13][140/345]	Time 0.677 (0.771)	Data 0.0000 (0.0000)	Loss 2.6293 (3.3015)	
label_Epoch: [13][150/345]	Time 0.659 (0.763)	Data 0.0000 (0.0000)	Loss 3.7312 (3.2988)	
label_Epoch: [13][160/345]	Time 0.660 (0.757)	Data 0.0000 (0.0000)	Loss 3.2355 (3.2639)	
label_Epoch: [13][170/345]	Time 0.692 (0.752)	Data 0.0000 (0.0000)	Loss 2.8850 (3.2307)	
label_Epoch: [13][180/345]	Time 0.655 (0.747)	Data 0.0000 (0.0000)	Loss 2.2533 (3.2243)	
label_Epoch: [13][190/345]	Time 0.657 (0.742)	Data 0.0000 (0.0000)	Loss 3.4583 (3.2004)	
label_Epoch: [13][200/345]	Time 0.660 (0.739)	Data 0.0000 (0.0000)	Loss 4.3782 (3.1925)	
label_Epoch: [13][210/345]	Time 0.664 (0.736)	Data 0.0000 (0.0000)	Loss 2.5181 (3.1766)	
label_Epoch: [13][220/345]	Time 0.661 (0.733)	Data 0.0000 (0.0000)	Loss 2.8342 (3.1555)	
label_Epoch: [13][230/345]	Time 0.662 (0.730)	Data 0.0000 (0.0000)	Loss 2.8815 (3.1373)	
label_Epoch: [13][240/345]	Time 0.651 (0.728)	Data 0.0000 (0.0000)	Loss 2.7805 (3.1129)	
label_Epoch: [13][250/345]	Time 0.656 (0.725)	Data 0.0000 (0.0000)	Loss 2.5508 (3.0856)	
label_Epoch: [13][260/345]	Time 0.670 (0.723)	Data 0.0000 (0.0000)	Loss 2.2333 (3.0590)	
label_Epoch: [13][270/345]	Time 1.102 (0.722)	Data 0.0000 (0.0000)	Loss 2.0153 (3.0387)	
label_Epoch: [13][280/345]	Time 0.657 (0.720)	Data 0.0000 (0.0000)	Loss 2.1144 (3.0113)	
label_Epoch: [13][290/345]	Time 0.662 (0.718)	Data 0.0000 (0.0000)	Loss 2.6241 (2.9867)	
label_Epoch: [13][300/345]	Time 0.669 (0.716)	Data 0.0000 (0.0000)	Loss 1.2286 (2.9516)	
label_Epoch: [13][310/345]	Time 0.653 (0.715)	Data 0.0000 (0.0000)	Loss 1.4113 (2.9206)	
label_Epoch: [13][320/345]	Time 0.637 (0.712)	Data 0.0000 (0.0000)	Loss 1.9730 (2.8908)	
label_Epoch: [13][330/345]	Time 0.616 (0.710)	Data 0.0000 (0.0000)	Loss 1.7324 (2.8584)	
label_Epoch: [13][340/345]	Time 0.627 (0.707)	Data 0.0000 (0.0000)	Loss 1.3182 (2.8210)	
13
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [14][10/345]	Time 0.627 (2.659)	Data 0.0000 (0.0000)	Loss 3.9456 (4.3635)	
label_Epoch: [14][20/345]	Time 0.623 (1.642)	Data 0.0000 (0.0000)	Loss 3.6089 (4.1709)	
label_Epoch: [14][30/345]	Time 0.655 (1.311)	Data 0.0000 (0.0000)	Loss 2.7617 (3.9278)	
label_Epoch: [14][40/345]	Time 0.665 (1.149)	Data 0.0000 (0.0000)	Loss 2.6396 (3.7659)	
label_Epoch: [14][50/345]	Time 0.650 (1.051)	Data 0.0000 (0.0000)	Loss 2.6885 (3.6096)	
label_Epoch: [14][60/345]	Time 0.659 (0.984)	Data 0.0000 (0.0000)	Loss 2.9475 (3.6204)	
label_Epoch: [14][70/345]	Time 0.638 (0.936)	Data 0.0000 (0.0000)	Loss 3.2974 (3.5574)	
label_Epoch: [14][80/345]	Time 0.640 (0.897)	Data 0.0000 (0.0000)	Loss 2.7714 (3.5119)	
label_Epoch: [14][90/345]	Time 0.666 (0.870)	Data 0.0000 (0.0000)	Loss 2.6176 (3.4614)	
label_Epoch: [14][100/345]	Time 0.624 (0.846)	Data 0.0000 (0.0000)	Loss 3.0699 (3.4283)	
label_Epoch: [14][110/345]	Time 0.633 (0.829)	Data 0.0000 (0.0000)	Loss 3.0873 (3.3675)	
label_Epoch: [14][120/345]	Time 0.626 (0.817)	Data 0.0000 (0.0000)	Loss 2.9082 (3.3573)	
label_Epoch: [14][130/345]	Time 0.646 (0.804)	Data 0.0000 (0.0000)	Loss 2.9599 (3.3464)	
label_Epoch: [14][140/345]	Time 0.624 (0.794)	Data 0.0000 (0.0000)	Loss 2.4700 (3.3288)	
label_Epoch: [14][150/345]	Time 0.634 (0.783)	Data 0.0000 (0.0000)	Loss 3.3332 (3.2927)	
label_Epoch: [14][160/345]	Time 0.620 (0.774)	Data 0.0000 (0.0000)	Loss 2.6047 (3.2704)	
label_Epoch: [14][170/345]	Time 0.621 (0.765)	Data 0.0000 (0.0000)	Loss 2.6565 (3.2320)	
label_Epoch: [14][180/345]	Time 0.633 (0.758)	Data 0.0000 (0.0000)	Loss 3.7345 (3.1921)	
label_Epoch: [14][190/345]	Time 0.643 (0.751)	Data 0.0000 (0.0000)	Loss 3.1041 (3.1814)	
label_Epoch: [14][200/345]	Time 0.631 (0.745)	Data 0.0000 (0.0000)	Loss 2.4312 (3.1434)	
label_Epoch: [14][210/345]	Time 0.625 (0.739)	Data 0.0000 (0.0000)	Loss 3.1963 (3.0974)	
label_Epoch: [14][220/345]	Time 0.629 (0.736)	Data 0.0000 (0.0000)	Loss 1.9806 (3.0656)	
label_Epoch: [14][230/345]	Time 0.631 (0.732)	Data 0.0000 (0.0000)	Loss 1.7551 (3.0625)	
label_Epoch: [14][240/345]	Time 0.619 (0.727)	Data 0.0000 (0.0000)	Loss 3.2929 (3.0447)	
label_Epoch: [14][250/345]	Time 0.639 (0.724)	Data 0.0000 (0.0000)	Loss 2.9990 (3.0187)	
label_Epoch: [14][260/345]	Time 0.627 (0.720)	Data 0.0000 (0.0000)	Loss 2.5697 (2.9937)	
label_Epoch: [14][270/345]	Time 0.626 (0.717)	Data 0.0000 (0.0000)	Loss 2.4802 (2.9514)	
label_Epoch: [14][280/345]	Time 0.642 (0.714)	Data 0.0000 (0.0000)	Loss 2.6857 (2.9282)	
label_Epoch: [14][290/345]	Time 0.622 (0.711)	Data 0.0000 (0.0000)	Loss 1.8911 (2.9006)	
label_Epoch: [14][300/345]	Time 0.622 (0.708)	Data 0.0000 (0.0000)	Loss 1.9425 (2.8790)	
label_Epoch: [14][310/345]	Time 0.620 (0.705)	Data 0.0000 (0.0000)	Loss 2.2300 (2.8506)	
label_Epoch: [14][320/345]	Time 0.629 (0.703)	Data 0.0000 (0.0000)	Loss 1.6197 (2.8158)	
label_Epoch: [14][330/345]	Time 0.625 (0.701)	Data 0.0000 (0.0000)	Loss 1.5440 (2.7815)	
label_Epoch: [14][340/345]	Time 0.631 (0.699)	Data 0.0000 (0.0000)	Loss 1.1510 (2.7435)	
14
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [15][10/345]	Time 0.620 (2.610)	Data 0.0000 (0.0000)	Loss 3.8538 (3.9619)	
label_Epoch: [15][20/345]	Time 0.626 (1.618)	Data 0.0000 (0.0000)	Loss 2.9080 (3.7681)	
label_Epoch: [15][30/345]	Time 0.634 (1.288)	Data 0.0000 (0.0000)	Loss 2.5199 (3.7390)	
label_Epoch: [15][40/345]	Time 0.627 (1.122)	Data 0.0000 (0.0000)	Loss 4.1104 (3.7136)	
label_Epoch: [15][50/345]	Time 0.635 (1.026)	Data 0.0000 (0.0000)	Loss 4.0340 (3.7029)	
label_Epoch: [15][60/345]	Time 0.632 (0.960)	Data 0.0000 (0.0000)	Loss 4.4472 (3.5879)	
label_Epoch: [15][70/345]	Time 0.629 (0.913)	Data 0.0000 (0.0000)	Loss 4.1380 (3.5137)	
label_Epoch: [15][80/345]	Time 0.626 (0.877)	Data 0.0000 (0.0000)	Loss 3.2463 (3.4596)	
label_Epoch: [15][90/345]	Time 0.628 (0.850)	Data 0.0000 (0.0000)	Loss 2.7300 (3.4778)	
label_Epoch: [15][100/345]	Time 0.634 (0.827)	Data 0.0000 (0.0000)	Loss 3.1095 (3.4415)	
label_Epoch: [15][110/345]	Time 0.633 (0.809)	Data 0.0000 (0.0000)	Loss 3.0828 (3.3772)	
label_Epoch: [15][120/345]	Time 0.625 (0.796)	Data 0.0000 (0.0000)	Loss 2.5493 (3.3352)	
label_Epoch: [15][130/345]	Time 0.630 (0.783)	Data 0.0000 (0.0000)	Loss 2.8962 (3.3227)	
label_Epoch: [15][140/345]	Time 0.633 (0.772)	Data 0.0000 (0.0000)	Loss 3.0644 (3.2846)	
label_Epoch: [15][150/345]	Time 0.622 (0.762)	Data 0.0000 (0.0000)	Loss 2.2238 (3.2459)	
label_Epoch: [15][160/345]	Time 0.624 (0.756)	Data 0.0000 (0.0000)	Loss 2.7611 (3.1971)	
label_Epoch: [15][170/345]	Time 0.621 (0.749)	Data 0.0000 (0.0000)	Loss 2.9245 (3.1473)	
label_Epoch: [15][180/345]	Time 0.626 (0.742)	Data 0.0000 (0.0000)	Loss 1.9586 (3.1144)	
label_Epoch: [15][190/345]	Time 0.628 (0.736)	Data 0.0000 (0.0000)	Loss 1.7377 (3.0782)	
label_Epoch: [15][200/345]	Time 0.632 (0.733)	Data 0.0000 (0.0000)	Loss 3.5641 (3.0532)	
label_Epoch: [15][210/345]	Time 0.631 (0.728)	Data 0.0000 (0.0000)	Loss 2.6001 (3.0342)	
label_Epoch: [15][220/345]	Time 0.633 (0.723)	Data 0.0000 (0.0000)	Loss 3.3333 (3.0077)	
label_Epoch: [15][230/345]	Time 0.629 (0.719)	Data 0.0000 (0.0000)	Loss 2.4915 (2.9807)	
label_Epoch: [15][240/345]	Time 0.622 (0.716)	Data 0.0000 (0.0000)	Loss 2.3167 (2.9520)	
label_Epoch: [15][250/345]	Time 0.633 (0.712)	Data 0.0000 (0.0000)	Loss 1.5197 (2.9305)	
label_Epoch: [15][260/345]	Time 0.629 (0.709)	Data 0.0000 (0.0000)	Loss 1.5601 (2.9104)	
label_Epoch: [15][270/345]	Time 0.622 (0.707)	Data 0.0000 (0.0000)	Loss 2.2726 (2.8848)	
label_Epoch: [15][280/345]	Time 0.633 (0.704)	Data 0.0000 (0.0000)	Loss 2.6252 (2.8584)	
label_Epoch: [15][290/345]	Time 0.624 (0.701)	Data 0.0000 (0.0000)	Loss 2.3314 (2.8371)	
label_Epoch: [15][300/345]	Time 0.621 (0.699)	Data 0.0000 (0.0000)	Loss 2.3385 (2.8108)	
label_Epoch: [15][310/345]	Time 0.656 (0.697)	Data 0.0000 (0.0000)	Loss 1.7934 (2.7816)	
label_Epoch: [15][320/345]	Time 0.632 (0.695)	Data 0.0000 (0.0000)	Loss 1.7736 (2.7502)	
label_Epoch: [15][330/345]	Time 0.626 (0.694)	Data 0.0000 (0.0000)	Loss 1.2468 (2.7207)	
label_Epoch: [15][340/345]	Time 0.654 (0.692)	Data 0.0000 (0.0000)	Loss 1.6655 (2.6970)	
15
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [16][10/345]	Time 0.620 (2.654)	Data 0.0000 (0.0000)	Loss 2.7802 (3.6221)	
label_Epoch: [16][20/345]	Time 0.629 (1.642)	Data 0.0000 (0.0000)	Loss 2.2885 (3.4358)	
label_Epoch: [16][30/345]	Time 0.633 (1.315)	Data 0.0000 (0.0000)	Loss 4.3059 (3.4140)	
label_Epoch: [16][40/345]	Time 0.623 (1.143)	Data 0.0000 (0.0000)	Loss 4.5367 (3.4524)	
label_Epoch: [16][50/345]	Time 0.613 (1.040)	Data 0.0000 (0.0000)	Loss 3.3179 (3.3821)	
label_Epoch: [16][60/345]	Time 0.624 (0.971)	Data 0.0000 (0.0000)	Loss 3.1956 (3.3874)	
label_Epoch: [16][70/345]	Time 0.622 (0.921)	Data 0.0000 (0.0000)	Loss 4.1858 (3.3434)	
label_Epoch: [16][80/345]	Time 0.628 (0.887)	Data 0.0000 (0.0000)	Loss 2.6896 (3.3185)	
label_Epoch: [16][90/345]	Time 0.621 (0.858)	Data 0.0000 (0.0000)	Loss 4.3426 (3.2954)	
label_Epoch: [16][100/345]	Time 0.637 (0.835)	Data 0.0000 (0.0000)	Loss 3.0019 (3.2860)	
label_Epoch: [16][110/345]	Time 0.620 (0.816)	Data 0.0000 (0.0000)	Loss 4.0838 (3.2654)	
label_Epoch: [16][120/345]	Time 0.623 (0.800)	Data 0.0000 (0.0000)	Loss 1.8781 (3.2405)	
label_Epoch: [16][130/345]	Time 0.625 (0.787)	Data 0.0000 (0.0000)	Loss 2.0959 (3.2051)	
label_Epoch: [16][140/345]	Time 0.631 (0.776)	Data 0.0000 (0.0000)	Loss 3.5162 (3.1810)	
label_Epoch: [16][150/345]	Time 0.627 (0.768)	Data 0.0000 (0.0000)	Loss 2.1951 (3.1366)	
label_Epoch: [16][160/345]	Time 0.629 (0.759)	Data 0.0000 (0.0000)	Loss 2.2069 (3.1251)	
label_Epoch: [16][170/345]	Time 0.614 (0.751)	Data 0.0000 (0.0000)	Loss 2.2336 (3.0969)	
label_Epoch: [16][180/345]	Time 0.641 (0.744)	Data 0.0000 (0.0000)	Loss 3.5434 (3.0804)	
label_Epoch: [16][190/345]	Time 0.638 (0.739)	Data 0.0000 (0.0000)	Loss 2.9238 (3.0517)	
label_Epoch: [16][200/345]	Time 0.630 (0.733)	Data 0.0000 (0.0000)	Loss 2.4172 (3.0298)	
label_Epoch: [16][210/345]	Time 0.619 (0.728)	Data 0.0000 (0.0000)	Loss 2.5258 (3.0034)	
label_Epoch: [16][220/345]	Time 0.632 (0.723)	Data 0.0000 (0.0000)	Loss 3.0637 (2.9908)	
label_Epoch: [16][230/345]	Time 0.647 (0.719)	Data 0.0000 (0.0000)	Loss 2.1974 (2.9655)	
label_Epoch: [16][240/345]	Time 0.630 (0.715)	Data 0.0000 (0.0000)	Loss 2.5121 (2.9499)	
label_Epoch: [16][250/345]	Time 0.632 (0.712)	Data 0.0000 (0.0000)	Loss 2.0096 (2.9252)	
label_Epoch: [16][260/345]	Time 0.628 (0.709)	Data 0.0000 (0.0000)	Loss 2.6242 (2.8924)	
label_Epoch: [16][270/345]	Time 0.618 (0.706)	Data 0.0000 (0.0000)	Loss 2.4048 (2.8558)	
label_Epoch: [16][280/345]	Time 0.632 (0.703)	Data 0.0000 (0.0000)	Loss 2.1659 (2.8255)	
label_Epoch: [16][290/345]	Time 0.626 (0.700)	Data 0.0000 (0.0000)	Loss 2.0067 (2.7901)	
label_Epoch: [16][300/345]	Time 0.623 (0.698)	Data 0.0000 (0.0000)	Loss 1.4494 (2.7579)	
label_Epoch: [16][310/345]	Time 0.633 (0.696)	Data 0.0000 (0.0000)	Loss 2.5999 (2.7320)	
label_Epoch: [16][320/345]	Time 0.623 (0.693)	Data 0.0000 (0.0000)	Loss 2.6467 (2.7123)	
label_Epoch: [16][330/345]	Time 0.639 (0.691)	Data 0.0000 (0.0000)	Loss 1.8925 (2.6850)	
label_Epoch: [16][340/345]	Time 0.629 (0.690)	Data 0.0000 (0.0000)	Loss 1.3226 (2.6490)	
16
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [17][10/345]	Time 0.618 (2.673)	Data 0.0000 (0.0000)	Loss 4.3738 (4.0475)	
label_Epoch: [17][20/345]	Time 0.654 (1.651)	Data 0.0000 (0.0000)	Loss 4.8000 (3.6889)	
label_Epoch: [17][30/345]	Time 0.632 (1.310)	Data 0.0000 (0.0000)	Loss 2.9048 (3.5185)	
label_Epoch: [17][40/345]	Time 0.624 (1.139)	Data 0.0000 (0.0000)	Loss 5.2800 (3.6257)	
label_Epoch: [17][50/345]	Time 0.623 (1.036)	Data 0.0000 (0.0000)	Loss 3.9054 (3.5329)	
label_Epoch: [17][60/345]	Time 0.617 (0.968)	Data 0.0000 (0.0000)	Loss 2.0773 (3.4743)	
label_Epoch: [17][70/345]	Time 0.627 (0.919)	Data 0.0000 (0.0000)	Loss 2.2518 (3.3882)	
label_Epoch: [17][80/345]	Time 0.625 (0.882)	Data 0.0000 (0.0000)	Loss 3.2243 (3.3640)	
label_Epoch: [17][90/345]	Time 0.619 (0.854)	Data 0.0000 (0.0000)	Loss 3.4277 (3.3047)	
label_Epoch: [17][100/345]	Time 0.624 (0.831)	Data 0.0000 (0.0000)	Loss 2.1697 (3.2659)	
label_Epoch: [17][110/345]	Time 0.639 (0.813)	Data 0.0000 (0.0000)	Loss 2.7718 (3.2232)	
label_Epoch: [17][120/345]	Time 0.621 (0.797)	Data 0.0000 (0.0000)	Loss 2.5581 (3.1891)	
label_Epoch: [17][130/345]	Time 0.651 (0.784)	Data 0.0000 (0.0000)	Loss 2.4783 (3.1531)	
label_Epoch: [17][140/345]	Time 0.623 (0.773)	Data 0.0000 (0.0000)	Loss 3.0459 (3.1305)	
label_Epoch: [17][150/345]	Time 0.632 (0.763)	Data 0.0000 (0.0000)	Loss 4.1871 (3.1083)	
label_Epoch: [17][160/345]	Time 0.620 (0.756)	Data 0.0000 (0.0000)	Loss 3.8381 (3.0808)	
label_Epoch: [17][170/345]	Time 0.622 (0.748)	Data 0.0000 (0.0000)	Loss 2.7754 (3.0550)	
label_Epoch: [17][180/345]	Time 0.621 (0.742)	Data 0.0000 (0.0000)	Loss 2.3272 (3.0254)	
label_Epoch: [17][190/345]	Time 0.618 (0.735)	Data 0.0000 (0.0000)	Loss 2.1292 (3.0021)	
label_Epoch: [17][200/345]	Time 0.620 (0.730)	Data 0.0000 (0.0000)	Loss 3.1371 (2.9728)	
label_Epoch: [17][210/345]	Time 0.634 (0.725)	Data 0.0000 (0.0000)	Loss 2.4209 (2.9494)	
label_Epoch: [17][220/345]	Time 0.633 (0.721)	Data 0.0000 (0.0000)	Loss 3.2174 (2.9300)	
label_Epoch: [17][230/345]	Time 0.623 (0.717)	Data 0.0000 (0.0000)	Loss 2.0505 (2.9070)	
label_Epoch: [17][240/345]	Time 0.620 (0.713)	Data 0.0000 (0.0000)	Loss 1.4059 (2.8763)	
label_Epoch: [17][250/345]	Time 0.626 (0.709)	Data 0.0000 (0.0000)	Loss 1.6274 (2.8492)	
label_Epoch: [17][260/345]	Time 0.621 (0.706)	Data 0.0000 (0.0000)	Loss 2.1222 (2.8244)	
label_Epoch: [17][270/345]	Time 0.624 (0.703)	Data 0.0000 (0.0000)	Loss 1.9878 (2.7976)	
label_Epoch: [17][280/345]	Time 0.645 (0.701)	Data 0.0000 (0.0000)	Loss 1.9302 (2.7665)	
label_Epoch: [17][290/345]	Time 0.616 (0.698)	Data 0.0000 (0.0000)	Loss 1.4130 (2.7375)	
label_Epoch: [17][300/345]	Time 0.625 (0.696)	Data 0.0000 (0.0000)	Loss 2.9230 (2.7119)	
label_Epoch: [17][310/345]	Time 0.639 (0.694)	Data 0.0000 (0.0000)	Loss 2.0447 (2.6906)	
label_Epoch: [17][320/345]	Time 0.631 (0.692)	Data 0.0000 (0.0000)	Loss 1.8785 (2.6669)	
label_Epoch: [17][330/345]	Time 0.621 (0.690)	Data 0.0000 (0.0000)	Loss 1.4623 (2.6475)	
label_Epoch: [17][340/345]	Time 0.629 (0.688)	Data 0.0000 (0.0000)	Loss 1.5411 (2.6200)	
17
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [18][10/345]	Time 0.614 (2.717)	Data 0.0000 (0.0000)	Loss 2.7571 (3.7977)	
label_Epoch: [18][20/345]	Time 0.624 (1.672)	Data 0.0000 (0.0000)	Loss 3.5106 (3.7662)	
label_Epoch: [18][30/345]	Time 0.614 (1.320)	Data 0.0000 (0.0000)	Loss 4.1073 (3.6451)	
label_Epoch: [18][40/345]	Time 0.635 (1.151)	Data 0.0000 (0.0000)	Loss 3.2996 (3.5030)	
label_Epoch: [18][50/345]	Time 0.654 (1.060)	Data 0.0000 (0.0000)	Loss 2.1055 (3.4064)	
label_Epoch: [18][60/345]	Time 0.630 (0.988)	Data 0.0000 (0.0000)	Loss 3.6355 (3.3132)	
label_Epoch: [18][70/345]	Time 0.622 (0.937)	Data 0.0000 (0.0000)	Loss 3.4670 (3.2827)	
label_Epoch: [18][80/345]	Time 0.629 (0.898)	Data 0.0000 (0.0000)	Loss 2.7148 (3.2133)	
label_Epoch: [18][90/345]	Time 0.648 (0.868)	Data 0.0000 (0.0000)	Loss 4.2590 (3.1873)	
label_Epoch: [18][100/345]	Time 0.620 (0.844)	Data 0.0000 (0.0000)	Loss 2.2238 (3.1512)	
label_Epoch: [18][110/345]	Time 0.626 (0.824)	Data 0.0000 (0.0000)	Loss 2.6638 (3.1340)	
label_Epoch: [18][120/345]	Time 0.626 (0.807)	Data 0.0000 (0.0000)	Loss 2.2615 (3.1030)	
label_Epoch: [18][130/345]	Time 0.626 (0.793)	Data 0.0000 (0.0000)	Loss 3.4804 (3.0897)	
label_Epoch: [18][140/345]	Time 0.630 (0.781)	Data 0.0000 (0.0000)	Loss 4.3049 (3.0381)	
label_Epoch: [18][150/345]	Time 0.621 (0.770)	Data 0.0000 (0.0000)	Loss 2.6751 (3.0052)	
label_Epoch: [18][160/345]	Time 0.622 (0.761)	Data 0.0000 (0.0000)	Loss 4.1510 (2.9950)	
label_Epoch: [18][170/345]	Time 0.624 (0.754)	Data 0.0000 (0.0000)	Loss 2.4164 (2.9939)	
label_Epoch: [18][180/345]	Time 0.621 (0.747)	Data 0.0000 (0.0000)	Loss 1.6955 (2.9807)	
label_Epoch: [18][190/345]	Time 0.627 (0.741)	Data 0.0000 (0.0000)	Loss 2.3681 (2.9608)	
label_Epoch: [18][200/345]	Time 0.624 (0.735)	Data 0.0000 (0.0000)	Loss 3.6107 (2.9483)	
label_Epoch: [18][210/345]	Time 0.622 (0.730)	Data 0.0000 (0.0000)	Loss 1.8476 (2.9067)	
label_Epoch: [18][220/345]	Time 0.618 (0.725)	Data 0.0000 (0.0000)	Loss 2.1807 (2.8831)	
label_Epoch: [18][230/345]	Time 0.620 (0.721)	Data 0.0000 (0.0000)	Loss 1.8884 (2.8683)	
label_Epoch: [18][240/345]	Time 0.627 (0.717)	Data 0.0000 (0.0000)	Loss 2.3864 (2.8431)	
label_Epoch: [18][250/345]	Time 0.631 (0.714)	Data 0.0000 (0.0000)	Loss 1.7033 (2.8219)	
label_Epoch: [18][260/345]	Time 0.627 (0.710)	Data 0.0000 (0.0000)	Loss 1.8286 (2.8020)	
label_Epoch: [18][270/345]	Time 0.618 (0.707)	Data 0.0000 (0.0000)	Loss 2.0772 (2.7781)	
label_Epoch: [18][280/345]	Time 0.621 (0.704)	Data 0.0000 (0.0000)	Loss 1.6130 (2.7532)	
label_Epoch: [18][290/345]	Time 0.625 (0.702)	Data 0.0000 (0.0000)	Loss 2.4139 (2.7349)	
label_Epoch: [18][300/345]	Time 0.633 (0.700)	Data 0.0000 (0.0000)	Loss 2.0480 (2.7075)	
label_Epoch: [18][310/345]	Time 0.634 (0.698)	Data 0.0000 (0.0000)	Loss 2.8117 (2.6889)	
label_Epoch: [18][320/345]	Time 0.633 (0.695)	Data 0.0000 (0.0000)	Loss 2.8411 (2.6685)	
label_Epoch: [18][330/345]	Time 0.621 (0.693)	Data 0.0000 (0.0000)	Loss 1.1829 (2.6360)	
label_Epoch: [18][340/345]	Time 0.628 (0.691)	Data 0.0000 (0.0000)	Loss 1.1823 (2.6071)	
18
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [19][10/345]	Time 0.624 (2.687)	Data 0.0000 (0.0000)	Loss 3.7349 (4.2640)	
label_Epoch: [19][20/345]	Time 0.632 (1.657)	Data 0.0000 (0.0000)	Loss 4.3272 (3.7209)	
label_Epoch: [19][30/345]	Time 0.627 (1.315)	Data 0.0000 (0.0000)	Loss 1.6909 (3.4035)	
label_Epoch: [19][40/345]	Time 0.636 (1.146)	Data 0.0000 (0.0000)	Loss 2.0424 (3.2013)	
label_Epoch: [19][50/345]	Time 0.633 (1.042)	Data 0.0000 (0.0000)	Loss 3.8369 (3.1934)	
label_Epoch: [19][60/345]	Time 0.622 (0.973)	Data 0.0000 (0.0000)	Loss 1.8603 (3.1915)	
label_Epoch: [19][70/345]	Time 0.628 (0.923)	Data 0.0000 (0.0000)	Loss 3.4167 (3.1828)	
label_Epoch: [19][80/345]	Time 0.632 (0.886)	Data 0.0000 (0.0000)	Loss 2.5462 (3.1456)	
label_Epoch: [19][90/345]	Time 0.622 (0.858)	Data 0.0000 (0.0000)	Loss 2.5379 (3.1309)	
label_Epoch: [19][100/345]	Time 0.631 (0.835)	Data 0.0000 (0.0000)	Loss 1.9835 (3.0912)	
label_Epoch: [19][110/345]	Time 0.621 (0.816)	Data 0.0000 (0.0000)	Loss 1.5660 (3.0673)	
label_Epoch: [19][120/345]	Time 0.639 (0.800)	Data 0.0000 (0.0000)	Loss 2.9662 (3.0604)	
label_Epoch: [19][130/345]	Time 0.626 (0.787)	Data 0.0000 (0.0000)	Loss 2.8527 (3.0353)	
label_Epoch: [19][140/345]	Time 0.639 (0.775)	Data 0.0000 (0.0000)	Loss 2.6947 (3.0334)	
label_Epoch: [19][150/345]	Time 0.619 (0.766)	Data 0.0000 (0.0000)	Loss 2.3300 (3.0166)	
label_Epoch: [19][160/345]	Time 0.627 (0.758)	Data 0.0000 (0.0000)	Loss 4.8379 (2.9987)	
label_Epoch: [19][170/345]	Time 0.637 (0.751)	Data 0.0000 (0.0000)	Loss 2.7853 (2.9682)	
label_Epoch: [19][180/345]	Time 0.624 (0.744)	Data 0.0000 (0.0000)	Loss 3.3700 (2.9460)	
label_Epoch: [19][190/345]	Time 0.623 (0.738)	Data 0.0000 (0.0000)	Loss 2.1169 (2.9251)	
label_Epoch: [19][200/345]	Time 0.631 (0.732)	Data 0.0000 (0.0000)	Loss 2.5379 (2.8974)	
label_Epoch: [19][210/345]	Time 0.616 (0.727)	Data 0.0000 (0.0000)	Loss 3.2191 (2.8809)	
label_Epoch: [19][220/345]	Time 0.628 (0.723)	Data 0.0000 (0.0000)	Loss 1.9688 (2.8578)	
label_Epoch: [19][230/345]	Time 0.626 (0.719)	Data 0.0000 (0.0000)	Loss 2.0750 (2.8279)	
label_Epoch: [19][240/345]	Time 0.619 (0.715)	Data 0.0000 (0.0000)	Loss 2.1280 (2.8130)	
label_Epoch: [19][250/345]	Time 0.624 (0.711)	Data 0.0000 (0.0000)	Loss 2.0997 (2.7916)	
label_Epoch: [19][260/345]	Time 0.626 (0.708)	Data 0.0000 (0.0000)	Loss 1.8290 (2.7620)	
label_Epoch: [19][270/345]	Time 0.627 (0.705)	Data 0.0000 (0.0000)	Loss 2.2736 (2.7376)	
label_Epoch: [19][280/345]	Time 0.630 (0.703)	Data 0.0000 (0.0000)	Loss 2.3870 (2.7136)	
label_Epoch: [19][290/345]	Time 0.631 (0.701)	Data 0.0000 (0.0000)	Loss 2.0510 (2.6854)	
label_Epoch: [19][300/345]	Time 0.629 (0.698)	Data 0.0000 (0.0000)	Loss 1.8428 (2.6582)	
label_Epoch: [19][310/345]	Time 0.626 (0.696)	Data 0.0000 (0.0000)	Loss 2.4101 (2.6330)	
label_Epoch: [19][320/345]	Time 0.626 (0.694)	Data 0.0000 (0.0000)	Loss 1.5672 (2.6055)	
label_Epoch: [19][330/345]	Time 0.628 (0.692)	Data 0.0000 (0.0000)	Loss 1.3963 (2.5756)	
label_Epoch: [19][340/345]	Time 0.624 (0.690)	Data 0.0000 (0.0000)	Loss 1.5438 (2.5434)	
19
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [20][10/345]	Time 0.624 (2.640)	Data 0.0000 (0.0000)	Loss 2.7671 (3.3776)	
label_Epoch: [20][20/345]	Time 0.633 (1.633)	Data 0.0000 (0.0000)	Loss 3.5501 (3.3444)	
label_Epoch: [20][30/345]	Time 0.638 (1.299)	Data 0.0000 (0.0000)	Loss 2.5069 (3.2751)	
label_Epoch: [20][40/345]	Time 0.621 (1.131)	Data 0.0000 (0.0000)	Loss 3.3936 (3.3081)	
label_Epoch: [20][50/345]	Time 0.620 (1.030)	Data 0.0000 (0.0000)	Loss 3.7665 (3.2834)	
label_Epoch: [20][60/345]	Time 0.627 (0.963)	Data 0.0000 (0.0000)	Loss 2.2738 (3.2077)	
label_Epoch: [20][70/345]	Time 0.634 (0.915)	Data 0.0000 (0.0000)	Loss 3.0459 (3.2243)	
label_Epoch: [20][80/345]	Time 0.634 (0.879)	Data 0.0000 (0.0000)	Loss 2.3932 (3.2047)	
label_Epoch: [20][90/345]	Time 0.620 (0.854)	Data 0.0000 (0.0000)	Loss 4.2572 (3.1635)	
label_Epoch: [20][100/345]	Time 0.620 (0.831)	Data 0.0000 (0.0000)	Loss 2.7463 (3.1233)	
label_Epoch: [20][110/345]	Time 0.633 (0.812)	Data 0.0000 (0.0000)	Loss 2.7935 (3.0821)	
label_Epoch: [20][120/345]	Time 0.629 (0.797)	Data 0.0000 (0.0000)	Loss 2.1500 (3.0725)	
label_Epoch: [20][130/345]	Time 0.636 (0.784)	Data 0.0000 (0.0000)	Loss 2.0420 (3.0568)	
label_Epoch: [20][140/345]	Time 0.626 (0.773)	Data 0.0000 (0.0000)	Loss 2.6225 (3.0175)	
label_Epoch: [20][150/345]	Time 0.636 (0.763)	Data 0.0000 (0.0000)	Loss 2.6344 (2.9929)	
label_Epoch: [20][160/345]	Time 0.629 (0.755)	Data 0.0000 (0.0000)	Loss 1.9073 (2.9594)	
label_Epoch: [20][170/345]	Time 0.622 (0.747)	Data 0.0000 (0.0000)	Loss 2.8245 (2.9427)	
label_Epoch: [20][180/345]	Time 0.611 (0.740)	Data 0.0000 (0.0000)	Loss 1.5434 (2.8984)	
label_Epoch: [20][190/345]	Time 0.636 (0.734)	Data 0.0000 (0.0000)	Loss 2.1054 (2.8577)	
label_Epoch: [20][200/345]	Time 0.620 (0.729)	Data 0.0000 (0.0000)	Loss 1.8229 (2.8220)	
label_Epoch: [20][210/345]	Time 0.620 (0.724)	Data 0.0000 (0.0000)	Loss 1.9998 (2.8069)	
label_Epoch: [20][220/345]	Time 0.625 (0.721)	Data 0.0000 (0.0000)	Loss 2.6679 (2.7888)	
label_Epoch: [20][230/345]	Time 0.636 (0.717)	Data 0.0000 (0.0000)	Loss 1.9356 (2.7707)	
label_Epoch: [20][240/345]	Time 0.620 (0.713)	Data 0.0000 (0.0000)	Loss 2.2928 (2.7486)	
label_Epoch: [20][250/345]	Time 0.629 (0.709)	Data 0.0000 (0.0000)	Loss 2.6890 (2.7318)	
label_Epoch: [20][260/345]	Time 0.628 (0.706)	Data 0.0000 (0.0000)	Loss 1.5158 (2.7121)	
label_Epoch: [20][270/345]	Time 0.622 (0.703)	Data 0.0000 (0.0000)	Loss 2.0202 (2.6898)	
label_Epoch: [20][280/345]	Time 0.626 (0.700)	Data 0.0000 (0.0000)	Loss 2.1341 (2.6695)	
label_Epoch: [20][290/345]	Time 0.641 (0.698)	Data 0.0000 (0.0000)	Loss 2.3665 (2.6493)	
label_Epoch: [20][300/345]	Time 0.634 (0.696)	Data 0.0000 (0.0000)	Loss 2.0083 (2.6221)	
label_Epoch: [20][310/345]	Time 0.622 (0.694)	Data 0.0000 (0.0000)	Loss 1.8574 (2.6147)	
label_Epoch: [20][320/345]	Time 0.622 (0.692)	Data 0.0000 (0.0000)	Loss 2.3959 (2.5902)	
label_Epoch: [20][330/345]	Time 0.636 (0.690)	Data 0.0000 (0.0000)	Loss 2.8764 (2.5654)	
label_Epoch: [20][340/345]	Time 0.631 (0.688)	Data 0.0000 (0.0000)	Loss 1.5274 (2.5407)	
20
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [21][10/345]	Time 0.625 (2.568)	Data 0.0000 (0.0000)	Loss 2.9681 (3.4734)	
label_Epoch: [21][20/345]	Time 0.633 (1.597)	Data 0.0000 (0.0000)	Loss 3.2298 (3.3105)	
label_Epoch: [21][30/345]	Time 0.615 (1.273)	Data 0.0000 (0.0000)	Loss 3.5906 (3.3898)	
label_Epoch: [21][40/345]	Time 0.617 (1.114)	Data 0.0000 (0.0000)	Loss 4.7777 (3.3618)	
label_Epoch: [21][50/345]	Time 0.629 (1.016)	Data 0.0000 (0.0000)	Loss 1.6186 (3.2612)	
label_Epoch: [21][60/345]	Time 0.632 (0.951)	Data 0.0000 (0.0000)	Loss 1.9485 (3.2276)	
label_Epoch: [21][70/345]	Time 0.635 (0.904)	Data 0.0000 (0.0000)	Loss 2.4446 (3.1497)	
label_Epoch: [21][80/345]	Time 0.631 (0.870)	Data 0.0000 (0.0000)	Loss 3.1888 (3.0876)	
label_Epoch: [21][90/345]	Time 0.624 (0.843)	Data 0.0000 (0.0000)	Loss 2.1342 (3.0169)	
label_Epoch: [21][100/345]	Time 0.620 (0.822)	Data 0.0000 (0.0000)	Loss 2.5555 (2.9599)	
label_Epoch: [21][110/345]	Time 0.624 (0.804)	Data 0.0000 (0.0000)	Loss 1.5577 (2.9222)	
label_Epoch: [21][120/345]	Time 0.625 (0.789)	Data 0.0000 (0.0000)	Loss 2.2113 (2.8866)	
label_Epoch: [21][130/345]	Time 0.628 (0.776)	Data 0.0000 (0.0000)	Loss 2.1748 (2.8348)	
label_Epoch: [21][140/345]	Time 0.629 (0.765)	Data 0.0000 (0.0000)	Loss 1.8963 (2.7886)	
label_Epoch: [21][150/345]	Time 0.635 (0.757)	Data 0.0000 (0.0000)	Loss 2.4156 (2.7547)	
label_Epoch: [21][160/345]	Time 0.672 (0.749)	Data 0.0000 (0.0000)	Loss 1.9874 (2.7240)	
label_Epoch: [21][170/345]	Time 0.659 (0.744)	Data 0.0000 (0.0000)	Loss 2.4941 (2.7070)	
label_Epoch: [21][180/345]	Time 0.655 (0.739)	Data 0.0000 (0.0000)	Loss 1.6886 (2.6643)	
label_Epoch: [21][190/345]	Time 0.664 (0.735)	Data 0.0000 (0.0000)	Loss 2.9502 (2.6482)	
label_Epoch: [21][200/345]	Time 0.642 (0.731)	Data 0.0000 (0.0000)	Loss 2.2815 (2.6238)	
label_Epoch: [21][210/345]	Time 0.621 (0.726)	Data 0.0000 (0.0000)	Loss 1.4782 (2.5906)	
label_Epoch: [21][220/345]	Time 0.625 (0.721)	Data 0.0000 (0.0000)	Loss 2.2164 (2.5554)	
label_Epoch: [21][230/345]	Time 0.616 (0.717)	Data 0.0000 (0.0000)	Loss 1.2761 (2.5229)	
label_Epoch: [21][240/345]	Time 0.633 (0.713)	Data 0.0000 (0.0000)	Loss 1.7014 (2.4879)	
label_Epoch: [21][250/345]	Time 0.628 (0.709)	Data 0.0000 (0.0000)	Loss 1.4898 (2.4797)	
label_Epoch: [21][260/345]	Time 0.629 (0.706)	Data 0.0000 (0.0000)	Loss 1.6153 (2.4507)	
label_Epoch: [21][270/345]	Time 0.650 (0.703)	Data 0.0000 (0.0000)	Loss 1.7644 (2.4318)	
label_Epoch: [21][280/345]	Time 0.625 (0.700)	Data 0.0000 (0.0000)	Loss 1.3831 (2.4003)	
label_Epoch: [21][290/345]	Time 0.666 (0.698)	Data 0.0000 (0.0000)	Loss 1.7857 (2.3759)	
label_Epoch: [21][300/345]	Time 0.668 (0.697)	Data 0.0000 (0.0000)	Loss 1.5092 (2.3597)	
label_Epoch: [21][310/345]	Time 0.668 (0.696)	Data 0.0000 (0.0000)	Loss 1.4362 (2.3369)	
label_Epoch: [21][320/345]	Time 0.663 (0.695)	Data 0.0000 (0.0000)	Loss 1.5078 (2.3153)	
label_Epoch: [21][330/345]	Time 0.666 (0.694)	Data 0.0000 (0.0000)	Loss 1.4791 (2.2928)	
label_Epoch: [21][340/345]	Time 0.673 (0.693)	Data 0.0000 (0.0000)	Loss 1.2003 (2.2663)	
21
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [22][10/345]	Time 0.657 (2.702)	Data 0.0000 (0.0000)	Loss 3.3991 (3.3187)	
label_Epoch: [22][20/345]	Time 0.664 (1.682)	Data 0.0000 (0.0000)	Loss 4.6461 (3.2247)	
label_Epoch: [22][30/345]	Time 0.671 (1.341)	Data 0.0000 (0.0000)	Loss 3.0486 (3.0932)	
label_Epoch: [22][40/345]	Time 0.653 (1.173)	Data 0.0000 (0.0000)	Loss 1.7511 (3.0505)	
label_Epoch: [22][50/345]	Time 0.657 (1.071)	Data 0.0000 (0.0000)	Loss 2.7315 (2.9612)	
label_Epoch: [22][60/345]	Time 0.657 (1.003)	Data 0.0000 (0.0000)	Loss 3.4653 (2.9253)	
label_Epoch: [22][70/345]	Time 0.650 (0.953)	Data 0.0000 (0.0000)	Loss 1.4714 (2.8203)	
label_Epoch: [22][80/345]	Time 0.712 (0.917)	Data 0.0000 (0.0000)	Loss 3.5544 (2.7645)	
label_Epoch: [22][90/345]	Time 0.671 (0.889)	Data 0.0000 (0.0000)	Loss 3.1909 (2.7031)	
label_Epoch: [22][100/345]	Time 0.654 (0.866)	Data 0.0000 (0.0000)	Loss 1.9866 (2.6645)	
label_Epoch: [22][110/345]	Time 0.661 (0.847)	Data 0.0000 (0.0000)	Loss 2.4213 (2.6191)	
label_Epoch: [22][120/345]	Time 0.646 (0.831)	Data 0.0000 (0.0000)	Loss 2.7376 (2.5850)	
label_Epoch: [22][130/345]	Time 0.619 (0.817)	Data 0.0000 (0.0000)	Loss 1.7943 (2.5255)	
label_Epoch: [22][140/345]	Time 0.650 (0.805)	Data 0.0000 (0.0000)	Loss 2.1513 (2.4873)	
label_Epoch: [22][150/345]	Time 0.651 (0.794)	Data 0.0000 (0.0000)	Loss 2.1041 (2.4712)	
label_Epoch: [22][160/345]	Time 0.645 (0.785)	Data 0.0000 (0.0000)	Loss 2.4423 (2.4541)	
label_Epoch: [22][170/345]	Time 0.652 (0.777)	Data 0.0000 (0.0000)	Loss 1.5452 (2.4235)	
label_Epoch: [22][180/345]	Time 0.631 (0.769)	Data 0.0000 (0.0000)	Loss 1.6237 (2.4052)	
label_Epoch: [22][190/345]	Time 0.614 (0.762)	Data 0.0000 (0.0000)	Loss 2.2617 (2.3811)	
label_Epoch: [22][200/345]	Time 0.622 (0.755)	Data 0.0000 (0.0000)	Loss 1.5018 (2.3454)	
label_Epoch: [22][210/345]	Time 0.645 (0.748)	Data 0.0000 (0.0000)	Loss 1.2922 (2.3112)	
label_Epoch: [22][220/345]	Time 0.605 (0.742)	Data 0.0000 (0.0000)	Loss 2.1299 (2.2925)	
label_Epoch: [22][230/345]	Time 0.606 (0.736)	Data 0.0000 (0.0000)	Loss 1.5890 (2.2751)	
label_Epoch: [22][240/345]	Time 0.619 (0.731)	Data 0.0000 (0.0000)	Loss 1.3495 (2.2579)	
label_Epoch: [22][250/345]	Time 0.627 (0.726)	Data 0.0000 (0.0000)	Loss 1.5706 (2.2296)	
label_Epoch: [22][260/345]	Time 0.605 (0.722)	Data 0.0000 (0.0000)	Loss 1.6887 (2.2127)	
label_Epoch: [22][270/345]	Time 0.627 (0.718)	Data 0.0000 (0.0000)	Loss 1.6240 (2.1990)	
label_Epoch: [22][280/345]	Time 0.599 (0.715)	Data 0.0000 (0.0000)	Loss 1.4510 (2.1795)	
label_Epoch: [22][290/345]	Time 0.598 (0.711)	Data 0.0000 (0.0000)	Loss 1.5726 (2.1588)	
label_Epoch: [22][300/345]	Time 0.611 (0.708)	Data 0.0000 (0.0000)	Loss 2.6759 (2.1388)	
label_Epoch: [22][310/345]	Time 0.628 (0.706)	Data 0.0000 (0.0000)	Loss 1.1801 (2.1220)	
label_Epoch: [22][320/345]	Time 0.607 (0.703)	Data 0.0000 (0.0000)	Loss 1.1561 (2.1005)	
label_Epoch: [22][330/345]	Time 0.606 (0.700)	Data 0.0000 (0.0000)	Loss 1.2385 (2.0799)	
label_Epoch: [22][340/345]	Time 0.636 (0.698)	Data 0.0000 (0.0000)	Loss 1.5316 (2.0591)	
22
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [23][10/345]	Time 0.615 (2.397)	Data 0.0000 (0.0000)	Loss 3.7409 (2.6874)	
label_Epoch: [23][20/345]	Time 0.616 (1.507)	Data 0.0000 (0.0000)	Loss 2.4340 (2.7403)	
label_Epoch: [23][30/345]	Time 0.617 (1.210)	Data 0.0000 (0.0000)	Loss 3.0310 (2.7948)	
label_Epoch: [23][40/345]	Time 0.608 (1.063)	Data 0.0000 (0.0000)	Loss 2.3102 (2.7778)	
label_Epoch: [23][50/345]	Time 0.635 (0.975)	Data 0.0000 (0.0000)	Loss 1.7529 (2.7750)	
label_Epoch: [23][60/345]	Time 0.605 (0.915)	Data 0.0000 (0.0000)	Loss 2.2897 (2.6893)	
label_Epoch: [23][70/345]	Time 0.620 (0.872)	Data 0.0000 (0.0000)	Loss 1.7032 (2.6096)	
label_Epoch: [23][80/345]	Time 0.614 (0.840)	Data 0.0000 (0.0000)	Loss 2.3167 (2.5927)	
label_Epoch: [23][90/345]	Time 0.628 (0.815)	Data 0.0000 (0.0000)	Loss 2.8478 (2.5947)	
label_Epoch: [23][100/345]	Time 0.624 (0.796)	Data 0.0000 (0.0000)	Loss 1.7943 (2.5502)	
label_Epoch: [23][110/345]	Time 0.608 (0.780)	Data 0.0000 (0.0000)	Loss 3.1595 (2.5253)	
label_Epoch: [23][120/345]	Time 0.641 (0.767)	Data 0.0000 (0.0000)	Loss 2.2195 (2.5063)	
label_Epoch: [23][130/345]	Time 0.612 (0.755)	Data 0.0000 (0.0000)	Loss 2.4212 (2.4702)	
label_Epoch: [23][140/345]	Time 0.653 (0.746)	Data 0.0000 (0.0000)	Loss 2.0880 (2.4397)	
label_Epoch: [23][150/345]	Time 0.607 (0.738)	Data 0.0000 (0.0000)	Loss 1.9327 (2.4107)	
label_Epoch: [23][160/345]	Time 0.612 (0.730)	Data 0.0000 (0.0000)	Loss 3.7425 (2.3906)	
label_Epoch: [23][170/345]	Time 0.637 (0.724)	Data 0.0000 (0.0000)	Loss 1.7619 (2.3497)	
label_Epoch: [23][180/345]	Time 0.622 (0.718)	Data 0.0000 (0.0000)	Loss 2.2157 (2.3239)	
label_Epoch: [23][190/345]	Time 0.611 (0.713)	Data 0.0000 (0.0000)	Loss 1.6566 (2.2946)	
label_Epoch: [23][200/345]	Time 0.608 (0.708)	Data 0.0000 (0.0000)	Loss 1.5358 (2.2739)	
label_Epoch: [23][210/345]	Time 0.620 (0.704)	Data 0.0000 (0.0000)	Loss 1.8110 (2.2494)	
label_Epoch: [23][220/345]	Time 0.619 (0.700)	Data 0.0000 (0.0000)	Loss 1.5981 (2.2337)	
label_Epoch: [23][230/345]	Time 0.612 (0.697)	Data 0.0000 (0.0000)	Loss 1.5193 (2.2110)	
label_Epoch: [23][240/345]	Time 0.617 (0.694)	Data 0.0000 (0.0000)	Loss 1.8025 (2.1876)	
label_Epoch: [23][250/345]	Time 0.611 (0.691)	Data 0.0000 (0.0000)	Loss 1.6677 (2.1600)	
label_Epoch: [23][260/345]	Time 0.614 (0.688)	Data 0.0000 (0.0000)	Loss 1.7284 (2.1367)	
label_Epoch: [23][270/345]	Time 0.631 (0.685)	Data 0.0000 (0.0000)	Loss 1.9134 (2.1213)	
label_Epoch: [23][280/345]	Time 0.626 (0.683)	Data 0.0000 (0.0000)	Loss 1.2305 (2.1038)	
label_Epoch: [23][290/345]	Time 0.622 (0.681)	Data 0.0000 (0.0000)	Loss 1.2245 (2.0825)	
label_Epoch: [23][300/345]	Time 0.622 (0.679)	Data 0.0000 (0.0000)	Loss 1.5354 (2.0678)	
label_Epoch: [23][310/345]	Time 0.645 (0.677)	Data 0.0000 (0.0000)	Loss 1.5705 (2.0493)	
label_Epoch: [23][320/345]	Time 0.620 (0.676)	Data 0.0000 (0.0000)	Loss 1.3428 (2.0310)	
label_Epoch: [23][330/345]	Time 0.658 (0.675)	Data 0.0000 (0.0000)	Loss 1.1468 (2.0120)	
label_Epoch: [23][340/345]	Time 0.651 (0.675)	Data 0.0000 (0.0000)	Loss 1.3913 (1.9895)	
23
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [24][10/345]	Time 0.646 (2.605)	Data 0.0000 (0.0000)	Loss 2.5571 (2.1722)	
label_Epoch: [24][20/345]	Time 0.634 (1.622)	Data 0.0000 (0.0000)	Loss 2.9707 (2.2847)	
label_Epoch: [24][30/345]	Time 0.644 (1.298)	Data 0.0000 (0.0000)	Loss 2.3779 (2.5556)	
label_Epoch: [24][40/345]	Time 0.641 (1.135)	Data 0.0000 (0.0000)	Loss 2.7885 (2.6482)	
label_Epoch: [24][50/345]	Time 0.638 (1.036)	Data 0.0000 (0.0000)	Loss 1.6742 (2.5861)	
label_Epoch: [24][60/345]	Time 0.633 (0.971)	Data 0.0000 (0.0000)	Loss 1.4207 (2.6005)	
label_Epoch: [24][70/345]	Time 0.647 (0.925)	Data 0.0000 (0.0000)	Loss 3.3110 (2.5344)	
label_Epoch: [24][80/345]	Time 0.608 (0.888)	Data 0.0000 (0.0000)	Loss 1.4126 (2.4935)	
label_Epoch: [24][90/345]	Time 0.613 (0.858)	Data 0.0000 (0.0000)	Loss 2.5913 (2.4742)	
label_Epoch: [24][100/345]	Time 0.631 (0.834)	Data 0.0000 (0.0000)	Loss 2.1122 (2.4331)	
label_Epoch: [24][110/345]	Time 0.612 (0.815)	Data 0.0000 (0.0000)	Loss 2.0774 (2.4216)	
label_Epoch: [24][120/345]	Time 0.620 (0.799)	Data 0.0000 (0.0000)	Loss 2.4393 (2.4042)	
label_Epoch: [24][130/345]	Time 0.613 (0.786)	Data 0.0000 (0.0000)	Loss 1.6998 (2.3910)	
label_Epoch: [24][140/345]	Time 0.631 (0.774)	Data 0.0000 (0.0000)	Loss 1.4103 (2.3491)	
label_Epoch: [24][150/345]	Time 0.622 (0.764)	Data 0.0000 (0.0000)	Loss 1.7437 (2.3362)	
label_Epoch: [24][160/345]	Time 0.618 (0.755)	Data 0.0000 (0.0000)	Loss 1.7437 (2.3190)	
label_Epoch: [24][170/345]	Time 0.616 (0.747)	Data 0.0000 (0.0000)	Loss 1.7246 (2.3013)	
label_Epoch: [24][180/345]	Time 0.621 (0.740)	Data 0.0000 (0.0000)	Loss 1.5990 (2.2735)	
label_Epoch: [24][190/345]	Time 0.617 (0.733)	Data 0.0000 (0.0000)	Loss 1.7367 (2.2443)	
label_Epoch: [24][200/345]	Time 0.639 (0.728)	Data 0.0000 (0.0000)	Loss 1.3936 (2.2082)	
label_Epoch: [24][210/345]	Time 0.627 (0.724)	Data 0.0000 (0.0000)	Loss 1.7488 (2.1890)	
label_Epoch: [24][220/345]	Time 0.617 (0.719)	Data 0.0000 (0.0000)	Loss 2.4614 (2.1667)	
label_Epoch: [24][230/345]	Time 0.604 (0.715)	Data 0.0000 (0.0000)	Loss 1.4774 (2.1436)	
label_Epoch: [24][240/345]	Time 0.621 (0.711)	Data 0.0000 (0.0000)	Loss 1.4252 (2.1271)	
label_Epoch: [24][250/345]	Time 0.614 (0.707)	Data 0.0000 (0.0000)	Loss 1.9612 (2.1087)	
label_Epoch: [24][260/345]	Time 0.616 (0.703)	Data 0.0000 (0.0000)	Loss 1.7450 (2.0936)	
label_Epoch: [24][270/345]	Time 0.647 (0.700)	Data 0.0000 (0.0000)	Loss 1.7534 (2.0750)	
label_Epoch: [24][280/345]	Time 0.660 (0.697)	Data 0.0000 (0.0000)	Loss 1.7860 (2.0623)	
label_Epoch: [24][290/345]	Time 0.614 (0.695)	Data 0.0000 (0.0000)	Loss 1.3396 (2.0420)	
label_Epoch: [24][300/345]	Time 0.622 (0.693)	Data 0.0000 (0.0000)	Loss 1.1144 (2.0257)	
label_Epoch: [24][310/345]	Time 0.651 (0.691)	Data 0.0000 (0.0000)	Loss 1.2154 (2.0042)	
label_Epoch: [24][320/345]	Time 0.608 (0.689)	Data 0.0000 (0.0000)	Loss 1.5922 (1.9850)	
label_Epoch: [24][330/345]	Time 0.601 (0.686)	Data 0.0000 (0.0000)	Loss 1.7190 (1.9679)	
label_Epoch: [24][340/345]	Time 0.619 (0.685)	Data 0.0000 (0.0000)	Loss 1.4319 (1.9524)	
24
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [25][10/345]	Time 0.615 (2.373)	Data 0.0000 (0.0000)	Loss 3.8024 (3.3445)	
label_Epoch: [25][20/345]	Time 0.637 (1.497)	Data 0.0000 (0.0000)	Loss 3.7765 (3.0934)	
label_Epoch: [25][30/345]	Time 0.609 (1.206)	Data 0.0000 (0.0000)	Loss 1.6211 (2.9002)	
label_Epoch: [25][40/345]	Time 0.610 (1.058)	Data 0.0000 (0.0000)	Loss 2.3650 (2.8042)	
label_Epoch: [25][50/345]	Time 0.621 (0.970)	Data 0.0000 (0.0000)	Loss 2.4503 (2.6663)	
label_Epoch: [25][60/345]	Time 0.611 (0.911)	Data 0.0000 (0.0000)	Loss 2.5304 (2.6032)	
label_Epoch: [25][70/345]	Time 0.623 (0.869)	Data 0.0000 (0.0000)	Loss 2.8642 (2.5922)	
label_Epoch: [25][80/345]	Time 0.620 (0.837)	Data 0.0000 (0.0000)	Loss 2.1230 (2.5357)	
label_Epoch: [25][90/345]	Time 0.649 (0.814)	Data 0.0000 (0.0000)	Loss 1.2217 (2.4665)	
label_Epoch: [25][100/345]	Time 0.618 (0.796)	Data 0.0000 (0.0000)	Loss 1.4094 (2.4295)	
label_Epoch: [25][110/345]	Time 0.628 (0.780)	Data 0.0000 (0.0000)	Loss 1.7807 (2.3696)	
label_Epoch: [25][120/345]	Time 0.608 (0.766)	Data 0.0000 (0.0000)	Loss 1.3354 (2.3431)	
label_Epoch: [25][130/345]	Time 0.603 (0.755)	Data 0.0000 (0.0000)	Loss 1.7498 (2.3106)	
label_Epoch: [25][140/345]	Time 0.614 (0.745)	Data 0.0000 (0.0000)	Loss 1.5253 (2.3046)	
label_Epoch: [25][150/345]	Time 0.617 (0.736)	Data 0.0000 (0.0000)	Loss 1.6909 (2.2643)	
label_Epoch: [25][160/345]	Time 0.634 (0.729)	Data 0.0000 (0.0000)	Loss 2.2921 (2.2428)	
label_Epoch: [25][170/345]	Time 0.609 (0.722)	Data 0.0000 (0.0000)	Loss 1.3903 (2.2159)	
label_Epoch: [25][180/345]	Time 0.606 (0.717)	Data 0.0000 (0.0000)	Loss 1.8043 (2.1904)	
label_Epoch: [25][190/345]	Time 0.638 (0.712)	Data 0.0000 (0.0000)	Loss 1.7875 (2.1738)	
label_Epoch: [25][200/345]	Time 0.644 (0.708)	Data 0.0000 (0.0000)	Loss 1.9278 (2.1559)	
label_Epoch: [25][210/345]	Time 0.615 (0.704)	Data 0.0000 (0.0000)	Loss 1.7239 (2.1347)	
label_Epoch: [25][220/345]	Time 0.636 (0.700)	Data 0.0000 (0.0000)	Loss 3.5505 (2.1189)	
label_Epoch: [25][230/345]	Time 0.638 (0.697)	Data 0.0000 (0.0000)	Loss 2.1051 (2.1065)	
label_Epoch: [25][240/345]	Time 0.637 (0.695)	Data 0.0000 (0.0000)	Loss 2.0279 (2.0883)	
label_Epoch: [25][250/345]	Time 0.619 (0.692)	Data 0.0000 (0.0000)	Loss 1.6711 (2.0712)	
label_Epoch: [25][260/345]	Time 0.620 (0.689)	Data 0.0000 (0.0000)	Loss 1.6929 (2.0497)	
label_Epoch: [25][270/345]	Time 0.615 (0.686)	Data 0.0000 (0.0000)	Loss 1.5243 (2.0237)	
label_Epoch: [25][280/345]	Time 0.616 (0.684)	Data 0.0000 (0.0000)	Loss 1.3863 (2.0025)	
label_Epoch: [25][290/345]	Time 0.596 (0.682)	Data 0.0000 (0.0000)	Loss 1.6247 (1.9864)	
label_Epoch: [25][300/345]	Time 0.607 (0.679)	Data 0.0000 (0.0000)	Loss 1.1999 (1.9682)	
label_Epoch: [25][310/345]	Time 0.619 (0.677)	Data 0.0000 (0.0000)	Loss 1.4876 (1.9495)	
label_Epoch: [25][320/345]	Time 0.635 (0.676)	Data 0.0000 (0.0000)	Loss 1.6596 (1.9371)	
label_Epoch: [25][330/345]	Time 0.617 (0.675)	Data 0.0000 (0.0000)	Loss 1.2355 (1.9205)	
label_Epoch: [25][340/345]	Time 0.626 (0.673)	Data 0.0000 (0.0000)	Loss 1.0799 (1.8996)	
25
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [26][10/345]	Time 0.612 (2.384)	Data 0.0000 (0.0000)	Loss 3.2717 (2.3654)	
label_Epoch: [26][20/345]	Time 0.626 (1.502)	Data 0.0000 (0.0000)	Loss 3.7563 (2.5074)	
label_Epoch: [26][30/345]	Time 0.617 (1.209)	Data 0.0000 (0.0000)	Loss 1.2572 (2.4292)	
label_Epoch: [26][40/345]	Time 0.622 (1.063)	Data 0.0000 (0.0000)	Loss 2.8682 (2.4295)	
label_Epoch: [26][50/345]	Time 0.624 (0.974)	Data 0.0000 (0.0000)	Loss 3.1253 (2.5030)	
label_Epoch: [26][60/345]	Time 0.621 (0.915)	Data 0.0000 (0.0000)	Loss 2.4986 (2.4244)	
label_Epoch: [26][70/345]	Time 0.625 (0.873)	Data 0.0000 (0.0000)	Loss 2.9878 (2.4450)	
label_Epoch: [26][80/345]	Time 0.637 (0.841)	Data 0.0000 (0.0000)	Loss 2.8556 (2.4275)	
label_Epoch: [26][90/345]	Time 0.631 (0.816)	Data 0.0000 (0.0000)	Loss 1.8626 (2.3928)	
label_Epoch: [26][100/345]	Time 0.604 (0.797)	Data 0.0000 (0.0000)	Loss 1.8824 (2.3737)	
label_Epoch: [26][110/345]	Time 0.619 (0.780)	Data 0.0000 (0.0000)	Loss 2.6944 (2.3454)	
label_Epoch: [26][120/345]	Time 0.625 (0.766)	Data 0.0000 (0.0000)	Loss 1.1876 (2.3282)	
label_Epoch: [26][130/345]	Time 0.601 (0.754)	Data 0.0000 (0.0000)	Loss 1.8382 (2.2837)	
label_Epoch: [26][140/345]	Time 0.623 (0.745)	Data 0.0000 (0.0000)	Loss 1.7957 (2.2422)	
label_Epoch: [26][150/345]	Time 0.621 (0.737)	Data 0.0000 (0.0000)	Loss 1.4620 (2.2129)	
label_Epoch: [26][160/345]	Time 0.625 (0.729)	Data 0.0000 (0.0000)	Loss 2.8728 (2.2109)	
label_Epoch: [26][170/345]	Time 0.619 (0.723)	Data 0.0000 (0.0000)	Loss 1.9433 (2.1920)	
label_Epoch: [26][180/345]	Time 0.613 (0.717)	Data 0.0000 (0.0000)	Loss 1.9334 (2.1688)	
label_Epoch: [26][190/345]	Time 0.651 (0.712)	Data 0.0000 (0.0000)	Loss 1.6762 (2.1470)	
label_Epoch: [26][200/345]	Time 0.611 (0.708)	Data 0.0000 (0.0000)	Loss 1.5053 (2.1184)	
label_Epoch: [26][210/345]	Time 0.606 (0.703)	Data 0.0000 (0.0000)	Loss 2.0660 (2.1038)	
label_Epoch: [26][220/345]	Time 0.622 (0.699)	Data 0.0000 (0.0000)	Loss 1.4304 (2.0761)	
label_Epoch: [26][230/345]	Time 0.613 (0.696)	Data 0.0000 (0.0000)	Loss 1.8331 (2.0559)	
label_Epoch: [26][240/345]	Time 0.635 (0.693)	Data 0.0000 (0.0000)	Loss 1.3010 (2.0327)	
label_Epoch: [26][250/345]	Time 0.619 (0.689)	Data 0.0000 (0.0000)	Loss 1.3200 (2.0181)	
label_Epoch: [26][260/345]	Time 0.617 (0.687)	Data 0.0000 (0.0000)	Loss 1.6029 (1.9957)	
label_Epoch: [26][270/345]	Time 0.612 (0.684)	Data 0.0000 (0.0000)	Loss 1.5404 (1.9760)	
label_Epoch: [26][280/345]	Time 0.613 (0.682)	Data 0.0000 (0.0000)	Loss 1.4778 (1.9575)	
label_Epoch: [26][290/345]	Time 0.607 (0.680)	Data 0.0000 (0.0000)	Loss 1.4627 (1.9479)	
label_Epoch: [26][300/345]	Time 0.601 (0.678)	Data 0.0000 (0.0000)	Loss 1.2773 (1.9286)	
label_Epoch: [26][310/345]	Time 0.625 (0.676)	Data 0.0000 (0.0000)	Loss 1.2468 (1.9110)	
label_Epoch: [26][320/345]	Time 0.610 (0.674)	Data 0.0000 (0.0000)	Loss 1.1849 (1.8976)	
label_Epoch: [26][330/345]	Time 0.604 (0.672)	Data 0.0000 (0.0000)	Loss 1.2415 (1.8832)	
label_Epoch: [26][340/345]	Time 0.604 (0.670)	Data 0.0000 (0.0000)	Loss 1.0733 (1.8661)	
26
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [27][10/345]	Time 0.619 (2.379)	Data 0.0000 (0.0000)	Loss 4.3373 (2.9846)	
label_Epoch: [27][20/345]	Time 0.620 (1.497)	Data 0.0000 (0.0000)	Loss 3.2998 (2.8698)	
label_Epoch: [27][30/345]	Time 0.637 (1.209)	Data 0.0000 (0.0000)	Loss 2.2853 (2.7806)	
label_Epoch: [27][40/345]	Time 0.627 (1.063)	Data 0.0000 (0.0000)	Loss 1.5084 (2.5640)	
label_Epoch: [27][50/345]	Time 0.617 (0.976)	Data 0.0000 (0.0000)	Loss 1.6511 (2.4754)	
label_Epoch: [27][60/345]	Time 0.605 (0.917)	Data 0.0000 (0.0000)	Loss 1.2613 (2.3926)	
label_Epoch: [27][70/345]	Time 0.618 (0.875)	Data 0.0000 (0.0000)	Loss 2.3770 (2.4235)	
label_Epoch: [27][80/345]	Time 0.615 (0.843)	Data 0.0000 (0.0000)	Loss 2.7369 (2.4070)	
label_Epoch: [27][90/345]	Time 0.620 (0.818)	Data 0.0000 (0.0000)	Loss 2.2765 (2.3386)	
label_Epoch: [27][100/345]	Time 0.611 (0.798)	Data 0.0000 (0.0000)	Loss 2.3913 (2.3415)	
label_Epoch: [27][110/345]	Time 0.628 (0.782)	Data 0.0000 (0.0000)	Loss 1.5083 (2.3104)	
label_Epoch: [27][120/345]	Time 0.613 (0.769)	Data 0.0000 (0.0000)	Loss 1.8214 (2.2771)	
label_Epoch: [27][130/345]	Time 0.633 (0.757)	Data 0.0000 (0.0000)	Loss 1.4833 (2.2456)	
label_Epoch: [27][140/345]	Time 0.614 (0.747)	Data 0.0000 (0.0000)	Loss 1.6846 (2.2197)	
label_Epoch: [27][150/345]	Time 0.599 (0.738)	Data 0.0000 (0.0000)	Loss 2.0400 (2.1868)	
label_Epoch: [27][160/345]	Time 0.610 (0.731)	Data 0.0000 (0.0000)	Loss 2.2224 (2.1620)	
label_Epoch: [27][170/345]	Time 0.622 (0.724)	Data 0.0000 (0.0000)	Loss 2.7785 (2.1468)	
label_Epoch: [27][180/345]	Time 0.609 (0.718)	Data 0.0000 (0.0000)	Loss 1.6440 (2.1168)	
label_Epoch: [27][190/345]	Time 0.631 (0.713)	Data 0.0000 (0.0000)	Loss 1.7416 (2.1080)	
label_Epoch: [27][200/345]	Time 0.600 (0.708)	Data 0.0000 (0.0000)	Loss 1.3786 (2.0841)	
label_Epoch: [27][210/345]	Time 0.624 (0.703)	Data 0.0000 (0.0000)	Loss 1.6277 (2.0562)	
label_Epoch: [27][220/345]	Time 0.603 (0.699)	Data 0.0000 (0.0000)	Loss 1.9050 (2.0428)	
label_Epoch: [27][230/345]	Time 0.612 (0.696)	Data 0.0000 (0.0000)	Loss 1.8984 (2.0256)	
label_Epoch: [27][240/345]	Time 0.630 (0.693)	Data 0.0000 (0.0000)	Loss 1.5808 (2.0088)	
label_Epoch: [27][250/345]	Time 0.613 (0.690)	Data 0.0000 (0.0000)	Loss 1.3525 (1.9941)	
label_Epoch: [27][260/345]	Time 0.603 (0.687)	Data 0.0000 (0.0000)	Loss 1.5193 (1.9797)	
label_Epoch: [27][270/345]	Time 0.628 (0.685)	Data 0.0000 (0.0000)	Loss 1.2742 (1.9599)	
label_Epoch: [27][280/345]	Time 0.625 (0.682)	Data 0.0000 (0.0000)	Loss 1.3380 (1.9416)	
label_Epoch: [27][290/345]	Time 0.618 (0.680)	Data 0.0000 (0.0000)	Loss 1.3416 (1.9294)	
label_Epoch: [27][300/345]	Time 0.617 (0.678)	Data 0.0000 (0.0000)	Loss 1.6389 (1.9120)	
label_Epoch: [27][310/345]	Time 0.610 (0.676)	Data 0.0000 (0.0000)	Loss 1.3191 (1.9042)	
label_Epoch: [27][320/345]	Time 0.617 (0.674)	Data 0.0000 (0.0000)	Loss 1.3776 (1.8936)	
label_Epoch: [27][330/345]	Time 0.618 (0.672)	Data 0.0000 (0.0000)	Loss 1.2169 (1.8784)	
label_Epoch: [27][340/345]	Time 0.602 (0.671)	Data 0.0000 (0.0000)	Loss 1.2208 (1.8649)	
27
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [28][10/345]	Time 0.621 (2.390)	Data 0.0000 (0.0000)	Loss 3.0361 (2.7081)	
label_Epoch: [28][20/345]	Time 0.603 (1.506)	Data 0.0000 (0.0000)	Loss 1.8536 (2.4844)	
label_Epoch: [28][30/345]	Time 0.617 (1.209)	Data 0.0000 (0.0000)	Loss 3.0638 (2.3408)	
label_Epoch: [28][40/345]	Time 0.612 (1.060)	Data 0.0000 (0.0000)	Loss 2.0048 (2.3001)	
label_Epoch: [28][50/345]	Time 0.611 (0.972)	Data 0.0000 (0.0000)	Loss 2.5863 (2.3574)	
label_Epoch: [28][60/345]	Time 0.617 (0.914)	Data 0.0000 (0.0000)	Loss 3.5314 (2.4172)	
label_Epoch: [28][70/345]	Time 0.615 (0.872)	Data 0.0000 (0.0000)	Loss 2.5956 (2.3926)	
label_Epoch: [28][80/345]	Time 0.629 (0.840)	Data 0.0000 (0.0000)	Loss 2.0768 (2.3430)	
label_Epoch: [28][90/345]	Time 0.617 (0.816)	Data 0.0000 (0.0000)	Loss 2.5418 (2.3312)	
label_Epoch: [28][100/345]	Time 0.620 (0.797)	Data 0.0000 (0.0000)	Loss 1.6592 (2.2841)	
label_Epoch: [28][110/345]	Time 0.634 (0.780)	Data 0.0000 (0.0000)	Loss 1.4583 (2.2451)	
label_Epoch: [28][120/345]	Time 0.602 (0.766)	Data 0.0000 (0.0000)	Loss 1.6666 (2.2083)	
label_Epoch: [28][130/345]	Time 0.601 (0.755)	Data 0.0000 (0.0000)	Loss 1.7609 (2.1795)	
label_Epoch: [28][140/345]	Time 0.604 (0.745)	Data 0.0000 (0.0000)	Loss 1.6589 (2.1665)	
label_Epoch: [28][150/345]	Time 0.615 (0.736)	Data 0.0000 (0.0000)	Loss 1.5359 (2.1387)	
label_Epoch: [28][160/345]	Time 0.615 (0.728)	Data 0.0000 (0.0000)	Loss 2.0261 (2.1165)	
label_Epoch: [28][170/345]	Time 0.620 (0.722)	Data 0.0000 (0.0000)	Loss 1.5023 (2.0985)	
label_Epoch: [28][180/345]	Time 0.616 (0.716)	Data 0.0000 (0.0000)	Loss 1.3826 (2.0770)	
label_Epoch: [28][190/345]	Time 0.620 (0.711)	Data 0.0000 (0.0000)	Loss 1.9495 (2.0568)	
label_Epoch: [28][200/345]	Time 0.602 (0.706)	Data 0.0000 (0.0000)	Loss 2.2405 (2.0340)	
label_Epoch: [28][210/345]	Time 0.599 (0.702)	Data 0.0000 (0.0000)	Loss 1.7326 (2.0215)	
label_Epoch: [28][220/345]	Time 0.600 (0.698)	Data 0.0000 (0.0000)	Loss 1.3817 (2.0062)	
label_Epoch: [28][230/345]	Time 0.621 (0.694)	Data 0.0000 (0.0000)	Loss 1.8728 (1.9958)	
label_Epoch: [28][240/345]	Time 0.619 (0.691)	Data 0.0000 (0.0000)	Loss 1.6180 (1.9773)	
label_Epoch: [28][250/345]	Time 0.632 (0.688)	Data 0.0000 (0.0000)	Loss 1.4319 (1.9612)	
label_Epoch: [28][260/345]	Time 0.628 (0.686)	Data 0.0000 (0.0000)	Loss 1.2605 (1.9415)	
label_Epoch: [28][270/345]	Time 0.610 (0.683)	Data 0.0000 (0.0000)	Loss 1.3180 (1.9264)	
label_Epoch: [28][280/345]	Time 0.602 (0.681)	Data 0.0000 (0.0000)	Loss 1.8633 (1.9130)	
label_Epoch: [28][290/345]	Time 0.622 (0.679)	Data 0.0000 (0.0000)	Loss 1.4752 (1.8970)	
label_Epoch: [28][300/345]	Time 0.624 (0.677)	Data 0.0000 (0.0000)	Loss 1.3868 (1.8840)	
label_Epoch: [28][310/345]	Time 0.617 (0.675)	Data 0.0000 (0.0000)	Loss 1.2674 (1.8734)	
label_Epoch: [28][320/345]	Time 0.600 (0.673)	Data 0.0000 (0.0000)	Loss 1.1615 (1.8591)	
label_Epoch: [28][330/345]	Time 0.622 (0.671)	Data 0.0000 (0.0000)	Loss 1.2293 (1.8446)	
label_Epoch: [28][340/345]	Time 0.614 (0.670)	Data 0.0000 (0.0000)	Loss 1.2148 (1.8261)	
28
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [29][10/345]	Time 0.615 (2.408)	Data 0.0000 (0.0000)	Loss 2.1043 (2.6080)	
label_Epoch: [29][20/345]	Time 0.618 (1.516)	Data 0.0000 (0.0000)	Loss 2.0043 (2.5936)	
label_Epoch: [29][30/345]	Time 0.629 (1.218)	Data 0.0000 (0.0000)	Loss 3.1525 (2.5240)	
label_Epoch: [29][40/345]	Time 0.629 (1.068)	Data 0.0000 (0.0000)	Loss 2.1930 (2.4633)	
label_Epoch: [29][50/345]	Time 0.641 (0.978)	Data 0.0000 (0.0000)	Loss 2.4410 (2.3742)	
label_Epoch: [29][60/345]	Time 0.623 (0.918)	Data 0.0000 (0.0000)	Loss 3.0145 (2.3639)	
label_Epoch: [29][70/345]	Time 0.628 (0.877)	Data 0.0000 (0.0000)	Loss 2.4435 (2.3763)	
label_Epoch: [29][80/345]	Time 0.629 (0.845)	Data 0.0000 (0.0000)	Loss 1.7784 (2.3326)	
label_Epoch: [29][90/345]	Time 0.616 (0.822)	Data 0.0000 (0.0000)	Loss 1.9448 (2.2850)	
label_Epoch: [29][100/345]	Time 0.619 (0.802)	Data 0.0000 (0.0000)	Loss 2.4845 (2.2588)	
label_Epoch: [29][110/345]	Time 0.623 (0.786)	Data 0.0000 (0.0000)	Loss 2.8645 (2.2256)	
label_Epoch: [29][120/345]	Time 0.653 (0.773)	Data 0.0000 (0.0000)	Loss 1.2000 (2.2068)	
label_Epoch: [29][130/345]	Time 0.645 (0.762)	Data 0.0000 (0.0000)	Loss 1.8818 (2.1981)	
label_Epoch: [29][140/345]	Time 0.616 (0.752)	Data 0.0000 (0.0000)	Loss 1.1724 (2.1623)	
label_Epoch: [29][150/345]	Time 0.616 (0.744)	Data 0.0000 (0.0000)	Loss 1.8008 (2.1350)	
label_Epoch: [29][160/345]	Time 0.623 (0.737)	Data 0.0000 (0.0000)	Loss 1.3870 (2.1090)	
label_Epoch: [29][170/345]	Time 0.608 (0.730)	Data 0.0000 (0.0000)	Loss 1.6649 (2.0863)	
label_Epoch: [29][180/345]	Time 0.611 (0.724)	Data 0.0000 (0.0000)	Loss 1.5340 (2.0671)	
label_Epoch: [29][190/345]	Time 0.612 (0.719)	Data 0.0000 (0.0000)	Loss 1.3581 (2.0538)	
label_Epoch: [29][200/345]	Time 0.613 (0.714)	Data 0.0000 (0.0000)	Loss 1.4197 (2.0374)	
label_Epoch: [29][210/345]	Time 0.616 (0.709)	Data 0.0000 (0.0000)	Loss 1.6864 (2.0249)	
label_Epoch: [29][220/345]	Time 0.610 (0.705)	Data 0.0000 (0.0000)	Loss 1.7747 (2.0017)	
label_Epoch: [29][230/345]	Time 0.609 (0.701)	Data 0.0000 (0.0000)	Loss 1.2397 (1.9845)	
label_Epoch: [29][240/345]	Time 0.614 (0.697)	Data 0.0000 (0.0000)	Loss 1.4236 (1.9649)	
label_Epoch: [29][250/345]	Time 0.634 (0.694)	Data 0.0000 (0.0000)	Loss 1.2387 (1.9523)	
label_Epoch: [29][260/345]	Time 0.602 (0.691)	Data 0.0000 (0.0000)	Loss 1.3415 (1.9329)	
label_Epoch: [29][270/345]	Time 0.626 (0.688)	Data 0.0000 (0.0000)	Loss 1.2429 (1.9140)	
label_Epoch: [29][280/345]	Time 0.602 (0.685)	Data 0.0000 (0.0000)	Loss 1.6663 (1.9031)	
label_Epoch: [29][290/345]	Time 0.615 (0.683)	Data 0.0000 (0.0000)	Loss 1.7268 (1.8853)	
label_Epoch: [29][300/345]	Time 0.622 (0.680)	Data 0.0000 (0.0000)	Loss 1.7732 (1.8718)	
label_Epoch: [29][310/345]	Time 0.618 (0.678)	Data 0.0000 (0.0000)	Loss 1.1714 (1.8591)	
label_Epoch: [29][320/345]	Time 0.621 (0.676)	Data 0.0000 (0.0000)	Loss 1.2996 (1.8423)	
label_Epoch: [29][330/345]	Time 0.620 (0.675)	Data 0.0000 (0.0000)	Loss 1.1564 (1.8289)	
label_Epoch: [29][340/345]	Time 0.625 (0.673)	Data 0.0000 (0.0000)	Loss 1.1758 (1.8128)	
29
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [30][10/345]	Time 0.616 (2.316)	Data 0.0000 (0.0000)	Loss 2.5383 (2.5439)	
label_Epoch: [30][20/345]	Time 0.618 (1.467)	Data 0.0000 (0.0000)	Loss 1.9713 (2.5503)	
label_Epoch: [30][30/345]	Time 0.613 (1.185)	Data 0.0000 (0.0000)	Loss 1.8715 (2.5044)	
label_Epoch: [30][40/345]	Time 0.604 (1.043)	Data 0.0000 (0.0000)	Loss 1.5093 (2.4323)	
label_Epoch: [30][50/345]	Time 0.618 (0.958)	Data 0.0000 (0.0000)	Loss 2.9312 (2.3926)	
label_Epoch: [30][60/345]	Time 0.616 (0.901)	Data 0.0000 (0.0000)	Loss 1.6683 (2.3135)	
label_Epoch: [30][70/345]	Time 0.617 (0.860)	Data 0.0000 (0.0000)	Loss 1.7253 (2.2835)	
label_Epoch: [30][80/345]	Time 0.633 (0.830)	Data 0.0000 (0.0000)	Loss 2.2205 (2.2384)	
label_Epoch: [30][90/345]	Time 0.624 (0.807)	Data 0.0000 (0.0000)	Loss 1.3541 (2.2273)	
label_Epoch: [30][100/345]	Time 0.618 (0.789)	Data 0.0000 (0.0000)	Loss 1.6611 (2.1926)	
label_Epoch: [30][110/345]	Time 0.623 (0.772)	Data 0.0000 (0.0000)	Loss 1.7176 (2.1532)	
label_Epoch: [30][120/345]	Time 0.620 (0.760)	Data 0.0000 (0.0000)	Loss 2.3842 (2.1366)	
label_Epoch: [30][130/345]	Time 0.611 (0.749)	Data 0.0000 (0.0000)	Loss 1.2460 (2.1052)	
label_Epoch: [30][140/345]	Time 0.602 (0.739)	Data 0.0000 (0.0000)	Loss 2.4452 (2.0843)	
label_Epoch: [30][150/345]	Time 0.607 (0.731)	Data 0.0000 (0.0000)	Loss 1.2887 (2.0397)	
label_Epoch: [30][160/345]	Time 0.597 (0.724)	Data 0.0000 (0.0000)	Loss 1.3206 (2.0287)	
label_Epoch: [30][170/345]	Time 0.644 (0.717)	Data 0.0000 (0.0000)	Loss 2.0222 (2.0140)	
label_Epoch: [30][180/345]	Time 0.611 (0.712)	Data 0.0000 (0.0000)	Loss 1.6788 (2.0109)	
label_Epoch: [30][190/345]	Time 0.601 (0.707)	Data 0.0000 (0.0000)	Loss 1.3252 (1.9957)	
label_Epoch: [30][200/345]	Time 0.618 (0.703)	Data 0.0000 (0.0000)	Loss 1.8705 (1.9766)	
label_Epoch: [30][210/345]	Time 0.606 (0.699)	Data 0.0000 (0.0000)	Loss 1.1071 (1.9569)	
label_Epoch: [30][220/345]	Time 0.625 (0.695)	Data 0.0000 (0.0000)	Loss 1.5675 (1.9454)	
label_Epoch: [30][230/345]	Time 0.623 (0.692)	Data 0.0000 (0.0000)	Loss 1.8107 (1.9399)	
label_Epoch: [30][240/345]	Time 0.618 (0.688)	Data 0.0000 (0.0000)	Loss 1.4401 (1.9275)	
label_Epoch: [30][250/345]	Time 0.614 (0.686)	Data 0.0000 (0.0000)	Loss 1.6168 (1.9135)	
label_Epoch: [30][260/345]	Time 0.609 (0.683)	Data 0.0000 (0.0000)	Loss 1.2903 (1.8963)	
label_Epoch: [30][270/345]	Time 0.610 (0.681)	Data 0.0000 (0.0000)	Loss 1.1530 (1.8866)	
label_Epoch: [30][280/345]	Time 0.621 (0.678)	Data 0.0000 (0.0000)	Loss 1.4102 (1.8755)	
label_Epoch: [30][290/345]	Time 0.621 (0.676)	Data 0.0000 (0.0000)	Loss 1.2425 (1.8581)	
label_Epoch: [30][300/345]	Time 0.617 (0.674)	Data 0.0000 (0.0000)	Loss 1.4754 (1.8451)	
label_Epoch: [30][310/345]	Time 0.642 (0.672)	Data 0.0000 (0.0000)	Loss 1.2943 (1.8312)	
label_Epoch: [30][320/345]	Time 0.607 (0.671)	Data 0.0000 (0.0000)	Loss 1.2481 (1.8163)	
label_Epoch: [30][330/345]	Time 0.602 (0.669)	Data 0.0000 (0.0000)	Loss 1.1247 (1.7966)	
label_Epoch: [30][340/345]	Time 0.619 (0.668)	Data 0.0000 (0.0000)	Loss 1.1315 (1.7805)	
30
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [31][10/345]	Time 0.606 (2.512)	Data 0.0000 (0.0000)	Loss 1.8802 (2.3526)	
label_Epoch: [31][20/345]	Time 0.605 (1.561)	Data 0.0000 (0.0000)	Loss 2.2970 (2.3853)	
label_Epoch: [31][30/345]	Time 0.629 (1.247)	Data 0.0000 (0.0000)	Loss 1.3870 (2.2221)	
label_Epoch: [31][40/345]	Time 0.629 (1.090)	Data 0.0000 (0.0000)	Loss 1.7557 (2.1660)	
label_Epoch: [31][50/345]	Time 0.630 (0.995)	Data 0.0000 (0.0000)	Loss 2.2969 (2.1725)	
label_Epoch: [31][60/345]	Time 0.628 (0.933)	Data 0.0000 (0.0000)	Loss 2.8511 (2.1951)	
label_Epoch: [31][70/345]	Time 0.617 (0.888)	Data 0.0000 (0.0000)	Loss 1.6350 (2.1438)	
label_Epoch: [31][80/345]	Time 0.611 (0.855)	Data 0.0000 (0.0000)	Loss 2.2738 (2.0968)	
label_Epoch: [31][90/345]	Time 0.616 (0.828)	Data 0.0000 (0.0000)	Loss 2.2553 (2.0845)	
label_Epoch: [31][100/345]	Time 0.610 (0.807)	Data 0.0000 (0.0000)	Loss 1.3957 (2.1067)	
label_Epoch: [31][110/345]	Time 0.611 (0.789)	Data 0.0000 (0.0000)	Loss 2.4437 (2.0957)	
label_Epoch: [31][120/345]	Time 0.618 (0.774)	Data 0.0000 (0.0000)	Loss 1.6941 (2.0497)	
label_Epoch: [31][130/345]	Time 0.607 (0.762)	Data 0.0000 (0.0000)	Loss 1.4206 (2.0302)	
label_Epoch: [31][140/345]	Time 0.617 (0.752)	Data 0.0000 (0.0000)	Loss 1.7046 (2.0233)	
label_Epoch: [31][150/345]	Time 0.625 (0.743)	Data 0.0000 (0.0000)	Loss 2.4577 (2.0025)	
label_Epoch: [31][160/345]	Time 0.606 (0.735)	Data 0.0000 (0.0000)	Loss 1.5189 (1.9798)	
label_Epoch: [31][170/345]	Time 0.617 (0.728)	Data 0.0000 (0.0000)	Loss 1.1874 (1.9664)	
label_Epoch: [31][180/345]	Time 0.628 (0.722)	Data 0.0000 (0.0000)	Loss 2.1494 (1.9491)	
label_Epoch: [31][190/345]	Time 0.627 (0.717)	Data 0.0000 (0.0000)	Loss 1.9969 (1.9356)	
label_Epoch: [31][200/345]	Time 0.617 (0.712)	Data 0.0000 (0.0000)	Loss 1.4305 (1.9226)	
label_Epoch: [31][210/345]	Time 0.630 (0.707)	Data 0.0000 (0.0000)	Loss 1.4914 (1.9124)	
label_Epoch: [31][220/345]	Time 0.620 (0.703)	Data 0.0000 (0.0000)	Loss 1.1351 (1.8933)	
label_Epoch: [31][230/345]	Time 0.610 (0.699)	Data 0.0000 (0.0000)	Loss 1.7455 (1.8812)	
label_Epoch: [31][240/345]	Time 0.622 (0.696)	Data 0.0000 (0.0000)	Loss 2.1089 (1.8674)	
label_Epoch: [31][250/345]	Time 0.602 (0.693)	Data 0.0000 (0.0000)	Loss 1.2898 (1.8570)	
label_Epoch: [31][260/345]	Time 0.610 (0.690)	Data 0.0000 (0.0000)	Loss 1.3538 (1.8404)	
label_Epoch: [31][270/345]	Time 0.610 (0.687)	Data 0.0000 (0.0000)	Loss 1.6113 (1.8260)	
label_Epoch: [31][280/345]	Time 0.616 (0.685)	Data 0.0000 (0.0000)	Loss 1.6106 (1.8191)	
label_Epoch: [31][290/345]	Time 0.604 (0.683)	Data 0.0000 (0.0000)	Loss 1.3012 (1.8051)	
label_Epoch: [31][300/345]	Time 0.612 (0.680)	Data 0.0000 (0.0000)	Loss 1.3034 (1.7965)	
label_Epoch: [31][310/345]	Time 0.624 (0.678)	Data 0.0000 (0.0000)	Loss 1.2929 (1.7848)	
label_Epoch: [31][320/345]	Time 0.630 (0.676)	Data 0.0000 (0.0000)	Loss 1.1491 (1.7736)	
label_Epoch: [31][330/345]	Time 0.605 (0.674)	Data 0.0000 (0.0000)	Loss 1.1643 (1.7568)	
label_Epoch: [31][340/345]	Time 0.599 (0.673)	Data 0.0000 (0.0000)	Loss 1.0699 (1.7396)	
31
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [32][10/345]	Time 0.601 (2.368)	Data 0.0000 (0.0000)	Loss 1.5523 (2.5299)	
label_Epoch: [32][20/345]	Time 0.629 (1.491)	Data 0.0000 (0.0000)	Loss 1.3191 (2.2916)	
label_Epoch: [32][30/345]	Time 0.627 (1.199)	Data 0.0000 (0.0000)	Loss 3.8861 (2.4006)	
label_Epoch: [32][40/345]	Time 0.614 (1.052)	Data 0.0000 (0.0000)	Loss 3.1895 (2.4490)	
label_Epoch: [32][50/345]	Time 0.603 (0.964)	Data 0.0000 (0.0000)	Loss 1.4675 (2.3803)	
label_Epoch: [32][60/345]	Time 0.610 (0.905)	Data 0.0000 (0.0000)	Loss 2.8216 (2.3250)	
label_Epoch: [32][70/345]	Time 0.641 (0.864)	Data 0.0000 (0.0000)	Loss 1.6863 (2.2643)	
label_Epoch: [32][80/345]	Time 0.624 (0.834)	Data 0.0000 (0.0000)	Loss 2.0386 (2.2205)	
label_Epoch: [32][90/345]	Time 0.602 (0.810)	Data 0.0000 (0.0000)	Loss 1.4310 (2.1657)	
label_Epoch: [32][100/345]	Time 0.614 (0.791)	Data 0.0000 (0.0000)	Loss 1.9522 (2.1625)	
label_Epoch: [32][110/345]	Time 0.600 (0.775)	Data 0.0000 (0.0000)	Loss 1.7652 (2.1308)	
label_Epoch: [32][120/345]	Time 0.644 (0.762)	Data 0.0000 (0.0000)	Loss 1.5553 (2.1037)	
label_Epoch: [32][130/345]	Time 0.635 (0.751)	Data 0.0000 (0.0000)	Loss 1.9350 (2.0757)	
label_Epoch: [32][140/345]	Time 0.620 (0.741)	Data 0.0000 (0.0000)	Loss 1.3288 (2.0411)	
label_Epoch: [32][150/345]	Time 0.613 (0.733)	Data 0.0000 (0.0000)	Loss 2.1912 (2.0243)	
label_Epoch: [32][160/345]	Time 0.599 (0.726)	Data 0.0000 (0.0000)	Loss 1.5067 (2.0138)	
label_Epoch: [32][170/345]	Time 0.609 (0.720)	Data 0.0000 (0.0000)	Loss 1.7070 (1.9975)	
label_Epoch: [32][180/345]	Time 0.609 (0.714)	Data 0.0000 (0.0000)	Loss 1.5822 (1.9671)	
label_Epoch: [32][190/345]	Time 0.603 (0.709)	Data 0.0000 (0.0000)	Loss 1.7031 (1.9433)	
label_Epoch: [32][200/345]	Time 0.630 (0.704)	Data 0.0000 (0.0000)	Loss 1.4193 (1.9289)	
label_Epoch: [32][210/345]	Time 0.609 (0.700)	Data 0.0000 (0.0000)	Loss 1.8148 (1.9169)	
label_Epoch: [32][220/345]	Time 0.623 (0.696)	Data 0.0000 (0.0000)	Loss 1.3435 (1.8966)	
label_Epoch: [32][230/345]	Time 0.624 (0.693)	Data 0.0000 (0.0000)	Loss 1.5204 (1.8785)	
label_Epoch: [32][240/345]	Time 0.606 (0.690)	Data 0.0000 (0.0000)	Loss 1.9931 (1.8622)	
label_Epoch: [32][250/345]	Time 0.601 (0.687)	Data 0.0000 (0.0000)	Loss 1.3069 (1.8488)	
label_Epoch: [32][260/345]	Time 0.610 (0.685)	Data 0.0000 (0.0000)	Loss 1.6338 (1.8350)	
label_Epoch: [32][270/345]	Time 0.642 (0.682)	Data 0.0000 (0.0000)	Loss 1.4502 (1.8246)	
label_Epoch: [32][280/345]	Time 0.605 (0.680)	Data 0.0000 (0.0000)	Loss 1.4213 (1.8134)	
label_Epoch: [32][290/345]	Time 0.636 (0.678)	Data 0.0000 (0.0000)	Loss 1.4936 (1.7994)	
label_Epoch: [32][300/345]	Time 0.625 (0.676)	Data 0.0000 (0.0000)	Loss 1.5087 (1.7851)	
label_Epoch: [32][310/345]	Time 0.623 (0.674)	Data 0.0000 (0.0000)	Loss 1.1394 (1.7702)	
label_Epoch: [32][320/345]	Time 0.619 (0.673)	Data 0.0000 (0.0000)	Loss 1.2235 (1.7540)	
label_Epoch: [32][330/345]	Time 0.620 (0.671)	Data 0.0000 (0.0000)	Loss 1.2774 (1.7410)	
label_Epoch: [32][340/345]	Time 0.612 (0.669)	Data 0.0000 (0.0000)	Loss 1.1093 (1.7241)	
32
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [33][10/345]	Time 0.619 (2.346)	Data 0.0000 (0.0000)	Loss 2.4634 (2.1842)	
label_Epoch: [33][20/345]	Time 0.620 (1.484)	Data 0.0000 (0.0000)	Loss 2.0269 (2.2436)	
label_Epoch: [33][30/345]	Time 0.615 (1.196)	Data 0.0000 (0.0000)	Loss 3.0671 (2.3269)	
label_Epoch: [33][40/345]	Time 0.619 (1.051)	Data 0.0000 (0.0000)	Loss 2.5951 (2.2731)	
label_Epoch: [33][50/345]	Time 0.619 (0.964)	Data 0.0000 (0.0000)	Loss 2.4317 (2.2688)	
label_Epoch: [33][60/345]	Time 0.634 (0.906)	Data 0.0000 (0.0000)	Loss 1.6730 (2.2268)	
label_Epoch: [33][70/345]	Time 0.623 (0.865)	Data 0.0000 (0.0000)	Loss 2.5616 (2.2258)	
label_Epoch: [33][80/345]	Time 0.615 (0.834)	Data 0.0000 (0.0000)	Loss 2.4382 (2.2126)	
label_Epoch: [33][90/345]	Time 0.636 (0.811)	Data 0.0000 (0.0000)	Loss 1.9658 (2.1600)	
label_Epoch: [33][100/345]	Time 0.616 (0.792)	Data 0.0000 (0.0000)	Loss 1.7919 (2.1663)	
label_Epoch: [33][110/345]	Time 0.626 (0.776)	Data 0.0000 (0.0000)	Loss 1.1700 (2.1187)	
label_Epoch: [33][120/345]	Time 0.605 (0.764)	Data 0.0000 (0.0000)	Loss 3.2777 (2.1005)	
label_Epoch: [33][130/345]	Time 0.614 (0.752)	Data 0.0000 (0.0000)	Loss 1.4137 (2.0807)	
label_Epoch: [33][140/345]	Time 0.607 (0.743)	Data 0.0000 (0.0000)	Loss 1.9348 (2.0600)	
label_Epoch: [33][150/345]	Time 0.646 (0.734)	Data 0.0000 (0.0000)	Loss 1.4009 (2.0306)	
label_Epoch: [33][160/345]	Time 0.626 (0.727)	Data 0.0000 (0.0000)	Loss 1.5470 (1.9992)	
label_Epoch: [33][170/345]	Time 0.616 (0.721)	Data 0.0000 (0.0000)	Loss 1.5550 (1.9738)	
label_Epoch: [33][180/345]	Time 0.621 (0.715)	Data 0.0000 (0.0000)	Loss 1.8110 (1.9488)	
label_Epoch: [33][190/345]	Time 0.637 (0.710)	Data 0.0000 (0.0000)	Loss 2.2482 (1.9310)	
label_Epoch: [33][200/345]	Time 0.625 (0.706)	Data 0.0000 (0.0000)	Loss 1.5172 (1.9199)	
label_Epoch: [33][210/345]	Time 0.610 (0.702)	Data 0.0000 (0.0000)	Loss 1.9290 (1.9010)	
label_Epoch: [33][220/345]	Time 0.611 (0.698)	Data 0.0000 (0.0000)	Loss 1.1329 (1.8819)	
label_Epoch: [33][230/345]	Time 0.606 (0.694)	Data 0.0000 (0.0000)	Loss 1.5990 (1.8728)	
label_Epoch: [33][240/345]	Time 0.615 (0.691)	Data 0.0000 (0.0000)	Loss 1.4583 (1.8601)	
label_Epoch: [33][250/345]	Time 0.619 (0.688)	Data 0.0000 (0.0000)	Loss 1.4340 (1.8391)	
label_Epoch: [33][260/345]	Time 0.622 (0.686)	Data 0.0000 (0.0000)	Loss 2.4207 (1.8279)	
label_Epoch: [33][270/345]	Time 0.609 (0.683)	Data 0.0000 (0.0000)	Loss 1.5549 (1.8179)	
label_Epoch: [33][280/345]	Time 0.606 (0.680)	Data 0.0000 (0.0000)	Loss 1.1694 (1.8010)	
label_Epoch: [33][290/345]	Time 0.601 (0.678)	Data 0.0000 (0.0000)	Loss 1.1087 (1.7852)	
label_Epoch: [33][300/345]	Time 0.615 (0.676)	Data 0.0000 (0.0000)	Loss 1.3768 (1.7740)	
label_Epoch: [33][310/345]	Time 0.613 (0.674)	Data 0.0000 (0.0000)	Loss 1.3852 (1.7574)	
label_Epoch: [33][320/345]	Time 0.614 (0.672)	Data 0.0000 (0.0000)	Loss 1.1329 (1.7416)	
label_Epoch: [33][330/345]	Time 0.630 (0.671)	Data 0.0000 (0.0000)	Loss 1.0921 (1.7258)	
label_Epoch: [33][340/345]	Time 0.623 (0.669)	Data 0.0000 (0.0000)	Loss 1.0795 (1.7102)	
33
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [34][10/345]	Time 0.601 (2.477)	Data 0.0000 (0.0000)	Loss 2.5297 (2.4110)	
label_Epoch: [34][20/345]	Time 0.621 (1.547)	Data 0.0000 (0.0000)	Loss 3.4547 (2.3189)	
label_Epoch: [34][30/345]	Time 0.612 (1.237)	Data 0.0000 (0.0000)	Loss 1.5107 (2.1727)	
label_Epoch: [34][40/345]	Time 0.603 (1.082)	Data 0.0000 (0.0000)	Loss 1.3305 (2.1168)	
label_Epoch: [34][50/345]	Time 0.637 (0.990)	Data 0.0000 (0.0000)	Loss 1.4204 (2.0837)	
label_Epoch: [34][60/345]	Time 0.620 (0.928)	Data 0.0000 (0.0000)	Loss 1.9648 (2.0720)	
label_Epoch: [34][70/345]	Time 0.629 (0.884)	Data 0.0000 (0.0000)	Loss 1.5634 (2.1074)	
label_Epoch: [34][80/345]	Time 0.629 (0.851)	Data 0.0000 (0.0000)	Loss 2.6290 (2.0969)	
label_Epoch: [34][90/345]	Time 0.619 (0.825)	Data 0.0000 (0.0000)	Loss 1.7332 (2.0909)	
label_Epoch: [34][100/345]	Time 0.609 (0.804)	Data 0.0000 (0.0000)	Loss 1.9006 (2.0987)	
label_Epoch: [34][110/345]	Time 0.617 (0.787)	Data 0.0000 (0.0000)	Loss 1.1783 (2.0584)	
label_Epoch: [34][120/345]	Time 0.605 (0.772)	Data 0.0000 (0.0000)	Loss 2.1736 (2.0529)	
label_Epoch: [34][130/345]	Time 0.606 (0.761)	Data 0.0000 (0.0000)	Loss 1.4398 (2.0240)	
label_Epoch: [34][140/345]	Time 0.628 (0.751)	Data 0.0000 (0.0000)	Loss 1.6641 (1.9831)	
label_Epoch: [34][150/345]	Time 0.614 (0.742)	Data 0.0000 (0.0000)	Loss 1.4188 (1.9576)	
label_Epoch: [34][160/345]	Time 0.606 (0.734)	Data 0.0000 (0.0000)	Loss 1.5006 (1.9481)	
label_Epoch: [34][170/345]	Time 0.636 (0.727)	Data 0.0000 (0.0000)	Loss 1.1857 (1.9367)	
label_Epoch: [34][180/345]	Time 0.604 (0.721)	Data 0.0000 (0.0000)	Loss 1.4337 (1.9128)	
label_Epoch: [34][190/345]	Time 0.616 (0.716)	Data 0.0000 (0.0000)	Loss 1.5955 (1.8892)	
label_Epoch: [34][200/345]	Time 0.630 (0.711)	Data 0.0000 (0.0000)	Loss 1.1500 (1.8653)	
label_Epoch: [34][210/345]	Time 0.623 (0.707)	Data 0.0000 (0.0000)	Loss 1.1459 (1.8455)	
label_Epoch: [34][220/345]	Time 0.604 (0.702)	Data 0.0000 (0.0000)	Loss 1.2701 (1.8391)	
label_Epoch: [34][230/345]	Time 0.641 (0.699)	Data 0.0000 (0.0000)	Loss 1.4287 (1.8205)	
label_Epoch: [34][240/345]	Time 0.615 (0.696)	Data 0.0000 (0.0000)	Loss 1.2415 (1.8055)	
label_Epoch: [34][250/345]	Time 0.627 (0.693)	Data 0.0000 (0.0000)	Loss 1.4284 (1.7898)	
label_Epoch: [34][260/345]	Time 0.609 (0.690)	Data 0.0000 (0.0000)	Loss 1.1745 (1.7793)	
label_Epoch: [34][270/345]	Time 0.629 (0.687)	Data 0.0000 (0.0000)	Loss 1.1181 (1.7661)	
label_Epoch: [34][280/345]	Time 0.609 (0.685)	Data 0.0000 (0.0000)	Loss 1.0821 (1.7511)	
label_Epoch: [34][290/345]	Time 0.622 (0.682)	Data 0.0000 (0.0000)	Loss 1.6227 (1.7374)	
label_Epoch: [34][300/345]	Time 0.601 (0.680)	Data 0.0000 (0.0000)	Loss 1.1411 (1.7314)	
label_Epoch: [34][310/345]	Time 0.621 (0.678)	Data 0.0000 (0.0000)	Loss 1.1442 (1.7159)	
label_Epoch: [34][320/345]	Time 0.614 (0.676)	Data 0.0000 (0.0000)	Loss 1.0750 (1.7048)	
label_Epoch: [34][330/345]	Time 0.616 (0.674)	Data 0.0000 (0.0000)	Loss 1.5989 (1.6986)	
label_Epoch: [34][340/345]	Time 0.629 (0.673)	Data 0.0000 (0.0000)	Loss 1.1177 (1.6844)	
34
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [35][10/345]	Time 0.618 (2.385)	Data 0.0000 (0.0000)	Loss 1.4735 (2.3474)	
label_Epoch: [35][20/345]	Time 0.614 (1.502)	Data 0.0000 (0.0000)	Loss 2.3408 (2.2561)	
label_Epoch: [35][30/345]	Time 0.611 (1.206)	Data 0.0000 (0.0000)	Loss 2.0916 (2.2437)	
label_Epoch: [35][40/345]	Time 0.612 (1.059)	Data 0.0000 (0.0000)	Loss 1.3706 (2.2720)	
label_Epoch: [35][50/345]	Time 0.607 (0.969)	Data 0.0000 (0.0000)	Loss 2.7274 (2.2006)	
label_Epoch: [35][60/345]	Time 0.620 (0.911)	Data 0.0000 (0.0000)	Loss 1.4749 (2.1309)	
label_Epoch: [35][70/345]	Time 0.633 (0.870)	Data 0.0000 (0.0000)	Loss 1.5584 (2.1151)	
label_Epoch: [35][80/345]	Time 0.615 (0.839)	Data 0.0000 (0.0000)	Loss 1.6699 (2.1044)	
label_Epoch: [35][90/345]	Time 0.620 (0.815)	Data 0.0000 (0.0000)	Loss 2.0427 (2.0649)	
label_Epoch: [35][100/345]	Time 0.638 (0.795)	Data 0.0000 (0.0000)	Loss 1.4923 (2.0438)	
label_Epoch: [35][110/345]	Time 0.633 (0.779)	Data 0.0000 (0.0000)	Loss 2.2027 (2.0430)	
label_Epoch: [35][120/345]	Time 0.622 (0.766)	Data 0.0000 (0.0000)	Loss 1.8103 (2.0253)	
label_Epoch: [35][130/345]	Time 0.614 (0.755)	Data 0.0000 (0.0000)	Loss 2.4193 (2.0013)	
label_Epoch: [35][140/345]	Time 0.615 (0.746)	Data 0.0000 (0.0000)	Loss 1.8229 (1.9819)	
label_Epoch: [35][150/345]	Time 0.605 (0.737)	Data 0.0000 (0.0000)	Loss 1.8226 (1.9586)	
label_Epoch: [35][160/345]	Time 0.610 (0.729)	Data 0.0000 (0.0000)	Loss 1.1258 (1.9349)	
label_Epoch: [35][170/345]	Time 0.629 (0.723)	Data 0.0000 (0.0000)	Loss 1.5915 (1.9168)	
label_Epoch: [35][180/345]	Time 0.619 (0.717)	Data 0.0000 (0.0000)	Loss 1.4628 (1.9037)	
label_Epoch: [35][190/345]	Time 0.628 (0.712)	Data 0.0000 (0.0000)	Loss 1.1218 (1.8941)	
label_Epoch: [35][200/345]	Time 0.606 (0.707)	Data 0.0000 (0.0000)	Loss 2.4661 (1.8797)	
label_Epoch: [35][210/345]	Time 0.626 (0.703)	Data 0.0000 (0.0000)	Loss 1.8838 (1.8623)	
label_Epoch: [35][220/345]	Time 0.633 (0.699)	Data 0.0000 (0.0000)	Loss 1.2994 (1.8482)	
label_Epoch: [35][230/345]	Time 0.624 (0.696)	Data 0.0000 (0.0000)	Loss 1.5400 (1.8378)	
label_Epoch: [35][240/345]	Time 0.616 (0.693)	Data 0.0000 (0.0000)	Loss 1.2955 (1.8199)	
label_Epoch: [35][250/345]	Time 0.615 (0.690)	Data 0.0000 (0.0000)	Loss 1.5724 (1.8075)	
label_Epoch: [35][260/345]	Time 0.638 (0.687)	Data 0.0000 (0.0000)	Loss 1.6271 (1.7930)	
label_Epoch: [35][270/345]	Time 0.601 (0.685)	Data 0.0000 (0.0000)	Loss 1.1326 (1.7752)	
label_Epoch: [35][280/345]	Time 0.616 (0.682)	Data 0.0000 (0.0000)	Loss 1.3216 (1.7750)	
label_Epoch: [35][290/345]	Time 0.614 (0.680)	Data 0.0000 (0.0000)	Loss 1.2994 (1.7616)	
label_Epoch: [35][300/345]	Time 0.607 (0.678)	Data 0.0000 (0.0000)	Loss 1.3257 (1.7471)	
label_Epoch: [35][310/345]	Time 0.623 (0.676)	Data 0.0000 (0.0000)	Loss 1.1619 (1.7312)	
label_Epoch: [35][320/345]	Time 0.610 (0.674)	Data 0.0000 (0.0000)	Loss 1.0923 (1.7183)	
label_Epoch: [35][330/345]	Time 0.619 (0.672)	Data 0.0000 (0.0000)	Loss 1.3155 (1.7055)	
label_Epoch: [35][340/345]	Time 0.615 (0.671)	Data 0.0000 (0.0000)	Loss 1.3037 (1.6937)	
35
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [36][10/345]	Time 0.633 (2.390)	Data 0.0000 (0.0000)	Loss 2.4770 (2.3135)	
label_Epoch: [36][20/345]	Time 0.620 (1.503)	Data 0.0000 (0.0000)	Loss 2.1764 (2.1095)	
label_Epoch: [36][30/345]	Time 0.610 (1.209)	Data 0.0000 (0.0000)	Loss 1.2133 (2.1872)	
label_Epoch: [36][40/345]	Time 0.660 (1.062)	Data 0.0000 (0.0000)	Loss 2.2934 (2.1190)	
label_Epoch: [36][50/345]	Time 0.646 (0.973)	Data 0.0000 (0.0000)	Loss 1.8845 (2.1056)	
label_Epoch: [36][60/345]	Time 0.621 (0.914)	Data 0.0000 (0.0000)	Loss 1.7385 (2.0627)	
label_Epoch: [36][70/345]	Time 0.629 (0.874)	Data 0.0000 (0.0000)	Loss 1.5288 (2.0380)	
label_Epoch: [36][80/345]	Time 0.613 (0.843)	Data 0.0000 (0.0000)	Loss 2.4867 (2.0374)	
label_Epoch: [36][90/345]	Time 0.616 (0.818)	Data 0.0000 (0.0000)	Loss 1.4301 (2.0100)	
label_Epoch: [36][100/345]	Time 0.610 (0.798)	Data 0.0000 (0.0000)	Loss 1.3383 (1.9925)	
label_Epoch: [36][110/345]	Time 0.620 (0.782)	Data 0.0000 (0.0000)	Loss 1.5831 (1.9545)	
label_Epoch: [36][120/345]	Time 0.611 (0.768)	Data 0.0000 (0.0000)	Loss 1.3572 (1.9297)	
label_Epoch: [36][130/345]	Time 0.613 (0.756)	Data 0.0000 (0.0000)	Loss 3.0727 (1.9267)	
label_Epoch: [36][140/345]	Time 0.618 (0.747)	Data 0.0000 (0.0000)	Loss 1.6262 (1.9155)	
label_Epoch: [36][150/345]	Time 0.620 (0.738)	Data 0.0000 (0.0000)	Loss 2.3181 (1.9079)	
label_Epoch: [36][160/345]	Time 0.623 (0.731)	Data 0.0000 (0.0000)	Loss 1.5753 (1.8916)	
label_Epoch: [36][170/345]	Time 0.600 (0.724)	Data 0.0000 (0.0000)	Loss 1.9174 (1.8730)	
label_Epoch: [36][180/345]	Time 0.623 (0.719)	Data 0.0000 (0.0000)	Loss 1.4739 (1.8613)	
label_Epoch: [36][190/345]	Time 0.608 (0.714)	Data 0.0000 (0.0000)	Loss 1.5394 (1.8452)	
label_Epoch: [36][200/345]	Time 0.602 (0.709)	Data 0.0000 (0.0000)	Loss 1.4912 (1.8331)	
label_Epoch: [36][210/345]	Time 0.610 (0.704)	Data 0.0000 (0.0000)	Loss 1.3439 (1.8222)	
label_Epoch: [36][220/345]	Time 0.607 (0.701)	Data 0.0000 (0.0000)	Loss 1.5171 (1.8015)	
label_Epoch: [36][230/345]	Time 0.615 (0.697)	Data 0.0000 (0.0000)	Loss 1.1836 (1.7861)	
label_Epoch: [36][240/345]	Time 0.626 (0.694)	Data 0.0000 (0.0000)	Loss 1.3378 (1.7760)	
label_Epoch: [36][250/345]	Time 0.631 (0.690)	Data 0.0000 (0.0000)	Loss 1.7520 (1.7643)	
label_Epoch: [36][260/345]	Time 0.600 (0.687)	Data 0.0000 (0.0000)	Loss 2.3348 (1.7517)	
label_Epoch: [36][270/345]	Time 0.610 (0.685)	Data 0.0000 (0.0000)	Loss 1.4036 (1.7402)	
label_Epoch: [36][280/345]	Time 0.623 (0.683)	Data 0.0000 (0.0000)	Loss 1.1831 (1.7359)	
label_Epoch: [36][290/345]	Time 0.616 (0.680)	Data 0.0000 (0.0000)	Loss 2.5989 (1.7234)	
label_Epoch: [36][300/345]	Time 0.628 (0.678)	Data 0.0000 (0.0000)	Loss 1.6600 (1.7120)	
label_Epoch: [36][310/345]	Time 0.603 (0.676)	Data 0.0000 (0.0000)	Loss 1.2238 (1.6992)	
label_Epoch: [36][320/345]	Time 0.619 (0.674)	Data 0.0000 (0.0000)	Loss 1.1261 (1.6871)	
label_Epoch: [36][330/345]	Time 0.622 (0.673)	Data 0.0000 (0.0000)	Loss 1.4647 (1.6748)	
label_Epoch: [36][340/345]	Time 0.606 (0.671)	Data 0.0000 (0.0000)	Loss 1.2209 (1.6634)	
36
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [37][10/345]	Time 0.617 (2.370)	Data 0.0000 (0.0000)	Loss 2.3230 (2.5140)	
label_Epoch: [37][20/345]	Time 0.606 (1.493)	Data 0.0000 (0.0000)	Loss 1.8999 (2.3825)	
label_Epoch: [37][30/345]	Time 0.645 (1.204)	Data 0.0000 (0.0000)	Loss 2.8002 (2.3655)	
label_Epoch: [37][40/345]	Time 0.612 (1.058)	Data 0.0000 (0.0000)	Loss 2.8784 (2.3316)	
label_Epoch: [37][50/345]	Time 0.633 (0.972)	Data 0.0000 (0.0000)	Loss 1.9324 (2.2464)	
label_Epoch: [37][60/345]	Time 0.615 (0.913)	Data 0.0000 (0.0000)	Loss 1.8549 (2.2283)	
label_Epoch: [37][70/345]	Time 0.613 (0.871)	Data 0.0000 (0.0000)	Loss 2.9180 (2.1986)	
label_Epoch: [37][80/345]	Time 0.599 (0.840)	Data 0.0000 (0.0000)	Loss 1.7403 (2.1368)	
label_Epoch: [37][90/345]	Time 0.633 (0.815)	Data 0.0000 (0.0000)	Loss 2.4942 (2.0774)	
label_Epoch: [37][100/345]	Time 0.631 (0.795)	Data 0.0000 (0.0000)	Loss 1.4851 (2.0481)	
label_Epoch: [37][110/345]	Time 0.609 (0.779)	Data 0.0000 (0.0000)	Loss 1.4538 (2.0144)	
label_Epoch: [37][120/345]	Time 0.610 (0.765)	Data 0.0000 (0.0000)	Loss 2.1110 (1.9892)	
label_Epoch: [37][130/345]	Time 0.634 (0.754)	Data 0.0000 (0.0000)	Loss 2.6161 (1.9805)	
label_Epoch: [37][140/345]	Time 0.606 (0.744)	Data 0.0000 (0.0000)	Loss 1.3261 (1.9482)	
label_Epoch: [37][150/345]	Time 0.601 (0.736)	Data 0.0000 (0.0000)	Loss 1.9308 (1.9335)	
label_Epoch: [37][160/345]	Time 0.624 (0.728)	Data 0.0000 (0.0000)	Loss 1.6292 (1.9155)	
label_Epoch: [37][170/345]	Time 0.617 (0.722)	Data 0.0000 (0.0000)	Loss 1.4171 (1.8987)	
label_Epoch: [37][180/345]	Time 0.611 (0.716)	Data 0.0000 (0.0000)	Loss 1.5956 (1.8704)	
label_Epoch: [37][190/345]	Time 0.624 (0.711)	Data 0.0000 (0.0000)	Loss 1.7269 (1.8517)	
label_Epoch: [37][200/345]	Time 0.619 (0.706)	Data 0.0000 (0.0000)	Loss 1.3348 (1.8310)	
label_Epoch: [37][210/345]	Time 0.634 (0.702)	Data 0.0000 (0.0000)	Loss 2.0114 (1.8203)	
label_Epoch: [37][220/345]	Time 0.627 (0.699)	Data 0.0000 (0.0000)	Loss 1.6944 (1.8093)	
label_Epoch: [37][230/345]	Time 0.614 (0.695)	Data 0.0000 (0.0000)	Loss 1.1904 (1.7879)	
label_Epoch: [37][240/345]	Time 0.625 (0.692)	Data 0.0000 (0.0000)	Loss 1.0854 (1.7757)	
label_Epoch: [37][250/345]	Time 0.621 (0.689)	Data 0.0000 (0.0000)	Loss 1.5802 (1.7589)	
label_Epoch: [37][260/345]	Time 0.616 (0.686)	Data 0.0000 (0.0000)	Loss 1.3613 (1.7432)	
label_Epoch: [37][270/345]	Time 0.606 (0.684)	Data 0.0000 (0.0000)	Loss 1.1294 (1.7241)	
label_Epoch: [37][280/345]	Time 0.609 (0.681)	Data 0.0000 (0.0000)	Loss 1.6554 (1.7151)	
label_Epoch: [37][290/345]	Time 0.610 (0.679)	Data 0.0000 (0.0000)	Loss 2.0047 (1.7038)	
label_Epoch: [37][300/345]	Time 0.637 (0.677)	Data 0.0000 (0.0000)	Loss 1.1286 (1.6919)	
label_Epoch: [37][310/345]	Time 0.617 (0.676)	Data 0.0000 (0.0000)	Loss 1.1104 (1.6789)	
label_Epoch: [37][320/345]	Time 0.601 (0.674)	Data 0.0000 (0.0000)	Loss 1.2476 (1.6658)	
label_Epoch: [37][330/345]	Time 0.603 (0.672)	Data 0.0000 (0.0000)	Loss 1.1164 (1.6516)	
label_Epoch: [37][340/345]	Time 0.624 (0.670)	Data 0.0000 (0.0000)	Loss 1.1686 (1.6370)	
37
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [38][10/345]	Time 0.622 (2.352)	Data 0.0000 (0.0000)	Loss 1.8027 (1.9469)	
label_Epoch: [38][20/345]	Time 0.615 (1.484)	Data 0.0000 (0.0000)	Loss 2.6765 (2.1737)	
label_Epoch: [38][30/345]	Time 0.624 (1.197)	Data 0.0000 (0.0000)	Loss 1.8158 (2.1197)	
label_Epoch: [38][40/345]	Time 0.624 (1.052)	Data 0.0000 (0.0000)	Loss 3.6174 (2.0729)	
label_Epoch: [38][50/345]	Time 0.624 (0.965)	Data 0.0000 (0.0000)	Loss 1.9636 (2.0828)	
label_Epoch: [38][60/345]	Time 0.610 (0.907)	Data 0.0000 (0.0000)	Loss 2.1240 (2.0874)	
label_Epoch: [38][70/345]	Time 0.618 (0.866)	Data 0.0000 (0.0000)	Loss 1.1441 (2.0334)	
label_Epoch: [38][80/345]	Time 0.631 (0.835)	Data 0.0000 (0.0000)	Loss 1.5815 (2.0235)	
label_Epoch: [38][90/345]	Time 0.612 (0.811)	Data 0.0000 (0.0000)	Loss 1.9359 (2.0106)	
label_Epoch: [38][100/345]	Time 0.621 (0.791)	Data 0.0000 (0.0000)	Loss 1.7601 (1.9939)	
label_Epoch: [38][110/345]	Time 0.623 (0.776)	Data 0.0000 (0.0000)	Loss 1.3141 (1.9680)	
label_Epoch: [38][120/345]	Time 0.633 (0.762)	Data 0.0000 (0.0000)	Loss 1.4856 (1.9364)	
label_Epoch: [38][130/345]	Time 0.628 (0.751)	Data 0.0000 (0.0000)	Loss 1.6576 (1.9075)	
label_Epoch: [38][140/345]	Time 0.632 (0.742)	Data 0.0000 (0.0000)	Loss 1.9195 (1.9063)	
label_Epoch: [38][150/345]	Time 0.627 (0.734)	Data 0.0000 (0.0000)	Loss 1.3873 (1.9014)	
label_Epoch: [38][160/345]	Time 0.624 (0.726)	Data 0.0000 (0.0000)	Loss 1.3980 (1.8791)	
label_Epoch: [38][170/345]	Time 0.633 (0.720)	Data 0.0000 (0.0000)	Loss 1.2274 (1.8610)	
label_Epoch: [38][180/345]	Time 0.622 (0.714)	Data 0.0000 (0.0000)	Loss 1.7667 (1.8356)	
label_Epoch: [38][190/345]	Time 0.628 (0.709)	Data 0.0000 (0.0000)	Loss 1.2524 (1.8236)	
label_Epoch: [38][200/345]	Time 0.615 (0.705)	Data 0.0000 (0.0000)	Loss 1.8774 (1.8123)	
label_Epoch: [38][210/345]	Time 0.595 (0.701)	Data 0.0000 (0.0000)	Loss 1.4265 (1.8024)	
label_Epoch: [38][220/345]	Time 0.610 (0.697)	Data 0.0000 (0.0000)	Loss 1.5434 (1.7896)	
label_Epoch: [38][230/345]	Time 0.633 (0.694)	Data 0.0000 (0.0000)	Loss 1.1276 (1.7803)	
label_Epoch: [38][240/345]	Time 0.610 (0.691)	Data 0.0000 (0.0000)	Loss 1.1921 (1.7637)	
label_Epoch: [38][250/345]	Time 0.611 (0.688)	Data 0.0000 (0.0000)	Loss 1.1095 (1.7471)	
label_Epoch: [38][260/345]	Time 0.615 (0.685)	Data 0.0000 (0.0000)	Loss 1.5974 (1.7302)	
label_Epoch: [38][270/345]	Time 0.619 (0.682)	Data 0.0000 (0.0000)	Loss 1.2275 (1.7173)	
label_Epoch: [38][280/345]	Time 0.609 (0.680)	Data 0.0000 (0.0000)	Loss 1.1467 (1.7051)	
label_Epoch: [38][290/345]	Time 0.622 (0.678)	Data 0.0000 (0.0000)	Loss 1.6153 (1.6933)	
label_Epoch: [38][300/345]	Time 0.599 (0.676)	Data 0.0000 (0.0000)	Loss 1.1596 (1.6842)	
label_Epoch: [38][310/345]	Time 0.610 (0.674)	Data 0.0000 (0.0000)	Loss 1.1050 (1.6755)	
label_Epoch: [38][320/345]	Time 0.614 (0.673)	Data 0.0000 (0.0000)	Loss 1.8302 (1.6636)	
label_Epoch: [38][330/345]	Time 0.611 (0.671)	Data 0.0000 (0.0000)	Loss 1.1584 (1.6499)	
label_Epoch: [38][340/345]	Time 0.606 (0.670)	Data 0.0000 (0.0000)	Loss 1.0747 (1.6366)	
38
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [39][10/345]	Time 0.613 (2.367)	Data 0.0000 (0.0000)	Loss 2.0099 (2.1267)	
label_Epoch: [39][20/345]	Time 0.624 (1.494)	Data 0.0000 (0.0000)	Loss 3.3454 (2.3550)	
label_Epoch: [39][30/345]	Time 0.640 (1.201)	Data 0.0000 (0.0000)	Loss 2.8684 (2.3705)	
label_Epoch: [39][40/345]	Time 0.613 (1.057)	Data 0.0000 (0.0000)	Loss 3.3774 (2.3253)	
label_Epoch: [39][50/345]	Time 0.610 (0.968)	Data 0.0000 (0.0000)	Loss 1.9628 (2.2560)	
label_Epoch: [39][60/345]	Time 0.615 (0.911)	Data 0.0000 (0.0000)	Loss 1.6660 (2.1999)	
label_Epoch: [39][70/345]	Time 0.626 (0.869)	Data 0.0000 (0.0000)	Loss 1.3901 (2.1238)	
label_Epoch: [39][80/345]	Time 0.602 (0.838)	Data 0.0000 (0.0000)	Loss 1.7962 (2.0934)	
label_Epoch: [39][90/345]	Time 0.601 (0.814)	Data 0.0000 (0.0000)	Loss 2.2089 (2.0827)	
label_Epoch: [39][100/345]	Time 0.603 (0.794)	Data 0.0000 (0.0000)	Loss 1.4666 (2.0213)	
label_Epoch: [39][110/345]	Time 0.607 (0.778)	Data 0.0000 (0.0000)	Loss 1.7341 (1.9874)	
label_Epoch: [39][120/345]	Time 0.606 (0.764)	Data 0.0000 (0.0000)	Loss 1.2133 (1.9589)	
label_Epoch: [39][130/345]	Time 0.626 (0.753)	Data 0.0000 (0.0000)	Loss 1.1063 (1.9342)	
label_Epoch: [39][140/345]	Time 0.629 (0.744)	Data 0.0000 (0.0000)	Loss 1.1986 (1.9184)	
label_Epoch: [39][150/345]	Time 0.614 (0.735)	Data 0.0000 (0.0000)	Loss 1.8062 (1.8970)	
label_Epoch: [39][160/345]	Time 0.622 (0.728)	Data 0.0000 (0.0000)	Loss 1.9213 (1.8752)	
label_Epoch: [39][170/345]	Time 0.599 (0.721)	Data 0.0000 (0.0000)	Loss 1.2366 (1.8535)	
label_Epoch: [39][180/345]	Time 0.619 (0.715)	Data 0.0000 (0.0000)	Loss 1.2120 (1.8339)	
label_Epoch: [39][190/345]	Time 0.614 (0.710)	Data 0.0000 (0.0000)	Loss 1.2376 (1.8222)	
label_Epoch: [39][200/345]	Time 0.613 (0.706)	Data 0.0000 (0.0000)	Loss 1.5294 (1.8095)	
label_Epoch: [39][210/345]	Time 0.613 (0.702)	Data 0.0000 (0.0000)	Loss 1.4365 (1.7918)	
label_Epoch: [39][220/345]	Time 0.595 (0.698)	Data 0.0000 (0.0000)	Loss 1.4661 (1.7800)	
label_Epoch: [39][230/345]	Time 0.606 (0.695)	Data 0.0000 (0.0000)	Loss 1.1774 (1.7703)	
label_Epoch: [39][240/345]	Time 0.601 (0.692)	Data 0.0000 (0.0000)	Loss 1.2461 (1.7565)	
label_Epoch: [39][250/345]	Time 0.619 (0.689)	Data 0.0000 (0.0000)	Loss 1.4403 (1.7437)	
label_Epoch: [39][260/345]	Time 0.624 (0.686)	Data 0.0000 (0.0000)	Loss 1.2113 (1.7340)	
label_Epoch: [39][270/345]	Time 0.628 (0.683)	Data 0.0000 (0.0000)	Loss 1.5602 (1.7236)	
label_Epoch: [39][280/345]	Time 0.611 (0.681)	Data 0.0000 (0.0000)	Loss 1.2108 (1.7088)	
label_Epoch: [39][290/345]	Time 0.616 (0.679)	Data 0.0000 (0.0000)	Loss 1.5196 (1.6943)	
label_Epoch: [39][300/345]	Time 0.651 (0.677)	Data 0.0000 (0.0000)	Loss 1.0807 (1.6838)	
label_Epoch: [39][310/345]	Time 0.612 (0.675)	Data 0.0000 (0.0000)	Loss 1.6406 (1.6725)	
label_Epoch: [39][320/345]	Time 0.609 (0.673)	Data 0.0000 (0.0000)	Loss 1.1353 (1.6546)	
label_Epoch: [39][330/345]	Time 0.611 (0.671)	Data 0.0000 (0.0000)	Loss 1.1635 (1.6420)	
label_Epoch: [39][340/345]	Time 0.618 (0.670)	Data 0.0000 (0.0000)	Loss 1.1098 (1.6287)	
39
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [40][10/345]	Time 0.629 (2.428)	Data 0.0000 (0.0000)	Loss 1.3550 (2.3519)	
label_Epoch: [40][20/345]	Time 0.615 (1.526)	Data 0.0000 (0.0000)	Loss 1.7343 (2.2674)	
label_Epoch: [40][30/345]	Time 0.604 (1.223)	Data 0.0000 (0.0000)	Loss 2.9100 (2.2967)	
label_Epoch: [40][40/345]	Time 0.612 (1.071)	Data 0.0000 (0.0000)	Loss 1.2894 (2.1490)	
label_Epoch: [40][50/345]	Time 0.597 (0.979)	Data 0.0000 (0.0000)	Loss 1.6627 (2.0688)	
label_Epoch: [40][60/345]	Time 0.617 (0.919)	Data 0.0000 (0.0000)	Loss 1.2576 (2.0500)	
label_Epoch: [40][70/345]	Time 0.635 (0.877)	Data 0.0000 (0.0000)	Loss 2.1136 (2.0017)	
label_Epoch: [40][80/345]	Time 0.621 (0.844)	Data 0.0000 (0.0000)	Loss 1.4771 (2.0031)	
label_Epoch: [40][90/345]	Time 0.608 (0.819)	Data 0.0000 (0.0000)	Loss 3.6746 (1.9854)	
label_Epoch: [40][100/345]	Time 0.604 (0.799)	Data 0.0000 (0.0000)	Loss 1.2230 (1.9653)	
label_Epoch: [40][110/345]	Time 0.629 (0.783)	Data 0.0000 (0.0000)	Loss 1.6380 (1.9427)	
label_Epoch: [40][120/345]	Time 0.615 (0.768)	Data 0.0000 (0.0000)	Loss 1.6349 (1.9173)	
label_Epoch: [40][130/345]	Time 0.622 (0.757)	Data 0.0000 (0.0000)	Loss 1.4279 (1.8923)	
label_Epoch: [40][140/345]	Time 0.605 (0.747)	Data 0.0000 (0.0000)	Loss 1.4216 (1.8651)	
label_Epoch: [40][150/345]	Time 0.627 (0.738)	Data 0.0000 (0.0000)	Loss 1.2629 (1.8476)	
label_Epoch: [40][160/345]	Time 0.621 (0.731)	Data 0.0000 (0.0000)	Loss 1.4913 (1.8214)	
label_Epoch: [40][170/345]	Time 0.631 (0.725)	Data 0.0000 (0.0000)	Loss 1.2174 (1.8118)	
label_Epoch: [40][180/345]	Time 0.619 (0.719)	Data 0.0000 (0.0000)	Loss 1.7357 (1.7988)	
label_Epoch: [40][190/345]	Time 0.635 (0.715)	Data 0.0000 (0.0000)	Loss 2.5880 (1.7917)	
label_Epoch: [40][200/345]	Time 0.631 (0.711)	Data 0.0000 (0.0000)	Loss 1.1863 (1.7723)	
label_Epoch: [40][210/345]	Time 0.623 (0.707)	Data 0.0000 (0.0000)	Loss 1.3733 (1.7647)	
label_Epoch: [40][220/345]	Time 0.638 (0.703)	Data 0.0000 (0.0000)	Loss 1.9316 (1.7467)	
label_Epoch: [40][230/345]	Time 0.626 (0.700)	Data 0.0000 (0.0000)	Loss 1.2053 (1.7392)	
label_Epoch: [40][240/345]	Time 0.626 (0.698)	Data 0.0000 (0.0000)	Loss 2.1857 (1.7318)	
label_Epoch: [40][250/345]	Time 0.616 (0.695)	Data 0.0000 (0.0000)	Loss 1.2923 (1.7201)	
label_Epoch: [40][260/345]	Time 0.617 (0.692)	Data 0.0000 (0.0000)	Loss 1.3330 (1.7053)	
label_Epoch: [40][270/345]	Time 0.600 (0.689)	Data 0.0000 (0.0000)	Loss 1.6160 (1.6954)	
label_Epoch: [40][280/345]	Time 0.635 (0.687)	Data 0.0000 (0.0000)	Loss 1.2338 (1.6840)	
label_Epoch: [40][290/345]	Time 0.636 (0.684)	Data 0.0000 (0.0000)	Loss 1.5374 (1.6710)	
label_Epoch: [40][300/345]	Time 0.610 (0.682)	Data 0.0000 (0.0000)	Loss 1.4998 (1.6578)	
label_Epoch: [40][310/345]	Time 0.620 (0.680)	Data 0.0000 (0.0000)	Loss 1.1934 (1.6448)	
label_Epoch: [40][320/345]	Time 0.611 (0.678)	Data 0.0000 (0.0000)	Loss 1.1445 (1.6331)	
label_Epoch: [40][330/345]	Time 0.598 (0.676)	Data 0.0000 (0.0000)	Loss 1.5508 (1.6244)	
label_Epoch: [40][340/345]	Time 0.600 (0.675)	Data 0.0000 (0.0000)	Loss 1.0567 (1.6127)	
40
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [41][10/345]	Time 0.606 (2.418)	Data 0.0000 (0.0000)	Loss 1.1204 (1.9084)	
label_Epoch: [41][20/345]	Time 0.622 (1.520)	Data 0.0000 (0.0000)	Loss 2.3190 (1.9724)	
label_Epoch: [41][30/345]	Time 0.621 (1.221)	Data 0.0000 (0.0000)	Loss 1.2996 (2.0760)	
label_Epoch: [41][40/345]	Time 0.614 (1.071)	Data 0.0000 (0.0000)	Loss 1.5055 (2.0762)	
label_Epoch: [41][50/345]	Time 0.601 (0.979)	Data 0.0000 (0.0000)	Loss 1.5963 (1.9884)	
label_Epoch: [41][60/345]	Time 0.638 (0.918)	Data 0.0000 (0.0000)	Loss 1.2837 (2.0076)	
label_Epoch: [41][70/345]	Time 0.619 (0.875)	Data 0.0000 (0.0000)	Loss 1.2971 (1.9711)	
label_Epoch: [41][80/345]	Time 0.638 (0.843)	Data 0.0000 (0.0000)	Loss 2.9540 (1.9746)	
label_Epoch: [41][90/345]	Time 0.646 (0.819)	Data 0.0000 (0.0000)	Loss 2.4138 (1.9659)	
label_Epoch: [41][100/345]	Time 0.611 (0.798)	Data 0.0000 (0.0000)	Loss 1.2799 (1.9826)	
label_Epoch: [41][110/345]	Time 0.605 (0.782)	Data 0.0000 (0.0000)	Loss 1.6238 (1.9437)	
label_Epoch: [41][120/345]	Time 0.620 (0.768)	Data 0.0000 (0.0000)	Loss 1.8750 (1.9173)	
label_Epoch: [41][130/345]	Time 0.619 (0.757)	Data 0.0000 (0.0000)	Loss 1.2811 (1.8803)	
label_Epoch: [41][140/345]	Time 0.608 (0.747)	Data 0.0000 (0.0000)	Loss 1.3979 (1.8624)	
label_Epoch: [41][150/345]	Time 0.611 (0.738)	Data 0.0000 (0.0000)	Loss 2.1134 (1.8381)	
label_Epoch: [41][160/345]	Time 0.619 (0.731)	Data 0.0000 (0.0000)	Loss 1.5348 (1.8213)	
label_Epoch: [41][170/345]	Time 0.624 (0.724)	Data 0.0000 (0.0000)	Loss 1.2476 (1.8047)	
label_Epoch: [41][180/345]	Time 0.635 (0.719)	Data 0.0000 (0.0000)	Loss 2.4380 (1.7937)	
label_Epoch: [41][190/345]	Time 0.609 (0.714)	Data 0.0000 (0.0000)	Loss 1.3410 (1.7797)	
label_Epoch: [41][200/345]	Time 0.620 (0.710)	Data 0.0000 (0.0000)	Loss 1.9640 (1.7679)	
label_Epoch: [41][210/345]	Time 0.598 (0.706)	Data 0.0000 (0.0000)	Loss 1.8636 (1.7531)	
label_Epoch: [41][220/345]	Time 0.621 (0.702)	Data 0.0000 (0.0000)	Loss 1.3920 (1.7387)	
label_Epoch: [41][230/345]	Time 0.609 (0.699)	Data 0.0000 (0.0000)	Loss 1.5567 (1.7221)	
label_Epoch: [41][240/345]	Time 0.622 (0.695)	Data 0.0000 (0.0000)	Loss 1.0994 (1.7048)	
label_Epoch: [41][250/345]	Time 0.614 (0.692)	Data 0.0000 (0.0000)	Loss 1.3542 (1.6940)	
label_Epoch: [41][260/345]	Time 0.624 (0.689)	Data 0.0000 (0.0000)	Loss 1.1593 (1.6794)	
label_Epoch: [41][270/345]	Time 0.618 (0.687)	Data 0.0000 (0.0000)	Loss 1.4693 (1.6650)	
label_Epoch: [41][280/345]	Time 0.622 (0.684)	Data 0.0000 (0.0000)	Loss 1.9142 (1.6548)	
label_Epoch: [41][290/345]	Time 0.645 (0.682)	Data 0.0000 (0.0000)	Loss 1.2809 (1.6432)	
label_Epoch: [41][300/345]	Time 0.606 (0.679)	Data 0.0000 (0.0000)	Loss 1.0711 (1.6341)	
label_Epoch: [41][310/345]	Time 0.613 (0.677)	Data 0.0000 (0.0000)	Loss 1.1501 (1.6222)	
label_Epoch: [41][320/345]	Time 0.602 (0.675)	Data 0.0000 (0.0000)	Loss 1.0752 (1.6167)	
label_Epoch: [41][330/345]	Time 0.601 (0.674)	Data 0.0000 (0.0000)	Loss 1.3758 (1.6048)	
label_Epoch: [41][340/345]	Time 0.625 (0.672)	Data 0.0000 (0.0000)	Loss 1.0370 (1.5927)	
41
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [42][10/345]	Time 0.620 (2.392)	Data 0.0000 (0.0000)	Loss 2.3873 (2.1266)	
label_Epoch: [42][20/345]	Time 0.619 (1.504)	Data 0.0000 (0.0000)	Loss 1.2661 (2.1275)	
label_Epoch: [42][30/345]	Time 0.617 (1.210)	Data 0.0000 (0.0000)	Loss 1.6552 (1.9757)	
label_Epoch: [42][40/345]	Time 0.620 (1.062)	Data 0.0000 (0.0000)	Loss 1.2136 (1.9985)	
label_Epoch: [42][50/345]	Time 0.639 (0.974)	Data 0.0000 (0.0000)	Loss 2.1602 (2.0020)	
label_Epoch: [42][60/345]	Time 0.619 (0.914)	Data 0.0000 (0.0000)	Loss 1.3318 (1.9949)	
label_Epoch: [42][70/345]	Time 0.607 (0.872)	Data 0.0000 (0.0000)	Loss 1.9509 (2.0098)	
label_Epoch: [42][80/345]	Time 0.612 (0.839)	Data 0.0000 (0.0000)	Loss 1.2237 (2.0022)	
label_Epoch: [42][90/345]	Time 0.624 (0.814)	Data 0.0000 (0.0000)	Loss 2.9434 (2.0055)	
label_Epoch: [42][100/345]	Time 0.609 (0.794)	Data 0.0000 (0.0000)	Loss 2.5408 (1.9739)	
label_Epoch: [42][110/345]	Time 0.604 (0.778)	Data 0.0000 (0.0000)	Loss 1.8720 (1.9545)	
label_Epoch: [42][120/345]	Time 0.611 (0.765)	Data 0.0000 (0.0000)	Loss 1.7338 (1.9149)	
label_Epoch: [42][130/345]	Time 0.622 (0.753)	Data 0.0000 (0.0000)	Loss 1.8295 (1.8923)	
label_Epoch: [42][140/345]	Time 0.624 (0.744)	Data 0.0000 (0.0000)	Loss 1.3001 (1.8666)	
label_Epoch: [42][150/345]	Time 0.613 (0.735)	Data 0.0000 (0.0000)	Loss 1.5092 (1.8360)	
label_Epoch: [42][160/345]	Time 0.611 (0.728)	Data 0.0000 (0.0000)	Loss 1.2670 (1.8151)	
label_Epoch: [42][170/345]	Time 0.626 (0.722)	Data 0.0000 (0.0000)	Loss 1.1161 (1.7933)	
label_Epoch: [42][180/345]	Time 0.610 (0.716)	Data 0.0000 (0.0000)	Loss 1.4450 (1.7746)	
label_Epoch: [42][190/345]	Time 0.619 (0.710)	Data 0.0000 (0.0000)	Loss 1.5050 (1.7565)	
label_Epoch: [42][200/345]	Time 0.618 (0.706)	Data 0.0000 (0.0000)	Loss 1.4029 (1.7376)	
label_Epoch: [42][210/345]	Time 0.601 (0.701)	Data 0.0000 (0.0000)	Loss 1.2194 (1.7177)	
label_Epoch: [42][220/345]	Time 0.631 (0.698)	Data 0.0000 (0.0000)	Loss 1.2498 (1.6999)	
label_Epoch: [42][230/345]	Time 0.613 (0.694)	Data 0.0000 (0.0000)	Loss 1.6928 (1.6845)	
label_Epoch: [42][240/345]	Time 0.610 (0.691)	Data 0.0000 (0.0000)	Loss 1.2145 (1.6709)	
label_Epoch: [42][250/345]	Time 0.599 (0.688)	Data 0.0000 (0.0000)	Loss 1.1202 (1.6527)	
label_Epoch: [42][260/345]	Time 0.606 (0.685)	Data 0.0000 (0.0000)	Loss 1.2665 (1.6386)	
label_Epoch: [42][270/345]	Time 0.620 (0.683)	Data 0.0000 (0.0000)	Loss 1.1744 (1.6268)	
label_Epoch: [42][280/345]	Time 0.623 (0.681)	Data 0.0000 (0.0000)	Loss 1.2666 (1.6139)	
label_Epoch: [42][290/345]	Time 0.623 (0.678)	Data 0.0000 (0.0000)	Loss 1.5193 (1.6029)	
label_Epoch: [42][300/345]	Time 0.619 (0.676)	Data 0.0000 (0.0000)	Loss 1.6782 (1.5956)	
label_Epoch: [42][310/345]	Time 0.611 (0.674)	Data 0.0000 (0.0000)	Loss 1.4684 (1.5851)	
label_Epoch: [42][320/345]	Time 0.606 (0.672)	Data 0.0000 (0.0000)	Loss 1.0589 (1.5711)	
label_Epoch: [42][330/345]	Time 0.622 (0.670)	Data 0.0000 (0.0000)	Loss 1.1446 (1.5573)	
label_Epoch: [42][340/345]	Time 0.616 (0.669)	Data 0.0000 (0.0000)	Loss 1.0975 (1.5455)	
42
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [43][10/345]	Time 0.604 (2.528)	Data 0.0000 (0.0000)	Loss 1.5729 (2.2085)	
label_Epoch: [43][20/345]	Time 0.623 (1.576)	Data 0.0000 (0.0000)	Loss 2.3889 (2.3099)	
label_Epoch: [43][30/345]	Time 0.616 (1.258)	Data 0.0000 (0.0000)	Loss 1.5189 (2.1281)	
label_Epoch: [43][40/345]	Time 0.630 (1.097)	Data 0.0000 (0.0000)	Loss 1.2115 (2.0772)	
label_Epoch: [43][50/345]	Time 0.625 (1.000)	Data 0.0000 (0.0000)	Loss 2.1589 (2.0580)	
label_Epoch: [43][60/345]	Time 0.634 (0.937)	Data 0.0000 (0.0000)	Loss 1.4042 (2.0193)	
label_Epoch: [43][70/345]	Time 0.621 (0.891)	Data 0.0000 (0.0000)	Loss 1.3095 (2.0041)	
label_Epoch: [43][80/345]	Time 0.612 (0.857)	Data 0.0000 (0.0000)	Loss 1.5818 (1.9717)	
label_Epoch: [43][90/345]	Time 0.617 (0.830)	Data 0.0000 (0.0000)	Loss 1.3825 (1.9502)	
label_Epoch: [43][100/345]	Time 0.615 (0.808)	Data 0.0000 (0.0000)	Loss 1.4896 (1.9272)	
label_Epoch: [43][110/345]	Time 0.616 (0.790)	Data 0.0000 (0.0000)	Loss 1.8805 (1.8892)	
label_Epoch: [43][120/345]	Time 0.600 (0.775)	Data 0.0000 (0.0000)	Loss 1.4282 (1.8573)	
label_Epoch: [43][130/345]	Time 0.622 (0.762)	Data 0.0000 (0.0000)	Loss 1.6552 (1.8347)	
label_Epoch: [43][140/345]	Time 0.636 (0.752)	Data 0.0000 (0.0000)	Loss 1.4827 (1.8027)	
label_Epoch: [43][150/345]	Time 0.603 (0.743)	Data 0.0000 (0.0000)	Loss 1.5946 (1.7816)	
label_Epoch: [43][160/345]	Time 0.620 (0.736)	Data 0.0000 (0.0000)	Loss 1.2658 (1.7683)	
label_Epoch: [43][170/345]	Time 0.618 (0.729)	Data 0.0000 (0.0000)	Loss 1.6346 (1.7549)	
label_Epoch: [43][180/345]	Time 0.628 (0.723)	Data 0.0000 (0.0000)	Loss 1.6541 (1.7357)	
label_Epoch: [43][190/345]	Time 0.617 (0.717)	Data 0.0000 (0.0000)	Loss 1.8649 (1.7195)	
label_Epoch: [43][200/345]	Time 0.633 (0.712)	Data 0.0000 (0.0000)	Loss 1.8363 (1.7063)	
label_Epoch: [43][210/345]	Time 0.617 (0.708)	Data 0.0000 (0.0000)	Loss 2.3351 (1.6946)	
label_Epoch: [43][220/345]	Time 0.618 (0.704)	Data 0.0000 (0.0000)	Loss 1.6393 (1.6884)	
label_Epoch: [43][230/345]	Time 0.637 (0.700)	Data 0.0000 (0.0000)	Loss 1.1300 (1.6781)	
label_Epoch: [43][240/345]	Time 0.616 (0.697)	Data 0.0000 (0.0000)	Loss 1.2644 (1.6642)	
label_Epoch: [43][250/345]	Time 0.622 (0.694)	Data 0.0000 (0.0000)	Loss 1.1462 (1.6489)	
label_Epoch: [43][260/345]	Time 0.606 (0.691)	Data 0.0000 (0.0000)	Loss 1.4918 (1.6397)	
label_Epoch: [43][270/345]	Time 0.618 (0.688)	Data 0.0000 (0.0000)	Loss 1.5862 (1.6260)	
label_Epoch: [43][280/345]	Time 0.610 (0.686)	Data 0.0000 (0.0000)	Loss 2.0717 (1.6170)	
label_Epoch: [43][290/345]	Time 0.633 (0.684)	Data 0.0000 (0.0000)	Loss 1.3656 (1.6083)	
label_Epoch: [43][300/345]	Time 0.616 (0.681)	Data 0.0000 (0.0000)	Loss 1.6614 (1.5965)	
label_Epoch: [43][310/345]	Time 0.616 (0.679)	Data 0.0000 (0.0000)	Loss 1.2475 (1.5851)	
label_Epoch: [43][320/345]	Time 0.617 (0.677)	Data 0.0000 (0.0000)	Loss 1.0971 (1.5713)	
label_Epoch: [43][330/345]	Time 0.630 (0.675)	Data 0.0000 (0.0000)	Loss 1.3519 (1.5603)	
label_Epoch: [43][340/345]	Time 0.615 (0.674)	Data 0.0000 (0.0000)	Loss 1.0629 (1.5524)	
43
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [44][10/345]	Time 0.600 (2.469)	Data 0.0000 (0.0000)	Loss 2.4417 (2.4028)	
label_Epoch: [44][20/345]	Time 0.637 (1.543)	Data 0.0000 (0.0000)	Loss 1.9439 (2.1480)	
label_Epoch: [44][30/345]	Time 0.616 (1.234)	Data 0.0000 (0.0000)	Loss 1.2906 (2.1039)	
label_Epoch: [44][40/345]	Time 0.627 (1.079)	Data 0.0000 (0.0000)	Loss 1.3308 (2.0845)	
label_Epoch: [44][50/345]	Time 0.622 (0.987)	Data 0.0000 (0.0000)	Loss 2.7083 (2.0088)	
label_Epoch: [44][60/345]	Time 0.619 (0.925)	Data 0.0000 (0.0000)	Loss 2.0215 (2.0243)	
label_Epoch: [44][70/345]	Time 0.613 (0.880)	Data 0.0000 (0.0000)	Loss 2.7204 (2.0315)	
label_Epoch: [44][80/345]	Time 0.606 (0.847)	Data 0.0000 (0.0000)	Loss 2.5031 (1.9748)	
label_Epoch: [44][90/345]	Time 0.617 (0.821)	Data 0.0000 (0.0000)	Loss 2.4436 (1.9548)	
label_Epoch: [44][100/345]	Time 0.601 (0.801)	Data 0.0000 (0.0000)	Loss 1.1102 (1.9227)	
label_Epoch: [44][110/345]	Time 0.616 (0.784)	Data 0.0000 (0.0000)	Loss 1.5568 (1.8858)	
label_Epoch: [44][120/345]	Time 0.632 (0.770)	Data 0.0000 (0.0000)	Loss 1.3047 (1.8612)	
label_Epoch: [44][130/345]	Time 0.635 (0.759)	Data 0.0000 (0.0000)	Loss 1.2212 (1.8304)	
label_Epoch: [44][140/345]	Time 0.631 (0.749)	Data 0.0000 (0.0000)	Loss 1.4915 (1.8185)	
label_Epoch: [44][150/345]	Time 0.606 (0.740)	Data 0.0000 (0.0000)	Loss 1.2836 (1.7900)	
label_Epoch: [44][160/345]	Time 0.619 (0.732)	Data 0.0000 (0.0000)	Loss 1.4219 (1.7657)	
label_Epoch: [44][170/345]	Time 0.596 (0.725)	Data 0.0000 (0.0000)	Loss 1.2786 (1.7614)	
label_Epoch: [44][180/345]	Time 0.614 (0.719)	Data 0.0000 (0.0000)	Loss 1.1199 (1.7506)	
label_Epoch: [44][190/345]	Time 0.627 (0.714)	Data 0.0000 (0.0000)	Loss 1.1225 (1.7327)	
label_Epoch: [44][200/345]	Time 0.639 (0.709)	Data 0.0000 (0.0000)	Loss 1.1850 (1.7256)	
label_Epoch: [44][210/345]	Time 0.623 (0.705)	Data 0.0000 (0.0000)	Loss 1.5257 (1.7137)	
label_Epoch: [44][220/345]	Time 0.599 (0.701)	Data 0.0000 (0.0000)	Loss 1.1269 (1.6980)	
label_Epoch: [44][230/345]	Time 0.611 (0.697)	Data 0.0000 (0.0000)	Loss 1.1979 (1.6826)	
label_Epoch: [44][240/345]	Time 0.621 (0.694)	Data 0.0000 (0.0000)	Loss 1.2681 (1.6740)	
label_Epoch: [44][250/345]	Time 0.612 (0.691)	Data 0.0000 (0.0000)	Loss 1.5057 (1.6630)	
label_Epoch: [44][260/345]	Time 0.620 (0.688)	Data 0.0000 (0.0000)	Loss 1.1699 (1.6566)	
label_Epoch: [44][270/345]	Time 0.614 (0.686)	Data 0.0000 (0.0000)	Loss 1.5565 (1.6428)	
label_Epoch: [44][280/345]	Time 0.627 (0.683)	Data 0.0000 (0.0000)	Loss 1.2018 (1.6295)	
label_Epoch: [44][290/345]	Time 0.613 (0.681)	Data 0.0000 (0.0000)	Loss 1.1269 (1.6150)	
label_Epoch: [44][300/345]	Time 0.612 (0.679)	Data 0.0000 (0.0000)	Loss 1.2517 (1.6008)	
label_Epoch: [44][310/345]	Time 0.615 (0.677)	Data 0.0000 (0.0000)	Loss 1.2045 (1.5882)	
label_Epoch: [44][320/345]	Time 0.617 (0.675)	Data 0.0000 (0.0000)	Loss 1.0856 (1.5770)	
label_Epoch: [44][330/345]	Time 0.620 (0.673)	Data 0.0000 (0.0000)	Loss 1.0284 (1.5656)	
label_Epoch: [44][340/345]	Time 0.631 (0.672)	Data 0.0000 (0.0000)	Loss 1.1559 (1.5519)	
44
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [45][10/345]	Time 0.605 (2.490)	Data 0.0000 (0.0000)	Loss 2.2956 (2.3782)	
label_Epoch: [45][20/345]	Time 0.620 (1.553)	Data 0.0000 (0.0000)	Loss 2.4565 (2.2775)	
label_Epoch: [45][30/345]	Time 0.621 (1.239)	Data 0.0000 (0.0000)	Loss 1.6111 (2.1589)	
label_Epoch: [45][40/345]	Time 0.610 (1.083)	Data 0.0000 (0.0000)	Loss 1.3786 (2.0318)	
label_Epoch: [45][50/345]	Time 0.613 (0.989)	Data 0.0000 (0.0000)	Loss 2.6764 (1.9930)	
label_Epoch: [45][60/345]	Time 0.612 (0.928)	Data 0.0000 (0.0000)	Loss 1.3796 (1.9519)	
label_Epoch: [45][70/345]	Time 0.613 (0.883)	Data 0.0000 (0.0000)	Loss 1.7094 (1.9044)	
label_Epoch: [45][80/345]	Time 0.618 (0.850)	Data 0.0000 (0.0000)	Loss 1.4430 (1.8612)	
label_Epoch: [45][90/345]	Time 0.622 (0.824)	Data 0.0000 (0.0000)	Loss 1.4101 (1.8364)	
label_Epoch: [45][100/345]	Time 0.615 (0.804)	Data 0.0000 (0.0000)	Loss 2.5099 (1.8319)	
label_Epoch: [45][110/345]	Time 0.606 (0.787)	Data 0.0000 (0.0000)	Loss 1.3394 (1.8050)	
label_Epoch: [45][120/345]	Time 0.644 (0.773)	Data 0.0000 (0.0000)	Loss 1.4557 (1.7772)	
label_Epoch: [45][130/345]	Time 0.625 (0.761)	Data 0.0000 (0.0000)	Loss 2.3956 (1.7763)	
label_Epoch: [45][140/345]	Time 0.601 (0.750)	Data 0.0000 (0.0000)	Loss 1.2039 (1.7619)	
label_Epoch: [45][150/345]	Time 0.623 (0.742)	Data 0.0000 (0.0000)	Loss 1.7640 (1.7421)	
label_Epoch: [45][160/345]	Time 0.622 (0.734)	Data 0.0000 (0.0000)	Loss 1.9107 (1.7379)	
label_Epoch: [45][170/345]	Time 0.612 (0.727)	Data 0.0000 (0.0000)	Loss 1.0864 (1.7192)	
label_Epoch: [45][180/345]	Time 0.614 (0.721)	Data 0.0000 (0.0000)	Loss 1.2005 (1.7033)	
label_Epoch: [45][190/345]	Time 0.623 (0.715)	Data 0.0000 (0.0000)	Loss 1.4576 (1.6937)	
label_Epoch: [45][200/345]	Time 0.628 (0.711)	Data 0.0000 (0.0000)	Loss 1.3816 (1.6788)	
label_Epoch: [45][210/345]	Time 0.615 (0.706)	Data 0.0000 (0.0000)	Loss 1.7069 (1.6618)	
label_Epoch: [45][220/345]	Time 0.607 (0.702)	Data 0.0000 (0.0000)	Loss 1.1300 (1.6457)	
label_Epoch: [45][230/345]	Time 0.613 (0.698)	Data 0.0000 (0.0000)	Loss 1.1952 (1.6347)	
label_Epoch: [45][240/345]	Time 0.620 (0.695)	Data 0.0000 (0.0000)	Loss 1.2466 (1.6230)	
label_Epoch: [45][250/345]	Time 0.614 (0.692)	Data 0.0000 (0.0000)	Loss 1.3327 (1.6117)	
label_Epoch: [45][260/345]	Time 0.619 (0.689)	Data 0.0000 (0.0000)	Loss 1.1031 (1.6013)	
label_Epoch: [45][270/345]	Time 0.627 (0.686)	Data 0.0000 (0.0000)	Loss 1.2022 (1.5961)	
label_Epoch: [45][280/345]	Time 0.633 (0.684)	Data 0.0000 (0.0000)	Loss 1.6175 (1.5837)	
label_Epoch: [45][290/345]	Time 0.613 (0.682)	Data 0.0000 (0.0000)	Loss 1.2320 (1.5779)	
label_Epoch: [45][300/345]	Time 0.611 (0.680)	Data 0.0000 (0.0000)	Loss 1.4899 (1.5681)	
label_Epoch: [45][310/345]	Time 0.615 (0.678)	Data 0.0000 (0.0000)	Loss 1.5159 (1.5590)	
label_Epoch: [45][320/345]	Time 0.631 (0.676)	Data 0.0000 (0.0000)	Loss 1.1534 (1.5480)	
label_Epoch: [45][330/345]	Time 0.600 (0.674)	Data 0.0000 (0.0000)	Loss 1.1894 (1.5387)	
label_Epoch: [45][340/345]	Time 0.630 (0.672)	Data 0.0000 (0.0000)	Loss 1.0235 (1.5273)	
45
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [46][10/345]	Time 0.630 (2.581)	Data 0.0000 (0.0000)	Loss 1.1980 (1.5987)	
label_Epoch: [46][20/345]	Time 0.628 (1.603)	Data 0.0000 (0.0000)	Loss 1.7178 (1.7247)	
label_Epoch: [46][30/345]	Time 0.618 (1.275)	Data 0.0000 (0.0000)	Loss 1.7676 (1.8393)	
label_Epoch: [46][40/345]	Time 0.619 (1.110)	Data 0.0000 (0.0000)	Loss 1.6823 (1.8165)	
label_Epoch: [46][50/345]	Time 0.611 (1.011)	Data 0.0000 (0.0000)	Loss 3.0236 (1.8090)	
label_Epoch: [46][60/345]	Time 0.618 (0.945)	Data 0.0000 (0.0000)	Loss 1.3083 (1.8179)	
label_Epoch: [46][70/345]	Time 0.600 (0.897)	Data 0.0000 (0.0000)	Loss 2.1322 (1.8165)	
label_Epoch: [46][80/345]	Time 0.612 (0.863)	Data 0.0000 (0.0000)	Loss 1.7165 (1.8164)	
label_Epoch: [46][90/345]	Time 0.614 (0.835)	Data 0.0000 (0.0000)	Loss 1.8197 (1.8192)	
label_Epoch: [46][100/345]	Time 0.623 (0.814)	Data 0.0000 (0.0000)	Loss 1.5050 (1.8334)	
label_Epoch: [46][110/345]	Time 0.624 (0.796)	Data 0.0000 (0.0000)	Loss 1.5482 (1.8134)	
label_Epoch: [46][120/345]	Time 0.638 (0.781)	Data 0.0000 (0.0000)	Loss 1.4283 (1.8051)	
label_Epoch: [46][130/345]	Time 0.607 (0.769)	Data 0.0000 (0.0000)	Loss 1.6958 (1.7943)	
label_Epoch: [46][140/345]	Time 0.620 (0.758)	Data 0.0000 (0.0000)	Loss 1.3928 (1.7818)	
label_Epoch: [46][150/345]	Time 0.612 (0.749)	Data 0.0000 (0.0000)	Loss 1.4415 (1.7554)	
label_Epoch: [46][160/345]	Time 0.602 (0.741)	Data 0.0000 (0.0000)	Loss 1.5666 (1.7369)	
label_Epoch: [46][170/345]	Time 0.602 (0.734)	Data 0.0000 (0.0000)	Loss 1.3994 (1.7158)	
label_Epoch: [46][180/345]	Time 0.606 (0.727)	Data 0.0000 (0.0000)	Loss 1.8206 (1.7082)	
label_Epoch: [46][190/345]	Time 0.630 (0.721)	Data 0.0000 (0.0000)	Loss 1.0529 (1.6910)	
label_Epoch: [46][200/345]	Time 0.611 (0.716)	Data 0.0000 (0.0000)	Loss 2.0769 (1.6869)	
label_Epoch: [46][210/345]	Time 0.610 (0.711)	Data 0.0000 (0.0000)	Loss 1.2326 (1.6728)	
label_Epoch: [46][220/345]	Time 0.606 (0.707)	Data 0.0000 (0.0000)	Loss 1.4020 (1.6578)	
label_Epoch: [46][230/345]	Time 0.620 (0.703)	Data 0.0000 (0.0000)	Loss 1.2241 (1.6438)	
label_Epoch: [46][240/345]	Time 0.640 (0.700)	Data 0.0000 (0.0000)	Loss 1.2649 (1.6280)	
label_Epoch: [46][250/345]	Time 0.631 (0.697)	Data 0.0000 (0.0000)	Loss 1.0793 (1.6137)	
label_Epoch: [46][260/345]	Time 0.604 (0.693)	Data 0.0000 (0.0000)	Loss 1.1123 (1.6064)	
label_Epoch: [46][270/345]	Time 0.644 (0.691)	Data 0.0000 (0.0000)	Loss 1.1648 (1.5978)	
label_Epoch: [46][280/345]	Time 0.629 (0.688)	Data 0.0000 (0.0000)	Loss 1.1892 (1.5854)	
label_Epoch: [46][290/345]	Time 0.648 (0.686)	Data 0.0000 (0.0000)	Loss 1.0564 (1.5774)	
label_Epoch: [46][300/345]	Time 0.635 (0.684)	Data 0.0000 (0.0000)	Loss 1.0632 (1.5661)	
label_Epoch: [46][310/345]	Time 0.605 (0.682)	Data 0.0000 (0.0000)	Loss 1.1431 (1.5556)	
label_Epoch: [46][320/345]	Time 0.627 (0.680)	Data 0.0000 (0.0000)	Loss 1.2427 (1.5431)	
label_Epoch: [46][330/345]	Time 0.625 (0.678)	Data 0.0000 (0.0000)	Loss 1.1400 (1.5308)	
label_Epoch: [46][340/345]	Time 0.610 (0.676)	Data 0.0000 (0.0000)	Loss 1.0635 (1.5195)	
46
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [47][10/345]	Time 0.600 (2.443)	Data 0.0000 (0.0000)	Loss 1.6834 (1.7309)	
label_Epoch: [47][20/345]	Time 0.613 (1.528)	Data 0.0000 (0.0000)	Loss 2.3038 (1.8917)	
label_Epoch: [47][30/345]	Time 0.614 (1.223)	Data 0.0000 (0.0000)	Loss 1.8904 (1.9313)	
label_Epoch: [47][40/345]	Time 0.615 (1.073)	Data 0.0000 (0.0000)	Loss 1.5429 (2.0301)	
label_Epoch: [47][50/345]	Time 0.626 (0.982)	Data 0.0000 (0.0000)	Loss 1.4133 (1.9942)	
label_Epoch: [47][60/345]	Time 0.626 (0.921)	Data 0.0000 (0.0000)	Loss 1.1369 (1.9483)	
label_Epoch: [47][70/345]	Time 0.642 (0.877)	Data 0.0000 (0.0000)	Loss 2.1762 (1.9549)	
label_Epoch: [47][80/345]	Time 0.621 (0.846)	Data 0.0000 (0.0000)	Loss 2.2155 (1.9083)	
label_Epoch: [47][90/345]	Time 0.620 (0.821)	Data 0.0000 (0.0000)	Loss 1.5400 (1.8709)	
label_Epoch: [47][100/345]	Time 0.639 (0.801)	Data 0.0000 (0.0000)	Loss 1.2891 (1.8778)	
label_Epoch: [47][110/345]	Time 0.622 (0.784)	Data 0.0000 (0.0000)	Loss 1.8464 (1.8697)	
label_Epoch: [47][120/345]	Time 0.618 (0.770)	Data 0.0000 (0.0000)	Loss 1.8096 (1.8497)	
label_Epoch: [47][130/345]	Time 0.607 (0.758)	Data 0.0000 (0.0000)	Loss 1.2228 (1.8152)	
label_Epoch: [47][140/345]	Time 0.632 (0.748)	Data 0.0000 (0.0000)	Loss 1.7446 (1.7901)	
label_Epoch: [47][150/345]	Time 0.636 (0.739)	Data 0.0000 (0.0000)	Loss 1.2693 (1.7653)	
label_Epoch: [47][160/345]	Time 0.612 (0.732)	Data 0.0000 (0.0000)	Loss 1.2057 (1.7441)	
label_Epoch: [47][170/345]	Time 0.624 (0.725)	Data 0.0000 (0.0000)	Loss 1.6719 (1.7188)	
label_Epoch: [47][180/345]	Time 0.626 (0.719)	Data 0.0000 (0.0000)	Loss 1.4261 (1.7187)	
label_Epoch: [47][190/345]	Time 0.630 (0.714)	Data 0.0000 (0.0000)	Loss 1.4948 (1.7013)	
label_Epoch: [47][200/345]	Time 0.618 (0.708)	Data 0.0000 (0.0000)	Loss 1.8686 (1.6878)	
label_Epoch: [47][210/345]	Time 0.603 (0.704)	Data 0.0000 (0.0000)	Loss 2.2133 (1.6720)	
label_Epoch: [47][220/345]	Time 0.636 (0.700)	Data 0.0000 (0.0000)	Loss 1.5667 (1.6592)	
label_Epoch: [47][230/345]	Time 0.624 (0.697)	Data 0.0000 (0.0000)	Loss 1.7128 (1.6477)	
label_Epoch: [47][240/345]	Time 0.612 (0.693)	Data 0.0000 (0.0000)	Loss 1.2344 (1.6384)	
label_Epoch: [47][250/345]	Time 0.617 (0.690)	Data 0.0000 (0.0000)	Loss 1.4028 (1.6258)	
label_Epoch: [47][260/345]	Time 0.626 (0.688)	Data 0.0000 (0.0000)	Loss 1.1610 (1.6152)	
label_Epoch: [47][270/345]	Time 0.641 (0.685)	Data 0.0000 (0.0000)	Loss 1.1613 (1.6021)	
label_Epoch: [47][280/345]	Time 0.627 (0.683)	Data 0.0000 (0.0000)	Loss 1.0691 (1.5917)	
label_Epoch: [47][290/345]	Time 0.604 (0.680)	Data 0.0000 (0.0000)	Loss 1.1823 (1.5777)	
label_Epoch: [47][300/345]	Time 0.613 (0.678)	Data 0.0000 (0.0000)	Loss 1.3347 (1.5647)	
label_Epoch: [47][310/345]	Time 0.603 (0.676)	Data 0.0000 (0.0000)	Loss 1.0811 (1.5530)	
label_Epoch: [47][320/345]	Time 0.617 (0.674)	Data 0.0000 (0.0000)	Loss 1.0481 (1.5413)	
label_Epoch: [47][330/345]	Time 0.616 (0.672)	Data 0.0000 (0.0000)	Loss 1.1285 (1.5290)	
label_Epoch: [47][340/345]	Time 0.621 (0.671)	Data 0.0000 (0.0000)	Loss 1.0548 (1.5172)	
47
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [48][10/345]	Time 0.610 (2.552)	Data 0.0000 (0.0000)	Loss 2.4298 (2.1482)	
label_Epoch: [48][20/345]	Time 0.627 (1.587)	Data 0.0000 (0.0000)	Loss 3.1152 (2.2360)	
label_Epoch: [48][30/345]	Time 0.619 (1.265)	Data 0.0000 (0.0000)	Loss 1.5732 (2.1359)	
label_Epoch: [48][40/345]	Time 0.623 (1.103)	Data 0.0000 (0.0000)	Loss 2.4853 (2.0782)	
label_Epoch: [48][50/345]	Time 0.610 (1.006)	Data 0.0000 (0.0000)	Loss 1.2435 (2.0083)	
label_Epoch: [48][60/345]	Time 0.611 (0.941)	Data 0.0000 (0.0000)	Loss 1.1509 (1.9610)	
label_Epoch: [48][70/345]	Time 0.627 (0.895)	Data 0.0000 (0.0000)	Loss 1.8194 (1.9408)	
label_Epoch: [48][80/345]	Time 0.620 (0.860)	Data 0.0000 (0.0000)	Loss 1.5131 (1.9253)	
label_Epoch: [48][90/345]	Time 0.603 (0.833)	Data 0.0000 (0.0000)	Loss 1.3231 (1.9120)	
label_Epoch: [48][100/345]	Time 0.603 (0.811)	Data 0.0000 (0.0000)	Loss 2.6784 (1.8953)	
label_Epoch: [48][110/345]	Time 0.620 (0.793)	Data 0.0000 (0.0000)	Loss 2.4729 (1.8946)	
label_Epoch: [48][120/345]	Time 0.609 (0.778)	Data 0.0000 (0.0000)	Loss 1.4251 (1.8766)	
label_Epoch: [48][130/345]	Time 0.604 (0.766)	Data 0.0000 (0.0000)	Loss 1.8153 (1.8517)	
label_Epoch: [48][140/345]	Time 0.614 (0.755)	Data 0.0000 (0.0000)	Loss 1.1208 (1.8127)	
label_Epoch: [48][150/345]	Time 0.614 (0.746)	Data 0.0000 (0.0000)	Loss 1.1998 (1.7920)	
label_Epoch: [48][160/345]	Time 0.612 (0.738)	Data 0.0000 (0.0000)	Loss 1.9672 (1.7711)	
label_Epoch: [48][170/345]	Time 0.616 (0.731)	Data 0.0000 (0.0000)	Loss 1.7401 (1.7593)	
label_Epoch: [48][180/345]	Time 0.613 (0.724)	Data 0.0000 (0.0000)	Loss 1.3711 (1.7359)	
label_Epoch: [48][190/345]	Time 0.644 (0.719)	Data 0.0000 (0.0000)	Loss 1.3550 (1.7177)	
label_Epoch: [48][200/345]	Time 0.609 (0.714)	Data 0.0000 (0.0000)	Loss 1.2070 (1.7040)	
label_Epoch: [48][210/345]	Time 0.602 (0.709)	Data 0.0000 (0.0000)	Loss 1.4463 (1.6875)	
label_Epoch: [48][220/345]	Time 0.608 (0.705)	Data 0.0000 (0.0000)	Loss 1.3648 (1.6778)	
label_Epoch: [48][230/345]	Time 0.604 (0.702)	Data 0.0000 (0.0000)	Loss 1.6942 (1.6671)	
label_Epoch: [48][240/345]	Time 0.633 (0.698)	Data 0.0000 (0.0000)	Loss 1.6593 (1.6496)	
label_Epoch: [48][250/345]	Time 0.626 (0.694)	Data 0.0000 (0.0000)	Loss 1.1108 (1.6360)	
label_Epoch: [48][260/345]	Time 0.615 (0.691)	Data 0.0000 (0.0000)	Loss 1.5368 (1.6217)	
label_Epoch: [48][270/345]	Time 0.604 (0.688)	Data 0.0000 (0.0000)	Loss 1.3952 (1.6130)	
label_Epoch: [48][280/345]	Time 0.604 (0.686)	Data 0.0000 (0.0000)	Loss 2.2865 (1.6066)	
label_Epoch: [48][290/345]	Time 0.633 (0.684)	Data 0.0000 (0.0000)	Loss 1.3614 (1.5939)	
label_Epoch: [48][300/345]	Time 0.621 (0.681)	Data 0.0000 (0.0000)	Loss 1.1591 (1.5812)	
label_Epoch: [48][310/345]	Time 0.627 (0.679)	Data 0.0000 (0.0000)	Loss 1.2280 (1.5709)	
label_Epoch: [48][320/345]	Time 0.603 (0.677)	Data 0.0000 (0.0000)	Loss 1.1906 (1.5592)	
label_Epoch: [48][330/345]	Time 0.610 (0.675)	Data 0.0000 (0.0000)	Loss 1.1951 (1.5475)	
label_Epoch: [48][340/345]	Time 0.600 (0.674)	Data 0.0000 (0.0000)	Loss 1.0422 (1.5383)	
48
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [49][10/345]	Time 0.630 (2.554)	Data 0.0000 (0.0000)	Loss 1.2523 (1.9287)	
label_Epoch: [49][20/345]	Time 0.632 (1.588)	Data 0.0000 (0.0000)	Loss 1.9918 (2.0169)	
label_Epoch: [49][30/345]	Time 0.610 (1.266)	Data 0.0000 (0.0000)	Loss 2.9840 (2.0063)	
label_Epoch: [49][40/345]	Time 0.626 (1.103)	Data 0.0000 (0.0000)	Loss 3.0494 (1.9774)	
label_Epoch: [49][50/345]	Time 0.606 (1.004)	Data 0.0000 (0.0000)	Loss 3.1779 (2.0385)	
label_Epoch: [49][60/345]	Time 0.619 (0.940)	Data 0.0000 (0.0000)	Loss 1.6887 (1.9703)	
label_Epoch: [49][70/345]	Time 0.608 (0.894)	Data 0.0000 (0.0000)	Loss 1.6859 (1.9344)	
label_Epoch: [49][80/345]	Time 0.638 (0.859)	Data 0.0000 (0.0000)	Loss 1.6979 (1.8841)	
label_Epoch: [49][90/345]	Time 0.630 (0.832)	Data 0.0000 (0.0000)	Loss 1.4331 (1.8819)	
label_Epoch: [49][100/345]	Time 0.616 (0.810)	Data 0.0000 (0.0000)	Loss 1.6635 (1.8754)	
label_Epoch: [49][110/345]	Time 0.602 (0.793)	Data 0.0000 (0.0000)	Loss 1.6091 (1.8289)	
label_Epoch: [49][120/345]	Time 0.610 (0.779)	Data 0.0000 (0.0000)	Loss 2.4365 (1.8293)	
label_Epoch: [49][130/345]	Time 0.602 (0.766)	Data 0.0000 (0.0000)	Loss 1.7606 (1.8095)	
label_Epoch: [49][140/345]	Time 0.619 (0.756)	Data 0.0000 (0.0000)	Loss 1.0936 (1.7823)	
label_Epoch: [49][150/345]	Time 0.604 (0.746)	Data 0.0000 (0.0000)	Loss 1.2740 (1.7704)	
label_Epoch: [49][160/345]	Time 0.625 (0.738)	Data 0.0000 (0.0000)	Loss 1.3727 (1.7446)	
label_Epoch: [49][170/345]	Time 0.621 (0.731)	Data 0.0000 (0.0000)	Loss 1.2642 (1.7301)	
label_Epoch: [49][180/345]	Time 0.618 (0.725)	Data 0.0000 (0.0000)	Loss 1.6122 (1.7101)	
label_Epoch: [49][190/345]	Time 0.618 (0.720)	Data 0.0000 (0.0000)	Loss 1.0930 (1.6946)	
label_Epoch: [49][200/345]	Time 0.622 (0.715)	Data 0.0000 (0.0000)	Loss 1.3139 (1.6808)	
label_Epoch: [49][210/345]	Time 0.619 (0.711)	Data 0.0000 (0.0000)	Loss 1.6143 (1.6646)	
label_Epoch: [49][220/345]	Time 0.599 (0.707)	Data 0.0000 (0.0000)	Loss 1.1790 (1.6498)	
label_Epoch: [49][230/345]	Time 0.629 (0.703)	Data 0.0000 (0.0000)	Loss 1.3633 (1.6388)	
label_Epoch: [49][240/345]	Time 0.630 (0.699)	Data 0.0000 (0.0000)	Loss 1.5503 (1.6254)	
label_Epoch: [49][250/345]	Time 0.616 (0.696)	Data 0.0000 (0.0000)	Loss 1.2685 (1.6118)	
label_Epoch: [49][260/345]	Time 0.627 (0.693)	Data 0.0000 (0.0000)	Loss 1.0701 (1.5962)	
label_Epoch: [49][270/345]	Time 0.611 (0.690)	Data 0.0000 (0.0000)	Loss 1.8677 (1.5888)	
label_Epoch: [49][280/345]	Time 0.609 (0.688)	Data 0.0000 (0.0000)	Loss 1.1705 (1.5792)	
label_Epoch: [49][290/345]	Time 0.619 (0.685)	Data 0.0000 (0.0000)	Loss 1.2733 (1.5673)	
label_Epoch: [49][300/345]	Time 0.625 (0.683)	Data 0.0000 (0.0000)	Loss 1.3459 (1.5561)	
label_Epoch: [49][310/345]	Time 0.614 (0.681)	Data 0.0000 (0.0000)	Loss 1.0543 (1.5485)	
label_Epoch: [49][320/345]	Time 0.619 (0.679)	Data 0.0000 (0.0000)	Loss 1.1199 (1.5368)	
label_Epoch: [49][330/345]	Time 0.617 (0.677)	Data 0.0000 (0.0000)	Loss 1.5820 (1.5299)	
label_Epoch: [49][340/345]	Time 0.621 (0.675)	Data 0.0000 (0.0000)	Loss 1.1630 (1.5208)	
49
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [50][10/345]	Time 0.639 (2.420)	Data 0.0000 (0.0000)	Loss 1.8958 (2.1911)	
label_Epoch: [50][20/345]	Time 0.637 (1.516)	Data 0.0000 (0.0000)	Loss 2.0463 (2.1141)	
label_Epoch: [50][30/345]	Time 0.618 (1.217)	Data 0.0000 (0.0000)	Loss 1.4807 (2.1575)	
label_Epoch: [50][40/345]	Time 0.621 (1.067)	Data 0.0000 (0.0000)	Loss 1.6123 (2.0660)	
label_Epoch: [50][50/345]	Time 0.604 (0.976)	Data 0.0000 (0.0000)	Loss 1.2916 (2.0529)	
label_Epoch: [50][60/345]	Time 0.620 (0.917)	Data 0.0000 (0.0000)	Loss 1.7417 (2.0493)	
label_Epoch: [50][70/345]	Time 0.639 (0.874)	Data 0.0000 (0.0000)	Loss 1.4129 (1.9746)	
label_Epoch: [50][80/345]	Time 0.620 (0.841)	Data 0.0000 (0.0000)	Loss 1.5708 (1.9472)	
label_Epoch: [50][90/345]	Time 0.621 (0.816)	Data 0.0000 (0.0000)	Loss 1.5073 (1.9055)	
label_Epoch: [50][100/345]	Time 0.612 (0.796)	Data 0.0000 (0.0000)	Loss 3.4599 (1.8960)	
label_Epoch: [50][110/345]	Time 0.604 (0.780)	Data 0.0000 (0.0000)	Loss 1.3064 (1.8775)	
label_Epoch: [50][120/345]	Time 0.615 (0.767)	Data 0.0000 (0.0000)	Loss 1.9755 (1.8688)	
label_Epoch: [50][130/345]	Time 0.610 (0.755)	Data 0.0000 (0.0000)	Loss 1.0991 (1.8349)	
label_Epoch: [50][140/345]	Time 0.615 (0.745)	Data 0.0000 (0.0000)	Loss 1.1013 (1.7951)	
label_Epoch: [50][150/345]	Time 0.629 (0.737)	Data 0.0000 (0.0000)	Loss 1.6247 (1.7730)	
label_Epoch: [50][160/345]	Time 0.608 (0.729)	Data 0.0000 (0.0000)	Loss 1.6605 (1.7506)	
label_Epoch: [50][170/345]	Time 0.611 (0.722)	Data 0.0000 (0.0000)	Loss 1.4774 (1.7450)	
label_Epoch: [50][180/345]	Time 0.622 (0.717)	Data 0.0000 (0.0000)	Loss 1.4044 (1.7276)	
label_Epoch: [50][190/345]	Time 0.621 (0.711)	Data 0.0000 (0.0000)	Loss 1.3785 (1.7183)	
label_Epoch: [50][200/345]	Time 0.623 (0.707)	Data 0.0000 (0.0000)	Loss 1.5609 (1.7030)	
label_Epoch: [50][210/345]	Time 0.613 (0.702)	Data 0.0000 (0.0000)	Loss 1.3581 (1.6871)	
label_Epoch: [50][220/345]	Time 0.622 (0.699)	Data 0.0000 (0.0000)	Loss 1.4212 (1.6725)	
label_Epoch: [50][230/345]	Time 0.597 (0.695)	Data 0.0000 (0.0000)	Loss 1.1725 (1.6539)	
label_Epoch: [50][240/345]	Time 0.615 (0.692)	Data 0.0000 (0.0000)	Loss 1.2107 (1.6475)	
label_Epoch: [50][250/345]	Time 0.607 (0.689)	Data 0.0000 (0.0000)	Loss 1.1455 (1.6341)	
label_Epoch: [50][260/345]	Time 0.621 (0.686)	Data 0.0000 (0.0000)	Loss 1.1379 (1.6206)	
label_Epoch: [50][270/345]	Time 0.605 (0.683)	Data 0.0000 (0.0000)	Loss 1.0402 (1.6050)	
label_Epoch: [50][280/345]	Time 0.612 (0.681)	Data 0.0000 (0.0000)	Loss 1.2356 (1.5926)	
label_Epoch: [50][290/345]	Time 0.622 (0.679)	Data 0.0000 (0.0000)	Loss 1.0626 (1.5830)	
label_Epoch: [50][300/345]	Time 0.604 (0.676)	Data 0.0000 (0.0000)	Loss 1.3743 (1.5733)	
label_Epoch: [50][310/345]	Time 0.611 (0.675)	Data 0.0000 (0.0000)	Loss 1.2335 (1.5643)	
label_Epoch: [50][320/345]	Time 0.618 (0.673)	Data 0.0000 (0.0000)	Loss 1.4569 (1.5530)	
label_Epoch: [50][330/345]	Time 0.613 (0.671)	Data 0.0000 (0.0000)	Loss 1.1429 (1.5423)	
label_Epoch: [50][340/345]	Time 0.617 (0.670)	Data 0.0000 (0.0000)	Loss 1.0651 (1.5319)	
50
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [51][10/345]	Time 0.614 (2.353)	Data 0.0000 (0.0000)	Loss 1.2962 (1.6960)	
label_Epoch: [51][20/345]	Time 0.613 (1.486)	Data 0.0000 (0.0000)	Loss 2.2944 (1.8192)	
label_Epoch: [51][30/345]	Time 0.615 (1.194)	Data 0.0000 (0.0000)	Loss 2.4203 (1.8140)	
label_Epoch: [51][40/345]	Time 0.626 (1.049)	Data 0.0000 (0.0000)	Loss 2.7867 (1.8762)	
label_Epoch: [51][50/345]	Time 0.604 (0.962)	Data 0.0000 (0.0000)	Loss 2.0300 (1.9204)	
label_Epoch: [51][60/345]	Time 0.629 (0.905)	Data 0.0000 (0.0000)	Loss 1.1798 (1.9105)	
label_Epoch: [51][70/345]	Time 0.617 (0.863)	Data 0.0000 (0.0000)	Loss 1.0742 (1.9021)	
label_Epoch: [51][80/345]	Time 0.620 (0.833)	Data 0.0000 (0.0000)	Loss 1.8161 (1.8833)	
label_Epoch: [51][90/345]	Time 0.624 (0.809)	Data 0.0000 (0.0000)	Loss 1.2355 (1.8555)	
label_Epoch: [51][100/345]	Time 0.604 (0.790)	Data 0.0000 (0.0000)	Loss 1.3614 (1.8383)	
label_Epoch: [51][110/345]	Time 0.621 (0.775)	Data 0.0000 (0.0000)	Loss 1.9747 (1.8307)	
label_Epoch: [51][120/345]	Time 0.611 (0.762)	Data 0.0000 (0.0000)	Loss 2.0526 (1.8158)	
label_Epoch: [51][130/345]	Time 0.631 (0.750)	Data 0.0000 (0.0000)	Loss 1.8674 (1.8017)	
label_Epoch: [51][140/345]	Time 0.627 (0.741)	Data 0.0000 (0.0000)	Loss 1.1959 (1.7763)	
label_Epoch: [51][150/345]	Time 0.622 (0.733)	Data 0.0000 (0.0000)	Loss 1.3084 (1.7473)	
label_Epoch: [51][160/345]	Time 0.625 (0.726)	Data 0.0000 (0.0000)	Loss 1.1978 (1.7370)	
label_Epoch: [51][170/345]	Time 0.618 (0.720)	Data 0.0000 (0.0000)	Loss 1.6484 (1.7208)	
label_Epoch: [51][180/345]	Time 0.635 (0.714)	Data 0.0000 (0.0000)	Loss 1.3928 (1.7068)	
label_Epoch: [51][190/345]	Time 0.610 (0.709)	Data 0.0000 (0.0000)	Loss 1.5544 (1.6966)	
label_Epoch: [51][200/345]	Time 0.609 (0.704)	Data 0.0000 (0.0000)	Loss 1.4763 (1.6804)	
label_Epoch: [51][210/345]	Time 0.631 (0.700)	Data 0.0000 (0.0000)	Loss 1.5599 (1.6745)	
label_Epoch: [51][220/345]	Time 0.630 (0.696)	Data 0.0000 (0.0000)	Loss 1.1404 (1.6583)	
label_Epoch: [51][230/345]	Time 0.613 (0.693)	Data 0.0000 (0.0000)	Loss 1.3248 (1.6437)	
label_Epoch: [51][240/345]	Time 0.639 (0.690)	Data 0.0000 (0.0000)	Loss 1.3422 (1.6325)	
label_Epoch: [51][250/345]	Time 0.613 (0.687)	Data 0.0000 (0.0000)	Loss 1.3365 (1.6237)	
label_Epoch: [51][260/345]	Time 0.629 (0.684)	Data 0.0000 (0.0000)	Loss 1.5658 (1.6073)	
label_Epoch: [51][270/345]	Time 0.610 (0.681)	Data 0.0000 (0.0000)	Loss 1.3737 (1.5982)	
label_Epoch: [51][280/345]	Time 0.616 (0.679)	Data 0.0000 (0.0000)	Loss 1.1744 (1.5849)	
label_Epoch: [51][290/345]	Time 0.613 (0.677)	Data 0.0000 (0.0000)	Loss 1.3958 (1.5755)	
label_Epoch: [51][300/345]	Time 0.599 (0.675)	Data 0.0000 (0.0000)	Loss 1.1209 (1.5615)	
label_Epoch: [51][310/345]	Time 0.604 (0.673)	Data 0.0000 (0.0000)	Loss 1.0538 (1.5518)	
label_Epoch: [51][320/345]	Time 0.609 (0.671)	Data 0.0000 (0.0000)	Loss 1.1228 (1.5411)	
label_Epoch: [51][330/345]	Time 0.615 (0.670)	Data 0.0000 (0.0000)	Loss 1.1828 (1.5315)	
label_Epoch: [51][340/345]	Time 0.630 (0.668)	Data 0.0000 (0.0000)	Loss 1.2321 (1.5206)	
51
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [52][10/345]	Time 0.614 (2.390)	Data 0.0000 (0.0000)	Loss 1.8784 (2.1124)	
label_Epoch: [52][20/345]	Time 0.609 (1.503)	Data 0.0000 (0.0000)	Loss 1.3820 (2.0034)	
label_Epoch: [52][30/345]	Time 0.609 (1.205)	Data 0.0000 (0.0000)	Loss 2.4451 (1.9871)	
label_Epoch: [52][40/345]	Time 0.626 (1.057)	Data 0.0000 (0.0000)	Loss 1.1527 (1.9605)	
label_Epoch: [52][50/345]	Time 0.620 (0.969)	Data 0.0000 (0.0000)	Loss 2.2940 (1.9370)	
label_Epoch: [52][60/345]	Time 0.618 (0.911)	Data 0.0000 (0.0000)	Loss 1.6514 (1.9281)	
label_Epoch: [52][70/345]	Time 0.631 (0.870)	Data 0.0000 (0.0000)	Loss 1.4231 (1.8939)	
label_Epoch: [52][80/345]	Time 0.600 (0.838)	Data 0.0000 (0.0000)	Loss 1.6003 (1.8793)	
label_Epoch: [52][90/345]	Time 0.611 (0.814)	Data 0.0000 (0.0000)	Loss 1.7022 (1.8419)	
label_Epoch: [52][100/345]	Time 0.619 (0.794)	Data 0.0000 (0.0000)	Loss 1.2591 (1.7942)	
label_Epoch: [52][110/345]	Time 0.602 (0.778)	Data 0.0000 (0.0000)	Loss 1.5329 (1.7665)	
label_Epoch: [52][120/345]	Time 0.621 (0.765)	Data 0.0000 (0.0000)	Loss 1.7324 (1.7557)	
label_Epoch: [52][130/345]	Time 0.605 (0.754)	Data 0.0000 (0.0000)	Loss 2.3760 (1.7553)	
label_Epoch: [52][140/345]	Time 0.600 (0.744)	Data 0.0000 (0.0000)	Loss 1.2685 (1.7353)	
label_Epoch: [52][150/345]	Time 0.619 (0.736)	Data 0.0000 (0.0000)	Loss 1.3237 (1.7251)	
label_Epoch: [52][160/345]	Time 0.605 (0.728)	Data 0.0000 (0.0000)	Loss 1.2436 (1.7090)	
label_Epoch: [52][170/345]	Time 0.624 (0.722)	Data 0.0000 (0.0000)	Loss 1.2872 (1.7010)	
label_Epoch: [52][180/345]	Time 0.634 (0.716)	Data 0.0000 (0.0000)	Loss 1.3456 (1.6971)	
label_Epoch: [52][190/345]	Time 0.609 (0.711)	Data 0.0000 (0.0000)	Loss 1.3687 (1.6863)	
label_Epoch: [52][200/345]	Time 0.608 (0.706)	Data 0.0000 (0.0000)	Loss 1.5058 (1.6718)	
label_Epoch: [52][210/345]	Time 0.622 (0.701)	Data 0.0000 (0.0000)	Loss 1.3231 (1.6626)	
label_Epoch: [52][220/345]	Time 0.622 (0.698)	Data 0.0000 (0.0000)	Loss 1.4872 (1.6540)	
label_Epoch: [52][230/345]	Time 0.606 (0.694)	Data 0.0000 (0.0000)	Loss 1.5293 (1.6396)	
label_Epoch: [52][240/345]	Time 0.611 (0.691)	Data 0.0000 (0.0000)	Loss 1.4030 (1.6254)	
label_Epoch: [52][250/345]	Time 0.622 (0.688)	Data 0.0000 (0.0000)	Loss 1.7809 (1.6147)	
label_Epoch: [52][260/345]	Time 0.620 (0.685)	Data 0.0000 (0.0000)	Loss 1.2774 (1.6003)	
label_Epoch: [52][270/345]	Time 0.604 (0.683)	Data 0.0000 (0.0000)	Loss 1.1427 (1.5882)	
label_Epoch: [52][280/345]	Time 0.624 (0.681)	Data 0.0000 (0.0000)	Loss 1.0964 (1.5782)	
label_Epoch: [52][290/345]	Time 0.617 (0.678)	Data 0.0000 (0.0000)	Loss 1.1147 (1.5660)	
label_Epoch: [52][300/345]	Time 0.602 (0.676)	Data 0.0000 (0.0000)	Loss 1.1999 (1.5588)	
label_Epoch: [52][310/345]	Time 0.603 (0.675)	Data 0.0000 (0.0000)	Loss 1.4703 (1.5461)	
label_Epoch: [52][320/345]	Time 0.628 (0.673)	Data 0.0000 (0.0000)	Loss 1.1354 (1.5349)	
label_Epoch: [52][330/345]	Time 0.613 (0.671)	Data 0.0000 (0.0000)	Loss 1.5307 (1.5244)	
label_Epoch: [52][340/345]	Time 0.629 (0.670)	Data 0.0000 (0.0000)	Loss 1.0423 (1.5134)	
52
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [53][10/345]	Time 0.637 (2.384)	Data 0.0000 (0.0000)	Loss 2.0786 (2.1867)	
label_Epoch: [53][20/345]	Time 0.602 (1.499)	Data 0.0000 (0.0000)	Loss 1.4842 (1.9493)	
label_Epoch: [53][30/345]	Time 0.616 (1.207)	Data 0.0000 (0.0000)	Loss 3.1934 (1.9332)	
label_Epoch: [53][40/345]	Time 0.634 (1.061)	Data 0.0000 (0.0000)	Loss 2.2664 (2.0023)	
label_Epoch: [53][50/345]	Time 0.611 (0.971)	Data 0.0000 (0.0000)	Loss 2.6605 (1.9849)	
label_Epoch: [53][60/345]	Time 0.619 (0.913)	Data 0.0000 (0.0000)	Loss 1.2108 (1.8998)	
label_Epoch: [53][70/345]	Time 0.606 (0.870)	Data 0.0000 (0.0000)	Loss 1.4977 (1.8612)	
label_Epoch: [53][80/345]	Time 0.611 (0.838)	Data 0.0000 (0.0000)	Loss 2.0835 (1.8231)	
label_Epoch: [53][90/345]	Time 0.622 (0.814)	Data 0.0000 (0.0000)	Loss 2.3545 (1.8259)	
label_Epoch: [53][100/345]	Time 0.616 (0.794)	Data 0.0000 (0.0000)	Loss 1.3276 (1.7930)	
label_Epoch: [53][110/345]	Time 0.611 (0.778)	Data 0.0000 (0.0000)	Loss 1.2646 (1.7849)	
label_Epoch: [53][120/345]	Time 0.615 (0.765)	Data 0.0000 (0.0000)	Loss 1.1791 (1.7557)	
label_Epoch: [53][130/345]	Time 0.633 (0.754)	Data 0.0000 (0.0000)	Loss 1.3845 (1.7414)	
label_Epoch: [53][140/345]	Time 0.611 (0.744)	Data 0.0000 (0.0000)	Loss 1.6903 (1.7166)	
label_Epoch: [53][150/345]	Time 0.622 (0.736)	Data 0.0000 (0.0000)	Loss 1.3954 (1.7156)	
label_Epoch: [53][160/345]	Time 0.624 (0.728)	Data 0.0000 (0.0000)	Loss 1.1706 (1.6991)	
label_Epoch: [53][170/345]	Time 0.601 (0.722)	Data 0.0000 (0.0000)	Loss 1.4092 (1.6899)	
label_Epoch: [53][180/345]	Time 0.602 (0.716)	Data 0.0000 (0.0000)	Loss 1.1105 (1.6756)	
label_Epoch: [53][190/345]	Time 0.619 (0.711)	Data 0.0000 (0.0000)	Loss 1.4252 (1.6625)	
label_Epoch: [53][200/345]	Time 0.636 (0.706)	Data 0.0000 (0.0000)	Loss 1.2590 (1.6477)	
label_Epoch: [53][210/345]	Time 0.618 (0.702)	Data 0.0000 (0.0000)	Loss 1.4144 (1.6335)	
label_Epoch: [53][220/345]	Time 0.601 (0.698)	Data 0.0000 (0.0000)	Loss 1.2335 (1.6179)	
label_Epoch: [53][230/345]	Time 0.620 (0.694)	Data 0.0000 (0.0000)	Loss 2.7663 (1.6111)	
label_Epoch: [53][240/345]	Time 0.617 (0.691)	Data 0.0000 (0.0000)	Loss 1.0885 (1.5989)	
label_Epoch: [53][250/345]	Time 0.635 (0.688)	Data 0.0000 (0.0000)	Loss 1.0988 (1.5873)	
label_Epoch: [53][260/345]	Time 0.630 (0.686)	Data 0.0000 (0.0000)	Loss 1.2963 (1.5773)	
label_Epoch: [53][270/345]	Time 0.608 (0.683)	Data 0.0000 (0.0000)	Loss 1.7211 (1.5691)	
label_Epoch: [53][280/345]	Time 0.612 (0.681)	Data 0.0000 (0.0000)	Loss 1.1096 (1.5583)	
label_Epoch: [53][290/345]	Time 0.621 (0.679)	Data 0.0000 (0.0000)	Loss 1.3315 (1.5471)	
label_Epoch: [53][300/345]	Time 0.615 (0.677)	Data 0.0000 (0.0000)	Loss 1.1732 (1.5398)	
label_Epoch: [53][310/345]	Time 0.614 (0.675)	Data 0.0000 (0.0000)	Loss 1.2580 (1.5304)	
label_Epoch: [53][320/345]	Time 0.641 (0.673)	Data 0.0000 (0.0000)	Loss 1.5348 (1.5212)	
label_Epoch: [53][330/345]	Time 0.616 (0.671)	Data 0.0000 (0.0000)	Loss 1.1174 (1.5148)	
label_Epoch: [53][340/345]	Time 0.622 (0.670)	Data 0.0000 (0.0000)	Loss 1.2817 (1.5038)	
53
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [54][10/345]	Time 0.621 (2.494)	Data 0.0000 (0.0000)	Loss 2.4213 (1.7249)	
label_Epoch: [54][20/345]	Time 0.618 (1.555)	Data 0.0000 (0.0000)	Loss 1.7277 (1.9256)	
label_Epoch: [54][30/345]	Time 0.622 (1.245)	Data 0.0000 (0.0000)	Loss 2.0015 (1.9662)	
label_Epoch: [54][40/345]	Time 0.619 (1.090)	Data 0.0000 (0.0000)	Loss 1.5103 (1.8959)	
label_Epoch: [54][50/345]	Time 0.611 (0.995)	Data 0.0000 (0.0000)	Loss 2.6179 (1.8959)	
label_Epoch: [54][60/345]	Time 0.614 (0.933)	Data 0.0000 (0.0000)	Loss 2.2544 (1.8978)	
label_Epoch: [54][70/345]	Time 0.637 (0.888)	Data 0.0000 (0.0000)	Loss 1.3751 (1.8617)	
label_Epoch: [54][80/345]	Time 0.611 (0.855)	Data 0.0000 (0.0000)	Loss 1.2501 (1.8284)	
label_Epoch: [54][90/345]	Time 0.609 (0.828)	Data 0.0000 (0.0000)	Loss 2.1749 (1.8255)	
label_Epoch: [54][100/345]	Time 0.609 (0.807)	Data 0.0000 (0.0000)	Loss 1.6194 (1.7907)	
label_Epoch: [54][110/345]	Time 0.625 (0.790)	Data 0.0000 (0.0000)	Loss 1.2533 (1.7689)	
label_Epoch: [54][120/345]	Time 0.614 (0.776)	Data 0.0000 (0.0000)	Loss 2.4907 (1.7705)	
label_Epoch: [54][130/345]	Time 0.616 (0.763)	Data 0.0000 (0.0000)	Loss 1.6601 (1.7618)	
label_Epoch: [54][140/345]	Time 0.618 (0.753)	Data 0.0000 (0.0000)	Loss 1.3467 (1.7471)	
label_Epoch: [54][150/345]	Time 0.615 (0.744)	Data 0.0000 (0.0000)	Loss 1.6983 (1.7292)	
label_Epoch: [54][160/345]	Time 0.603 (0.736)	Data 0.0000 (0.0000)	Loss 1.2930 (1.7075)	
label_Epoch: [54][170/345]	Time 0.614 (0.729)	Data 0.0000 (0.0000)	Loss 2.1902 (1.6913)	
label_Epoch: [54][180/345]	Time 0.623 (0.723)	Data 0.0000 (0.0000)	Loss 1.6295 (1.6790)	
label_Epoch: [54][190/345]	Time 0.628 (0.718)	Data 0.0000 (0.0000)	Loss 1.4328 (1.6674)	
label_Epoch: [54][200/345]	Time 0.621 (0.713)	Data 0.0000 (0.0000)	Loss 1.1196 (1.6491)	
label_Epoch: [54][210/345]	Time 0.627 (0.708)	Data 0.0000 (0.0000)	Loss 1.8732 (1.6414)	
label_Epoch: [54][220/345]	Time 0.604 (0.704)	Data 0.0000 (0.0000)	Loss 1.4000 (1.6291)	
label_Epoch: [54][230/345]	Time 0.617 (0.700)	Data 0.0000 (0.0000)	Loss 1.3496 (1.6180)	
label_Epoch: [54][240/345]	Time 0.614 (0.697)	Data 0.0000 (0.0000)	Loss 1.6961 (1.6145)	
label_Epoch: [54][250/345]	Time 0.639 (0.694)	Data 0.0000 (0.0000)	Loss 1.5480 (1.6017)	
label_Epoch: [54][260/345]	Time 0.610 (0.691)	Data 0.0000 (0.0000)	Loss 1.0899 (1.5916)	
label_Epoch: [54][270/345]	Time 0.603 (0.688)	Data 0.0000 (0.0000)	Loss 1.1038 (1.5784)	
label_Epoch: [54][280/345]	Time 0.623 (0.686)	Data 0.0000 (0.0000)	Loss 1.4397 (1.5666)	
label_Epoch: [54][290/345]	Time 0.619 (0.683)	Data 0.0000 (0.0000)	Loss 1.3782 (1.5543)	
label_Epoch: [54][300/345]	Time 0.636 (0.681)	Data 0.0000 (0.0000)	Loss 1.3017 (1.5462)	
label_Epoch: [54][310/345]	Time 0.612 (0.679)	Data 0.0000 (0.0000)	Loss 1.1016 (1.5357)	
label_Epoch: [54][320/345]	Time 0.618 (0.676)	Data 0.0000 (0.0000)	Loss 1.2489 (1.5260)	
label_Epoch: [54][330/345]	Time 0.613 (0.675)	Data 0.0000 (0.0000)	Loss 1.0871 (1.5161)	
label_Epoch: [54][340/345]	Time 0.600 (0.673)	Data 0.0000 (0.0000)	Loss 1.1208 (1.5056)	
54
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [55][10/345]	Time 0.609 (2.430)	Data 0.0000 (0.0000)	Loss 2.2660 (2.0511)	
label_Epoch: [55][20/345]	Time 0.630 (1.528)	Data 0.0000 (0.0000)	Loss 1.7760 (1.9206)	
label_Epoch: [55][30/345]	Time 0.625 (1.224)	Data 0.0000 (0.0000)	Loss 1.9262 (1.9372)	
label_Epoch: [55][40/345]	Time 0.613 (1.071)	Data 0.0000 (0.0000)	Loss 1.4672 (1.8452)	
label_Epoch: [55][50/345]	Time 0.613 (0.982)	Data 0.0000 (0.0000)	Loss 1.4865 (1.8096)	
label_Epoch: [55][60/345]	Time 0.605 (0.921)	Data 0.0000 (0.0000)	Loss 1.1116 (1.8692)	
label_Epoch: [55][70/345]	Time 0.604 (0.877)	Data 0.0000 (0.0000)	Loss 1.8524 (1.8873)	
label_Epoch: [55][80/345]	Time 0.630 (0.845)	Data 0.0000 (0.0000)	Loss 1.5609 (1.8889)	
label_Epoch: [55][90/345]	Time 0.625 (0.819)	Data 0.0000 (0.0000)	Loss 2.3274 (1.8936)	
label_Epoch: [55][100/345]	Time 0.611 (0.799)	Data 0.0000 (0.0000)	Loss 1.2579 (1.8761)	
label_Epoch: [55][110/345]	Time 0.607 (0.782)	Data 0.0000 (0.0000)	Loss 2.2920 (1.8409)	
label_Epoch: [55][120/345]	Time 0.617 (0.768)	Data 0.0000 (0.0000)	Loss 1.2640 (1.8314)	
label_Epoch: [55][130/345]	Time 0.606 (0.756)	Data 0.0000 (0.0000)	Loss 1.6370 (1.8120)	
label_Epoch: [55][140/345]	Time 0.616 (0.746)	Data 0.0000 (0.0000)	Loss 1.2020 (1.7725)	
label_Epoch: [55][150/345]	Time 0.604 (0.738)	Data 0.0000 (0.0000)	Loss 1.5681 (1.7496)	
label_Epoch: [55][160/345]	Time 0.613 (0.730)	Data 0.0000 (0.0000)	Loss 1.4880 (1.7402)	
label_Epoch: [55][170/345]	Time 0.609 (0.724)	Data 0.0000 (0.0000)	Loss 1.3088 (1.7211)	
label_Epoch: [55][180/345]	Time 0.651 (0.718)	Data 0.0000 (0.0000)	Loss 1.0608 (1.7024)	
label_Epoch: [55][190/345]	Time 0.630 (0.713)	Data 0.0000 (0.0000)	Loss 1.8953 (1.6850)	
label_Epoch: [55][200/345]	Time 0.605 (0.708)	Data 0.0000 (0.0000)	Loss 1.0925 (1.6649)	
label_Epoch: [55][210/345]	Time 0.624 (0.704)	Data 0.0000 (0.0000)	Loss 1.2596 (1.6503)	
label_Epoch: [55][220/345]	Time 0.608 (0.700)	Data 0.0000 (0.0000)	Loss 1.4191 (1.6353)	
label_Epoch: [55][230/345]	Time 0.616 (0.696)	Data 0.0000 (0.0000)	Loss 1.3928 (1.6200)	
label_Epoch: [55][240/345]	Time 0.599 (0.693)	Data 0.0000 (0.0000)	Loss 1.4971 (1.6080)	
label_Epoch: [55][250/345]	Time 0.625 (0.690)	Data 0.0000 (0.0000)	Loss 1.0815 (1.5972)	
label_Epoch: [55][260/345]	Time 0.615 (0.688)	Data 0.0000 (0.0000)	Loss 1.3904 (1.5849)	
label_Epoch: [55][270/345]	Time 0.614 (0.685)	Data 0.0000 (0.0000)	Loss 1.2712 (1.5773)	
label_Epoch: [55][280/345]	Time 0.619 (0.683)	Data 0.0000 (0.0000)	Loss 1.2919 (1.5708)	
label_Epoch: [55][290/345]	Time 0.602 (0.680)	Data 0.0000 (0.0000)	Loss 1.4456 (1.5618)	
label_Epoch: [55][300/345]	Time 0.615 (0.678)	Data 0.0000 (0.0000)	Loss 1.1767 (1.5518)	
label_Epoch: [55][310/345]	Time 0.621 (0.676)	Data 0.0000 (0.0000)	Loss 1.1473 (1.5472)	
label_Epoch: [55][320/345]	Time 0.614 (0.675)	Data 0.0000 (0.0000)	Loss 1.0575 (1.5383)	
label_Epoch: [55][330/345]	Time 0.622 (0.673)	Data 0.0000 (0.0000)	Loss 1.1256 (1.5285)	
label_Epoch: [55][340/345]	Time 0.635 (0.671)	Data 0.0000 (0.0000)	Loss 1.0693 (1.5166)	
55
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [56][10/345]	Time 0.615 (2.519)	Data 0.0000 (0.0000)	Loss 2.1720 (2.1604)	
label_Epoch: [56][20/345]	Time 0.602 (1.568)	Data 0.0000 (0.0000)	Loss 2.4364 (2.0279)	
label_Epoch: [56][30/345]	Time 0.612 (1.254)	Data 0.0000 (0.0000)	Loss 1.5987 (2.0281)	
label_Epoch: [56][40/345]	Time 0.618 (1.095)	Data 0.0000 (0.0000)	Loss 2.3037 (1.9343)	
label_Epoch: [56][50/345]	Time 0.600 (0.998)	Data 0.0000 (0.0000)	Loss 2.2415 (1.9045)	
label_Epoch: [56][60/345]	Time 0.608 (0.935)	Data 0.0000 (0.0000)	Loss 2.0444 (1.8632)	
label_Epoch: [56][70/345]	Time 0.609 (0.888)	Data 0.0000 (0.0000)	Loss 1.2614 (1.8773)	
label_Epoch: [56][80/345]	Time 0.634 (0.854)	Data 0.0000 (0.0000)	Loss 1.3144 (1.8775)	
label_Epoch: [56][90/345]	Time 0.636 (0.828)	Data 0.0000 (0.0000)	Loss 1.7509 (1.8602)	
label_Epoch: [56][100/345]	Time 0.617 (0.806)	Data 0.0000 (0.0000)	Loss 1.9661 (1.8247)	
label_Epoch: [56][110/345]	Time 0.627 (0.789)	Data 0.0000 (0.0000)	Loss 1.2664 (1.8145)	
label_Epoch: [56][120/345]	Time 0.598 (0.774)	Data 0.0000 (0.0000)	Loss 1.6045 (1.7786)	
label_Epoch: [56][130/345]	Time 0.623 (0.763)	Data 0.0000 (0.0000)	Loss 2.3528 (1.7765)	
label_Epoch: [56][140/345]	Time 0.612 (0.752)	Data 0.0000 (0.0000)	Loss 2.0913 (1.7696)	
label_Epoch: [56][150/345]	Time 0.621 (0.743)	Data 0.0000 (0.0000)	Loss 1.3538 (1.7521)	
label_Epoch: [56][160/345]	Time 0.615 (0.735)	Data 0.0000 (0.0000)	Loss 1.5972 (1.7300)	
label_Epoch: [56][170/345]	Time 0.628 (0.728)	Data 0.0000 (0.0000)	Loss 1.0801 (1.7164)	
label_Epoch: [56][180/345]	Time 0.623 (0.722)	Data 0.0000 (0.0000)	Loss 1.6897 (1.6966)	
label_Epoch: [56][190/345]	Time 0.610 (0.717)	Data 0.0000 (0.0000)	Loss 1.8314 (1.6761)	
label_Epoch: [56][200/345]	Time 0.625 (0.712)	Data 0.0000 (0.0000)	Loss 1.0825 (1.6598)	
label_Epoch: [56][210/345]	Time 0.629 (0.707)	Data 0.0000 (0.0000)	Loss 1.2986 (1.6433)	
label_Epoch: [56][220/345]	Time 0.627 (0.703)	Data 0.0000 (0.0000)	Loss 1.1728 (1.6301)	
label_Epoch: [56][230/345]	Time 0.623 (0.700)	Data 0.0000 (0.0000)	Loss 1.4021 (1.6138)	
label_Epoch: [56][240/345]	Time 0.602 (0.696)	Data 0.0000 (0.0000)	Loss 1.3806 (1.6046)	
label_Epoch: [56][250/345]	Time 0.625 (0.693)	Data 0.0000 (0.0000)	Loss 1.2747 (1.5960)	
label_Epoch: [56][260/345]	Time 0.619 (0.690)	Data 0.0000 (0.0000)	Loss 1.3528 (1.5852)	
label_Epoch: [56][270/345]	Time 0.635 (0.687)	Data 0.0000 (0.0000)	Loss 1.1671 (1.5758)	
label_Epoch: [56][280/345]	Time 0.597 (0.685)	Data 0.0000 (0.0000)	Loss 1.2556 (1.5650)	
label_Epoch: [56][290/345]	Time 0.616 (0.682)	Data 0.0000 (0.0000)	Loss 1.0546 (1.5574)	
label_Epoch: [56][300/345]	Time 0.637 (0.680)	Data 0.0000 (0.0000)	Loss 1.5088 (1.5478)	
label_Epoch: [56][310/345]	Time 0.614 (0.678)	Data 0.0000 (0.0000)	Loss 1.0889 (1.5373)	
label_Epoch: [56][320/345]	Time 0.601 (0.676)	Data 0.0000 (0.0000)	Loss 1.0933 (1.5260)	
label_Epoch: [56][330/345]	Time 0.612 (0.674)	Data 0.0000 (0.0000)	Loss 1.1374 (1.5143)	
label_Epoch: [56][340/345]	Time 0.610 (0.673)	Data 0.0000 (0.0000)	Loss 1.0768 (1.5040)	
56
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [57][10/345]	Time 0.612 (2.553)	Data 0.0000 (0.0000)	Loss 1.1580 (1.7557)	
label_Epoch: [57][20/345]	Time 0.630 (1.587)	Data 0.0000 (0.0000)	Loss 1.9832 (1.8689)	
label_Epoch: [57][30/345]	Time 0.619 (1.265)	Data 0.0000 (0.0000)	Loss 2.3391 (1.8628)	
label_Epoch: [57][40/345]	Time 0.613 (1.103)	Data 0.0000 (0.0000)	Loss 2.5415 (1.8777)	
label_Epoch: [57][50/345]	Time 0.604 (1.004)	Data 0.0000 (0.0000)	Loss 1.2887 (1.8221)	
label_Epoch: [57][60/345]	Time 0.606 (0.940)	Data 0.0000 (0.0000)	Loss 1.5196 (1.8553)	
label_Epoch: [57][70/345]	Time 0.629 (0.893)	Data 0.0000 (0.0000)	Loss 1.5105 (1.8350)	
label_Epoch: [57][80/345]	Time 0.624 (0.859)	Data 0.0000 (0.0000)	Loss 1.7978 (1.8243)	
label_Epoch: [57][90/345]	Time 0.610 (0.832)	Data 0.0000 (0.0000)	Loss 1.3074 (1.8116)	
label_Epoch: [57][100/345]	Time 0.613 (0.810)	Data 0.0000 (0.0000)	Loss 1.4638 (1.7969)	
label_Epoch: [57][110/345]	Time 0.616 (0.793)	Data 0.0000 (0.0000)	Loss 1.2369 (1.7872)	
label_Epoch: [57][120/345]	Time 0.606 (0.778)	Data 0.0000 (0.0000)	Loss 1.3827 (1.7712)	
label_Epoch: [57][130/345]	Time 0.602 (0.766)	Data 0.0000 (0.0000)	Loss 1.1512 (1.7417)	
label_Epoch: [57][140/345]	Time 0.643 (0.755)	Data 0.0000 (0.0000)	Loss 1.2442 (1.7255)	
label_Epoch: [57][150/345]	Time 0.647 (0.746)	Data 0.0000 (0.0000)	Loss 1.4616 (1.7121)	
label_Epoch: [57][160/345]	Time 0.630 (0.738)	Data 0.0000 (0.0000)	Loss 1.8642 (1.7084)	
label_Epoch: [57][170/345]	Time 0.611 (0.731)	Data 0.0000 (0.0000)	Loss 1.1999 (1.7114)	
label_Epoch: [57][180/345]	Time 0.617 (0.725)	Data 0.0000 (0.0000)	Loss 1.4658 (1.6950)	
label_Epoch: [57][190/345]	Time 0.626 (0.719)	Data 0.0000 (0.0000)	Loss 1.6201 (1.6785)	
label_Epoch: [57][200/345]	Time 0.618 (0.714)	Data 0.0000 (0.0000)	Loss 1.2001 (1.6593)	
label_Epoch: [57][210/345]	Time 0.604 (0.709)	Data 0.0000 (0.0000)	Loss 1.5334 (1.6436)	
label_Epoch: [57][220/345]	Time 0.622 (0.705)	Data 0.0000 (0.0000)	Loss 1.4677 (1.6299)	
label_Epoch: [57][230/345]	Time 0.625 (0.701)	Data 0.0000 (0.0000)	Loss 1.2378 (1.6197)	
label_Epoch: [57][240/345]	Time 0.616 (0.698)	Data 0.0000 (0.0000)	Loss 1.1510 (1.6046)	
label_Epoch: [57][250/345]	Time 0.602 (0.695)	Data 0.0000 (0.0000)	Loss 1.4525 (1.5939)	
label_Epoch: [57][260/345]	Time 0.621 (0.692)	Data 0.0000 (0.0000)	Loss 1.1005 (1.5868)	
label_Epoch: [57][270/345]	Time 0.646 (0.689)	Data 0.0000 (0.0000)	Loss 1.5507 (1.5750)	
label_Epoch: [57][280/345]	Time 0.606 (0.687)	Data 0.0000 (0.0000)	Loss 1.0590 (1.5618)	
label_Epoch: [57][290/345]	Time 0.640 (0.684)	Data 0.0000 (0.0000)	Loss 1.0873 (1.5491)	
label_Epoch: [57][300/345]	Time 0.607 (0.682)	Data 0.0000 (0.0000)	Loss 1.5974 (1.5405)	
label_Epoch: [57][310/345]	Time 0.607 (0.680)	Data 0.0000 (0.0000)	Loss 1.0164 (1.5285)	
label_Epoch: [57][320/345]	Time 0.607 (0.678)	Data 0.0000 (0.0000)	Loss 1.1272 (1.5156)	
label_Epoch: [57][330/345]	Time 0.610 (0.676)	Data 0.0000 (0.0000)	Loss 1.1840 (1.5061)	
label_Epoch: [57][340/345]	Time 0.620 (0.675)	Data 0.0000 (0.0000)	Loss 1.1370 (1.4970)	
57
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [58][10/345]	Time 0.623 (2.557)	Data 0.0000 (0.0000)	Loss 2.0985 (1.9320)	
label_Epoch: [58][20/345]	Time 0.599 (1.589)	Data 0.0000 (0.0000)	Loss 1.2564 (1.8797)	
label_Epoch: [58][30/345]	Time 0.629 (1.265)	Data 0.0000 (0.0000)	Loss 2.4946 (1.8495)	
label_Epoch: [58][40/345]	Time 0.634 (1.104)	Data 0.0000 (0.0000)	Loss 3.1371 (1.9094)	
label_Epoch: [58][50/345]	Time 0.610 (1.007)	Data 0.0000 (0.0000)	Loss 1.6510 (1.8439)	
label_Epoch: [58][60/345]	Time 0.624 (0.942)	Data 0.0000 (0.0000)	Loss 2.3287 (1.8390)	
label_Epoch: [58][70/345]	Time 0.633 (0.896)	Data 0.0000 (0.0000)	Loss 1.5645 (1.8168)	
label_Epoch: [58][80/345]	Time 0.621 (0.861)	Data 0.0000 (0.0000)	Loss 2.0398 (1.8139)	
label_Epoch: [58][90/345]	Time 0.632 (0.834)	Data 0.0000 (0.0000)	Loss 1.6700 (1.8228)	
label_Epoch: [58][100/345]	Time 0.612 (0.813)	Data 0.0000 (0.0000)	Loss 1.5002 (1.8032)	
label_Epoch: [58][110/345]	Time 0.636 (0.795)	Data 0.0000 (0.0000)	Loss 1.8304 (1.7981)	
label_Epoch: [58][120/345]	Time 0.609 (0.781)	Data 0.0000 (0.0000)	Loss 1.4443 (1.7662)	
label_Epoch: [58][130/345]	Time 0.615 (0.768)	Data 0.0000 (0.0000)	Loss 1.2359 (1.7534)	
label_Epoch: [58][140/345]	Time 0.601 (0.757)	Data 0.0000 (0.0000)	Loss 1.6334 (1.7486)	
label_Epoch: [58][150/345]	Time 0.618 (0.747)	Data 0.0000 (0.0000)	Loss 1.1515 (1.7283)	
label_Epoch: [58][160/345]	Time 0.628 (0.739)	Data 0.0000 (0.0000)	Loss 1.5127 (1.7023)	
label_Epoch: [58][170/345]	Time 0.631 (0.732)	Data 0.0000 (0.0000)	Loss 1.8300 (1.6854)	
label_Epoch: [58][180/345]	Time 0.613 (0.726)	Data 0.0000 (0.0000)	Loss 1.7975 (1.6724)	
label_Epoch: [58][190/345]	Time 0.601 (0.720)	Data 0.0000 (0.0000)	Loss 1.5401 (1.6607)	
label_Epoch: [58][200/345]	Time 0.604 (0.715)	Data 0.0000 (0.0000)	Loss 1.1562 (1.6401)	
label_Epoch: [58][210/345]	Time 0.604 (0.710)	Data 0.0000 (0.0000)	Loss 1.2220 (1.6294)	
label_Epoch: [58][220/345]	Time 0.611 (0.706)	Data 0.0000 (0.0000)	Loss 1.2236 (1.6119)	
label_Epoch: [58][230/345]	Time 0.613 (0.702)	Data 0.0000 (0.0000)	Loss 1.1198 (1.5972)	
label_Epoch: [58][240/345]	Time 0.642 (0.699)	Data 0.0000 (0.0000)	Loss 1.1016 (1.5887)	
label_Epoch: [58][250/345]	Time 0.607 (0.696)	Data 0.0000 (0.0000)	Loss 1.3523 (1.5803)	
label_Epoch: [58][260/345]	Time 0.639 (0.693)	Data 0.0000 (0.0000)	Loss 1.7839 (1.5745)	
label_Epoch: [58][270/345]	Time 0.608 (0.690)	Data 0.0000 (0.0000)	Loss 1.5554 (1.5650)	
label_Epoch: [58][280/345]	Time 0.607 (0.687)	Data 0.0000 (0.0000)	Loss 1.9303 (1.5561)	
label_Epoch: [58][290/345]	Time 0.625 (0.685)	Data 0.0000 (0.0000)	Loss 1.1486 (1.5460)	
label_Epoch: [58][300/345]	Time 0.617 (0.683)	Data 0.0000 (0.0000)	Loss 1.1051 (1.5356)	
label_Epoch: [58][310/345]	Time 0.625 (0.681)	Data 0.0000 (0.0000)	Loss 1.0983 (1.5274)	
label_Epoch: [58][320/345]	Time 0.619 (0.679)	Data 0.0000 (0.0000)	Loss 1.3452 (1.5207)	
label_Epoch: [58][330/345]	Time 0.624 (0.677)	Data 0.0000 (0.0000)	Loss 1.0540 (1.5120)	
label_Epoch: [58][340/345]	Time 0.619 (0.675)	Data 0.0000 (0.0000)	Loss 1.0873 (1.5037)	
58
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [59][10/345]	Time 0.616 (2.531)	Data 0.0000 (0.0000)	Loss 1.6325 (2.3596)	
label_Epoch: [59][20/345]	Time 0.610 (1.576)	Data 0.0000 (0.0000)	Loss 2.4472 (2.1643)	
label_Epoch: [59][30/345]	Time 0.612 (1.258)	Data 0.0000 (0.0000)	Loss 1.8906 (2.0866)	
label_Epoch: [59][40/345]	Time 0.648 (1.100)	Data 0.0000 (0.0000)	Loss 2.5627 (1.9718)	
label_Epoch: [59][50/345]	Time 0.621 (1.005)	Data 0.0000 (0.0000)	Loss 1.4510 (1.9494)	
label_Epoch: [59][60/345]	Time 0.624 (0.941)	Data 0.0000 (0.0000)	Loss 1.3271 (1.8940)	
label_Epoch: [59][70/345]	Time 0.604 (0.894)	Data 0.0000 (0.0000)	Loss 1.2266 (1.8442)	
label_Epoch: [59][80/345]	Time 0.619 (0.860)	Data 0.0000 (0.0000)	Loss 1.2346 (1.8026)	
label_Epoch: [59][90/345]	Time 0.603 (0.833)	Data 0.0000 (0.0000)	Loss 2.1805 (1.7874)	
label_Epoch: [59][100/345]	Time 0.608 (0.811)	Data 0.0000 (0.0000)	Loss 1.5469 (1.7889)	
label_Epoch: [59][110/345]	Time 0.615 (0.794)	Data 0.0000 (0.0000)	Loss 2.1211 (1.7700)	
label_Epoch: [59][120/345]	Time 0.600 (0.778)	Data 0.0000 (0.0000)	Loss 1.2957 (1.7487)	
label_Epoch: [59][130/345]	Time 0.627 (0.766)	Data 0.0000 (0.0000)	Loss 1.1755 (1.7397)	
label_Epoch: [59][140/345]	Time 0.620 (0.755)	Data 0.0000 (0.0000)	Loss 1.6997 (1.7314)	
label_Epoch: [59][150/345]	Time 0.614 (0.746)	Data 0.0000 (0.0000)	Loss 1.6056 (1.7313)	
label_Epoch: [59][160/345]	Time 0.632 (0.738)	Data 0.0000 (0.0000)	Loss 1.4403 (1.7082)	
label_Epoch: [59][170/345]	Time 0.602 (0.731)	Data 0.0000 (0.0000)	Loss 1.6015 (1.6926)	
label_Epoch: [59][180/345]	Time 0.606 (0.724)	Data 0.0000 (0.0000)	Loss 1.4027 (1.6741)	
label_Epoch: [59][190/345]	Time 0.623 (0.718)	Data 0.0000 (0.0000)	Loss 1.0916 (1.6606)	
label_Epoch: [59][200/345]	Time 0.612 (0.714)	Data 0.0000 (0.0000)	Loss 1.3701 (1.6484)	
label_Epoch: [59][210/345]	Time 0.637 (0.709)	Data 0.0000 (0.0000)	Loss 1.6224 (1.6363)	
label_Epoch: [59][220/345]	Time 0.629 (0.705)	Data 0.0000 (0.0000)	Loss 2.4987 (1.6277)	
label_Epoch: [59][230/345]	Time 0.611 (0.701)	Data 0.0000 (0.0000)	Loss 1.1625 (1.6129)	
label_Epoch: [59][240/345]	Time 0.630 (0.698)	Data 0.0000 (0.0000)	Loss 1.1377 (1.5985)	
label_Epoch: [59][250/345]	Time 0.612 (0.695)	Data 0.0000 (0.0000)	Loss 1.5383 (1.5923)	
label_Epoch: [59][260/345]	Time 0.617 (0.691)	Data 0.0000 (0.0000)	Loss 1.3561 (1.5840)	
label_Epoch: [59][270/345]	Time 0.611 (0.689)	Data 0.0000 (0.0000)	Loss 1.3911 (1.5712)	
label_Epoch: [59][280/345]	Time 0.614 (0.686)	Data 0.0000 (0.0000)	Loss 1.1526 (1.5619)	
label_Epoch: [59][290/345]	Time 0.627 (0.684)	Data 0.0000 (0.0000)	Loss 1.1595 (1.5528)	
label_Epoch: [59][300/345]	Time 0.602 (0.682)	Data 0.0000 (0.0000)	Loss 1.0958 (1.5428)	
label_Epoch: [59][310/345]	Time 0.636 (0.680)	Data 0.0000 (0.0000)	Loss 1.1236 (1.5304)	
label_Epoch: [59][320/345]	Time 0.620 (0.678)	Data 0.0000 (0.0000)	Loss 1.1708 (1.5189)	
label_Epoch: [59][330/345]	Time 0.621 (0.676)	Data 0.0000 (0.0000)	Loss 1.1569 (1.5093)	
label_Epoch: [59][340/345]	Time 0.636 (0.674)	Data 0.0000 (0.0000)	Loss 1.2043 (1.5006)	
59
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [60][10/345]	Time 0.647 (2.451)	Data 0.0000 (0.0000)	Loss 2.6862 (1.7427)	
label_Epoch: [60][20/345]	Time 0.617 (1.537)	Data 0.0000 (0.0000)	Loss 1.0925 (1.9877)	
label_Epoch: [60][30/345]	Time 0.644 (1.230)	Data 0.0000 (0.0000)	Loss 1.0762 (1.9650)	
label_Epoch: [60][40/345]	Time 0.624 (1.077)	Data 0.0000 (0.0000)	Loss 1.4635 (1.9502)	
label_Epoch: [60][50/345]	Time 0.625 (0.988)	Data 0.0000 (0.0000)	Loss 1.6054 (1.9314)	
label_Epoch: [60][60/345]	Time 0.611 (0.925)	Data 0.0000 (0.0000)	Loss 1.5196 (1.9167)	
label_Epoch: [60][70/345]	Time 0.625 (0.881)	Data 0.0000 (0.0000)	Loss 1.2014 (1.9033)	
label_Epoch: [60][80/345]	Time 0.624 (0.848)	Data 0.0000 (0.0000)	Loss 2.1639 (1.8452)	
label_Epoch: [60][90/345]	Time 0.602 (0.823)	Data 0.0000 (0.0000)	Loss 1.2976 (1.8250)	
label_Epoch: [60][100/345]	Time 0.615 (0.802)	Data 0.0000 (0.0000)	Loss 1.1629 (1.8177)	
label_Epoch: [60][110/345]	Time 0.616 (0.786)	Data 0.0000 (0.0000)	Loss 1.6719 (1.7940)	
label_Epoch: [60][120/345]	Time 0.620 (0.771)	Data 0.0000 (0.0000)	Loss 1.2284 (1.7608)	
label_Epoch: [60][130/345]	Time 0.623 (0.759)	Data 0.0000 (0.0000)	Loss 1.1616 (1.7414)	
label_Epoch: [60][140/345]	Time 0.601 (0.749)	Data 0.0000 (0.0000)	Loss 1.8278 (1.7306)	
label_Epoch: [60][150/345]	Time 0.611 (0.740)	Data 0.0000 (0.0000)	Loss 1.1358 (1.7079)	
label_Epoch: [60][160/345]	Time 0.604 (0.732)	Data 0.0000 (0.0000)	Loss 1.2963 (1.6855)	
label_Epoch: [60][170/345]	Time 0.617 (0.726)	Data 0.0000 (0.0000)	Loss 1.1036 (1.6619)	
label_Epoch: [60][180/345]	Time 0.608 (0.720)	Data 0.0000 (0.0000)	Loss 1.2915 (1.6461)	
label_Epoch: [60][190/345]	Time 0.614 (0.715)	Data 0.0000 (0.0000)	Loss 1.4882 (1.6348)	
label_Epoch: [60][200/345]	Time 0.638 (0.710)	Data 0.0000 (0.0000)	Loss 1.2378 (1.6209)	
label_Epoch: [60][210/345]	Time 0.624 (0.705)	Data 0.0000 (0.0000)	Loss 1.3783 (1.6080)	
label_Epoch: [60][220/345]	Time 0.615 (0.701)	Data 0.0000 (0.0000)	Loss 1.3824 (1.5971)	
label_Epoch: [60][230/345]	Time 0.606 (0.698)	Data 0.0000 (0.0000)	Loss 1.3913 (1.5927)	
label_Epoch: [60][240/345]	Time 0.605 (0.694)	Data 0.0000 (0.0000)	Loss 1.1484 (1.5782)	
label_Epoch: [60][250/345]	Time 0.615 (0.691)	Data 0.0000 (0.0000)	Loss 1.1083 (1.5707)	
label_Epoch: [60][260/345]	Time 0.619 (0.688)	Data 0.0000 (0.0000)	Loss 1.3843 (1.5607)	
label_Epoch: [60][270/345]	Time 0.608 (0.686)	Data 0.0000 (0.0000)	Loss 1.1178 (1.5498)	
label_Epoch: [60][280/345]	Time 0.626 (0.683)	Data 0.0000 (0.0000)	Loss 1.2130 (1.5423)	
label_Epoch: [60][290/345]	Time 0.616 (0.681)	Data 0.0000 (0.0000)	Loss 1.1890 (1.5328)	
label_Epoch: [60][300/345]	Time 0.616 (0.679)	Data 0.0000 (0.0000)	Loss 1.1433 (1.5229)	
label_Epoch: [60][310/345]	Time 0.606 (0.677)	Data 0.0000 (0.0000)	Loss 1.1205 (1.5122)	
label_Epoch: [60][320/345]	Time 0.604 (0.675)	Data 0.0000 (0.0000)	Loss 1.1667 (1.5025)	
label_Epoch: [60][330/345]	Time 0.606 (0.673)	Data 0.0000 (0.0000)	Loss 1.1725 (1.4925)	
label_Epoch: [60][340/345]	Time 0.646 (0.672)	Data 0.0000 (0.0000)	Loss 1.1879 (1.4857)	
60
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [61][10/345]	Time 0.613 (2.380)	Data 0.0000 (0.0000)	Loss 2.3463 (1.9599)	
label_Epoch: [61][20/345]	Time 0.627 (1.498)	Data 0.0000 (0.0000)	Loss 1.5068 (1.8146)	
label_Epoch: [61][30/345]	Time 0.626 (1.206)	Data 0.0000 (0.0000)	Loss 2.0357 (1.8064)	
label_Epoch: [61][40/345]	Time 0.624 (1.059)	Data 0.0000 (0.0000)	Loss 1.3261 (1.8606)	
label_Epoch: [61][50/345]	Time 0.636 (0.972)	Data 0.0000 (0.0000)	Loss 1.7152 (1.8501)	
label_Epoch: [61][60/345]	Time 0.616 (0.913)	Data 0.0000 (0.0000)	Loss 2.3693 (1.8488)	
label_Epoch: [61][70/345]	Time 0.604 (0.871)	Data 0.0000 (0.0000)	Loss 1.2659 (1.8033)	
label_Epoch: [61][80/345]	Time 0.618 (0.838)	Data 0.0000 (0.0000)	Loss 1.1593 (1.7699)	
label_Epoch: [61][90/345]	Time 0.608 (0.814)	Data 0.0000 (0.0000)	Loss 1.4851 (1.7510)	
label_Epoch: [61][100/345]	Time 0.603 (0.795)	Data 0.0000 (0.0000)	Loss 1.3996 (1.7241)	
label_Epoch: [61][110/345]	Time 0.639 (0.779)	Data 0.0000 (0.0000)	Loss 1.3570 (1.7309)	
label_Epoch: [61][120/345]	Time 0.615 (0.765)	Data 0.0000 (0.0000)	Loss 1.3894 (1.7208)	
label_Epoch: [61][130/345]	Time 0.617 (0.754)	Data 0.0000 (0.0000)	Loss 1.1554 (1.7157)	
label_Epoch: [61][140/345]	Time 0.650 (0.744)	Data 0.0000 (0.0000)	Loss 1.1080 (1.6997)	
label_Epoch: [61][150/345]	Time 0.604 (0.735)	Data 0.0000 (0.0000)	Loss 1.3204 (1.6984)	
label_Epoch: [61][160/345]	Time 0.628 (0.728)	Data 0.0000 (0.0000)	Loss 1.9579 (1.6867)	
label_Epoch: [61][170/345]	Time 0.597 (0.722)	Data 0.0000 (0.0000)	Loss 1.4840 (1.6734)	
label_Epoch: [61][180/345]	Time 0.612 (0.716)	Data 0.0000 (0.0000)	Loss 1.4720 (1.6602)	
label_Epoch: [61][190/345]	Time 0.612 (0.711)	Data 0.0000 (0.0000)	Loss 1.3300 (1.6443)	
label_Epoch: [61][200/345]	Time 0.638 (0.706)	Data 0.0000 (0.0000)	Loss 1.6853 (1.6334)	
label_Epoch: [61][210/345]	Time 0.607 (0.702)	Data 0.0000 (0.0000)	Loss 1.7175 (1.6229)	
label_Epoch: [61][220/345]	Time 0.618 (0.698)	Data 0.0000 (0.0000)	Loss 1.4560 (1.6073)	
label_Epoch: [61][230/345]	Time 0.602 (0.694)	Data 0.0000 (0.0000)	Loss 1.6010 (1.5987)	
label_Epoch: [61][240/345]	Time 0.619 (0.691)	Data 0.0000 (0.0000)	Loss 1.3235 (1.5969)	
label_Epoch: [61][250/345]	Time 0.615 (0.688)	Data 0.0000 (0.0000)	Loss 1.0751 (1.5823)	
label_Epoch: [61][260/345]	Time 0.620 (0.686)	Data 0.0000 (0.0000)	Loss 1.6577 (1.5718)	
label_Epoch: [61][270/345]	Time 0.626 (0.683)	Data 0.0000 (0.0000)	Loss 1.2084 (1.5606)	
label_Epoch: [61][280/345]	Time 0.622 (0.681)	Data 0.0000 (0.0000)	Loss 1.2383 (1.5523)	
label_Epoch: [61][290/345]	Time 0.608 (0.679)	Data 0.0000 (0.0000)	Loss 1.2896 (1.5429)	
label_Epoch: [61][300/345]	Time 0.615 (0.676)	Data 0.0000 (0.0000)	Loss 1.0425 (1.5315)	
label_Epoch: [61][310/345]	Time 0.603 (0.674)	Data 0.0000 (0.0000)	Loss 1.2342 (1.5195)	
label_Epoch: [61][320/345]	Time 0.615 (0.672)	Data 0.0000 (0.0000)	Loss 1.1529 (1.5086)	
label_Epoch: [61][330/345]	Time 0.608 (0.671)	Data 0.0000 (0.0000)	Loss 1.3507 (1.5031)	
label_Epoch: [61][340/345]	Time 0.608 (0.669)	Data 0.0000 (0.0000)	Loss 1.2850 (1.4930)	
61
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [62][10/345]	Time 0.613 (2.460)	Data 0.0000 (0.0000)	Loss 1.3774 (1.9406)	
label_Epoch: [62][20/345]	Time 0.648 (1.540)	Data 0.0000 (0.0000)	Loss 1.3713 (1.8871)	
label_Epoch: [62][30/345]	Time 0.617 (1.234)	Data 0.0000 (0.0000)	Loss 1.5210 (1.8073)	
label_Epoch: [62][40/345]	Time 0.624 (1.080)	Data 0.0000 (0.0000)	Loss 1.4875 (1.8648)	
label_Epoch: [62][50/345]	Time 0.616 (0.987)	Data 0.0000 (0.0000)	Loss 2.9561 (1.8952)	
label_Epoch: [62][60/345]	Time 0.628 (0.925)	Data 0.0000 (0.0000)	Loss 1.3957 (1.8945)	
label_Epoch: [62][70/345]	Time 0.609 (0.881)	Data 0.0000 (0.0000)	Loss 1.5755 (1.8712)	
label_Epoch: [62][80/345]	Time 0.608 (0.848)	Data 0.0000 (0.0000)	Loss 1.3289 (1.8428)	
label_Epoch: [62][90/345]	Time 0.621 (0.823)	Data 0.0000 (0.0000)	Loss 1.8538 (1.8203)	
label_Epoch: [62][100/345]	Time 0.623 (0.802)	Data 0.0000 (0.0000)	Loss 1.1514 (1.7767)	
label_Epoch: [62][110/345]	Time 0.634 (0.785)	Data 0.0000 (0.0000)	Loss 2.2263 (1.7561)	
label_Epoch: [62][120/345]	Time 0.616 (0.771)	Data 0.0000 (0.0000)	Loss 1.1959 (1.7324)	
label_Epoch: [62][130/345]	Time 0.623 (0.759)	Data 0.0000 (0.0000)	Loss 1.6057 (1.7190)	
label_Epoch: [62][140/345]	Time 0.620 (0.749)	Data 0.0000 (0.0000)	Loss 1.2403 (1.7039)	
label_Epoch: [62][150/345]	Time 0.611 (0.740)	Data 0.0000 (0.0000)	Loss 1.3550 (1.6799)	
label_Epoch: [62][160/345]	Time 0.609 (0.732)	Data 0.0000 (0.0000)	Loss 1.2620 (1.6658)	
label_Epoch: [62][170/345]	Time 0.625 (0.726)	Data 0.0000 (0.0000)	Loss 1.8910 (1.6510)	
label_Epoch: [62][180/345]	Time 0.617 (0.719)	Data 0.0000 (0.0000)	Loss 1.3288 (1.6368)	
label_Epoch: [62][190/345]	Time 0.608 (0.714)	Data 0.0000 (0.0000)	Loss 1.3742 (1.6209)	
label_Epoch: [62][200/345]	Time 0.602 (0.709)	Data 0.0000 (0.0000)	Loss 1.2482 (1.6084)	
label_Epoch: [62][210/345]	Time 0.626 (0.705)	Data 0.0000 (0.0000)	Loss 1.4411 (1.5919)	
label_Epoch: [62][220/345]	Time 0.623 (0.701)	Data 0.0000 (0.0000)	Loss 1.6158 (1.5820)	
label_Epoch: [62][230/345]	Time 0.606 (0.697)	Data 0.0000 (0.0000)	Loss 2.1518 (1.5792)	
label_Epoch: [62][240/345]	Time 0.604 (0.694)	Data 0.0000 (0.0000)	Loss 1.1798 (1.5683)	
label_Epoch: [62][250/345]	Time 0.606 (0.691)	Data 0.0000 (0.0000)	Loss 1.2489 (1.5652)	
label_Epoch: [62][260/345]	Time 0.617 (0.688)	Data 0.0000 (0.0000)	Loss 2.2125 (1.5587)	
label_Epoch: [62][270/345]	Time 0.614 (0.685)	Data 0.0000 (0.0000)	Loss 1.2170 (1.5518)	
label_Epoch: [62][280/345]	Time 0.596 (0.683)	Data 0.0000 (0.0000)	Loss 1.0819 (1.5379)	
label_Epoch: [62][290/345]	Time 0.618 (0.681)	Data 0.0000 (0.0000)	Loss 1.1200 (1.5290)	
label_Epoch: [62][300/345]	Time 0.617 (0.678)	Data 0.0000 (0.0000)	Loss 1.3123 (1.5172)	
label_Epoch: [62][310/345]	Time 0.606 (0.676)	Data 0.0000 (0.0000)	Loss 1.1187 (1.5079)	
label_Epoch: [62][320/345]	Time 0.616 (0.674)	Data 0.0000 (0.0000)	Loss 1.0468 (1.4968)	
label_Epoch: [62][330/345]	Time 0.623 (0.673)	Data 0.0000 (0.0000)	Loss 1.1648 (1.4860)	
label_Epoch: [62][340/345]	Time 0.618 (0.671)	Data 0.0000 (0.0000)	Loss 1.1840 (1.4774)	
62
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [63][10/345]	Time 0.611 (2.569)	Data 0.0000 (0.0000)	Loss 2.6095 (2.2086)	
label_Epoch: [63][20/345]	Time 0.625 (1.594)	Data 0.0000 (0.0000)	Loss 2.1495 (2.2076)	
label_Epoch: [63][30/345]	Time 0.620 (1.269)	Data 0.0000 (0.0000)	Loss 2.9591 (2.1411)	
label_Epoch: [63][40/345]	Time 0.623 (1.108)	Data 0.0000 (0.0000)	Loss 1.5809 (2.0512)	
label_Epoch: [63][50/345]	Time 0.609 (1.011)	Data 0.0000 (0.0000)	Loss 1.3699 (1.9545)	
label_Epoch: [63][60/345]	Time 0.619 (0.945)	Data 0.0000 (0.0000)	Loss 1.3605 (1.9464)	
label_Epoch: [63][70/345]	Time 0.619 (0.898)	Data 0.0000 (0.0000)	Loss 1.4741 (1.9486)	
label_Epoch: [63][80/345]	Time 0.620 (0.864)	Data 0.0000 (0.0000)	Loss 1.3844 (1.9278)	
label_Epoch: [63][90/345]	Time 0.626 (0.837)	Data 0.0000 (0.0000)	Loss 2.1336 (1.8930)	
label_Epoch: [63][100/345]	Time 0.606 (0.814)	Data 0.0000 (0.0000)	Loss 1.7157 (1.8669)	
label_Epoch: [63][110/345]	Time 0.596 (0.796)	Data 0.0000 (0.0000)	Loss 1.2484 (1.8527)	
label_Epoch: [63][120/345]	Time 0.601 (0.782)	Data 0.0000 (0.0000)	Loss 1.7280 (1.8253)	
label_Epoch: [63][130/345]	Time 0.603 (0.769)	Data 0.0000 (0.0000)	Loss 1.0727 (1.7970)	
label_Epoch: [63][140/345]	Time 0.626 (0.758)	Data 0.0000 (0.0000)	Loss 1.6764 (1.7706)	
label_Epoch: [63][150/345]	Time 0.607 (0.748)	Data 0.0000 (0.0000)	Loss 2.3151 (1.7595)	
label_Epoch: [63][160/345]	Time 0.609 (0.740)	Data 0.0000 (0.0000)	Loss 1.3528 (1.7344)	
label_Epoch: [63][170/345]	Time 0.644 (0.733)	Data 0.0000 (0.0000)	Loss 1.5097 (1.7195)	
label_Epoch: [63][180/345]	Time 0.624 (0.726)	Data 0.0000 (0.0000)	Loss 1.2343 (1.6946)	
label_Epoch: [63][190/345]	Time 0.610 (0.720)	Data 0.0000 (0.0000)	Loss 1.3447 (1.6798)	
label_Epoch: [63][200/345]	Time 0.653 (0.715)	Data 0.0000 (0.0000)	Loss 1.3425 (1.6600)	
label_Epoch: [63][210/345]	Time 0.617 (0.711)	Data 0.0000 (0.0000)	Loss 1.2314 (1.6438)	
label_Epoch: [63][220/345]	Time 0.631 (0.707)	Data 0.0000 (0.0000)	Loss 1.1716 (1.6253)	
label_Epoch: [63][230/345]	Time 0.624 (0.703)	Data 0.0000 (0.0000)	Loss 1.1047 (1.6128)	
label_Epoch: [63][240/345]	Time 0.640 (0.699)	Data 0.0000 (0.0000)	Loss 1.0995 (1.5990)	
label_Epoch: [63][250/345]	Time 0.605 (0.696)	Data 0.0000 (0.0000)	Loss 1.2308 (1.5901)	
label_Epoch: [63][260/345]	Time 0.622 (0.693)	Data 0.0000 (0.0000)	Loss 1.0615 (1.5761)	
label_Epoch: [63][270/345]	Time 0.602 (0.690)	Data 0.0000 (0.0000)	Loss 1.0562 (1.5646)	
label_Epoch: [63][280/345]	Time 0.605 (0.688)	Data 0.0000 (0.0000)	Loss 1.4024 (1.5539)	
label_Epoch: [63][290/345]	Time 0.633 (0.685)	Data 0.0000 (0.0000)	Loss 1.0700 (1.5420)	
label_Epoch: [63][300/345]	Time 0.603 (0.683)	Data 0.0000 (0.0000)	Loss 1.4243 (1.5296)	
label_Epoch: [63][310/345]	Time 0.621 (0.681)	Data 0.0000 (0.0000)	Loss 1.3833 (1.5183)	
label_Epoch: [63][320/345]	Time 0.620 (0.679)	Data 0.0000 (0.0000)	Loss 1.7429 (1.5086)	
label_Epoch: [63][330/345]	Time 0.630 (0.678)	Data 0.0000 (0.0000)	Loss 1.1420 (1.4990)	
label_Epoch: [63][340/345]	Time 0.621 (0.676)	Data 0.0000 (0.0000)	Loss 1.1689 (1.4972)	
63
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [64][10/345]	Time 0.620 (2.494)	Data 0.0000 (0.0000)	Loss 1.1213 (1.9158)	
label_Epoch: [64][20/345]	Time 0.616 (1.559)	Data 0.0000 (0.0000)	Loss 1.4360 (1.8510)	
label_Epoch: [64][30/345]	Time 0.617 (1.247)	Data 0.0000 (0.0000)	Loss 1.6964 (1.8510)	
label_Epoch: [64][40/345]	Time 0.617 (1.089)	Data 0.0000 (0.0000)	Loss 2.4112 (1.8831)	
label_Epoch: [64][50/345]	Time 0.603 (0.994)	Data 0.0000 (0.0000)	Loss 1.3540 (1.8757)	
label_Epoch: [64][60/345]	Time 0.608 (0.932)	Data 0.0000 (0.0000)	Loss 2.1232 (1.8763)	
label_Epoch: [64][70/345]	Time 0.609 (0.887)	Data 0.0000 (0.0000)	Loss 2.3039 (1.8424)	
label_Epoch: [64][80/345]	Time 0.611 (0.853)	Data 0.0000 (0.0000)	Loss 1.6257 (1.8368)	
label_Epoch: [64][90/345]	Time 0.602 (0.826)	Data 0.0000 (0.0000)	Loss 2.0527 (1.8107)	
label_Epoch: [64][100/345]	Time 0.614 (0.805)	Data 0.0000 (0.0000)	Loss 1.9164 (1.7813)	
label_Epoch: [64][110/345]	Time 0.625 (0.789)	Data 0.0000 (0.0000)	Loss 2.2077 (1.7832)	
label_Epoch: [64][120/345]	Time 0.647 (0.775)	Data 0.0000 (0.0000)	Loss 2.9285 (1.7768)	
label_Epoch: [64][130/345]	Time 0.615 (0.763)	Data 0.0000 (0.0000)	Loss 2.1397 (1.7590)	
label_Epoch: [64][140/345]	Time 0.603 (0.753)	Data 0.0000 (0.0000)	Loss 1.5209 (1.7351)	
label_Epoch: [64][150/345]	Time 0.604 (0.744)	Data 0.0000 (0.0000)	Loss 1.3955 (1.7080)	
label_Epoch: [64][160/345]	Time 0.607 (0.736)	Data 0.0000 (0.0000)	Loss 1.2235 (1.6845)	
label_Epoch: [64][170/345]	Time 0.625 (0.729)	Data 0.0000 (0.0000)	Loss 1.8559 (1.6747)	
label_Epoch: [64][180/345]	Time 0.632 (0.723)	Data 0.0000 (0.0000)	Loss 1.6773 (1.6553)	
label_Epoch: [64][190/345]	Time 0.617 (0.716)	Data 0.0000 (0.0000)	Loss 1.3816 (1.6378)	
label_Epoch: [64][200/345]	Time 0.635 (0.712)	Data 0.0000 (0.0000)	Loss 1.1353 (1.6225)	
label_Epoch: [64][210/345]	Time 0.619 (0.707)	Data 0.0000 (0.0000)	Loss 1.5034 (1.6149)	
label_Epoch: [64][220/345]	Time 0.600 (0.703)	Data 0.0000 (0.0000)	Loss 1.4379 (1.6040)	
label_Epoch: [64][230/345]	Time 0.618 (0.700)	Data 0.0000 (0.0000)	Loss 1.1498 (1.5915)	
label_Epoch: [64][240/345]	Time 0.617 (0.697)	Data 0.0000 (0.0000)	Loss 1.2586 (1.5795)	
label_Epoch: [64][250/345]	Time 0.624 (0.693)	Data 0.0000 (0.0000)	Loss 1.1414 (1.5696)	
label_Epoch: [64][260/345]	Time 0.616 (0.690)	Data 0.0000 (0.0000)	Loss 1.3560 (1.5577)	
label_Epoch: [64][270/345]	Time 0.614 (0.687)	Data 0.0000 (0.0000)	Loss 1.1902 (1.5519)	
label_Epoch: [64][280/345]	Time 0.606 (0.685)	Data 0.0000 (0.0000)	Loss 1.3497 (1.5409)	
label_Epoch: [64][290/345]	Time 0.618 (0.682)	Data 0.0000 (0.0000)	Loss 1.5921 (1.5324)	
label_Epoch: [64][300/345]	Time 0.615 (0.680)	Data 0.0000 (0.0000)	Loss 1.4022 (1.5212)	
label_Epoch: [64][310/345]	Time 0.612 (0.678)	Data 0.0000 (0.0000)	Loss 1.2832 (1.5118)	
label_Epoch: [64][320/345]	Time 0.603 (0.676)	Data 0.0000 (0.0000)	Loss 1.0944 (1.5003)	
label_Epoch: [64][330/345]	Time 0.623 (0.674)	Data 0.0000 (0.0000)	Loss 1.0767 (1.4884)	
label_Epoch: [64][340/345]	Time 0.623 (0.673)	Data 0.0000 (0.0000)	Loss 1.2720 (1.4770)	
64
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [65][10/345]	Time 0.618 (2.401)	Data 0.0000 (0.0000)	Loss 1.3944 (2.0119)	
label_Epoch: [65][20/345]	Time 0.633 (1.509)	Data 0.0000 (0.0000)	Loss 2.2078 (2.0671)	
label_Epoch: [65][30/345]	Time 0.627 (1.210)	Data 0.0000 (0.0000)	Loss 1.9425 (1.9958)	
label_Epoch: [65][40/345]	Time 0.642 (1.063)	Data 0.0000 (0.0000)	Loss 1.5011 (1.9514)	
label_Epoch: [65][50/345]	Time 0.636 (0.974)	Data 0.0000 (0.0000)	Loss 1.3637 (1.8846)	
label_Epoch: [65][60/345]	Time 0.624 (0.915)	Data 0.0000 (0.0000)	Loss 1.7390 (1.8476)	
label_Epoch: [65][70/345]	Time 0.613 (0.872)	Data 0.0000 (0.0000)	Loss 1.4701 (1.8045)	
label_Epoch: [65][80/345]	Time 0.631 (0.840)	Data 0.0000 (0.0000)	Loss 1.5878 (1.8054)	
label_Epoch: [65][90/345]	Time 0.613 (0.816)	Data 0.0000 (0.0000)	Loss 1.3676 (1.8085)	
label_Epoch: [65][100/345]	Time 0.613 (0.795)	Data 0.0000 (0.0000)	Loss 1.1225 (1.7728)	
label_Epoch: [65][110/345]	Time 0.616 (0.778)	Data 0.0000 (0.0000)	Loss 1.1215 (1.7293)	
label_Epoch: [65][120/345]	Time 0.618 (0.765)	Data 0.0000 (0.0000)	Loss 1.2727 (1.7001)	
label_Epoch: [65][130/345]	Time 0.636 (0.754)	Data 0.0000 (0.0000)	Loss 1.3983 (1.6943)	
label_Epoch: [65][140/345]	Time 0.616 (0.745)	Data 0.0000 (0.0000)	Loss 2.0654 (1.6786)	
label_Epoch: [65][150/345]	Time 0.617 (0.736)	Data 0.0000 (0.0000)	Loss 1.2818 (1.6786)	
label_Epoch: [65][160/345]	Time 0.608 (0.729)	Data 0.0000 (0.0000)	Loss 1.8680 (1.6591)	
label_Epoch: [65][170/345]	Time 0.620 (0.722)	Data 0.0000 (0.0000)	Loss 1.0987 (1.6563)	
label_Epoch: [65][180/345]	Time 0.613 (0.716)	Data 0.0000 (0.0000)	Loss 1.4298 (1.6418)	
label_Epoch: [65][190/345]	Time 0.625 (0.711)	Data 0.0000 (0.0000)	Loss 1.3788 (1.6303)	
label_Epoch: [65][200/345]	Time 0.615 (0.707)	Data 0.0000 (0.0000)	Loss 1.4396 (1.6152)	
label_Epoch: [65][210/345]	Time 0.625 (0.702)	Data 0.0000 (0.0000)	Loss 1.6810 (1.6054)	
label_Epoch: [65][220/345]	Time 0.615 (0.699)	Data 0.0000 (0.0000)	Loss 1.0704 (1.5899)	
label_Epoch: [65][230/345]	Time 0.622 (0.695)	Data 0.0000 (0.0000)	Loss 1.5202 (1.5830)	
label_Epoch: [65][240/345]	Time 0.621 (0.692)	Data 0.0000 (0.0000)	Loss 1.1905 (1.5682)	
label_Epoch: [65][250/345]	Time 0.624 (0.689)	Data 0.0000 (0.0000)	Loss 1.2295 (1.5579)	
label_Epoch: [65][260/345]	Time 0.619 (0.686)	Data 0.0000 (0.0000)	Loss 1.0976 (1.5470)	
label_Epoch: [65][270/345]	Time 0.619 (0.684)	Data 0.0000 (0.0000)	Loss 1.2797 (1.5398)	
label_Epoch: [65][280/345]	Time 0.610 (0.682)	Data 0.0000 (0.0000)	Loss 1.1668 (1.5301)	
label_Epoch: [65][290/345]	Time 0.613 (0.679)	Data 0.0000 (0.0000)	Loss 1.0972 (1.5231)	
label_Epoch: [65][300/345]	Time 0.633 (0.677)	Data 0.0000 (0.0000)	Loss 1.4294 (1.5134)	
label_Epoch: [65][310/345]	Time 0.615 (0.676)	Data 0.0000 (0.0000)	Loss 1.2190 (1.5035)	
label_Epoch: [65][320/345]	Time 0.632 (0.674)	Data 0.0000 (0.0000)	Loss 1.3833 (1.4939)	
label_Epoch: [65][330/345]	Time 0.602 (0.672)	Data 0.0000 (0.0000)	Loss 1.1930 (1.4854)	
label_Epoch: [65][340/345]	Time 0.614 (0.670)	Data 0.0000 (0.0000)	Loss 1.0402 (1.4746)	
65
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [66][10/345]	Time 0.621 (2.391)	Data 0.0000 (0.0000)	Loss 1.7221 (1.7426)	
label_Epoch: [66][20/345]	Time 0.615 (1.503)	Data 0.0000 (0.0000)	Loss 1.4576 (1.8022)	
label_Epoch: [66][30/345]	Time 0.635 (1.209)	Data 0.0000 (0.0000)	Loss 1.1647 (1.8989)	
label_Epoch: [66][40/345]	Time 0.604 (1.062)	Data 0.0000 (0.0000)	Loss 1.4230 (1.9118)	
label_Epoch: [66][50/345]	Time 0.637 (0.973)	Data 0.0000 (0.0000)	Loss 1.9521 (1.9039)	
label_Epoch: [66][60/345]	Time 0.618 (0.913)	Data 0.0000 (0.0000)	Loss 1.0909 (1.8531)	
label_Epoch: [66][70/345]	Time 0.632 (0.872)	Data 0.0000 (0.0000)	Loss 1.7963 (1.8410)	
label_Epoch: [66][80/345]	Time 0.639 (0.840)	Data 0.0000 (0.0000)	Loss 1.9125 (1.8460)	
label_Epoch: [66][90/345]	Time 0.609 (0.815)	Data 0.0000 (0.0000)	Loss 1.5600 (1.8267)	
label_Epoch: [66][100/345]	Time 0.601 (0.794)	Data 0.0000 (0.0000)	Loss 1.3530 (1.8060)	
label_Epoch: [66][110/345]	Time 0.620 (0.779)	Data 0.0000 (0.0000)	Loss 1.2436 (1.7671)	
label_Epoch: [66][120/345]	Time 0.616 (0.765)	Data 0.0000 (0.0000)	Loss 1.1053 (1.7432)	
label_Epoch: [66][130/345]	Time 0.616 (0.753)	Data 0.0000 (0.0000)	Loss 1.3521 (1.7215)	
label_Epoch: [66][140/345]	Time 0.632 (0.744)	Data 0.0000 (0.0000)	Loss 1.1853 (1.7107)	
label_Epoch: [66][150/345]	Time 0.619 (0.736)	Data 0.0000 (0.0000)	Loss 1.3551 (1.6862)	
label_Epoch: [66][160/345]	Time 0.610 (0.728)	Data 0.0000 (0.0000)	Loss 1.1864 (1.6672)	
label_Epoch: [66][170/345]	Time 0.609 (0.721)	Data 0.0000 (0.0000)	Loss 1.2174 (1.6560)	
label_Epoch: [66][180/345]	Time 0.623 (0.716)	Data 0.0000 (0.0000)	Loss 1.6914 (1.6403)	
label_Epoch: [66][190/345]	Time 0.634 (0.711)	Data 0.0000 (0.0000)	Loss 1.2443 (1.6254)	
label_Epoch: [66][200/345]	Time 0.616 (0.706)	Data 0.0000 (0.0000)	Loss 1.1080 (1.6130)	
label_Epoch: [66][210/345]	Time 0.632 (0.702)	Data 0.0000 (0.0000)	Loss 1.2700 (1.5994)	
label_Epoch: [66][220/345]	Time 0.613 (0.698)	Data 0.0000 (0.0000)	Loss 1.2692 (1.5925)	
label_Epoch: [66][230/345]	Time 0.615 (0.694)	Data 0.0000 (0.0000)	Loss 2.1959 (1.5824)	
label_Epoch: [66][240/345]	Time 0.615 (0.691)	Data 0.0000 (0.0000)	Loss 1.7272 (1.5704)	
label_Epoch: [66][250/345]	Time 0.615 (0.688)	Data 0.0000 (0.0000)	Loss 1.1215 (1.5600)	
label_Epoch: [66][260/345]	Time 0.636 (0.686)	Data 0.0000 (0.0000)	Loss 1.1465 (1.5571)	
label_Epoch: [66][270/345]	Time 0.623 (0.683)	Data 0.0000 (0.0000)	Loss 1.1019 (1.5510)	
label_Epoch: [66][280/345]	Time 0.613 (0.681)	Data 0.0000 (0.0000)	Loss 1.1236 (1.5383)	
label_Epoch: [66][290/345]	Time 0.636 (0.678)	Data 0.0000 (0.0000)	Loss 1.2145 (1.5273)	
label_Epoch: [66][300/345]	Time 0.625 (0.676)	Data 0.0000 (0.0000)	Loss 1.2280 (1.5191)	
label_Epoch: [66][310/345]	Time 0.599 (0.674)	Data 0.0000 (0.0000)	Loss 1.3889 (1.5109)	
label_Epoch: [66][320/345]	Time 0.618 (0.673)	Data 0.0000 (0.0000)	Loss 1.2027 (1.5013)	
label_Epoch: [66][330/345]	Time 0.611 (0.671)	Data 0.0000 (0.0000)	Loss 1.0783 (1.4905)	
label_Epoch: [66][340/345]	Time 0.626 (0.669)	Data 0.0000 (0.0000)	Loss 1.1316 (1.4793)	
66
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [67][10/345]	Time 0.617 (2.545)	Data 0.0000 (0.0000)	Loss 1.7135 (1.8109)	
label_Epoch: [67][20/345]	Time 0.620 (1.581)	Data 0.0000 (0.0000)	Loss 2.0113 (1.8187)	
label_Epoch: [67][30/345]	Time 0.624 (1.260)	Data 0.0000 (0.0000)	Loss 1.2240 (1.7678)	
label_Epoch: [67][40/345]	Time 0.603 (1.099)	Data 0.0000 (0.0000)	Loss 1.2249 (1.7326)	
label_Epoch: [67][50/345]	Time 0.618 (1.002)	Data 0.0000 (0.0000)	Loss 2.2298 (1.7738)	
label_Epoch: [67][60/345]	Time 0.626 (0.938)	Data 0.0000 (0.0000)	Loss 2.2034 (1.8280)	
label_Epoch: [67][70/345]	Time 0.608 (0.891)	Data 0.0000 (0.0000)	Loss 1.2652 (1.8326)	
label_Epoch: [67][80/345]	Time 0.620 (0.857)	Data 0.0000 (0.0000)	Loss 1.7674 (1.7874)	
label_Epoch: [67][90/345]	Time 0.617 (0.831)	Data 0.0000 (0.0000)	Loss 1.1687 (1.7635)	
label_Epoch: [67][100/345]	Time 0.615 (0.810)	Data 0.0000 (0.0000)	Loss 2.1877 (1.7646)	
label_Epoch: [67][110/345]	Time 0.621 (0.792)	Data 0.0000 (0.0000)	Loss 1.3273 (1.7324)	
label_Epoch: [67][120/345]	Time 0.616 (0.778)	Data 0.0000 (0.0000)	Loss 1.3392 (1.7275)	
label_Epoch: [67][130/345]	Time 0.615 (0.765)	Data 0.0000 (0.0000)	Loss 1.3741 (1.7183)	
label_Epoch: [67][140/345]	Time 0.609 (0.755)	Data 0.0000 (0.0000)	Loss 1.5183 (1.6977)	
label_Epoch: [67][150/345]	Time 0.621 (0.746)	Data 0.0000 (0.0000)	Loss 1.8535 (1.6768)	
label_Epoch: [67][160/345]	Time 0.614 (0.738)	Data 0.0000 (0.0000)	Loss 1.4923 (1.6651)	
label_Epoch: [67][170/345]	Time 0.618 (0.731)	Data 0.0000 (0.0000)	Loss 1.3131 (1.6403)	
label_Epoch: [67][180/345]	Time 0.637 (0.724)	Data 0.0000 (0.0000)	Loss 1.2046 (1.6284)	
label_Epoch: [67][190/345]	Time 0.618 (0.718)	Data 0.0000 (0.0000)	Loss 1.7623 (1.6138)	
label_Epoch: [67][200/345]	Time 0.604 (0.713)	Data 0.0000 (0.0000)	Loss 1.4345 (1.6013)	
label_Epoch: [67][210/345]	Time 0.627 (0.709)	Data 0.0000 (0.0000)	Loss 1.5213 (1.5911)	
label_Epoch: [67][220/345]	Time 0.622 (0.705)	Data 0.0000 (0.0000)	Loss 1.0430 (1.5821)	
label_Epoch: [67][230/345]	Time 0.614 (0.701)	Data 0.0000 (0.0000)	Loss 1.0721 (1.5639)	
label_Epoch: [67][240/345]	Time 0.610 (0.697)	Data 0.0000 (0.0000)	Loss 1.0649 (1.5499)	
label_Epoch: [67][250/345]	Time 0.606 (0.694)	Data 0.0000 (0.0000)	Loss 1.3316 (1.5445)	
label_Epoch: [67][260/345]	Time 0.640 (0.691)	Data 0.0000 (0.0000)	Loss 1.3692 (1.5355)	
label_Epoch: [67][270/345]	Time 0.607 (0.689)	Data 0.0000 (0.0000)	Loss 1.1681 (1.5244)	
label_Epoch: [67][280/345]	Time 0.606 (0.686)	Data 0.0000 (0.0000)	Loss 1.2724 (1.5135)	
label_Epoch: [67][290/345]	Time 0.606 (0.684)	Data 0.0000 (0.0000)	Loss 1.0800 (1.5068)	
label_Epoch: [67][300/345]	Time 0.620 (0.682)	Data 0.0000 (0.0000)	Loss 1.4227 (1.4986)	
label_Epoch: [67][310/345]	Time 0.628 (0.680)	Data 0.0000 (0.0000)	Loss 1.3251 (1.4900)	
label_Epoch: [67][320/345]	Time 0.599 (0.677)	Data 0.0000 (0.0000)	Loss 1.1881 (1.4824)	
label_Epoch: [67][330/345]	Time 0.620 (0.676)	Data 0.0000 (0.0000)	Loss 1.0758 (1.4718)	
label_Epoch: [67][340/345]	Time 0.617 (0.674)	Data 0.0000 (0.0000)	Loss 1.0561 (1.4620)	
67
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [68][10/345]	Time 0.625 (2.463)	Data 0.0000 (0.0000)	Loss 2.9091 (2.0479)	
label_Epoch: [68][20/345]	Time 0.627 (1.541)	Data 0.0000 (0.0000)	Loss 1.9854 (1.9411)	
label_Epoch: [68][30/345]	Time 0.620 (1.232)	Data 0.0000 (0.0000)	Loss 1.1837 (1.8736)	
label_Epoch: [68][40/345]	Time 0.608 (1.079)	Data 0.0000 (0.0000)	Loss 1.3663 (1.9043)	
label_Epoch: [68][50/345]	Time 0.629 (0.987)	Data 0.0000 (0.0000)	Loss 1.1974 (1.8703)	
label_Epoch: [68][60/345]	Time 0.628 (0.924)	Data 0.0000 (0.0000)	Loss 1.2776 (1.8157)	
label_Epoch: [68][70/345]	Time 0.621 (0.880)	Data 0.0000 (0.0000)	Loss 1.6205 (1.8290)	
label_Epoch: [68][80/345]	Time 0.617 (0.847)	Data 0.0000 (0.0000)	Loss 2.1356 (1.8188)	
label_Epoch: [68][90/345]	Time 0.617 (0.822)	Data 0.0000 (0.0000)	Loss 1.7938 (1.8044)	
label_Epoch: [68][100/345]	Time 0.623 (0.802)	Data 0.0000 (0.0000)	Loss 1.2031 (1.7700)	
label_Epoch: [68][110/345]	Time 0.629 (0.785)	Data 0.0000 (0.0000)	Loss 1.4512 (1.7576)	
label_Epoch: [68][120/345]	Time 0.617 (0.771)	Data 0.0000 (0.0000)	Loss 1.7371 (1.7500)	
label_Epoch: [68][130/345]	Time 0.603 (0.759)	Data 0.0000 (0.0000)	Loss 1.3371 (1.7403)	
label_Epoch: [68][140/345]	Time 0.610 (0.749)	Data 0.0000 (0.0000)	Loss 1.2071 (1.7182)	
label_Epoch: [68][150/345]	Time 0.609 (0.740)	Data 0.0000 (0.0000)	Loss 1.5812 (1.7097)	
label_Epoch: [68][160/345]	Time 0.597 (0.733)	Data 0.0000 (0.0000)	Loss 1.0504 (1.6875)	
label_Epoch: [68][170/345]	Time 0.647 (0.726)	Data 0.0000 (0.0000)	Loss 1.0897 (1.6685)	
label_Epoch: [68][180/345]	Time 0.613 (0.719)	Data 0.0000 (0.0000)	Loss 1.1021 (1.6491)	
label_Epoch: [68][190/345]	Time 0.614 (0.714)	Data 0.0000 (0.0000)	Loss 1.5485 (1.6454)	
label_Epoch: [68][200/345]	Time 0.627 (0.709)	Data 0.0000 (0.0000)	Loss 1.3816 (1.6270)	
label_Epoch: [68][210/345]	Time 0.617 (0.705)	Data 0.0000 (0.0000)	Loss 1.1757 (1.6142)	
label_Epoch: [68][220/345]	Time 0.600 (0.701)	Data 0.0000 (0.0000)	Loss 1.2388 (1.6022)	
label_Epoch: [68][230/345]	Time 0.635 (0.697)	Data 0.0000 (0.0000)	Loss 1.1985 (1.5830)	
label_Epoch: [68][240/345]	Time 0.624 (0.694)	Data 0.0000 (0.0000)	Loss 1.1153 (1.5668)	
label_Epoch: [68][250/345]	Time 0.601 (0.691)	Data 0.0000 (0.0000)	Loss 1.1822 (1.5569)	
label_Epoch: [68][260/345]	Time 0.618 (0.688)	Data 0.0000 (0.0000)	Loss 1.3331 (1.5492)	
label_Epoch: [68][270/345]	Time 0.619 (0.685)	Data 0.0000 (0.0000)	Loss 1.1218 (1.5334)	
label_Epoch: [68][280/345]	Time 0.631 (0.683)	Data 0.0000 (0.0000)	Loss 1.4516 (1.5210)	
label_Epoch: [68][290/345]	Time 0.617 (0.681)	Data 0.0000 (0.0000)	Loss 1.1321 (1.5082)	
label_Epoch: [68][300/345]	Time 0.610 (0.679)	Data 0.0000 (0.0000)	Loss 1.1679 (1.4953)	
label_Epoch: [68][310/345]	Time 0.612 (0.677)	Data 0.0000 (0.0000)	Loss 1.0635 (1.4860)	
label_Epoch: [68][320/345]	Time 0.609 (0.675)	Data 0.0000 (0.0000)	Loss 1.0668 (1.4781)	
label_Epoch: [68][330/345]	Time 0.632 (0.673)	Data 0.0000 (0.0000)	Loss 1.0442 (1.4709)	
label_Epoch: [68][340/345]	Time 0.619 (0.671)	Data 0.0000 (0.0000)	Loss 1.4274 (1.4647)	
68
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [69][10/345]	Time 0.604 (2.348)	Data 0.0000 (0.0000)	Loss 2.0843 (1.8448)	
label_Epoch: [69][20/345]	Time 0.614 (1.483)	Data 0.0000 (0.0000)	Loss 1.7196 (1.8012)	
label_Epoch: [69][30/345]	Time 0.604 (1.193)	Data 0.0000 (0.0000)	Loss 1.6085 (1.8019)	
label_Epoch: [69][40/345]	Time 0.600 (1.050)	Data 0.0000 (0.0000)	Loss 1.7150 (1.7866)	
label_Epoch: [69][50/345]	Time 0.603 (0.964)	Data 0.0000 (0.0000)	Loss 2.3676 (1.8410)	
label_Epoch: [69][60/345]	Time 0.603 (0.906)	Data 0.0000 (0.0000)	Loss 2.8875 (1.8506)	
label_Epoch: [69][70/345]	Time 0.637 (0.864)	Data 0.0000 (0.0000)	Loss 1.5101 (1.8161)	
label_Epoch: [69][80/345]	Time 0.616 (0.833)	Data 0.0000 (0.0000)	Loss 1.1680 (1.7812)	
label_Epoch: [69][90/345]	Time 0.601 (0.809)	Data 0.0000 (0.0000)	Loss 1.1777 (1.7809)	
label_Epoch: [69][100/345]	Time 0.602 (0.790)	Data 0.0000 (0.0000)	Loss 2.5417 (1.7735)	
label_Epoch: [69][110/345]	Time 0.604 (0.774)	Data 0.0000 (0.0000)	Loss 1.4344 (1.7586)	
label_Epoch: [69][120/345]	Time 0.613 (0.762)	Data 0.0000 (0.0000)	Loss 1.1249 (1.7282)	
label_Epoch: [69][130/345]	Time 0.618 (0.751)	Data 0.0000 (0.0000)	Loss 1.9033 (1.7170)	
label_Epoch: [69][140/345]	Time 0.611 (0.742)	Data 0.0000 (0.0000)	Loss 1.1550 (1.7039)	
label_Epoch: [69][150/345]	Time 0.615 (0.733)	Data 0.0000 (0.0000)	Loss 1.1990 (1.6903)	
label_Epoch: [69][160/345]	Time 0.615 (0.726)	Data 0.0000 (0.0000)	Loss 1.2662 (1.6628)	
label_Epoch: [69][170/345]	Time 0.634 (0.720)	Data 0.0000 (0.0000)	Loss 1.2581 (1.6430)	
label_Epoch: [69][180/345]	Time 0.607 (0.714)	Data 0.0000 (0.0000)	Loss 1.4978 (1.6205)	
label_Epoch: [69][190/345]	Time 0.630 (0.709)	Data 0.0000 (0.0000)	Loss 1.3485 (1.6099)	
label_Epoch: [69][200/345]	Time 0.610 (0.704)	Data 0.0000 (0.0000)	Loss 1.2945 (1.5948)	
label_Epoch: [69][210/345]	Time 0.615 (0.700)	Data 0.0000 (0.0000)	Loss 1.4399 (1.5852)	
label_Epoch: [69][220/345]	Time 0.614 (0.697)	Data 0.0000 (0.0000)	Loss 1.1184 (1.5688)	
label_Epoch: [69][230/345]	Time 0.601 (0.693)	Data 0.0000 (0.0000)	Loss 1.6484 (1.5627)	
label_Epoch: [69][240/345]	Time 0.611 (0.690)	Data 0.0000 (0.0000)	Loss 1.2144 (1.5540)	
label_Epoch: [69][250/345]	Time 0.617 (0.687)	Data 0.0000 (0.0000)	Loss 1.1278 (1.5414)	
label_Epoch: [69][260/345]	Time 0.616 (0.684)	Data 0.0000 (0.0000)	Loss 1.1199 (1.5277)	
label_Epoch: [69][270/345]	Time 0.622 (0.681)	Data 0.0000 (0.0000)	Loss 1.7088 (1.5219)	
label_Epoch: [69][280/345]	Time 0.614 (0.679)	Data 0.0000 (0.0000)	Loss 1.0869 (1.5123)	
label_Epoch: [69][290/345]	Time 0.631 (0.677)	Data 0.0000 (0.0000)	Loss 1.0889 (1.5027)	
label_Epoch: [69][300/345]	Time 0.617 (0.675)	Data 0.0000 (0.0000)	Loss 1.6289 (1.4978)	
label_Epoch: [69][310/345]	Time 0.633 (0.674)	Data 0.0000 (0.0000)	Loss 1.4129 (1.4872)	
label_Epoch: [69][320/345]	Time 0.611 (0.672)	Data 0.0000 (0.0000)	Loss 1.2606 (1.4800)	
label_Epoch: [69][330/345]	Time 0.623 (0.670)	Data 0.0000 (0.0000)	Loss 1.2288 (1.4714)	
label_Epoch: [69][340/345]	Time 0.626 (0.669)	Data 0.0000 (0.0000)	Loss 1.2269 (1.4612)	
69
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [70][10/345]	Time 0.622 (2.556)	Data 0.0000 (0.0000)	Loss 1.1627 (1.8769)	
label_Epoch: [70][20/345]	Time 0.635 (1.586)	Data 0.0000 (0.0000)	Loss 2.1966 (1.9535)	
label_Epoch: [70][30/345]	Time 0.603 (1.263)	Data 0.0000 (0.0000)	Loss 1.9784 (1.9657)	
label_Epoch: [70][40/345]	Time 0.612 (1.101)	Data 0.0000 (0.0000)	Loss 1.3964 (1.8493)	
label_Epoch: [70][50/345]	Time 0.616 (1.005)	Data 0.0000 (0.0000)	Loss 2.0001 (1.8212)	
label_Epoch: [70][60/345]	Time 0.610 (0.940)	Data 0.0000 (0.0000)	Loss 1.3990 (1.8341)	
label_Epoch: [70][70/345]	Time 0.622 (0.893)	Data 0.0000 (0.0000)	Loss 1.2051 (1.7916)	
label_Epoch: [70][80/345]	Time 0.618 (0.859)	Data 0.0000 (0.0000)	Loss 1.1345 (1.7931)	
label_Epoch: [70][90/345]	Time 0.614 (0.832)	Data 0.0000 (0.0000)	Loss 1.9670 (1.7863)	
label_Epoch: [70][100/345]	Time 0.615 (0.810)	Data 0.0000 (0.0000)	Loss 1.5939 (1.7661)	
label_Epoch: [70][110/345]	Time 0.609 (0.792)	Data 0.0000 (0.0000)	Loss 1.6641 (1.7505)	
label_Epoch: [70][120/345]	Time 0.620 (0.778)	Data 0.0000 (0.0000)	Loss 1.4405 (1.7193)	
label_Epoch: [70][130/345]	Time 0.629 (0.766)	Data 0.0000 (0.0000)	Loss 1.3482 (1.7002)	
label_Epoch: [70][140/345]	Time 0.631 (0.755)	Data 0.0000 (0.0000)	Loss 1.4327 (1.6852)	
label_Epoch: [70][150/345]	Time 0.601 (0.746)	Data 0.0000 (0.0000)	Loss 1.4306 (1.6710)	
label_Epoch: [70][160/345]	Time 0.637 (0.738)	Data 0.0000 (0.0000)	Loss 1.2922 (1.6631)	
label_Epoch: [70][170/345]	Time 0.623 (0.731)	Data 0.0000 (0.0000)	Loss 1.8178 (1.6467)	
label_Epoch: [70][180/345]	Time 0.627 (0.724)	Data 0.0000 (0.0000)	Loss 1.2617 (1.6325)	
label_Epoch: [70][190/345]	Time 0.613 (0.719)	Data 0.0000 (0.0000)	Loss 1.5231 (1.6220)	
label_Epoch: [70][200/345]	Time 0.607 (0.714)	Data 0.0000 (0.0000)	Loss 1.2789 (1.6094)	
label_Epoch: [70][210/345]	Time 0.607 (0.709)	Data 0.0000 (0.0000)	Loss 1.4919 (1.5996)	
label_Epoch: [70][220/345]	Time 0.620 (0.705)	Data 0.0000 (0.0000)	Loss 1.2748 (1.5852)	
label_Epoch: [70][230/345]	Time 0.606 (0.701)	Data 0.0000 (0.0000)	Loss 1.3358 (1.5725)	
label_Epoch: [70][240/345]	Time 0.621 (0.697)	Data 0.0000 (0.0000)	Loss 1.4462 (1.5623)	
label_Epoch: [70][250/345]	Time 0.616 (0.694)	Data 0.0000 (0.0000)	Loss 1.2598 (1.5492)	
label_Epoch: [70][260/345]	Time 0.635 (0.692)	Data 0.0000 (0.0000)	Loss 1.4657 (1.5368)	
label_Epoch: [70][270/345]	Time 0.601 (0.689)	Data 0.0000 (0.0000)	Loss 1.1778 (1.5278)	
label_Epoch: [70][280/345]	Time 0.617 (0.686)	Data 0.0000 (0.0000)	Loss 1.1590 (1.5182)	
label_Epoch: [70][290/345]	Time 0.633 (0.684)	Data 0.0000 (0.0000)	Loss 1.0956 (1.5191)	
label_Epoch: [70][300/345]	Time 0.622 (0.682)	Data 0.0000 (0.0000)	Loss 1.4090 (1.5120)	
label_Epoch: [70][310/345]	Time 0.601 (0.680)	Data 0.0000 (0.0000)	Loss 1.0429 (1.5019)	
label_Epoch: [70][320/345]	Time 0.610 (0.678)	Data 0.0000 (0.0000)	Loss 1.1171 (1.4906)	
label_Epoch: [70][330/345]	Time 0.627 (0.676)	Data 0.0000 (0.0000)	Loss 1.1526 (1.4789)	
label_Epoch: [70][340/345]	Time 0.631 (0.674)	Data 0.0000 (0.0000)	Loss 1.1749 (1.4705)	
70
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [71][10/345]	Time 0.627 (2.512)	Data 0.0000 (0.0000)	Loss 2.0257 (1.9924)	
label_Epoch: [71][20/345]	Time 0.628 (1.566)	Data 0.0000 (0.0000)	Loss 1.7861 (1.9465)	
label_Epoch: [71][30/345]	Time 0.602 (1.250)	Data 0.0000 (0.0000)	Loss 1.3367 (1.9399)	
label_Epoch: [71][40/345]	Time 0.625 (1.091)	Data 0.0000 (0.0000)	Loss 2.2690 (1.9441)	
label_Epoch: [71][50/345]	Time 0.635 (0.997)	Data 0.0000 (0.0000)	Loss 2.3302 (1.9429)	
label_Epoch: [71][60/345]	Time 0.639 (0.935)	Data 0.0000 (0.0000)	Loss 1.2416 (1.8932)	
label_Epoch: [71][70/345]	Time 0.625 (0.889)	Data 0.0000 (0.0000)	Loss 1.3651 (1.8732)	
label_Epoch: [71][80/345]	Time 0.620 (0.856)	Data 0.0000 (0.0000)	Loss 1.1069 (1.8253)	
label_Epoch: [71][90/345]	Time 0.622 (0.829)	Data 0.0000 (0.0000)	Loss 2.2692 (1.8281)	
label_Epoch: [71][100/345]	Time 0.613 (0.808)	Data 0.0000 (0.0000)	Loss 1.0963 (1.7993)	
label_Epoch: [71][110/345]	Time 0.615 (0.790)	Data 0.0000 (0.0000)	Loss 1.4206 (1.7780)	
label_Epoch: [71][120/345]	Time 0.629 (0.776)	Data 0.0000 (0.0000)	Loss 1.2614 (1.7614)	
label_Epoch: [71][130/345]	Time 0.606 (0.763)	Data 0.0000 (0.0000)	Loss 1.5069 (1.7519)	
label_Epoch: [71][140/345]	Time 0.599 (0.753)	Data 0.0000 (0.0000)	Loss 1.5935 (1.7399)	
label_Epoch: [71][150/345]	Time 0.611 (0.744)	Data 0.0000 (0.0000)	Loss 1.1214 (1.7166)	
label_Epoch: [71][160/345]	Time 0.611 (0.736)	Data 0.0000 (0.0000)	Loss 1.4713 (1.6977)	
label_Epoch: [71][170/345]	Time 0.613 (0.729)	Data 0.0000 (0.0000)	Loss 1.7024 (1.6873)	
label_Epoch: [71][180/345]	Time 0.601 (0.723)	Data 0.0000 (0.0000)	Loss 1.4323 (1.6685)	
label_Epoch: [71][190/345]	Time 0.622 (0.717)	Data 0.0000 (0.0000)	Loss 1.7541 (1.6545)	
label_Epoch: [71][200/345]	Time 0.615 (0.712)	Data 0.0000 (0.0000)	Loss 1.1520 (1.6371)	
label_Epoch: [71][210/345]	Time 0.636 (0.708)	Data 0.0000 (0.0000)	Loss 1.4286 (1.6256)	
label_Epoch: [71][220/345]	Time 0.603 (0.703)	Data 0.0000 (0.0000)	Loss 1.1932 (1.6062)	
label_Epoch: [71][230/345]	Time 0.619 (0.700)	Data 0.0000 (0.0000)	Loss 1.0745 (1.5900)	
label_Epoch: [71][240/345]	Time 0.616 (0.696)	Data 0.0000 (0.0000)	Loss 1.4325 (1.5778)	
label_Epoch: [71][250/345]	Time 0.624 (0.693)	Data 0.0000 (0.0000)	Loss 1.3099 (1.5631)	
label_Epoch: [71][260/345]	Time 0.616 (0.690)	Data 0.0000 (0.0000)	Loss 1.1207 (1.5482)	
label_Epoch: [71][270/345]	Time 0.630 (0.687)	Data 0.0000 (0.0000)	Loss 1.2013 (1.5397)	
label_Epoch: [71][280/345]	Time 0.601 (0.685)	Data 0.0000 (0.0000)	Loss 1.1563 (1.5304)	
label_Epoch: [71][290/345]	Time 0.628 (0.682)	Data 0.0000 (0.0000)	Loss 1.1317 (1.5199)	
label_Epoch: [71][300/345]	Time 0.616 (0.681)	Data 0.0000 (0.0000)	Loss 1.4153 (1.5109)	
label_Epoch: [71][310/345]	Time 0.629 (0.679)	Data 0.0000 (0.0000)	Loss 1.1420 (1.4998)	
label_Epoch: [71][320/345]	Time 0.622 (0.677)	Data 0.0000 (0.0000)	Loss 1.1016 (1.4898)	
label_Epoch: [71][330/345]	Time 0.617 (0.675)	Data 0.0000 (0.0000)	Loss 1.0542 (1.4791)	
label_Epoch: [71][340/345]	Time 0.606 (0.673)	Data 0.0000 (0.0000)	Loss 1.0473 (1.4697)	
71
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [72][10/345]	Time 0.628 (2.591)	Data 0.0000 (0.0000)	Loss 1.4972 (1.7016)	
label_Epoch: [72][20/345]	Time 0.616 (1.604)	Data 0.0000 (0.0000)	Loss 1.1499 (1.7169)	
label_Epoch: [72][30/345]	Time 0.622 (1.278)	Data 0.0000 (0.0000)	Loss 1.1868 (1.7920)	
label_Epoch: [72][40/345]	Time 0.639 (1.111)	Data 0.0000 (0.0000)	Loss 1.2918 (1.7208)	
label_Epoch: [72][50/345]	Time 0.623 (1.013)	Data 0.0000 (0.0000)	Loss 1.4096 (1.7610)	
label_Epoch: [72][60/345]	Time 0.607 (0.947)	Data 0.0000 (0.0000)	Loss 1.0441 (1.7272)	
label_Epoch: [72][70/345]	Time 0.622 (0.900)	Data 0.0000 (0.0000)	Loss 1.3876 (1.7215)	
label_Epoch: [72][80/345]	Time 0.609 (0.864)	Data 0.0000 (0.0000)	Loss 1.7260 (1.6861)	
label_Epoch: [72][90/345]	Time 0.614 (0.836)	Data 0.0000 (0.0000)	Loss 1.8493 (1.7106)	
label_Epoch: [72][100/345]	Time 0.629 (0.814)	Data 0.0000 (0.0000)	Loss 1.2415 (1.7077)	
label_Epoch: [72][110/345]	Time 0.611 (0.796)	Data 0.0000 (0.0000)	Loss 2.0802 (1.7051)	
label_Epoch: [72][120/345]	Time 0.640 (0.781)	Data 0.0000 (0.0000)	Loss 1.3590 (1.6761)	
label_Epoch: [72][130/345]	Time 0.614 (0.768)	Data 0.0000 (0.0000)	Loss 1.3989 (1.6591)	
label_Epoch: [72][140/345]	Time 0.623 (0.757)	Data 0.0000 (0.0000)	Loss 1.3287 (1.6343)	
label_Epoch: [72][150/345]	Time 0.624 (0.748)	Data 0.0000 (0.0000)	Loss 1.3349 (1.6272)	
label_Epoch: [72][160/345]	Time 0.606 (0.740)	Data 0.0000 (0.0000)	Loss 1.4439 (1.6117)	
label_Epoch: [72][170/345]	Time 0.618 (0.733)	Data 0.0000 (0.0000)	Loss 1.5081 (1.5955)	
label_Epoch: [72][180/345]	Time 0.604 (0.726)	Data 0.0000 (0.0000)	Loss 2.6629 (1.5995)	
label_Epoch: [72][190/345]	Time 0.638 (0.721)	Data 0.0000 (0.0000)	Loss 1.8800 (1.5862)	
label_Epoch: [72][200/345]	Time 0.618 (0.716)	Data 0.0000 (0.0000)	Loss 1.5972 (1.5809)	
label_Epoch: [72][210/345]	Time 0.619 (0.711)	Data 0.0000 (0.0000)	Loss 1.0518 (1.5648)	
label_Epoch: [72][220/345]	Time 0.604 (0.707)	Data 0.0000 (0.0000)	Loss 1.1173 (1.5543)	
label_Epoch: [72][230/345]	Time 0.620 (0.703)	Data 0.0000 (0.0000)	Loss 1.1608 (1.5492)	
label_Epoch: [72][240/345]	Time 0.628 (0.699)	Data 0.0000 (0.0000)	Loss 1.7034 (1.5436)	
label_Epoch: [72][250/345]	Time 0.609 (0.696)	Data 0.0000 (0.0000)	Loss 1.4157 (1.5377)	
label_Epoch: [72][260/345]	Time 0.631 (0.693)	Data 0.0000 (0.0000)	Loss 1.4678 (1.5254)	
label_Epoch: [72][270/345]	Time 0.623 (0.690)	Data 0.0000 (0.0000)	Loss 1.1344 (1.5155)	
label_Epoch: [72][280/345]	Time 0.630 (0.687)	Data 0.0000 (0.0000)	Loss 1.0692 (1.5110)	
label_Epoch: [72][290/345]	Time 0.633 (0.685)	Data 0.0000 (0.0000)	Loss 1.4681 (1.5002)	
label_Epoch: [72][300/345]	Time 0.627 (0.682)	Data 0.0000 (0.0000)	Loss 1.0368 (1.4895)	
label_Epoch: [72][310/345]	Time 0.620 (0.680)	Data 0.0000 (0.0000)	Loss 1.0475 (1.4807)	
label_Epoch: [72][320/345]	Time 0.626 (0.678)	Data 0.0000 (0.0000)	Loss 1.1873 (1.4727)	
label_Epoch: [72][330/345]	Time 0.633 (0.677)	Data 0.0000 (0.0000)	Loss 1.1994 (1.4646)	
label_Epoch: [72][340/345]	Time 0.637 (0.675)	Data 0.0000 (0.0000)	Loss 1.0146 (1.4540)	
72
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [73][10/345]	Time 0.607 (2.454)	Data 0.0000 (0.0000)	Loss 2.1515 (1.8795)	
label_Epoch: [73][20/345]	Time 0.623 (1.539)	Data 0.0000 (0.0000)	Loss 2.1430 (1.8449)	
label_Epoch: [73][30/345]	Time 0.606 (1.230)	Data 0.0000 (0.0000)	Loss 2.8575 (1.9104)	
label_Epoch: [73][40/345]	Time 0.610 (1.077)	Data 0.0000 (0.0000)	Loss 1.3438 (1.8949)	
label_Epoch: [73][50/345]	Time 0.630 (0.984)	Data 0.0000 (0.0000)	Loss 2.1627 (1.8570)	
label_Epoch: [73][60/345]	Time 0.607 (0.923)	Data 0.0000 (0.0000)	Loss 1.1471 (1.8416)	
label_Epoch: [73][70/345]	Time 0.630 (0.879)	Data 0.0000 (0.0000)	Loss 1.2721 (1.7997)	
label_Epoch: [73][80/345]	Time 0.624 (0.846)	Data 0.0000 (0.0000)	Loss 2.2395 (1.8112)	
label_Epoch: [73][90/345]	Time 0.618 (0.820)	Data 0.0000 (0.0000)	Loss 1.1823 (1.7981)	
label_Epoch: [73][100/345]	Time 0.603 (0.799)	Data 0.0000 (0.0000)	Loss 1.2471 (1.7846)	
label_Epoch: [73][110/345]	Time 0.608 (0.783)	Data 0.0000 (0.0000)	Loss 1.2302 (1.7476)	
label_Epoch: [73][120/345]	Time 0.610 (0.769)	Data 0.0000 (0.0000)	Loss 1.6887 (1.7300)	
label_Epoch: [73][130/345]	Time 0.622 (0.757)	Data 0.0000 (0.0000)	Loss 1.9449 (1.7059)	
label_Epoch: [73][140/345]	Time 0.621 (0.747)	Data 0.0000 (0.0000)	Loss 2.2534 (1.7117)	
label_Epoch: [73][150/345]	Time 0.620 (0.738)	Data 0.0000 (0.0000)	Loss 1.1881 (1.6957)	
label_Epoch: [73][160/345]	Time 0.621 (0.731)	Data 0.0000 (0.0000)	Loss 1.6058 (1.6783)	
label_Epoch: [73][170/345]	Time 0.611 (0.724)	Data 0.0000 (0.0000)	Loss 1.2108 (1.6613)	
label_Epoch: [73][180/345]	Time 0.616 (0.718)	Data 0.0000 (0.0000)	Loss 1.4590 (1.6426)	
label_Epoch: [73][190/345]	Time 0.599 (0.713)	Data 0.0000 (0.0000)	Loss 1.6042 (1.6278)	
label_Epoch: [73][200/345]	Time 0.622 (0.708)	Data 0.0000 (0.0000)	Loss 1.3429 (1.6173)	
label_Epoch: [73][210/345]	Time 0.629 (0.704)	Data 0.0000 (0.0000)	Loss 1.3685 (1.6066)	
label_Epoch: [73][220/345]	Time 0.634 (0.701)	Data 0.0000 (0.0000)	Loss 1.3797 (1.5967)	
label_Epoch: [73][230/345]	Time 0.623 (0.697)	Data 0.0000 (0.0000)	Loss 1.2031 (1.5852)	
label_Epoch: [73][240/345]	Time 0.614 (0.694)	Data 0.0000 (0.0000)	Loss 1.1284 (1.5706)	
label_Epoch: [73][250/345]	Time 0.632 (0.691)	Data 0.0000 (0.0000)	Loss 1.1905 (1.5579)	
label_Epoch: [73][260/345]	Time 0.608 (0.688)	Data 0.0000 (0.0000)	Loss 1.2646 (1.5469)	
label_Epoch: [73][270/345]	Time 0.631 (0.686)	Data 0.0000 (0.0000)	Loss 1.2047 (1.5371)	
label_Epoch: [73][280/345]	Time 0.638 (0.683)	Data 0.0000 (0.0000)	Loss 1.1282 (1.5270)	
label_Epoch: [73][290/345]	Time 0.612 (0.681)	Data 0.0000 (0.0000)	Loss 1.2969 (1.5203)	
label_Epoch: [73][300/345]	Time 0.624 (0.679)	Data 0.0000 (0.0000)	Loss 1.0741 (1.5086)	
label_Epoch: [73][310/345]	Time 0.650 (0.677)	Data 0.0000 (0.0000)	Loss 1.1592 (1.4979)	
label_Epoch: [73][320/345]	Time 0.622 (0.675)	Data 0.0000 (0.0000)	Loss 1.0859 (1.4882)	
label_Epoch: [73][330/345]	Time 0.612 (0.673)	Data 0.0000 (0.0000)	Loss 1.1537 (1.4781)	
label_Epoch: [73][340/345]	Time 0.616 (0.672)	Data 0.0000 (0.0000)	Loss 1.0887 (1.4673)	
73
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [74][10/345]	Time 0.626 (2.552)	Data 0.0000 (0.0000)	Loss 1.4245 (2.0719)	
label_Epoch: [74][20/345]	Time 0.638 (1.586)	Data 0.0000 (0.0000)	Loss 1.8713 (1.9536)	
label_Epoch: [74][30/345]	Time 0.626 (1.263)	Data 0.0000 (0.0000)	Loss 1.5304 (1.9592)	
label_Epoch: [74][40/345]	Time 0.616 (1.102)	Data 0.0000 (0.0000)	Loss 2.2307 (1.9534)	
label_Epoch: [74][50/345]	Time 0.604 (1.004)	Data 0.0000 (0.0000)	Loss 1.9579 (1.8793)	
label_Epoch: [74][60/345]	Time 0.614 (0.939)	Data 0.0000 (0.0000)	Loss 1.5535 (1.8421)	
label_Epoch: [74][70/345]	Time 0.624 (0.893)	Data 0.0000 (0.0000)	Loss 1.2738 (1.8058)	
label_Epoch: [74][80/345]	Time 0.616 (0.859)	Data 0.0000 (0.0000)	Loss 1.3041 (1.7818)	
label_Epoch: [74][90/345]	Time 0.612 (0.832)	Data 0.0000 (0.0000)	Loss 1.9871 (1.7697)	
label_Epoch: [74][100/345]	Time 0.614 (0.811)	Data 0.0000 (0.0000)	Loss 1.6489 (1.7540)	
label_Epoch: [74][110/345]	Time 0.620 (0.794)	Data 0.0000 (0.0000)	Loss 2.2229 (1.7244)	
label_Epoch: [74][120/345]	Time 0.619 (0.779)	Data 0.0000 (0.0000)	Loss 1.1765 (1.7226)	
label_Epoch: [74][130/345]	Time 0.603 (0.766)	Data 0.0000 (0.0000)	Loss 1.4206 (1.7003)	
label_Epoch: [74][140/345]	Time 0.623 (0.755)	Data 0.0000 (0.0000)	Loss 1.2407 (1.6711)	
label_Epoch: [74][150/345]	Time 0.635 (0.747)	Data 0.0000 (0.0000)	Loss 2.4608 (1.6596)	
label_Epoch: [74][160/345]	Time 0.632 (0.738)	Data 0.0000 (0.0000)	Loss 1.0943 (1.6432)	
label_Epoch: [74][170/345]	Time 0.603 (0.731)	Data 0.0000 (0.0000)	Loss 1.1030 (1.6318)	
label_Epoch: [74][180/345]	Time 0.613 (0.724)	Data 0.0000 (0.0000)	Loss 2.1079 (1.6164)	
label_Epoch: [74][190/345]	Time 0.640 (0.719)	Data 0.0000 (0.0000)	Loss 1.6529 (1.6048)	
label_Epoch: [74][200/345]	Time 0.626 (0.714)	Data 0.0000 (0.0000)	Loss 1.0509 (1.5882)	
label_Epoch: [74][210/345]	Time 0.623 (0.709)	Data 0.0000 (0.0000)	Loss 1.2708 (1.5754)	
label_Epoch: [74][220/345]	Time 0.636 (0.705)	Data 0.0000 (0.0000)	Loss 1.3076 (1.5662)	
label_Epoch: [74][230/345]	Time 0.622 (0.701)	Data 0.0000 (0.0000)	Loss 1.1046 (1.5581)	
label_Epoch: [74][240/345]	Time 0.621 (0.698)	Data 0.0000 (0.0000)	Loss 1.3220 (1.5492)	
label_Epoch: [74][250/345]	Time 0.606 (0.695)	Data 0.0000 (0.0000)	Loss 1.2791 (1.5366)	
label_Epoch: [74][260/345]	Time 0.615 (0.692)	Data 0.0000 (0.0000)	Loss 1.0284 (1.5263)	
label_Epoch: [74][270/345]	Time 0.611 (0.689)	Data 0.0000 (0.0000)	Loss 1.1544 (1.5185)	
label_Epoch: [74][280/345]	Time 0.620 (0.686)	Data 0.0000 (0.0000)	Loss 1.1757 (1.5082)	
label_Epoch: [74][290/345]	Time 0.626 (0.684)	Data 0.0000 (0.0000)	Loss 1.2318 (1.5050)	
label_Epoch: [74][300/345]	Time 0.619 (0.682)	Data 0.0000 (0.0000)	Loss 1.5606 (1.4983)	
label_Epoch: [74][310/345]	Time 0.610 (0.679)	Data 0.0000 (0.0000)	Loss 1.4115 (1.4906)	
label_Epoch: [74][320/345]	Time 0.630 (0.678)	Data 0.0000 (0.0000)	Loss 1.1340 (1.4795)	
label_Epoch: [74][330/345]	Time 0.622 (0.676)	Data 0.0000 (0.0000)	Loss 1.0875 (1.4695)	
label_Epoch: [74][340/345]	Time 0.618 (0.674)	Data 0.0000 (0.0000)	Loss 1.2334 (1.4602)	
74
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [75][10/345]	Time 0.607 (2.386)	Data 0.0000 (0.0000)	Loss 2.2198 (1.7332)	
label_Epoch: [75][20/345]	Time 0.599 (1.503)	Data 0.0000 (0.0000)	Loss 1.9479 (1.7529)	
label_Epoch: [75][30/345]	Time 0.621 (1.207)	Data 0.0000 (0.0000)	Loss 2.4500 (1.7859)	
label_Epoch: [75][40/345]	Time 0.626 (1.060)	Data 0.0000 (0.0000)	Loss 2.1771 (1.7568)	
label_Epoch: [75][50/345]	Time 0.604 (0.970)	Data 0.0000 (0.0000)	Loss 1.3070 (1.7182)	
label_Epoch: [75][60/345]	Time 0.626 (0.912)	Data 0.0000 (0.0000)	Loss 2.0403 (1.7067)	
label_Epoch: [75][70/345]	Time 0.616 (0.869)	Data 0.0000 (0.0000)	Loss 1.6500 (1.7355)	
label_Epoch: [75][80/345]	Time 0.609 (0.837)	Data 0.0000 (0.0000)	Loss 1.8982 (1.7271)	
label_Epoch: [75][90/345]	Time 0.611 (0.813)	Data 0.0000 (0.0000)	Loss 1.2591 (1.7177)	
label_Epoch: [75][100/345]	Time 0.618 (0.793)	Data 0.0000 (0.0000)	Loss 1.6226 (1.6986)	
label_Epoch: [75][110/345]	Time 0.620 (0.777)	Data 0.0000 (0.0000)	Loss 1.7926 (1.7166)	
label_Epoch: [75][120/345]	Time 0.603 (0.764)	Data 0.0000 (0.0000)	Loss 1.2726 (1.6931)	
label_Epoch: [75][130/345]	Time 0.603 (0.752)	Data 0.0000 (0.0000)	Loss 1.3360 (1.6875)	
label_Epoch: [75][140/345]	Time 0.622 (0.743)	Data 0.0000 (0.0000)	Loss 1.9208 (1.6785)	
label_Epoch: [75][150/345]	Time 0.600 (0.734)	Data 0.0000 (0.0000)	Loss 1.4744 (1.6697)	
label_Epoch: [75][160/345]	Time 0.616 (0.727)	Data 0.0000 (0.0000)	Loss 1.3024 (1.6527)	
label_Epoch: [75][170/345]	Time 0.636 (0.720)	Data 0.0000 (0.0000)	Loss 1.4490 (1.6445)	
label_Epoch: [75][180/345]	Time 0.622 (0.714)	Data 0.0000 (0.0000)	Loss 1.4587 (1.6367)	
label_Epoch: [75][190/345]	Time 0.625 (0.709)	Data 0.0000 (0.0000)	Loss 1.4195 (1.6208)	
label_Epoch: [75][200/345]	Time 0.601 (0.704)	Data 0.0000 (0.0000)	Loss 1.2803 (1.6105)	
label_Epoch: [75][210/345]	Time 0.620 (0.700)	Data 0.0000 (0.0000)	Loss 1.1393 (1.5985)	
label_Epoch: [75][220/345]	Time 0.619 (0.696)	Data 0.0000 (0.0000)	Loss 1.1598 (1.5852)	
label_Epoch: [75][230/345]	Time 0.614 (0.693)	Data 0.0000 (0.0000)	Loss 1.0469 (1.5674)	
label_Epoch: [75][240/345]	Time 0.619 (0.690)	Data 0.0000 (0.0000)	Loss 1.1570 (1.5557)	
label_Epoch: [75][250/345]	Time 0.610 (0.687)	Data 0.0000 (0.0000)	Loss 1.5012 (1.5495)	
label_Epoch: [75][260/345]	Time 0.634 (0.684)	Data 0.0000 (0.0000)	Loss 1.4164 (1.5427)	
label_Epoch: [75][270/345]	Time 0.635 (0.682)	Data 0.0000 (0.0000)	Loss 1.1309 (1.5348)	
label_Epoch: [75][280/345]	Time 0.603 (0.679)	Data 0.0000 (0.0000)	Loss 1.1600 (1.5217)	
label_Epoch: [75][290/345]	Time 0.629 (0.677)	Data 0.0000 (0.0000)	Loss 1.0888 (1.5129)	
label_Epoch: [75][300/345]	Time 0.617 (0.675)	Data 0.0000 (0.0000)	Loss 1.2080 (1.5036)	
label_Epoch: [75][310/345]	Time 0.632 (0.673)	Data 0.0000 (0.0000)	Loss 1.1385 (1.4939)	
label_Epoch: [75][320/345]	Time 0.611 (0.671)	Data 0.0000 (0.0000)	Loss 1.1308 (1.4859)	
label_Epoch: [75][330/345]	Time 0.616 (0.669)	Data 0.0000 (0.0000)	Loss 1.0865 (1.4762)	
label_Epoch: [75][340/345]	Time 0.614 (0.668)	Data 0.0000 (0.0000)	Loss 1.1270 (1.4653)	
75
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [76][10/345]	Time 0.635 (2.543)	Data 0.0000 (0.0000)	Loss 1.6677 (2.0068)	
label_Epoch: [76][20/345]	Time 0.622 (1.581)	Data 0.0000 (0.0000)	Loss 2.1923 (2.0078)	
label_Epoch: [76][30/345]	Time 0.622 (1.261)	Data 0.0000 (0.0000)	Loss 1.9642 (1.8927)	
label_Epoch: [76][40/345]	Time 0.622 (1.101)	Data 0.0000 (0.0000)	Loss 2.1410 (1.9322)	
label_Epoch: [76][50/345]	Time 0.611 (1.002)	Data 0.0000 (0.0000)	Loss 1.8298 (1.8901)	
label_Epoch: [76][60/345]	Time 0.622 (0.937)	Data 0.0000 (0.0000)	Loss 2.3226 (1.8621)	
label_Epoch: [76][70/345]	Time 0.613 (0.891)	Data 0.0000 (0.0000)	Loss 1.5539 (1.8142)	
label_Epoch: [76][80/345]	Time 0.613 (0.856)	Data 0.0000 (0.0000)	Loss 1.8656 (1.8131)	
label_Epoch: [76][90/345]	Time 0.620 (0.829)	Data 0.0000 (0.0000)	Loss 1.6674 (1.7943)	
label_Epoch: [76][100/345]	Time 0.604 (0.807)	Data 0.0000 (0.0000)	Loss 1.8102 (1.7761)	
label_Epoch: [76][110/345]	Time 0.629 (0.790)	Data 0.0000 (0.0000)	Loss 1.1012 (1.7541)	
label_Epoch: [76][120/345]	Time 0.630 (0.776)	Data 0.0000 (0.0000)	Loss 1.9272 (1.7436)	
label_Epoch: [76][130/345]	Time 0.617 (0.764)	Data 0.0000 (0.0000)	Loss 1.2480 (1.7280)	
label_Epoch: [76][140/345]	Time 0.622 (0.754)	Data 0.0000 (0.0000)	Loss 1.2837 (1.7297)	
label_Epoch: [76][150/345]	Time 0.605 (0.744)	Data 0.0000 (0.0000)	Loss 1.5620 (1.7057)	
label_Epoch: [76][160/345]	Time 0.619 (0.736)	Data 0.0000 (0.0000)	Loss 1.1196 (1.6886)	
label_Epoch: [76][170/345]	Time 0.634 (0.729)	Data 0.0000 (0.0000)	Loss 1.2803 (1.6679)	
label_Epoch: [76][180/345]	Time 0.607 (0.723)	Data 0.0000 (0.0000)	Loss 1.1505 (1.6508)	
label_Epoch: [76][190/345]	Time 0.611 (0.717)	Data 0.0000 (0.0000)	Loss 1.2750 (1.6348)	
label_Epoch: [76][200/345]	Time 0.619 (0.712)	Data 0.0000 (0.0000)	Loss 1.1352 (1.6179)	
label_Epoch: [76][210/345]	Time 0.621 (0.707)	Data 0.0000 (0.0000)	Loss 1.2610 (1.6033)	
label_Epoch: [76][220/345]	Time 0.624 (0.703)	Data 0.0000 (0.0000)	Loss 1.2622 (1.5920)	
label_Epoch: [76][230/345]	Time 0.620 (0.699)	Data 0.0000 (0.0000)	Loss 1.4975 (1.5818)	
label_Epoch: [76][240/345]	Time 0.601 (0.696)	Data 0.0000 (0.0000)	Loss 1.2720 (1.5664)	
label_Epoch: [76][250/345]	Time 0.636 (0.693)	Data 0.0000 (0.0000)	Loss 1.1428 (1.5522)	
label_Epoch: [76][260/345]	Time 0.626 (0.690)	Data 0.0000 (0.0000)	Loss 1.2384 (1.5384)	
label_Epoch: [76][270/345]	Time 0.633 (0.688)	Data 0.0000 (0.0000)	Loss 1.4219 (1.5302)	
label_Epoch: [76][280/345]	Time 0.605 (0.685)	Data 0.0000 (0.0000)	Loss 1.2299 (1.5196)	
label_Epoch: [76][290/345]	Time 0.628 (0.683)	Data 0.0000 (0.0000)	Loss 1.1340 (1.5080)	
label_Epoch: [76][300/345]	Time 0.610 (0.681)	Data 0.0000 (0.0000)	Loss 1.3354 (1.4962)	
label_Epoch: [76][310/345]	Time 0.602 (0.679)	Data 0.0000 (0.0000)	Loss 1.0622 (1.4863)	
label_Epoch: [76][320/345]	Time 0.607 (0.677)	Data 0.0000 (0.0000)	Loss 1.0290 (1.4748)	
label_Epoch: [76][330/345]	Time 0.602 (0.675)	Data 0.0000 (0.0000)	Loss 1.0641 (1.4645)	
label_Epoch: [76][340/345]	Time 0.617 (0.674)	Data 0.0000 (0.0000)	Loss 1.1998 (1.4542)	
76
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [77][10/345]	Time 0.614 (2.376)	Data 0.0000 (0.0000)	Loss 3.1728 (2.1971)	
label_Epoch: [77][20/345]	Time 0.608 (1.496)	Data 0.0000 (0.0000)	Loss 1.7805 (1.9959)	
label_Epoch: [77][30/345]	Time 0.604 (1.202)	Data 0.0000 (0.0000)	Loss 2.4048 (1.9177)	
label_Epoch: [77][40/345]	Time 0.625 (1.056)	Data 0.0000 (0.0000)	Loss 2.0809 (1.8755)	
label_Epoch: [77][50/345]	Time 0.634 (0.968)	Data 0.0000 (0.0000)	Loss 1.4692 (1.7878)	
label_Epoch: [77][60/345]	Time 0.612 (0.909)	Data 0.0000 (0.0000)	Loss 1.2633 (1.7781)	
label_Epoch: [77][70/345]	Time 0.600 (0.867)	Data 0.0000 (0.0000)	Loss 2.6440 (1.7672)	
label_Epoch: [77][80/345]	Time 0.614 (0.835)	Data 0.0000 (0.0000)	Loss 2.3279 (1.7711)	
label_Epoch: [77][90/345]	Time 0.612 (0.811)	Data 0.0000 (0.0000)	Loss 1.2660 (1.7672)	
label_Epoch: [77][100/345]	Time 0.612 (0.792)	Data 0.0000 (0.0000)	Loss 1.3037 (1.7371)	
label_Epoch: [77][110/345]	Time 0.613 (0.776)	Data 0.0000 (0.0000)	Loss 2.0918 (1.7283)	
label_Epoch: [77][120/345]	Time 0.617 (0.763)	Data 0.0000 (0.0000)	Loss 1.2753 (1.7470)	
label_Epoch: [77][130/345]	Time 0.608 (0.752)	Data 0.0000 (0.0000)	Loss 1.2096 (1.7128)	
label_Epoch: [77][140/345]	Time 0.627 (0.742)	Data 0.0000 (0.0000)	Loss 1.3739 (1.7054)	
label_Epoch: [77][150/345]	Time 0.619 (0.734)	Data 0.0000 (0.0000)	Loss 1.2123 (1.6786)	
label_Epoch: [77][160/345]	Time 0.623 (0.727)	Data 0.0000 (0.0000)	Loss 1.3998 (1.6480)	
label_Epoch: [77][170/345]	Time 0.619 (0.721)	Data 0.0000 (0.0000)	Loss 1.1257 (1.6285)	
label_Epoch: [77][180/345]	Time 0.604 (0.715)	Data 0.0000 (0.0000)	Loss 1.6545 (1.6117)	
label_Epoch: [77][190/345]	Time 0.612 (0.710)	Data 0.0000 (0.0000)	Loss 1.1242 (1.5992)	
label_Epoch: [77][200/345]	Time 0.636 (0.705)	Data 0.0000 (0.0000)	Loss 1.3167 (1.5934)	
label_Epoch: [77][210/345]	Time 0.619 (0.701)	Data 0.0000 (0.0000)	Loss 1.2284 (1.5812)	
label_Epoch: [77][220/345]	Time 0.629 (0.697)	Data 0.0000 (0.0000)	Loss 1.1828 (1.5745)	
label_Epoch: [77][230/345]	Time 0.635 (0.694)	Data 0.0000 (0.0000)	Loss 1.4069 (1.5653)	
label_Epoch: [77][240/345]	Time 0.631 (0.691)	Data 0.0000 (0.0000)	Loss 1.3758 (1.5521)	
label_Epoch: [77][250/345]	Time 0.621 (0.688)	Data 0.0000 (0.0000)	Loss 1.1019 (1.5422)	
label_Epoch: [77][260/345]	Time 0.612 (0.685)	Data 0.0000 (0.0000)	Loss 1.1412 (1.5315)	
label_Epoch: [77][270/345]	Time 0.620 (0.683)	Data 0.0000 (0.0000)	Loss 1.4182 (1.5201)	
label_Epoch: [77][280/345]	Time 0.627 (0.680)	Data 0.0000 (0.0000)	Loss 1.0166 (1.5124)	
label_Epoch: [77][290/345]	Time 0.615 (0.678)	Data 0.0000 (0.0000)	Loss 1.1480 (1.5015)	
label_Epoch: [77][300/345]	Time 0.622 (0.676)	Data 0.0000 (0.0000)	Loss 1.1097 (1.4911)	
label_Epoch: [77][310/345]	Time 0.598 (0.674)	Data 0.0000 (0.0000)	Loss 1.1172 (1.4825)	
label_Epoch: [77][320/345]	Time 0.621 (0.672)	Data 0.0000 (0.0000)	Loss 1.0462 (1.4732)	
label_Epoch: [77][330/345]	Time 0.615 (0.670)	Data 0.0000 (0.0000)	Loss 1.0586 (1.4634)	
label_Epoch: [77][340/345]	Time 0.609 (0.669)	Data 0.0000 (0.0000)	Loss 1.0755 (1.4537)	
77
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [78][10/345]	Time 0.601 (2.539)	Data 0.0000 (0.0000)	Loss 1.3582 (1.8894)	
label_Epoch: [78][20/345]	Time 0.610 (1.578)	Data 0.0000 (0.0000)	Loss 1.6787 (1.9279)	
label_Epoch: [78][30/345]	Time 0.618 (1.257)	Data 0.0000 (0.0000)	Loss 2.0303 (1.9179)	
label_Epoch: [78][40/345]	Time 0.621 (1.099)	Data 0.0000 (0.0000)	Loss 1.1228 (1.9388)	
label_Epoch: [78][50/345]	Time 0.601 (1.002)	Data 0.0000 (0.0000)	Loss 1.0876 (1.9103)	
label_Epoch: [78][60/345]	Time 0.628 (0.939)	Data 0.0000 (0.0000)	Loss 1.8335 (1.8705)	
label_Epoch: [78][70/345]	Time 0.602 (0.893)	Data 0.0000 (0.0000)	Loss 1.3475 (1.8388)	
label_Epoch: [78][80/345]	Time 0.612 (0.858)	Data 0.0000 (0.0000)	Loss 1.3791 (1.8125)	
label_Epoch: [78][90/345]	Time 0.617 (0.831)	Data 0.0000 (0.0000)	Loss 1.1033 (1.7636)	
label_Epoch: [78][100/345]	Time 0.620 (0.810)	Data 0.0000 (0.0000)	Loss 1.5013 (1.7263)	
label_Epoch: [78][110/345]	Time 0.630 (0.792)	Data 0.0000 (0.0000)	Loss 1.4435 (1.7128)	
label_Epoch: [78][120/345]	Time 0.629 (0.778)	Data 0.0000 (0.0000)	Loss 1.5765 (1.6911)	
label_Epoch: [78][130/345]	Time 0.614 (0.766)	Data 0.0000 (0.0000)	Loss 1.3728 (1.6817)	
label_Epoch: [78][140/345]	Time 0.632 (0.755)	Data 0.0000 (0.0000)	Loss 1.0955 (1.6550)	
label_Epoch: [78][150/345]	Time 0.638 (0.746)	Data 0.0000 (0.0000)	Loss 1.5574 (1.6373)	
label_Epoch: [78][160/345]	Time 0.616 (0.738)	Data 0.0000 (0.0000)	Loss 1.2236 (1.6278)	
label_Epoch: [78][170/345]	Time 0.605 (0.731)	Data 0.0000 (0.0000)	Loss 1.1158 (1.6198)	
label_Epoch: [78][180/345]	Time 0.616 (0.724)	Data 0.0000 (0.0000)	Loss 1.1196 (1.6103)	
label_Epoch: [78][190/345]	Time 0.622 (0.719)	Data 0.0000 (0.0000)	Loss 1.3201 (1.6071)	
label_Epoch: [78][200/345]	Time 0.619 (0.713)	Data 0.0000 (0.0000)	Loss 1.1146 (1.5939)	
label_Epoch: [78][210/345]	Time 0.624 (0.709)	Data 0.0000 (0.0000)	Loss 1.0749 (1.5774)	
label_Epoch: [78][220/345]	Time 0.654 (0.705)	Data 0.0000 (0.0000)	Loss 1.2757 (1.5633)	
label_Epoch: [78][230/345]	Time 0.628 (0.701)	Data 0.0000 (0.0000)	Loss 1.1619 (1.5497)	
label_Epoch: [78][240/345]	Time 0.612 (0.698)	Data 0.0000 (0.0000)	Loss 1.3877 (1.5376)	
label_Epoch: [78][250/345]	Time 0.617 (0.695)	Data 0.0000 (0.0000)	Loss 1.3789 (1.5236)	
label_Epoch: [78][260/345]	Time 0.628 (0.692)	Data 0.0000 (0.0000)	Loss 1.1109 (1.5153)	
label_Epoch: [78][270/345]	Time 0.611 (0.689)	Data 0.0000 (0.0000)	Loss 1.5253 (1.5070)	
label_Epoch: [78][280/345]	Time 0.610 (0.686)	Data 0.0000 (0.0000)	Loss 1.0765 (1.4964)	
label_Epoch: [78][290/345]	Time 0.606 (0.684)	Data 0.0000 (0.0000)	Loss 1.1976 (1.4857)	
label_Epoch: [78][300/345]	Time 0.615 (0.682)	Data 0.0000 (0.0000)	Loss 1.2977 (1.4782)	
label_Epoch: [78][310/345]	Time 0.627 (0.680)	Data 0.0000 (0.0000)	Loss 1.3491 (1.4701)	
label_Epoch: [78][320/345]	Time 0.614 (0.678)	Data 0.0000 (0.0000)	Loss 1.0967 (1.4632)	
label_Epoch: [78][330/345]	Time 0.616 (0.676)	Data 0.0000 (0.0000)	Loss 1.0292 (1.4521)	
label_Epoch: [78][340/345]	Time 0.610 (0.674)	Data 0.0000 (0.0000)	Loss 1.2904 (1.4438)	
78
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [79][10/345]	Time 0.619 (2.545)	Data 0.0000 (0.0000)	Loss 1.4932 (1.8324)	
label_Epoch: [79][20/345]	Time 0.627 (1.580)	Data 0.0000 (0.0000)	Loss 1.9050 (1.9393)	
label_Epoch: [79][30/345]	Time 0.619 (1.259)	Data 0.0000 (0.0000)	Loss 1.4436 (2.0127)	
label_Epoch: [79][40/345]	Time 0.628 (1.098)	Data 0.0000 (0.0000)	Loss 2.1543 (2.0254)	
label_Epoch: [79][50/345]	Time 0.609 (1.002)	Data 0.0000 (0.0000)	Loss 1.3142 (1.9299)	
label_Epoch: [79][60/345]	Time 0.617 (0.940)	Data 0.0000 (0.0000)	Loss 1.3237 (1.9135)	
label_Epoch: [79][70/345]	Time 0.620 (0.893)	Data 0.0000 (0.0000)	Loss 1.7362 (1.8496)	
label_Epoch: [79][80/345]	Time 0.630 (0.858)	Data 0.0000 (0.0000)	Loss 1.9059 (1.8105)	
label_Epoch: [79][90/345]	Time 0.620 (0.832)	Data 0.0000 (0.0000)	Loss 1.3160 (1.7702)	
label_Epoch: [79][100/345]	Time 0.614 (0.810)	Data 0.0000 (0.0000)	Loss 1.2800 (1.7384)	
label_Epoch: [79][110/345]	Time 0.625 (0.792)	Data 0.0000 (0.0000)	Loss 2.2031 (1.7135)	
label_Epoch: [79][120/345]	Time 0.638 (0.778)	Data 0.0000 (0.0000)	Loss 1.7711 (1.6908)	
label_Epoch: [79][130/345]	Time 0.624 (0.765)	Data 0.0000 (0.0000)	Loss 1.3963 (1.6685)	
label_Epoch: [79][140/345]	Time 0.609 (0.755)	Data 0.0000 (0.0000)	Loss 2.1314 (1.6772)	
label_Epoch: [79][150/345]	Time 0.615 (0.746)	Data 0.0000 (0.0000)	Loss 1.1981 (1.6538)	
label_Epoch: [79][160/345]	Time 0.623 (0.738)	Data 0.0000 (0.0000)	Loss 1.9054 (1.6381)	
label_Epoch: [79][170/345]	Time 0.623 (0.731)	Data 0.0000 (0.0000)	Loss 1.2354 (1.6269)	
label_Epoch: [79][180/345]	Time 0.613 (0.725)	Data 0.0000 (0.0000)	Loss 1.4021 (1.6051)	
label_Epoch: [79][190/345]	Time 0.628 (0.719)	Data 0.0000 (0.0000)	Loss 1.1274 (1.5951)	
label_Epoch: [79][200/345]	Time 0.625 (0.714)	Data 0.0000 (0.0000)	Loss 1.1260 (1.5835)	
label_Epoch: [79][210/345]	Time 0.613 (0.709)	Data 0.0000 (0.0000)	Loss 1.0882 (1.5694)	
label_Epoch: [79][220/345]	Time 0.612 (0.705)	Data 0.0000 (0.0000)	Loss 1.1183 (1.5585)	
label_Epoch: [79][230/345]	Time 0.610 (0.701)	Data 0.0000 (0.0000)	Loss 1.5223 (1.5497)	
label_Epoch: [79][240/345]	Time 0.618 (0.698)	Data 0.0000 (0.0000)	Loss 1.5050 (1.5380)	
label_Epoch: [79][250/345]	Time 0.620 (0.695)	Data 0.0000 (0.0000)	Loss 1.5539 (1.5280)	
label_Epoch: [79][260/345]	Time 0.645 (0.692)	Data 0.0000 (0.0000)	Loss 1.1093 (1.5197)	
label_Epoch: [79][270/345]	Time 0.612 (0.689)	Data 0.0000 (0.0000)	Loss 1.1816 (1.5073)	
label_Epoch: [79][280/345]	Time 0.611 (0.686)	Data 0.0000 (0.0000)	Loss 1.0755 (1.4966)	
label_Epoch: [79][290/345]	Time 0.620 (0.684)	Data 0.0000 (0.0000)	Loss 1.0914 (1.4881)	
label_Epoch: [79][300/345]	Time 0.625 (0.682)	Data 0.0000 (0.0000)	Loss 1.1429 (1.4808)	
label_Epoch: [79][310/345]	Time 0.631 (0.680)	Data 0.0000 (0.0000)	Loss 1.0736 (1.4703)	
label_Epoch: [79][320/345]	Time 0.636 (0.678)	Data 0.0000 (0.0000)	Loss 1.1668 (1.4595)	
label_Epoch: [79][330/345]	Time 0.614 (0.676)	Data 0.0000 (0.0000)	Loss 1.0756 (1.4498)	
label_Epoch: [79][340/345]	Time 0.624 (0.675)	Data 0.0000 (0.0000)	Loss 1.1888 (1.4400)	
79
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [80][10/345]	Time 0.616 (2.462)	Data 0.0000 (0.0000)	Loss 1.7949 (1.8208)	
label_Epoch: [80][20/345]	Time 0.621 (1.540)	Data 0.0000 (0.0000)	Loss 2.0136 (1.9836)	
label_Epoch: [80][30/345]	Time 0.623 (1.233)	Data 0.0000 (0.0000)	Loss 1.2377 (1.8366)	
label_Epoch: [80][40/345]	Time 0.611 (1.078)	Data 0.0000 (0.0000)	Loss 1.6374 (1.8537)	
label_Epoch: [80][50/345]	Time 0.603 (0.986)	Data 0.0000 (0.0000)	Loss 1.2213 (1.8343)	
label_Epoch: [80][60/345]	Time 0.611 (0.924)	Data 0.0000 (0.0000)	Loss 1.1676 (1.7773)	
label_Epoch: [80][70/345]	Time 0.606 (0.880)	Data 0.0000 (0.0000)	Loss 2.1389 (1.7822)	
label_Epoch: [80][80/345]	Time 0.612 (0.847)	Data 0.0000 (0.0000)	Loss 1.2866 (1.7864)	
label_Epoch: [80][90/345]	Time 0.622 (0.822)	Data 0.0000 (0.0000)	Loss 1.9093 (1.7591)	
label_Epoch: [80][100/345]	Time 0.625 (0.802)	Data 0.0000 (0.0000)	Loss 1.4280 (1.7352)	
label_Epoch: [80][110/345]	Time 0.609 (0.785)	Data 0.0000 (0.0000)	Loss 1.9892 (1.7293)	
label_Epoch: [80][120/345]	Time 0.628 (0.771)	Data 0.0000 (0.0000)	Loss 1.3385 (1.7022)	
label_Epoch: [80][130/345]	Time 0.642 (0.760)	Data 0.0000 (0.0000)	Loss 1.5992 (1.6862)	
label_Epoch: [80][140/345]	Time 0.641 (0.750)	Data 0.0000 (0.0000)	Loss 1.2488 (1.6670)	
label_Epoch: [80][150/345]	Time 0.615 (0.741)	Data 0.0000 (0.0000)	Loss 1.1542 (1.6576)	
label_Epoch: [80][160/345]	Time 0.635 (0.734)	Data 0.0000 (0.0000)	Loss 1.2563 (1.6400)	
label_Epoch: [80][170/345]	Time 0.631 (0.727)	Data 0.0000 (0.0000)	Loss 1.3547 (1.6217)	
label_Epoch: [80][180/345]	Time 0.628 (0.721)	Data 0.0000 (0.0000)	Loss 1.1220 (1.6075)	
label_Epoch: [80][190/345]	Time 0.620 (0.715)	Data 0.0000 (0.0000)	Loss 1.4116 (1.5941)	
label_Epoch: [80][200/345]	Time 0.606 (0.711)	Data 0.0000 (0.0000)	Loss 1.3521 (1.5755)	
label_Epoch: [80][210/345]	Time 0.634 (0.706)	Data 0.0000 (0.0000)	Loss 1.1616 (1.5615)	
label_Epoch: [80][220/345]	Time 0.612 (0.702)	Data 0.0000 (0.0000)	Loss 1.4659 (1.5521)	
label_Epoch: [80][230/345]	Time 0.612 (0.698)	Data 0.0000 (0.0000)	Loss 1.2928 (1.5494)	
label_Epoch: [80][240/345]	Time 0.615 (0.695)	Data 0.0000 (0.0000)	Loss 1.5291 (1.5406)	
label_Epoch: [80][250/345]	Time 0.631 (0.692)	Data 0.0000 (0.0000)	Loss 1.1539 (1.5265)	
label_Epoch: [80][260/345]	Time 0.619 (0.689)	Data 0.0000 (0.0000)	Loss 1.2475 (1.5173)	
label_Epoch: [80][270/345]	Time 0.608 (0.686)	Data 0.0000 (0.0000)	Loss 1.0576 (1.5093)	
label_Epoch: [80][280/345]	Time 0.637 (0.684)	Data 0.0000 (0.0000)	Loss 1.1144 (1.4973)	
label_Epoch: [80][290/345]	Time 0.602 (0.682)	Data 0.0000 (0.0000)	Loss 1.6942 (1.4940)	
label_Epoch: [80][300/345]	Time 0.619 (0.680)	Data 0.0000 (0.0000)	Loss 1.1275 (1.4865)	
label_Epoch: [80][310/345]	Time 0.612 (0.678)	Data 0.0000 (0.0000)	Loss 1.0785 (1.4757)	
label_Epoch: [80][320/345]	Time 0.607 (0.676)	Data 0.0000 (0.0000)	Loss 1.3562 (1.4658)	
label_Epoch: [80][330/345]	Time 0.632 (0.674)	Data 0.0000 (0.0000)	Loss 1.0849 (1.4550)	
label_Epoch: [80][340/345]	Time 0.601 (0.672)	Data 0.0000 (0.0000)	Loss 1.1739 (1.4462)	
==> Test
Evaluating market1501 ...
# Using Flip Eval
Extracted features for query set, obtained 3368-by-3072 matrix
Extracted features for gallery set, obtained 15913-by-3072 matrix
==> BatchTime(s)/BatchSize(img): 0.090/100
Computing CMC and mAP
Results ----------
mAP: 51.20%
CMC curve
Rank-1  : 74.47%
Rank-5  : 88.24%
Rank-10 : 92.58%
Rank-20 : 95.01%
------------------
Save! 0 0.7446556
Finished. Total elapsed time (h:m:s): 7:13:00. Training time (h:m:s): 7:04:15.
=> Show summary
market1501 (source)
- epoch 80	 rank1 74.5%
