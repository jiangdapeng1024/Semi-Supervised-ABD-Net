==========
Args:Namespace(abd_dan=['cam', 'pam'], abd_dan_no_head=False, abd_dim=1024, abd_np=2, adam_beta1=0.9, adam_beta2=0.999, arch='resnet50', branches=['global', 'abd'], compatibility=False, criterion='htri', cuhk03_classic_split=False, cuhk03_labeled=False, dan_dan=[], dan_dan_no_head=False, dan_dim=1024, data_augment=['crop', 'random-erase'], dropout=0, eval_freq=-1, evaluate=False, fixbase=False, fixbase_epoch=10, flip_eval=True, gamma=0.1, global_dim=1024, global_max_pooling=False, gpu_devices='0', height=384, htri_only=False, label_smooth=True, lambda_htri=0.1, lambda_xent=1, load_weights='', lr=0.0003, margin=1.2, max_epoch=80, momentum=0.9, np_dim=1024, np_max_pooling=False, np_np=2, np_with_global=False, num_instances=4, of_beta=1e-06, of_position=['before', 'after', 'cam', 'pam', 'intermediate'], of_start_epoch=23, open_layers=['classifier'], optim='adam', ow_beta=0.001, pool_tracklet_features='avg', print_freq=10, resume='', rmsprop_alpha=0.99, root='data', sample_method='evenly', save_dir='path/to/dir/jpf1', seed=1, seq_len=15, sgd_dampening=0, sgd_nesterov=False, shallow_cam=True, source_names=['market1501'], split_id=0, start_epoch=0, start_eval=0, stepsize=[20, 40], target_names=['market1501'], test_batch_size=100, train_batch_size=8, train_sampler='', use_avai_gpus=False, use_cpu=False, use_metric_cuhk03=False, use_of=True, use_ow=True, visualize_ranks=False, weight_decay=0.0005, width=128, workers=0)
==========
Currently using GPU 0
Initializing image data manager
Using augmentation: {'crop', 'random-erase'}
Using transform: Compose(
    <torchreid.transforms.Random2DTranslation object at 0x00000157C9999470>
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <torchreid.transforms.RandomErasing object at 0x00000157C9999390>
)
=> Initializing TRAIN (source) datasets
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  label_train    |     8 |      170 |         6
  unlabel_train    |   743 |    12766 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------
!!! Using RandomIdentitySampler !!!
=> Initializing TEST (target) datasets
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  label_train    |     8 |      170 |         6
  unlabel_train    |   743 |    12766 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------


  **************** Summary ****************
  train names      : ['market1501']
  # train datasets : 1
  # train ids      : 8
  # label_train images   : 170
  # unlabel_train images   : 12766
  # train cameras  : 6
  test names       : ['market1501']
  *****************************************


Initializing model: resnet50
Initialized model with pretrained weights from https://download.pytorch.org/models/resnet50-19c8e357.pth
MultiBranchResNet(
  (common_branch): ResNetCommonBranch(
    (backbone1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (shallow_cam): ShallowCAM(
      (_cam_module): CAM_Module(
        (softmax): Softmax(dim=-1)
      )
    )
    (backbone2): Sequential(
      (0): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
  )
  (branches): ModuleList(
    (0): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): ABDBranch(
        (reduction): Sequential(
          (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (before_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): Identity()
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (cam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): CAM_Module(
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (pam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): PAM_Module(
            (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (sum_conv): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifiers): ModuleList(
          (0): Linear(in_features=1024, out_features=8, bias=True)
          (1): Linear(in_features=1024, out_features=8, bias=True)
        )
      )
    )
    (1): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): GlobalBranch(
        (fc): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Dropout(p=0, inplace=False)
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifier): Linear(in_features=1024, out_features=8, bias=True)
      )
    )
  )
)
Model size: 66.890 M
Initialized model with pretrained weights from https://download.pytorch.org/models/resnet50-19c8e357.pth
MultiBranchResNet(
  (common_branch): ResNetCommonBranch(
    (backbone1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (shallow_cam): ShallowCAM(
      (_cam_module): CAM_Module(
        (softmax): Softmax(dim=-1)
      )
    )
    (backbone2): Sequential(
      (0): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
  )
  (branches): ModuleList(
    (0): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): ABDBranch(
        (reduction): Sequential(
          (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (before_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): Identity()
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (cam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): CAM_Module(
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (pam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): PAM_Module(
            (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (sum_conv): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifiers): ModuleList(
          (0): Linear(in_features=1024, out_features=8, bias=True)
          (1): Linear(in_features=1024, out_features=8, bias=True)
        )
      )
    )
    (1): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): GlobalBranch(
        (fc): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Dropout(p=0, inplace=False)
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifier): Linear(in_features=1024, out_features=8, bias=True)
      )
    )
  )
)
ema_Model size: 66.890 M
==> Start training
Train ['classifier'] for 10 epochs while keeping other layers frozen
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
F:\新建文件夹\ABD-Net-master\torchreid\losses\hard_mine_triplet_loss.py:58: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ..\torch\csrc\utils\python_arg_parser.cpp:766.)
  dist.addmm_(1, -2, inputs, inputs.t())
label_Epoch: [1][10/19]	Time 0.328 (2.986)	Data 0.0000 (0.0000)	Loss 3.0873 (3.4945)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [2][10/19]	Time 0.344 (2.752)	Data 0.0000 (0.0000)	Loss 3.2510 (2.7997)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [3][10/19]	Time 0.359 (2.648)	Data 0.0000 (0.0000)	Loss 1.5423 (2.3636)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [4][10/19]	Time 0.344 (2.833)	Data 0.0000 (0.0000)	Loss 2.1037 (2.4180)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [5][10/19]	Time 0.375 (2.903)	Data 0.0000 (0.0000)	Loss 1.6771 (2.2030)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [6][10/19]	Time 0.343 (2.894)	Data 0.0000 (0.0000)	Loss 2.1606 (2.1076)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [7][10/19]	Time 0.328 (2.955)	Data 0.0000 (0.0000)	Loss 1.5419 (1.9541)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [8][10/19]	Time 0.391 (2.648)	Data 0.0000 (0.0000)	Loss 1.9941 (1.9774)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [9][10/19]	Time 0.375 (2.764)	Data 0.0000 (0.0000)	Loss 2.3510 (1.8670)	
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
open _cam_module
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
open fc
open classifier
label_Epoch: [10][10/19]	Time 0.359 (2.857)	Data 0.0000 (0.0000)	Loss 1.8502 (1.7784)	
Done. All layers are open to train for 80 epochs
0
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [1][10/19]	Time 0.609 (3.212)	Data 0.0000 (0.0000)	Loss 2.4355 (2.9186)	
1
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [2][10/19]	Time 0.640 (3.039)	Data 0.0000 (0.0000)	Loss 2.4344 (2.6606)	
2
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [3][10/19]	Time 0.625 (2.911)	Data 0.0000 (0.0000)	Loss 2.6512 (2.3653)	
3
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [4][10/19]	Time 0.609 (2.864)	Data 0.0000 (0.0000)	Loss 1.4406 (2.0498)	
4
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [5][10/19]	Time 0.609 (2.966)	Data 0.0000 (0.0000)	Loss 1.3275 (1.9924)	
5
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [6][10/19]	Time 0.610 (2.927)	Data 0.0000 (0.0000)	Loss 1.7136 (1.7095)	
6
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [7][10/19]	Time 0.625 (3.021)	Data 0.0000 (0.0000)	Loss 0.9548 (1.8376)	
7
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [8][10/19]	Time 0.640 (3.023)	Data 0.0000 (0.0000)	Loss 1.1867 (1.5972)	
8
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [9][10/19]	Time 0.609 (2.951)	Data 0.0000 (0.0000)	Loss 1.0998 (1.7111)	
9
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [10][10/19]	Time 0.625 (2.909)	Data 0.0000 (0.0000)	Loss 1.2205 (1.6369)	
10
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [11][10/19]	Time 0.641 (3.031)	Data 0.0000 (0.0000)	Loss 0.7883 (1.5524)	
11
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [12][10/19]	Time 0.641 (2.992)	Data 0.0000 (0.0000)	Loss 1.6572 (1.4202)	
12
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [13][10/19]	Time 0.610 (3.028)	Data 0.0000 (0.0000)	Loss 0.8359 (1.2858)	
13
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [14][10/19]	Time 0.640 (3.017)	Data 0.0000 (0.0000)	Loss 1.0231 (1.2681)	
14
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [15][10/19]	Time 0.609 (3.025)	Data 0.0000 (0.0000)	Loss 1.7888 (1.2271)	
15
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [16][10/19]	Time 0.609 (3.042)	Data 0.0000 (0.0000)	Loss 0.8072 (1.2330)	
16
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [17][10/19]	Time 0.642 (3.036)	Data 0.0000 (0.0000)	Loss 0.6564 (1.0897)	
17
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [18][10/19]	Time 0.609 (2.938)	Data 0.0000 (0.0000)	Loss 0.7476 (1.0841)	
18
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [19][10/19]	Time 0.609 (2.917)	Data 0.0000 (0.0000)	Loss 0.7448 (1.0604)	
19
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [20][10/19]	Time 0.609 (3.041)	Data 0.0000 (0.0000)	Loss 0.9266 (1.0708)	
20
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [21][10/19]	Time 0.609 (2.856)	Data 0.0000 (0.0000)	Loss 0.9434 (0.9690)	
21
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [22][10/19]	Time 0.625 (2.859)	Data 0.0000 (0.0000)	Loss 0.6168 (0.8887)	
22
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
label_Epoch: [23][10/19]	Time 0.640 (3.001)	Data 0.0000 (0.0000)	Loss 0.7453 (0.9154)	
23
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [24][10/19]	Time 0.609 (2.879)	Data 0.0000 (0.0000)	Loss 0.6594 (0.8759)	
24
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [25][10/19]	Time 0.610 (2.869)	Data 0.0000 (0.0000)	Loss 0.6814 (0.8353)	
25
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [26][10/19]	Time 0.609 (2.936)	Data 0.0000 (0.0000)	Loss 0.6267 (0.9055)	
26
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [27][10/19]	Time 0.625 (2.888)	Data 0.0000 (0.0000)	Loss 0.6393 (0.7987)	
27
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [28][10/19]	Time 0.609 (2.887)	Data 0.0000 (0.0000)	Loss 0.5606 (0.7737)	
28
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [29][10/19]	Time 0.640 (2.950)	Data 0.0000 (0.0000)	Loss 0.6220 (0.7726)	
29
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [30][10/19]	Time 0.625 (2.917)	Data 0.0000 (0.0000)	Loss 0.5668 (0.7795)	
30
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [31][10/19]	Time 0.625 (2.866)	Data 0.0000 (0.0000)	Loss 0.5789 (0.7676)	
31
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [32][10/19]	Time 0.609 (2.827)	Data 0.0000 (0.0000)	Loss 0.5779 (0.8432)	
32
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [33][10/19]	Time 0.640 (2.859)	Data 0.0000 (0.0000)	Loss 0.5648 (0.7061)	
33
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [34][10/19]	Time 0.640 (2.878)	Data 0.0000 (0.0000)	Loss 0.6219 (0.7717)	
34
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [35][10/19]	Time 0.627 (2.861)	Data 0.0000 (0.0000)	Loss 0.6171 (0.7529)	
35
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [36][10/19]	Time 0.625 (2.831)	Data 0.0000 (0.0000)	Loss 0.5749 (0.7420)	
36
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [37][10/19]	Time 0.609 (2.858)	Data 0.0000 (0.0000)	Loss 0.5914 (0.7668)	
37
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [38][10/19]	Time 0.625 (2.846)	Data 0.0000 (0.0000)	Loss 0.6074 (0.7354)	
38
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [39][10/19]	Time 0.611 (2.847)	Data 0.0000 (0.0000)	Loss 0.5927 (0.7314)	
39
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [40][10/19]	Time 0.609 (2.855)	Data 0.0000 (0.0000)	Loss 0.5856 (0.7134)	
40
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [41][10/19]	Time 0.625 (2.853)	Data 0.0000 (0.0000)	Loss 0.5723 (0.7198)	
41
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [42][10/19]	Time 0.640 (2.850)	Data 0.0000 (0.0000)	Loss 0.7239 (0.7194)	
42
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [43][10/19]	Time 0.610 (2.867)	Data 0.0000 (0.0000)	Loss 0.6001 (0.7095)	
43
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [44][10/19]	Time 0.625 (2.931)	Data 0.0000 (0.0000)	Loss 0.6176 (0.7489)	
44
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [45][10/19]	Time 0.627 (2.908)	Data 0.0000 (0.0000)	Loss 0.6370 (0.7069)	
45
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [46][10/19]	Time 0.641 (2.924)	Data 0.0000 (0.0000)	Loss 0.8336 (0.7894)	
46
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [47][10/19]	Time 0.641 (2.924)	Data 0.0000 (0.0000)	Loss 0.5565 (0.7045)	
47
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [48][10/19]	Time 0.625 (2.906)	Data 0.0000 (0.0000)	Loss 0.6564 (0.7066)	
48
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [49][10/19]	Time 0.610 (2.882)	Data 0.0000 (0.0000)	Loss 0.5960 (0.6714)	
49
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [50][10/19]	Time 0.627 (2.928)	Data 0.0000 (0.0000)	Loss 0.5539 (0.7261)	
50
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [51][10/19]	Time 0.625 (2.908)	Data 0.0000 (0.0000)	Loss 0.6555 (0.7109)	
51
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [52][10/19]	Time 0.609 (2.920)	Data 0.0000 (0.0000)	Loss 0.5701 (0.7371)	
52
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [53][10/19]	Time 0.625 (2.914)	Data 0.0000 (0.0000)	Loss 0.8148 (0.7417)	
53
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [54][10/19]	Time 0.612 (2.894)	Data 0.0000 (0.0000)	Loss 0.5554 (0.7102)	
54
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [55][10/19]	Time 0.625 (2.916)	Data 0.0000 (0.0000)	Loss 0.6566 (0.6604)	
55
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [56][10/19]	Time 0.625 (2.914)	Data 0.0000 (0.0000)	Loss 0.6014 (0.7342)	
56
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [57][10/19]	Time 0.609 (2.911)	Data 0.0000 (0.0000)	Loss 0.5711 (0.7071)	
57
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [58][10/19]	Time 0.656 (2.945)	Data 0.0000 (0.0000)	Loss 0.6524 (0.7834)	
58
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [59][10/19]	Time 0.637 (2.947)	Data 0.0000 (0.0000)	Loss 0.5554 (0.7185)	
59
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [60][10/19]	Time 0.628 (2.899)	Data 0.0000 (0.0000)	Loss 0.5767 (0.6920)	
60
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [61][10/19]	Time 0.625 (2.916)	Data 0.0000 (0.0000)	Loss 0.6460 (0.7121)	
61
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [62][10/19]	Time 0.614 (3.258)	Data 0.0000 (0.0000)	Loss 0.5895 (0.7050)	
62
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [63][10/19]	Time 0.647 (3.301)	Data 0.0000 (0.0000)	Loss 0.5722 (0.7057)	
63
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [64][10/19]	Time 0.645 (3.176)	Data 0.0000 (0.0000)	Loss 0.6141 (0.6974)	
64
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [65][10/19]	Time 0.626 (3.169)	Data 0.0000 (0.0000)	Loss 0.5486 (0.6965)	
65
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [66][10/19]	Time 0.668 (3.133)	Data 0.0000 (0.0000)	Loss 0.5606 (0.7440)	
66
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [67][10/19]	Time 0.653 (3.142)	Data 0.0000 (0.0000)	Loss 0.5693 (0.6750)	
67
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [68][10/19]	Time 0.643 (3.291)	Data 0.0000 (0.0000)	Loss 0.5862 (0.6967)	
68
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [69][10/19]	Time 0.627 (3.256)	Data 0.0000 (0.0000)	Loss 0.6618 (0.7342)	
69
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [70][10/19]	Time 0.664 (3.391)	Data 0.0000 (0.0000)	Loss 0.6598 (0.6962)	
70
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [71][10/19]	Time 0.657 (3.201)	Data 0.0000 (0.0000)	Loss 0.5622 (0.7120)	
71
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [72][10/19]	Time 0.665 (3.226)	Data 0.0000 (0.0000)	Loss 0.6067 (0.6934)	
72
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [73][10/19]	Time 0.643 (2.960)	Data 0.0000 (0.0000)	Loss 0.5719 (0.6904)	
73
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [74][10/19]	Time 0.659 (3.208)	Data 0.0000 (0.0000)	Loss 0.5483 (0.7202)	
74
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [75][10/19]	Time 0.662 (3.170)	Data 0.0000 (0.0000)	Loss 0.6608 (0.7568)	
75
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [76][10/19]	Time 0.678 (3.266)	Data 0.0000 (0.0000)	Loss 0.8269 (0.6717)	
76
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [77][10/19]	Time 0.667 (3.232)	Data 0.0000 (0.0000)	Loss 0.5827 (0.6761)	
77
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [78][10/19]	Time 0.672 (3.220)	Data 0.0000 (0.0000)	Loss 0.5981 (0.7059)	
78
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [79][10/19]	Time 0.672 (3.227)	Data 0.0000 (0.0000)	Loss 0.5536 (0.6870)	
79
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
label_Epoch: [80][10/19]	Time 0.672 (3.241)	Data 0.0000 (0.0000)	Loss 0.5680 (0.7149)	
==> Test
Evaluating market1501 ...
# Using Flip Eval
Extracted features for query set, obtained 3368-by-3072 matrix
Extracted features for gallery set, obtained 15913-by-3072 matrix
==> BatchTime(s)/BatchSize(img): 0.092/100
Computing CMC and mAP
Results ----------
mAP: 6.88%
CMC curve
Rank-1  : 17.52%
Rank-5  : 34.68%
Rank-10 : 43.79%
Rank-20 : 52.88%
------------------
Save! 0 0.17517814
Finished. Total elapsed time (h:m:s): 1:05:02. Training time (h:m:s): 0:55:58.
=> Show summary
market1501 (source)
- epoch 80	 rank1 17.5%
