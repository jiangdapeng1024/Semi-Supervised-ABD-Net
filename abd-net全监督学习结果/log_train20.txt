==========
Args:Namespace(abd_dan=['cam', 'pam'], abd_dan_no_head=False, abd_dim=1024, abd_np=2, adam_beta1=0.9, adam_beta2=0.999, arch='resnet50', branches=['global', 'abd'], compatibility=False, criterion='htri', cuhk03_classic_split=False, cuhk03_labeled=False, dan_dan=[], dan_dan_no_head=False, dan_dim=1024, data_augment=['crop', 'random-erase'], dropout=0.5, eval_freq=-1, evaluate=False, fixbase=False, fixbase_epoch=10, flip_eval=True, gamma=0.1, global_dim=1024, global_max_pooling=False, gpu_devices='0', height=384, htri_only=False, label_smooth=True, lambda_htri=0.1, lambda_xent=1, load_weights='', lr=0.0003, margin=1.2, max_epoch=80, momentum=0.9, np_dim=1024, np_max_pooling=False, np_np=2, np_with_global=False, num_instances=4, of_beta=1e-06, of_position=['before', 'after', 'cam', 'pam', 'intermediate'], of_start_epoch=23, open_layers=['classifier'], optim='adam', ow_beta=0.001, pool_tracklet_features='avg', print_freq=10, resume='', rmsprop_alpha=0.99, root='data', sample_method='evenly', save_dir='path/to/dir/jpf20', seed=1, seq_len=15, sgd_dampening=0, sgd_nesterov=False, shallow_cam=True, source_names=['market1501'], split_id=0, start_epoch=0, start_eval=0, stepsize=[20, 40], target_names=['market1501'], test_batch_size=100, train_batch_size=8, train_sampler='', use_avai_gpus=False, use_cpu=False, use_metric_cuhk03=False, use_of=True, use_ow=True, visualize_ranks=False, weight_decay=0.0005, width=128, workers=0)
==========
Currently using GPU 0
Initializing image data manager
Using augmentation: {'random-erase', 'crop'}
Using transform: Compose(
    <torchreid.transforms.Random2DTranslation object at 0x0000023931153D30>
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <torchreid.transforms.RandomErasing object at 0x0000023931153C18>
)
=> Initializing TRAIN (source) datasets
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   150 |     2967 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------
!!! Using RandomIdentitySampler !!!
=> Initializing TEST (target) datasets
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   150 |     2967 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------


  **************** Summary ****************
  train names      : ['market1501']
  # train datasets : 1
  # train ids      : 150
  # train images   : 2967
  # train cameras  : 6
  test names       : ['market1501']
  *****************************************


Initializing model: resnet50
Initialized model with pretrained weights from https://download.pytorch.org/models/resnet50-19c8e357.pth
MultiBranchResNet(
  (common_branch): ResNetCommonBranch(
    (backbone1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (shallow_cam): ShallowCAM(
      (_cam_module): CAM_Module(
        (softmax): Softmax(dim=-1)
      )
    )
    (backbone2): Sequential(
      (0): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
  )
  (branches): ModuleList(
    (0): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): GlobalBranch(
        (fc): Sequential(
          (0): Linear(in_features=2048, out_features=1024, bias=True)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Dropout(p=0.5, inplace=False)
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifier): Linear(in_features=1024, out_features=150, bias=True)
      )
    )
    (1): Sequential(
      (0): ResNetDeepBranch(
        (backbone): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU()
          )
        )
      )
      (1): ABDBranch(
        (reduction): Sequential(
          (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (before_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): Identity()
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (cam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): CAM_Module(
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (pam_module): DANetHead(
          (conv5c): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (attention_module): PAM_Module(
            (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
            (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (softmax): Softmax(dim=-1)
          )
          (conv52): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (conv7): Sequential(
            (0): Dropout2d(p=0.1, inplace=False)
            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (sum_conv): Sequential(
          (0): Dropout2d(p=0.1, inplace=False)
          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (classifiers): ModuleList(
          (0): Linear(in_features=1024, out_features=150, bias=True)
          (1): Linear(in_features=1024, out_features=150, bias=True)
        )
      )
    )
  )
)
Model size: 67.327 M
==> Start training
Train ['classifier'] for 10 epochs while keeping other layers frozen
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
D:\jpf\ABD-Net-master\torchreid\losses\hard_mine_triplet_loss.py:58: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ..\torch\csrc\utils\python_arg_parser.cpp:766.)
  dist.addmm_(1, -2, inputs, inputs.t())
Epoch: [1][10/345]	Time 0.125 (0.518)	Data 0.0160 (0.0340)	Loss 5.3401 (5.6480)	
Epoch: [1][20/345]	Time 0.127 (0.326)	Data 0.0150 (0.0271)	Loss 5.9394 (5.7263)	
Epoch: [1][30/345]	Time 0.143 (0.265)	Data 0.0160 (0.0262)	Loss 6.0843 (5.7982)	
Epoch: [1][40/345]	Time 0.128 (0.231)	Data 0.0130 (0.0234)	Loss 5.5235 (5.8619)	
Epoch: [1][50/345]	Time 0.124 (0.211)	Data 0.0150 (0.0222)	Loss 5.0147 (5.8438)	
Epoch: [1][60/345]	Time 0.133 (0.198)	Data 0.0229 (0.0216)	Loss 6.1801 (5.8833)	
Epoch: [1][70/345]	Time 0.146 (0.189)	Data 0.0170 (0.0210)	Loss 6.2527 (5.9284)	
Epoch: [1][80/345]	Time 0.142 (0.182)	Data 0.0249 (0.0209)	Loss 5.5576 (5.9122)	
Epoch: [1][90/345]	Time 0.126 (0.176)	Data 0.0140 (0.0206)	Loss 6.4610 (5.9247)	
Epoch: [1][100/345]	Time 0.129 (0.172)	Data 0.0150 (0.0203)	Loss 5.3179 (5.9250)	
Epoch: [1][110/345]	Time 0.123 (0.169)	Data 0.0140 (0.0205)	Loss 5.7307 (5.9069)	
Epoch: [1][120/345]	Time 0.134 (0.166)	Data 0.0160 (0.0204)	Loss 5.1324 (5.8654)	
Epoch: [1][130/345]	Time 0.149 (0.163)	Data 0.0289 (0.0202)	Loss 6.8133 (5.8780)	
Epoch: [1][140/345]	Time 0.126 (0.161)	Data 0.0150 (0.0200)	Loss 5.6950 (5.8662)	
Epoch: [1][150/345]	Time 0.131 (0.159)	Data 0.0130 (0.0199)	Loss 5.2522 (5.8371)	
Epoch: [1][160/345]	Time 0.125 (0.157)	Data 0.0170 (0.0200)	Loss 5.2777 (5.8144)	
Epoch: [1][170/345]	Time 0.125 (0.156)	Data 0.0150 (0.0200)	Loss 4.9684 (5.7970)	
Epoch: [1][180/345]	Time 0.132 (0.155)	Data 0.0170 (0.0198)	Loss 5.6526 (5.7683)	
Epoch: [1][190/345]	Time 0.127 (0.153)	Data 0.0140 (0.0197)	Loss 5.9903 (5.7599)	
Epoch: [1][200/345]	Time 0.122 (0.152)	Data 0.0130 (0.0196)	Loss 6.0530 (5.7528)	
Epoch: [1][210/345]	Time 0.149 (0.151)	Data 0.0130 (0.0194)	Loss 5.5752 (5.7407)	
Epoch: [1][220/345]	Time 0.147 (0.150)	Data 0.0180 (0.0192)	Loss 5.7825 (5.7119)	
Epoch: [1][230/345]	Time 0.137 (0.150)	Data 0.0190 (0.0191)	Loss 4.8518 (5.6898)	
Epoch: [1][240/345]	Time 0.134 (0.149)	Data 0.0140 (0.0190)	Loss 4.3781 (5.6686)	
Epoch: [1][250/345]	Time 0.131 (0.148)	Data 0.0130 (0.0189)	Loss 3.9316 (5.6470)	
Epoch: [1][260/345]	Time 0.130 (0.147)	Data 0.0140 (0.0188)	Loss 4.6488 (5.6303)	
Epoch: [1][270/345]	Time 0.131 (0.146)	Data 0.0180 (0.0187)	Loss 4.8696 (5.6147)	
Epoch: [1][280/345]	Time 0.118 (0.146)	Data 0.0120 (0.0185)	Loss 6.3268 (5.5866)	
Epoch: [1][290/345]	Time 0.132 (0.145)	Data 0.0140 (0.0185)	Loss 5.3965 (5.5760)	
Epoch: [1][300/345]	Time 0.127 (0.145)	Data 0.0130 (0.0184)	Loss 4.7073 (5.5571)	
Epoch: [1][310/345]	Time 0.125 (0.144)	Data 0.0140 (0.0183)	Loss 5.0986 (5.5272)	
Epoch: [1][320/345]	Time 0.130 (0.144)	Data 0.0150 (0.0182)	Loss 4.7358 (5.4850)	
Epoch: [1][330/345]	Time 0.124 (0.143)	Data 0.0130 (0.0181)	Loss 4.7931 (5.4558)	
Epoch: [1][340/345]	Time 0.128 (0.143)	Data 0.0160 (0.0180)	Loss 4.2442 (5.4173)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [2][10/345]	Time 0.129 (0.129)	Data 0.0180 (0.0156)	Loss 5.9694 (6.0283)	
Epoch: [2][20/345]	Time 0.137 (0.131)	Data 0.0130 (0.0157)	Loss 5.7187 (5.8210)	
Epoch: [2][30/345]	Time 0.127 (0.130)	Data 0.0130 (0.0154)	Loss 6.4393 (5.7223)	
Epoch: [2][40/345]	Time 0.135 (0.129)	Data 0.0150 (0.0152)	Loss 4.7922 (5.6902)	
Epoch: [2][50/345]	Time 0.127 (0.128)	Data 0.0160 (0.0149)	Loss 4.9921 (5.6215)	
Epoch: [2][60/345]	Time 0.127 (0.129)	Data 0.0140 (0.0150)	Loss 5.4265 (5.5731)	
Epoch: [2][70/345]	Time 0.118 (0.129)	Data 0.0130 (0.0149)	Loss 5.9333 (5.5287)	
Epoch: [2][80/345]	Time 0.122 (0.129)	Data 0.0130 (0.0148)	Loss 5.9866 (5.5315)	
Epoch: [2][90/345]	Time 0.129 (0.129)	Data 0.0140 (0.0148)	Loss 5.8948 (5.5004)	
Epoch: [2][100/345]	Time 0.130 (0.129)	Data 0.0130 (0.0148)	Loss 5.7375 (5.4684)	
Epoch: [2][110/345]	Time 0.139 (0.129)	Data 0.0170 (0.0150)	Loss 5.7264 (5.4468)	
Epoch: [2][120/345]	Time 0.132 (0.129)	Data 0.0150 (0.0150)	Loss 4.9250 (5.4235)	
Epoch: [2][130/345]	Time 0.144 (0.129)	Data 0.0259 (0.0151)	Loss 5.5956 (5.3873)	
Epoch: [2][140/345]	Time 0.126 (0.129)	Data 0.0130 (0.0150)	Loss 5.0041 (5.3800)	
Epoch: [2][150/345]	Time 0.137 (0.129)	Data 0.0150 (0.0151)	Loss 5.3579 (5.3517)	
Epoch: [2][160/345]	Time 0.132 (0.130)	Data 0.0140 (0.0151)	Loss 5.1942 (5.3231)	
Epoch: [2][170/345]	Time 0.136 (0.130)	Data 0.0130 (0.0151)	Loss 5.8183 (5.3152)	
Epoch: [2][180/345]	Time 0.133 (0.130)	Data 0.0160 (0.0152)	Loss 4.7150 (5.3144)	
Epoch: [2][190/345]	Time 0.138 (0.130)	Data 0.0130 (0.0152)	Loss 4.2300 (5.2959)	
Epoch: [2][200/345]	Time 0.127 (0.130)	Data 0.0130 (0.0152)	Loss 3.6048 (5.2822)	
Epoch: [2][210/345]	Time 0.132 (0.130)	Data 0.0130 (0.0151)	Loss 4.5718 (5.2656)	
Epoch: [2][220/345]	Time 0.128 (0.130)	Data 0.0140 (0.0151)	Loss 5.1348 (5.2421)	
Epoch: [2][230/345]	Time 0.133 (0.131)	Data 0.0130 (0.0152)	Loss 4.5074 (5.2207)	
Epoch: [2][240/345]	Time 0.135 (0.131)	Data 0.0160 (0.0152)	Loss 5.4856 (5.2063)	
Epoch: [2][250/345]	Time 0.126 (0.131)	Data 0.0160 (0.0152)	Loss 4.9954 (5.1949)	
Epoch: [2][260/345]	Time 0.139 (0.131)	Data 0.0170 (0.0152)	Loss 4.7634 (5.1771)	
Epoch: [2][270/345]	Time 0.136 (0.131)	Data 0.0189 (0.0153)	Loss 4.6004 (5.1575)	
Epoch: [2][280/345]	Time 0.135 (0.131)	Data 0.0150 (0.0154)	Loss 4.4141 (5.1390)	
Epoch: [2][290/345]	Time 0.144 (0.132)	Data 0.0180 (0.0154)	Loss 4.7183 (5.1129)	
Epoch: [2][300/345]	Time 0.133 (0.132)	Data 0.0140 (0.0155)	Loss 4.4668 (5.0912)	
Epoch: [2][310/345]	Time 0.151 (0.132)	Data 0.0190 (0.0155)	Loss 4.6752 (5.0617)	
Epoch: [2][320/345]	Time 0.136 (0.132)	Data 0.0130 (0.0156)	Loss 4.6637 (5.0496)	
Epoch: [2][330/345]	Time 0.132 (0.132)	Data 0.0180 (0.0156)	Loss 3.5781 (5.0247)	
Epoch: [2][340/345]	Time 0.142 (0.132)	Data 0.0190 (0.0156)	Loss 4.5841 (4.9980)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [3][10/345]	Time 0.131 (0.135)	Data 0.0170 (0.0165)	Loss 6.0523 (5.9311)	
Epoch: [3][20/345]	Time 0.133 (0.136)	Data 0.0120 (0.0164)	Loss 5.4629 (5.6559)	
Epoch: [3][30/345]	Time 0.134 (0.134)	Data 0.0150 (0.0162)	Loss 4.5323 (5.5674)	
Epoch: [3][40/345]	Time 0.146 (0.135)	Data 0.0180 (0.0163)	Loss 5.3437 (5.5120)	
Epoch: [3][50/345]	Time 0.127 (0.134)	Data 0.0160 (0.0160)	Loss 5.2634 (5.4613)	
Epoch: [3][60/345]	Time 0.122 (0.134)	Data 0.0130 (0.0160)	Loss 4.9035 (5.4280)	
Epoch: [3][70/345]	Time 0.125 (0.133)	Data 0.0130 (0.0157)	Loss 5.1706 (5.4108)	
Epoch: [3][80/345]	Time 0.134 (0.133)	Data 0.0160 (0.0159)	Loss 4.3715 (5.3507)	
Epoch: [3][90/345]	Time 0.142 (0.134)	Data 0.0170 (0.0160)	Loss 5.1459 (5.3447)	
Epoch: [3][100/345]	Time 0.128 (0.134)	Data 0.0120 (0.0160)	Loss 5.7332 (5.3104)	
Epoch: [3][110/345]	Time 0.143 (0.134)	Data 0.0180 (0.0160)	Loss 4.4160 (5.2670)	
Epoch: [3][120/345]	Time 0.132 (0.134)	Data 0.0130 (0.0160)	Loss 4.1868 (5.2292)	
Epoch: [3][130/345]	Time 0.126 (0.134)	Data 0.0120 (0.0160)	Loss 5.2419 (5.2014)	
Epoch: [3][140/345]	Time 0.128 (0.134)	Data 0.0160 (0.0159)	Loss 5.2283 (5.1901)	
Epoch: [3][150/345]	Time 0.134 (0.133)	Data 0.0170 (0.0159)	Loss 5.1765 (5.1601)	
Epoch: [3][160/345]	Time 0.127 (0.133)	Data 0.0130 (0.0159)	Loss 5.4263 (5.1489)	
Epoch: [3][170/345]	Time 0.124 (0.134)	Data 0.0130 (0.0158)	Loss 5.5469 (5.1390)	
Epoch: [3][180/345]	Time 0.133 (0.134)	Data 0.0160 (0.0158)	Loss 4.1251 (5.1046)	
Epoch: [3][190/345]	Time 0.126 (0.134)	Data 0.0160 (0.0158)	Loss 4.0872 (5.0852)	
Epoch: [3][200/345]	Time 0.123 (0.133)	Data 0.0130 (0.0158)	Loss 4.5482 (5.0656)	
Epoch: [3][210/345]	Time 0.121 (0.133)	Data 0.0120 (0.0158)	Loss 5.2279 (5.0521)	
Epoch: [3][220/345]	Time 0.138 (0.133)	Data 0.0140 (0.0158)	Loss 3.7867 (5.0178)	
Epoch: [3][230/345]	Time 0.133 (0.133)	Data 0.0130 (0.0158)	Loss 2.9224 (4.9941)	
Epoch: [3][240/345]	Time 0.138 (0.133)	Data 0.0130 (0.0158)	Loss 3.8416 (4.9668)	
Epoch: [3][250/345]	Time 0.125 (0.133)	Data 0.0170 (0.0158)	Loss 5.5083 (4.9549)	
Epoch: [3][260/345]	Time 0.139 (0.133)	Data 0.0180 (0.0157)	Loss 3.5974 (4.9311)	
Epoch: [3][270/345]	Time 0.124 (0.133)	Data 0.0150 (0.0157)	Loss 4.9517 (4.9102)	
Epoch: [3][280/345]	Time 0.133 (0.133)	Data 0.0130 (0.0156)	Loss 4.3117 (4.9040)	
Epoch: [3][290/345]	Time 0.132 (0.132)	Data 0.0180 (0.0156)	Loss 3.8380 (4.8876)	
Epoch: [3][300/345]	Time 0.123 (0.132)	Data 0.0140 (0.0156)	Loss 3.9056 (4.8589)	
Epoch: [3][310/345]	Time 0.119 (0.132)	Data 0.0130 (0.0156)	Loss 3.9673 (4.8360)	
Epoch: [3][320/345]	Time 0.130 (0.132)	Data 0.0170 (0.0156)	Loss 3.5688 (4.8128)	
Epoch: [3][330/345]	Time 0.133 (0.132)	Data 0.0180 (0.0156)	Loss 2.4473 (4.7846)	
Epoch: [3][340/345]	Time 0.135 (0.132)	Data 0.0180 (0.0155)	Loss 4.2958 (4.7589)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [4][10/345]	Time 0.128 (0.130)	Data 0.0150 (0.0160)	Loss 5.6437 (5.9842)	
Epoch: [4][20/345]	Time 0.140 (0.131)	Data 0.0199 (0.0164)	Loss 5.5164 (5.6912)	
Epoch: [4][30/345]	Time 0.138 (0.132)	Data 0.0180 (0.0163)	Loss 5.4914 (5.4908)	
Epoch: [4][40/345]	Time 0.139 (0.133)	Data 0.0170 (0.0165)	Loss 5.9143 (5.4007)	
Epoch: [4][50/345]	Time 0.139 (0.133)	Data 0.0180 (0.0162)	Loss 5.0151 (5.3469)	
Epoch: [4][60/345]	Time 0.137 (0.134)	Data 0.0140 (0.0161)	Loss 5.2793 (5.3243)	
Epoch: [4][70/345]	Time 0.130 (0.134)	Data 0.0140 (0.0159)	Loss 5.1928 (5.2902)	
Epoch: [4][80/345]	Time 0.144 (0.134)	Data 0.0180 (0.0160)	Loss 4.5949 (5.2438)	
Epoch: [4][90/345]	Time 0.149 (0.134)	Data 0.0189 (0.0159)	Loss 4.1977 (5.2237)	
Epoch: [4][100/345]	Time 0.125 (0.134)	Data 0.0150 (0.0160)	Loss 5.1351 (5.1902)	
Epoch: [4][110/345]	Time 0.128 (0.134)	Data 0.0120 (0.0158)	Loss 5.3190 (5.1835)	
Epoch: [4][120/345]	Time 0.123 (0.133)	Data 0.0140 (0.0158)	Loss 4.6849 (5.1591)	
Epoch: [4][130/345]	Time 0.129 (0.133)	Data 0.0140 (0.0157)	Loss 4.6656 (5.1310)	
Epoch: [4][140/345]	Time 0.133 (0.133)	Data 0.0140 (0.0157)	Loss 4.6040 (5.1182)	
Epoch: [4][150/345]	Time 0.129 (0.133)	Data 0.0180 (0.0156)	Loss 3.5609 (5.0823)	
Epoch: [4][160/345]	Time 0.124 (0.132)	Data 0.0170 (0.0156)	Loss 5.6296 (5.0620)	
Epoch: [4][170/345]	Time 0.143 (0.132)	Data 0.0150 (0.0155)	Loss 4.1948 (5.0485)	
Epoch: [4][180/345]	Time 0.131 (0.132)	Data 0.0130 (0.0154)	Loss 5.0015 (5.0255)	
Epoch: [4][190/345]	Time 0.122 (0.132)	Data 0.0120 (0.0154)	Loss 4.8001 (5.0148)	
Epoch: [4][200/345]	Time 0.131 (0.132)	Data 0.0180 (0.0155)	Loss 5.7657 (4.9907)	
Epoch: [4][210/345]	Time 0.132 (0.132)	Data 0.0170 (0.0155)	Loss 4.2942 (4.9770)	
Epoch: [4][220/345]	Time 0.119 (0.132)	Data 0.0130 (0.0155)	Loss 4.3325 (4.9566)	
Epoch: [4][230/345]	Time 0.130 (0.132)	Data 0.0130 (0.0154)	Loss 4.3090 (4.9264)	
Epoch: [4][240/345]	Time 0.123 (0.132)	Data 0.0130 (0.0154)	Loss 5.4886 (4.9074)	
Epoch: [4][250/345]	Time 0.134 (0.132)	Data 0.0180 (0.0155)	Loss 5.4470 (4.8996)	
Epoch: [4][260/345]	Time 0.126 (0.132)	Data 0.0120 (0.0154)	Loss 3.9331 (4.8739)	
Epoch: [4][270/345]	Time 0.133 (0.132)	Data 0.0170 (0.0155)	Loss 3.3074 (4.8525)	
Epoch: [4][280/345]	Time 0.136 (0.132)	Data 0.0170 (0.0155)	Loss 4.9952 (4.8357)	
Epoch: [4][290/345]	Time 0.140 (0.132)	Data 0.0160 (0.0155)	Loss 3.4692 (4.8079)	
Epoch: [4][300/345]	Time 0.138 (0.133)	Data 0.0180 (0.0155)	Loss 3.9834 (4.7849)	
Epoch: [4][310/345]	Time 0.142 (0.133)	Data 0.0180 (0.0156)	Loss 3.5935 (4.7587)	
Epoch: [4][320/345]	Time 0.128 (0.133)	Data 0.0130 (0.0155)	Loss 4.1366 (4.7270)	
Epoch: [4][330/345]	Time 0.124 (0.133)	Data 0.0120 (0.0155)	Loss 3.3958 (4.6923)	
Epoch: [4][340/345]	Time 0.125 (0.133)	Data 0.0130 (0.0155)	Loss 3.5093 (4.6467)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [5][10/345]	Time 0.132 (0.133)	Data 0.0170 (0.0165)	Loss 4.8446 (5.8223)	
Epoch: [5][20/345]	Time 0.136 (0.135)	Data 0.0150 (0.0162)	Loss 5.2233 (5.5439)	
Epoch: [5][30/345]	Time 0.151 (0.135)	Data 0.0279 (0.0164)	Loss 4.5792 (5.5621)	
Epoch: [5][40/345]	Time 0.141 (0.136)	Data 0.0189 (0.0164)	Loss 5.2328 (5.4779)	
Epoch: [5][50/345]	Time 0.130 (0.135)	Data 0.0140 (0.0162)	Loss 5.2557 (5.4285)	
Epoch: [5][60/345]	Time 0.141 (0.136)	Data 0.0189 (0.0163)	Loss 6.0578 (5.3938)	
Epoch: [5][70/345]	Time 0.128 (0.135)	Data 0.0140 (0.0160)	Loss 4.9081 (5.3279)	
Epoch: [5][80/345]	Time 0.148 (0.135)	Data 0.0229 (0.0163)	Loss 4.6402 (5.2727)	
Epoch: [5][90/345]	Time 0.130 (0.135)	Data 0.0180 (0.0163)	Loss 4.9783 (5.2201)	
Epoch: [5][100/345]	Time 0.131 (0.134)	Data 0.0180 (0.0161)	Loss 5.3278 (5.2045)	
Epoch: [5][110/345]	Time 0.146 (0.134)	Data 0.0209 (0.0161)	Loss 4.9108 (5.1653)	
Epoch: [5][120/345]	Time 0.134 (0.134)	Data 0.0170 (0.0161)	Loss 5.0115 (5.1252)	
Epoch: [5][130/345]	Time 0.124 (0.133)	Data 0.0140 (0.0161)	Loss 4.7125 (5.1102)	
Epoch: [5][140/345]	Time 0.132 (0.133)	Data 0.0189 (0.0161)	Loss 4.6328 (5.0719)	
Epoch: [5][150/345]	Time 0.124 (0.133)	Data 0.0140 (0.0161)	Loss 5.1098 (5.0374)	
Epoch: [5][160/345]	Time 0.127 (0.133)	Data 0.0140 (0.0161)	Loss 5.3377 (5.0267)	
Epoch: [5][170/345]	Time 0.127 (0.133)	Data 0.0160 (0.0161)	Loss 5.2833 (4.9944)	
Epoch: [5][180/345]	Time 0.130 (0.133)	Data 0.0170 (0.0160)	Loss 3.7879 (4.9636)	
Epoch: [5][190/345]	Time 0.131 (0.132)	Data 0.0130 (0.0160)	Loss 4.9967 (4.9284)	
Epoch: [5][200/345]	Time 0.137 (0.132)	Data 0.0160 (0.0160)	Loss 4.5952 (4.9034)	
Epoch: [5][210/345]	Time 0.122 (0.132)	Data 0.0140 (0.0159)	Loss 5.3470 (4.8987)	
Epoch: [5][220/345]	Time 0.133 (0.132)	Data 0.0150 (0.0159)	Loss 4.2490 (4.8700)	
Epoch: [5][230/345]	Time 0.133 (0.132)	Data 0.0249 (0.0159)	Loss 4.5163 (4.8477)	
Epoch: [5][240/345]	Time 0.118 (0.132)	Data 0.0130 (0.0159)	Loss 3.8033 (4.8195)	
Epoch: [5][250/345]	Time 0.130 (0.132)	Data 0.0160 (0.0158)	Loss 4.8690 (4.8075)	
Epoch: [5][260/345]	Time 0.129 (0.132)	Data 0.0180 (0.0158)	Loss 3.6303 (4.7867)	
Epoch: [5][270/345]	Time 0.123 (0.132)	Data 0.0130 (0.0158)	Loss 3.3671 (4.7647)	
Epoch: [5][280/345]	Time 0.132 (0.132)	Data 0.0150 (0.0158)	Loss 3.6997 (4.7348)	
Epoch: [5][290/345]	Time 0.129 (0.132)	Data 0.0120 (0.0158)	Loss 5.1171 (4.7161)	
Epoch: [5][300/345]	Time 0.127 (0.132)	Data 0.0170 (0.0158)	Loss 3.4101 (4.6848)	
Epoch: [5][310/345]	Time 0.134 (0.132)	Data 0.0170 (0.0157)	Loss 4.3062 (4.6602)	
Epoch: [5][320/345]	Time 0.132 (0.131)	Data 0.0170 (0.0157)	Loss 3.0963 (4.6299)	
Epoch: [5][330/345]	Time 0.133 (0.131)	Data 0.0130 (0.0157)	Loss 3.6243 (4.6048)	
Epoch: [5][340/345]	Time 0.126 (0.131)	Data 0.0120 (0.0156)	Loss 3.3078 (4.5726)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [6][10/345]	Time 0.122 (0.129)	Data 0.0130 (0.0163)	Loss 4.7426 (5.6493)	
Epoch: [6][20/345]	Time 0.125 (0.128)	Data 0.0130 (0.0154)	Loss 6.1186 (5.4654)	
Epoch: [6][30/345]	Time 0.130 (0.128)	Data 0.0150 (0.0152)	Loss 4.9375 (5.3116)	
Epoch: [6][40/345]	Time 0.130 (0.128)	Data 0.0189 (0.0152)	Loss 5.0999 (5.2805)	
Epoch: [6][50/345]	Time 0.125 (0.127)	Data 0.0130 (0.0150)	Loss 5.6461 (5.2882)	
Epoch: [6][60/345]	Time 0.134 (0.127)	Data 0.0150 (0.0149)	Loss 4.0292 (5.2052)	
Epoch: [6][70/345]	Time 0.131 (0.127)	Data 0.0120 (0.0148)	Loss 4.6366 (5.1399)	
Epoch: [6][80/345]	Time 0.133 (0.128)	Data 0.0170 (0.0149)	Loss 4.7694 (5.1136)	
Epoch: [6][90/345]	Time 0.120 (0.128)	Data 0.0120 (0.0149)	Loss 4.3421 (5.0595)	
Epoch: [6][100/345]	Time 0.130 (0.128)	Data 0.0120 (0.0148)	Loss 4.7108 (5.0388)	
Epoch: [6][110/345]	Time 0.130 (0.128)	Data 0.0130 (0.0149)	Loss 5.1079 (5.0410)	
Epoch: [6][120/345]	Time 0.130 (0.128)	Data 0.0189 (0.0149)	Loss 4.5894 (5.0097)	
Epoch: [6][130/345]	Time 0.125 (0.128)	Data 0.0180 (0.0150)	Loss 4.7214 (4.9550)	
Epoch: [6][140/345]	Time 0.133 (0.128)	Data 0.0180 (0.0151)	Loss 3.9152 (4.9362)	
Epoch: [6][150/345]	Time 0.128 (0.129)	Data 0.0120 (0.0151)	Loss 4.9793 (4.8999)	
Epoch: [6][160/345]	Time 0.127 (0.129)	Data 0.0189 (0.0151)	Loss 4.0598 (4.8777)	
Epoch: [6][170/345]	Time 0.128 (0.129)	Data 0.0130 (0.0152)	Loss 4.3449 (4.8523)	
Epoch: [6][180/345]	Time 0.135 (0.129)	Data 0.0170 (0.0152)	Loss 4.8811 (4.8261)	
Epoch: [6][190/345]	Time 0.129 (0.129)	Data 0.0130 (0.0151)	Loss 4.0047 (4.7922)	
Epoch: [6][200/345]	Time 0.145 (0.129)	Data 0.0170 (0.0151)	Loss 3.4944 (4.7774)	
Epoch: [6][210/345]	Time 0.140 (0.129)	Data 0.0180 (0.0151)	Loss 5.4954 (4.7595)	
Epoch: [6][220/345]	Time 0.128 (0.129)	Data 0.0209 (0.0152)	Loss 4.8095 (4.7439)	
Epoch: [6][230/345]	Time 0.130 (0.129)	Data 0.0130 (0.0152)	Loss 4.2571 (4.7254)	
Epoch: [6][240/345]	Time 0.130 (0.129)	Data 0.0120 (0.0152)	Loss 4.6971 (4.6972)	
Epoch: [6][250/345]	Time 0.128 (0.129)	Data 0.0130 (0.0151)	Loss 4.5756 (4.6935)	
Epoch: [6][260/345]	Time 0.126 (0.129)	Data 0.0160 (0.0151)	Loss 4.7099 (4.6666)	
Epoch: [6][270/345]	Time 0.136 (0.129)	Data 0.0190 (0.0151)	Loss 3.5628 (4.6488)	
Epoch: [6][280/345]	Time 0.124 (0.129)	Data 0.0130 (0.0151)	Loss 4.4027 (4.6348)	
Epoch: [6][290/345]	Time 0.131 (0.129)	Data 0.0170 (0.0151)	Loss 4.3530 (4.6199)	
Epoch: [6][300/345]	Time 0.123 (0.129)	Data 0.0140 (0.0151)	Loss 4.0420 (4.5940)	
Epoch: [6][310/345]	Time 0.132 (0.129)	Data 0.0160 (0.0152)	Loss 4.3796 (4.5695)	
Epoch: [6][320/345]	Time 0.132 (0.129)	Data 0.0180 (0.0152)	Loss 4.8337 (4.5384)	
Epoch: [6][330/345]	Time 0.139 (0.129)	Data 0.0170 (0.0152)	Loss 3.6389 (4.5086)	
Epoch: [6][340/345]	Time 0.136 (0.129)	Data 0.0180 (0.0152)	Loss 2.9229 (4.4702)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [7][10/345]	Time 0.127 (0.128)	Data 0.0150 (0.0150)	Loss 5.0408 (5.8062)	
Epoch: [7][20/345]	Time 0.129 (0.128)	Data 0.0180 (0.0153)	Loss 4.5164 (5.4790)	
Epoch: [7][30/345]	Time 0.138 (0.128)	Data 0.0170 (0.0148)	Loss 3.6782 (5.2051)	
Epoch: [7][40/345]	Time 0.129 (0.129)	Data 0.0140 (0.0149)	Loss 5.3500 (5.0902)	
Epoch: [7][50/345]	Time 0.123 (0.129)	Data 0.0140 (0.0147)	Loss 4.9077 (5.0237)	
Epoch: [7][60/345]	Time 0.133 (0.129)	Data 0.0130 (0.0148)	Loss 4.9175 (5.0290)	
Epoch: [7][70/345]	Time 0.134 (0.129)	Data 0.0130 (0.0148)	Loss 4.4816 (4.9965)	
Epoch: [7][80/345]	Time 0.124 (0.129)	Data 0.0130 (0.0148)	Loss 3.6851 (4.9612)	
Epoch: [7][90/345]	Time 0.131 (0.129)	Data 0.0150 (0.0148)	Loss 4.4219 (4.9347)	
Epoch: [7][100/345]	Time 0.149 (0.129)	Data 0.0130 (0.0148)	Loss 5.0814 (4.9304)	
Epoch: [7][110/345]	Time 0.136 (0.129)	Data 0.0130 (0.0146)	Loss 4.3213 (4.9036)	
Epoch: [7][120/345]	Time 0.126 (0.129)	Data 0.0120 (0.0147)	Loss 5.2445 (4.8963)	
Epoch: [7][130/345]	Time 0.131 (0.129)	Data 0.0130 (0.0146)	Loss 3.9857 (4.8672)	
Epoch: [7][140/345]	Time 0.131 (0.129)	Data 0.0160 (0.0146)	Loss 4.3683 (4.8522)	
Epoch: [7][150/345]	Time 0.123 (0.129)	Data 0.0120 (0.0146)	Loss 4.0482 (4.8093)	
Epoch: [7][160/345]	Time 0.129 (0.129)	Data 0.0140 (0.0146)	Loss 3.7874 (4.7909)	
Epoch: [7][170/345]	Time 0.123 (0.129)	Data 0.0130 (0.0146)	Loss 4.1771 (4.7785)	
Epoch: [7][180/345]	Time 0.125 (0.129)	Data 0.0130 (0.0146)	Loss 4.1069 (4.7473)	
Epoch: [7][190/345]	Time 0.125 (0.128)	Data 0.0140 (0.0146)	Loss 4.6821 (4.7365)	
Epoch: [7][200/345]	Time 0.124 (0.128)	Data 0.0130 (0.0147)	Loss 4.2278 (4.7305)	
Epoch: [7][210/345]	Time 0.131 (0.128)	Data 0.0130 (0.0147)	Loss 3.4444 (4.6899)	
Epoch: [7][220/345]	Time 0.138 (0.129)	Data 0.0160 (0.0148)	Loss 4.5749 (4.6703)	
Epoch: [7][230/345]	Time 0.140 (0.129)	Data 0.0199 (0.0147)	Loss 3.7264 (4.6396)	
Epoch: [7][240/345]	Time 0.129 (0.129)	Data 0.0120 (0.0147)	Loss 3.7547 (4.6306)	
Epoch: [7][250/345]	Time 0.133 (0.129)	Data 0.0120 (0.0147)	Loss 3.7628 (4.6091)	
Epoch: [7][260/345]	Time 0.131 (0.129)	Data 0.0140 (0.0147)	Loss 4.3174 (4.5870)	
Epoch: [7][270/345]	Time 0.134 (0.129)	Data 0.0170 (0.0148)	Loss 3.3667 (4.5620)	
Epoch: [7][280/345]	Time 0.130 (0.129)	Data 0.0160 (0.0148)	Loss 3.4637 (4.5481)	
Epoch: [7][290/345]	Time 0.123 (0.129)	Data 0.0170 (0.0149)	Loss 4.0648 (4.5176)	
Epoch: [7][300/345]	Time 0.118 (0.129)	Data 0.0120 (0.0149)	Loss 2.8601 (4.4874)	
Epoch: [7][310/345]	Time 0.143 (0.129)	Data 0.0180 (0.0149)	Loss 3.8000 (4.4529)	
Epoch: [7][320/345]	Time 0.131 (0.129)	Data 0.0140 (0.0149)	Loss 2.4882 (4.4222)	
Epoch: [7][330/345]	Time 0.125 (0.129)	Data 0.0120 (0.0149)	Loss 2.3794 (4.3772)	
Epoch: [7][340/345]	Time 0.123 (0.129)	Data 0.0130 (0.0149)	Loss 2.9210 (4.3385)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [8][10/345]	Time 0.127 (0.131)	Data 0.0130 (0.0166)	Loss 4.8469 (4.8977)	
Epoch: [8][20/345]	Time 0.126 (0.127)	Data 0.0150 (0.0151)	Loss 5.9720 (4.9793)	
Epoch: [8][30/345]	Time 0.133 (0.128)	Data 0.0130 (0.0150)	Loss 4.4149 (4.9919)	
Epoch: [8][40/345]	Time 0.127 (0.129)	Data 0.0150 (0.0153)	Loss 5.5478 (4.9754)	
Epoch: [8][50/345]	Time 0.130 (0.129)	Data 0.0170 (0.0151)	Loss 5.1162 (4.8803)	
Epoch: [8][60/345]	Time 0.126 (0.128)	Data 0.0130 (0.0150)	Loss 4.6032 (4.8362)	
Epoch: [8][70/345]	Time 0.125 (0.128)	Data 0.0120 (0.0149)	Loss 5.2554 (4.8545)	
Epoch: [8][80/345]	Time 0.129 (0.128)	Data 0.0130 (0.0148)	Loss 5.6804 (4.8160)	
Epoch: [8][90/345]	Time 0.123 (0.128)	Data 0.0140 (0.0148)	Loss 4.5777 (4.7958)	
Epoch: [8][100/345]	Time 0.119 (0.128)	Data 0.0150 (0.0149)	Loss 4.4947 (4.7741)	
Epoch: [8][110/345]	Time 0.125 (0.128)	Data 0.0120 (0.0148)	Loss 4.4944 (4.7904)	
Epoch: [8][120/345]	Time 0.135 (0.128)	Data 0.0180 (0.0148)	Loss 3.8277 (4.7879)	
Epoch: [8][130/345]	Time 0.129 (0.128)	Data 0.0189 (0.0149)	Loss 4.3223 (4.7662)	
Epoch: [8][140/345]	Time 0.122 (0.128)	Data 0.0130 (0.0149)	Loss 4.9446 (4.7319)	
Epoch: [8][150/345]	Time 0.119 (0.128)	Data 0.0130 (0.0149)	Loss 5.1444 (4.7009)	
Epoch: [8][160/345]	Time 0.130 (0.128)	Data 0.0130 (0.0148)	Loss 4.6804 (4.6641)	
Epoch: [8][170/345]	Time 0.120 (0.128)	Data 0.0130 (0.0149)	Loss 5.4616 (4.6430)	
Epoch: [8][180/345]	Time 0.135 (0.128)	Data 0.0130 (0.0149)	Loss 5.2690 (4.6251)	
Epoch: [8][190/345]	Time 0.123 (0.128)	Data 0.0130 (0.0148)	Loss 4.5778 (4.5999)	
Epoch: [8][200/345]	Time 0.126 (0.128)	Data 0.0120 (0.0148)	Loss 4.4068 (4.5764)	
Epoch: [8][210/345]	Time 0.133 (0.128)	Data 0.0170 (0.0148)	Loss 3.8662 (4.5591)	
Epoch: [8][220/345]	Time 0.136 (0.129)	Data 0.0120 (0.0148)	Loss 3.8860 (4.5361)	
Epoch: [8][230/345]	Time 0.130 (0.129)	Data 0.0180 (0.0149)	Loss 3.7700 (4.5172)	
Epoch: [8][240/345]	Time 0.130 (0.129)	Data 0.0160 (0.0149)	Loss 4.4622 (4.4937)	
Epoch: [8][250/345]	Time 0.125 (0.129)	Data 0.0170 (0.0149)	Loss 4.7086 (4.4628)	
Epoch: [8][260/345]	Time 0.132 (0.129)	Data 0.0140 (0.0149)	Loss 4.1375 (4.4469)	
Epoch: [8][270/345]	Time 0.143 (0.129)	Data 0.0160 (0.0149)	Loss 4.3114 (4.4259)	
Epoch: [8][280/345]	Time 0.122 (0.129)	Data 0.0130 (0.0149)	Loss 3.9413 (4.4003)	
Epoch: [8][290/345]	Time 0.136 (0.129)	Data 0.0130 (0.0149)	Loss 4.2688 (4.3855)	
Epoch: [8][300/345]	Time 0.130 (0.129)	Data 0.0180 (0.0149)	Loss 3.8655 (4.3706)	
Epoch: [8][310/345]	Time 0.123 (0.129)	Data 0.0170 (0.0149)	Loss 3.5834 (4.3591)	
Epoch: [8][320/345]	Time 0.139 (0.129)	Data 0.0140 (0.0149)	Loss 3.7753 (4.3451)	
Epoch: [8][330/345]	Time 0.125 (0.129)	Data 0.0150 (0.0150)	Loss 3.3849 (4.3221)	
Epoch: [8][340/345]	Time 0.127 (0.129)	Data 0.0180 (0.0150)	Loss 3.0025 (4.3000)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [9][10/345]	Time 0.141 (0.132)	Data 0.0180 (0.0167)	Loss 4.4878 (5.3657)	
Epoch: [9][20/345]	Time 0.131 (0.131)	Data 0.0180 (0.0166)	Loss 4.3785 (5.1744)	
Epoch: [9][30/345]	Time 0.122 (0.130)	Data 0.0130 (0.0159)	Loss 3.9846 (5.1029)	
Epoch: [9][40/345]	Time 0.126 (0.130)	Data 0.0150 (0.0153)	Loss 5.0563 (5.0218)	
Epoch: [9][50/345]	Time 0.133 (0.131)	Data 0.0140 (0.0155)	Loss 3.3366 (4.9274)	
Epoch: [9][60/345]	Time 0.134 (0.131)	Data 0.0130 (0.0155)	Loss 4.9114 (4.8298)	
Epoch: [9][70/345]	Time 0.129 (0.130)	Data 0.0140 (0.0154)	Loss 3.5756 (4.7583)	
Epoch: [9][80/345]	Time 0.138 (0.130)	Data 0.0180 (0.0154)	Loss 3.4902 (4.7471)	
Epoch: [9][90/345]	Time 0.120 (0.130)	Data 0.0120 (0.0152)	Loss 3.9102 (4.7375)	
Epoch: [9][100/345]	Time 0.131 (0.131)	Data 0.0150 (0.0154)	Loss 4.7614 (4.7029)	
Epoch: [9][110/345]	Time 0.125 (0.130)	Data 0.0140 (0.0153)	Loss 4.7976 (4.6963)	
Epoch: [9][120/345]	Time 0.130 (0.130)	Data 0.0180 (0.0154)	Loss 4.2659 (4.6389)	
Epoch: [9][130/345]	Time 0.131 (0.130)	Data 0.0180 (0.0154)	Loss 3.4946 (4.5987)	
Epoch: [9][140/345]	Time 0.121 (0.130)	Data 0.0130 (0.0153)	Loss 4.7228 (4.5754)	
Epoch: [9][150/345]	Time 0.124 (0.130)	Data 0.0150 (0.0153)	Loss 3.7357 (4.5547)	
Epoch: [9][160/345]	Time 0.133 (0.130)	Data 0.0170 (0.0152)	Loss 3.6373 (4.5534)	
Epoch: [9][170/345]	Time 0.129 (0.130)	Data 0.0180 (0.0152)	Loss 4.8403 (4.5355)	
Epoch: [9][180/345]	Time 0.127 (0.130)	Data 0.0150 (0.0152)	Loss 4.9547 (4.5438)	
Epoch: [9][190/345]	Time 0.115 (0.130)	Data 0.0120 (0.0151)	Loss 3.7493 (4.5383)	
Epoch: [9][200/345]	Time 0.128 (0.130)	Data 0.0170 (0.0152)	Loss 4.0404 (4.5249)	
Epoch: [9][210/345]	Time 0.125 (0.130)	Data 0.0170 (0.0152)	Loss 3.9249 (4.5009)	
Epoch: [9][220/345]	Time 0.130 (0.130)	Data 0.0140 (0.0152)	Loss 3.6501 (4.4813)	
Epoch: [9][230/345]	Time 0.126 (0.130)	Data 0.0160 (0.0152)	Loss 4.6971 (4.4623)	
Epoch: [9][240/345]	Time 0.125 (0.130)	Data 0.0120 (0.0152)	Loss 4.1602 (4.4414)	
Epoch: [9][250/345]	Time 0.133 (0.130)	Data 0.0180 (0.0152)	Loss 3.7298 (4.4309)	
Epoch: [9][260/345]	Time 0.141 (0.130)	Data 0.0170 (0.0152)	Loss 3.8619 (4.4124)	
Epoch: [9][270/345]	Time 0.130 (0.130)	Data 0.0150 (0.0152)	Loss 4.1243 (4.3908)	
Epoch: [9][280/345]	Time 0.140 (0.130)	Data 0.0160 (0.0152)	Loss 3.1218 (4.3728)	
Epoch: [9][290/345]	Time 0.131 (0.130)	Data 0.0130 (0.0151)	Loss 3.3145 (4.3451)	
Epoch: [9][300/345]	Time 0.131 (0.129)	Data 0.0140 (0.0151)	Loss 3.1907 (4.3207)	
Epoch: [9][310/345]	Time 0.127 (0.129)	Data 0.0180 (0.0151)	Loss 3.1171 (4.2993)	
Epoch: [9][320/345]	Time 0.138 (0.130)	Data 0.0160 (0.0151)	Loss 3.1017 (4.2693)	
Epoch: [9][330/345]	Time 0.124 (0.130)	Data 0.0150 (0.0151)	Loss 2.8812 (4.2347)	
Epoch: [9][340/345]	Time 0.129 (0.130)	Data 0.0170 (0.0151)	Loss 2.6436 (4.1871)	
open _cam_module
open fc
open classifier
open reduction
open before_module
open cam_module
open pam_module
open sum_conv
open classifiers
Epoch: [10][10/345]	Time 0.128 (0.131)	Data 0.0130 (0.0142)	Loss 4.7016 (5.3309)	
Epoch: [10][20/345]	Time 0.124 (0.128)	Data 0.0170 (0.0142)	Loss 5.0498 (5.0313)	
Epoch: [10][30/345]	Time 0.129 (0.128)	Data 0.0150 (0.0144)	Loss 5.3303 (5.0670)	
Epoch: [10][40/345]	Time 0.134 (0.129)	Data 0.0140 (0.0146)	Loss 5.5756 (4.9700)	
Epoch: [10][50/345]	Time 0.127 (0.130)	Data 0.0170 (0.0149)	Loss 4.0359 (4.8676)	
Epoch: [10][60/345]	Time 0.131 (0.129)	Data 0.0170 (0.0151)	Loss 4.1520 (4.8416)	
Epoch: [10][70/345]	Time 0.125 (0.129)	Data 0.0120 (0.0150)	Loss 4.7753 (4.8124)	
Epoch: [10][80/345]	Time 0.125 (0.129)	Data 0.0140 (0.0150)	Loss 5.1720 (4.7534)	
Epoch: [10][90/345]	Time 0.133 (0.130)	Data 0.0170 (0.0151)	Loss 4.0571 (4.7087)	
Epoch: [10][100/345]	Time 0.145 (0.130)	Data 0.0150 (0.0151)	Loss 5.0283 (4.6760)	
Epoch: [10][110/345]	Time 0.144 (0.130)	Data 0.0180 (0.0151)	Loss 4.4915 (4.6618)	
Epoch: [10][120/345]	Time 0.145 (0.130)	Data 0.0180 (0.0152)	Loss 3.6195 (4.6462)	
Epoch: [10][130/345]	Time 0.133 (0.130)	Data 0.0180 (0.0153)	Loss 4.4885 (4.6305)	
Epoch: [10][140/345]	Time 0.150 (0.131)	Data 0.0150 (0.0152)	Loss 3.7976 (4.6121)	
Epoch: [10][150/345]	Time 0.140 (0.131)	Data 0.0140 (0.0153)	Loss 3.1105 (4.6027)	
Epoch: [10][160/345]	Time 0.134 (0.131)	Data 0.0180 (0.0154)	Loss 3.4496 (4.5811)	
Epoch: [10][170/345]	Time 0.141 (0.131)	Data 0.0150 (0.0155)	Loss 4.3429 (4.5483)	
Epoch: [10][180/345]	Time 0.131 (0.131)	Data 0.0140 (0.0154)	Loss 3.5216 (4.5280)	
Epoch: [10][190/345]	Time 0.119 (0.131)	Data 0.0120 (0.0154)	Loss 4.0591 (4.5102)	
Epoch: [10][200/345]	Time 0.133 (0.131)	Data 0.0180 (0.0154)	Loss 4.6975 (4.4942)	
Epoch: [10][210/345]	Time 0.131 (0.131)	Data 0.0120 (0.0154)	Loss 5.0434 (4.4670)	
Epoch: [10][220/345]	Time 0.143 (0.131)	Data 0.0170 (0.0154)	Loss 3.9043 (4.4593)	
Epoch: [10][230/345]	Time 0.130 (0.131)	Data 0.0180 (0.0154)	Loss 3.9440 (4.4408)	
Epoch: [10][240/345]	Time 0.127 (0.131)	Data 0.0180 (0.0154)	Loss 3.6228 (4.4132)	
Epoch: [10][250/345]	Time 0.131 (0.131)	Data 0.0150 (0.0154)	Loss 4.0169 (4.3863)	
Epoch: [10][260/345]	Time 0.125 (0.131)	Data 0.0130 (0.0154)	Loss 3.5291 (4.3618)	
Epoch: [10][270/345]	Time 0.137 (0.131)	Data 0.0180 (0.0154)	Loss 3.5700 (4.3227)	
Epoch: [10][280/345]	Time 0.125 (0.131)	Data 0.0160 (0.0153)	Loss 3.1638 (4.3012)	
Epoch: [10][290/345]	Time 0.136 (0.131)	Data 0.0180 (0.0154)	Loss 3.7901 (4.2703)	
Epoch: [10][300/345]	Time 0.130 (0.131)	Data 0.0180 (0.0154)	Loss 4.5644 (4.2426)	
Epoch: [10][310/345]	Time 0.131 (0.131)	Data 0.0150 (0.0154)	Loss 2.0659 (4.2042)	
Epoch: [10][320/345]	Time 0.127 (0.131)	Data 0.0180 (0.0154)	Loss 2.2316 (4.1781)	
Epoch: [10][330/345]	Time 0.134 (0.131)	Data 0.0180 (0.0154)	Loss 2.7675 (4.1536)	
Epoch: [10][340/345]	Time 0.136 (0.131)	Data 0.0170 (0.0155)	Loss 2.2159 (4.1155)	
Done. All layers are open to train for 80 epochs
0
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [1][10/345]	Time 0.165 (0.227)	Data 0.0160 (0.0170)	Loss 5.8966 (6.5079)	
Epoch: [1][20/345]	Time 0.167 (0.196)	Data 0.0150 (0.0172)	Loss 5.6363 (6.4451)	
Epoch: [1][30/345]	Time 0.175 (0.186)	Data 0.0170 (0.0174)	Loss 6.0894 (6.3751)	
Epoch: [1][40/345]	Time 0.165 (0.180)	Data 0.0140 (0.0174)	Loss 6.7280 (6.3513)	
Epoch: [1][50/345]	Time 0.185 (0.178)	Data 0.0170 (0.0174)	Loss 6.7595 (6.3515)	
Epoch: [1][60/345]	Time 0.158 (0.176)	Data 0.0160 (0.0174)	Loss 5.4177 (6.2804)	
Epoch: [1][70/345]	Time 0.162 (0.175)	Data 0.0150 (0.0176)	Loss 6.5990 (6.2731)	
Epoch: [1][80/345]	Time 0.155 (0.174)	Data 0.0140 (0.0175)	Loss 5.9720 (6.2630)	
Epoch: [1][90/345]	Time 0.169 (0.173)	Data 0.0219 (0.0175)	Loss 5.8380 (6.2367)	
Epoch: [1][100/345]	Time 0.184 (0.173)	Data 0.0180 (0.0176)	Loss 5.8141 (6.1641)	
Epoch: [1][110/345]	Time 0.161 (0.173)	Data 0.0140 (0.0177)	Loss 6.9945 (6.1253)	
Epoch: [1][120/345]	Time 0.163 (0.172)	Data 0.0150 (0.0175)	Loss 5.7539 (6.1350)	
Epoch: [1][130/345]	Time 0.180 (0.172)	Data 0.0199 (0.0176)	Loss 5.3314 (6.1066)	
Epoch: [1][140/345]	Time 0.173 (0.171)	Data 0.0140 (0.0175)	Loss 6.7249 (6.0743)	
Epoch: [1][150/345]	Time 0.187 (0.171)	Data 0.0249 (0.0176)	Loss 5.9515 (6.0436)	
Epoch: [1][160/345]	Time 0.162 (0.170)	Data 0.0209 (0.0175)	Loss 6.0246 (6.0167)	
Epoch: [1][170/345]	Time 0.154 (0.170)	Data 0.0140 (0.0175)	Loss 6.7357 (5.9918)	
Epoch: [1][180/345]	Time 0.159 (0.170)	Data 0.0150 (0.0175)	Loss 5.2028 (5.9690)	
Epoch: [1][190/345]	Time 0.173 (0.170)	Data 0.0160 (0.0175)	Loss 5.3688 (5.9460)	
Epoch: [1][200/345]	Time 0.173 (0.170)	Data 0.0189 (0.0174)	Loss 4.9545 (5.9030)	
Epoch: [1][210/345]	Time 0.165 (0.170)	Data 0.0180 (0.0174)	Loss 4.4798 (5.8803)	
Epoch: [1][220/345]	Time 0.183 (0.169)	Data 0.0219 (0.0174)	Loss 5.1683 (5.8369)	
Epoch: [1][230/345]	Time 0.166 (0.169)	Data 0.0160 (0.0173)	Loss 5.5049 (5.8189)	
Epoch: [1][240/345]	Time 0.166 (0.169)	Data 0.0199 (0.0173)	Loss 6.1299 (5.7923)	
Epoch: [1][250/345]	Time 0.163 (0.169)	Data 0.0150 (0.0173)	Loss 5.4835 (5.7671)	
Epoch: [1][260/345]	Time 0.169 (0.169)	Data 0.0160 (0.0172)	Loss 4.7634 (5.7340)	
Epoch: [1][270/345]	Time 0.158 (0.169)	Data 0.0140 (0.0172)	Loss 5.1998 (5.6995)	
Epoch: [1][280/345]	Time 0.164 (0.169)	Data 0.0219 (0.0174)	Loss 4.8153 (5.6622)	
Epoch: [1][290/345]	Time 0.160 (0.168)	Data 0.0209 (0.0174)	Loss 5.3746 (5.6338)	
Epoch: [1][300/345]	Time 0.172 (0.168)	Data 0.0160 (0.0173)	Loss 4.8594 (5.5874)	
Epoch: [1][310/345]	Time 0.170 (0.168)	Data 0.0209 (0.0173)	Loss 3.6637 (5.5383)	
Epoch: [1][320/345]	Time 0.173 (0.168)	Data 0.0170 (0.0173)	Loss 4.3271 (5.4946)	
Epoch: [1][330/345]	Time 0.184 (0.168)	Data 0.0160 (0.0173)	Loss 3.6622 (5.4416)	
Epoch: [1][340/345]	Time 0.173 (0.168)	Data 0.0180 (0.0174)	Loss 3.1387 (5.3734)	
1
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [2][10/345]	Time 0.154 (0.161)	Data 0.0150 (0.0171)	Loss 6.2601 (6.4122)	
Epoch: [2][20/345]	Time 0.170 (0.163)	Data 0.0140 (0.0170)	Loss 6.0481 (6.0158)	
Epoch: [2][30/345]	Time 0.165 (0.165)	Data 0.0150 (0.0176)	Loss 5.7155 (5.8810)	
Epoch: [2][40/345]	Time 0.165 (0.165)	Data 0.0130 (0.0173)	Loss 4.8600 (5.7827)	
Epoch: [2][50/345]	Time 0.172 (0.165)	Data 0.0189 (0.0173)	Loss 4.7983 (5.7357)	
Epoch: [2][60/345]	Time 0.167 (0.167)	Data 0.0140 (0.0173)	Loss 5.1208 (5.6968)	
Epoch: [2][70/345]	Time 0.153 (0.166)	Data 0.0160 (0.0174)	Loss 6.0005 (5.6796)	
Epoch: [2][80/345]	Time 0.169 (0.167)	Data 0.0170 (0.0175)	Loss 5.4943 (5.6317)	
Epoch: [2][90/345]	Time 0.187 (0.167)	Data 0.0299 (0.0175)	Loss 5.3662 (5.6067)	
Epoch: [2][100/345]	Time 0.169 (0.167)	Data 0.0170 (0.0176)	Loss 5.2255 (5.5834)	
Epoch: [2][110/345]	Time 0.177 (0.167)	Data 0.0219 (0.0175)	Loss 4.7989 (5.5414)	
Epoch: [2][120/345]	Time 0.170 (0.167)	Data 0.0150 (0.0175)	Loss 4.9180 (5.5056)	
Epoch: [2][130/345]	Time 0.167 (0.167)	Data 0.0180 (0.0175)	Loss 4.3803 (5.4714)	
Epoch: [2][140/345]	Time 0.185 (0.167)	Data 0.0180 (0.0175)	Loss 5.3403 (5.4578)	
Epoch: [2][150/345]	Time 0.173 (0.167)	Data 0.0150 (0.0175)	Loss 5.0113 (5.4343)	
Epoch: [2][160/345]	Time 0.171 (0.167)	Data 0.0130 (0.0175)	Loss 5.2118 (5.4055)	
Epoch: [2][170/345]	Time 0.176 (0.167)	Data 0.0239 (0.0176)	Loss 4.9254 (5.3823)	
Epoch: [2][180/345]	Time 0.171 (0.167)	Data 0.0259 (0.0176)	Loss 6.0468 (5.3769)	
Epoch: [2][190/345]	Time 0.152 (0.166)	Data 0.0190 (0.0175)	Loss 4.5167 (5.3343)	
Epoch: [2][200/345]	Time 0.174 (0.167)	Data 0.0160 (0.0176)	Loss 4.0528 (5.2981)	
Epoch: [2][210/345]	Time 0.156 (0.166)	Data 0.0150 (0.0176)	Loss 4.8256 (5.2652)	
Epoch: [2][220/345]	Time 0.160 (0.167)	Data 0.0130 (0.0175)	Loss 4.0672 (5.2211)	
Epoch: [2][230/345]	Time 0.172 (0.167)	Data 0.0150 (0.0176)	Loss 3.8141 (5.1758)	
Epoch: [2][240/345]	Time 0.157 (0.167)	Data 0.0170 (0.0175)	Loss 4.8947 (5.1506)	
Epoch: [2][250/345]	Time 0.163 (0.167)	Data 0.0150 (0.0175)	Loss 4.5504 (5.1081)	
Epoch: [2][260/345]	Time 0.176 (0.167)	Data 0.0160 (0.0175)	Loss 4.5763 (5.0791)	
Epoch: [2][270/345]	Time 0.178 (0.167)	Data 0.0209 (0.0174)	Loss 3.5240 (5.0552)	
Epoch: [2][280/345]	Time 0.160 (0.167)	Data 0.0150 (0.0174)	Loss 3.0438 (5.0250)	
Epoch: [2][290/345]	Time 0.157 (0.167)	Data 0.0170 (0.0174)	Loss 3.9110 (4.9935)	
Epoch: [2][300/345]	Time 0.174 (0.167)	Data 0.0209 (0.0174)	Loss 3.6319 (4.9667)	
Epoch: [2][310/345]	Time 0.182 (0.167)	Data 0.0229 (0.0174)	Loss 4.7177 (4.9412)	
Epoch: [2][320/345]	Time 0.162 (0.167)	Data 0.0150 (0.0174)	Loss 3.0569 (4.9038)	
Epoch: [2][330/345]	Time 0.162 (0.167)	Data 0.0150 (0.0174)	Loss 4.1144 (4.8773)	
Epoch: [2][340/345]	Time 0.166 (0.167)	Data 0.0140 (0.0174)	Loss 5.0432 (4.8349)	
2
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [3][10/345]	Time 0.168 (0.167)	Data 0.0150 (0.0174)	Loss 4.8410 (5.6478)	
Epoch: [3][20/345]	Time 0.160 (0.166)	Data 0.0150 (0.0167)	Loss 5.3899 (5.5985)	
Epoch: [3][30/345]	Time 0.170 (0.166)	Data 0.0130 (0.0169)	Loss 6.0949 (5.4716)	
Epoch: [3][40/345]	Time 0.153 (0.165)	Data 0.0190 (0.0169)	Loss 4.7667 (5.4226)	
Epoch: [3][50/345]	Time 0.158 (0.164)	Data 0.0219 (0.0169)	Loss 4.8613 (5.3907)	
Epoch: [3][60/345]	Time 0.150 (0.165)	Data 0.0170 (0.0172)	Loss 4.9313 (5.3425)	
Epoch: [3][70/345]	Time 0.145 (0.163)	Data 0.0150 (0.0169)	Loss 5.3626 (5.2741)	
Epoch: [3][80/345]	Time 0.156 (0.163)	Data 0.0150 (0.0168)	Loss 5.2413 (5.2254)	
Epoch: [3][90/345]	Time 0.166 (0.162)	Data 0.0180 (0.0168)	Loss 5.4876 (5.2049)	
Epoch: [3][100/345]	Time 0.164 (0.163)	Data 0.0140 (0.0171)	Loss 5.2575 (5.1887)	
Epoch: [3][110/345]	Time 0.161 (0.163)	Data 0.0140 (0.0170)	Loss 5.1880 (5.1327)	
Epoch: [3][120/345]	Time 0.170 (0.163)	Data 0.0209 (0.0171)	Loss 5.6102 (5.1094)	
Epoch: [3][130/345]	Time 0.158 (0.163)	Data 0.0150 (0.0170)	Loss 4.3860 (5.0819)	
Epoch: [3][140/345]	Time 0.171 (0.163)	Data 0.0239 (0.0173)	Loss 5.0159 (5.0731)	
Epoch: [3][150/345]	Time 0.148 (0.163)	Data 0.0130 (0.0173)	Loss 5.1171 (5.0611)	
Epoch: [3][160/345]	Time 0.164 (0.163)	Data 0.0140 (0.0172)	Loss 4.4551 (5.0197)	
Epoch: [3][170/345]	Time 0.162 (0.162)	Data 0.0130 (0.0171)	Loss 5.5164 (5.0144)	
Epoch: [3][180/345]	Time 0.169 (0.163)	Data 0.0190 (0.0171)	Loss 5.4791 (4.9761)	
Epoch: [3][190/345]	Time 0.169 (0.163)	Data 0.0209 (0.0171)	Loss 3.8813 (4.9523)	
Epoch: [3][200/345]	Time 0.169 (0.163)	Data 0.0150 (0.0172)	Loss 3.7243 (4.9423)	
Epoch: [3][210/345]	Time 0.170 (0.162)	Data 0.0160 (0.0172)	Loss 4.5363 (4.9275)	
Epoch: [3][220/345]	Time 0.165 (0.162)	Data 0.0130 (0.0172)	Loss 4.7550 (4.9057)	
Epoch: [3][230/345]	Time 0.157 (0.162)	Data 0.0140 (0.0173)	Loss 4.0449 (4.8755)	
Epoch: [3][240/345]	Time 0.173 (0.162)	Data 0.0180 (0.0172)	Loss 5.0212 (4.8478)	
Epoch: [3][250/345]	Time 0.157 (0.162)	Data 0.0140 (0.0172)	Loss 2.9530 (4.8115)	
Epoch: [3][260/345]	Time 0.163 (0.162)	Data 0.0219 (0.0172)	Loss 2.7486 (4.7749)	
Epoch: [3][270/345]	Time 0.165 (0.162)	Data 0.0199 (0.0172)	Loss 3.8393 (4.7403)	
Epoch: [3][280/345]	Time 0.161 (0.162)	Data 0.0190 (0.0172)	Loss 3.9575 (4.7086)	
Epoch: [3][290/345]	Time 0.166 (0.162)	Data 0.0150 (0.0172)	Loss 2.7265 (4.6673)	
Epoch: [3][300/345]	Time 0.160 (0.162)	Data 0.0180 (0.0172)	Loss 2.6486 (4.6310)	
Epoch: [3][310/345]	Time 0.158 (0.163)	Data 0.0140 (0.0172)	Loss 3.3794 (4.5951)	
Epoch: [3][320/345]	Time 0.157 (0.162)	Data 0.0150 (0.0171)	Loss 4.0555 (4.5540)	
Epoch: [3][330/345]	Time 0.192 (0.162)	Data 0.0269 (0.0171)	Loss 4.0722 (4.5152)	
Epoch: [3][340/345]	Time 0.155 (0.162)	Data 0.0199 (0.0171)	Loss 2.9417 (4.4697)	
3
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [4][10/345]	Time 0.163 (0.160)	Data 0.0189 (0.0180)	Loss 5.3361 (5.2591)	
Epoch: [4][20/345]	Time 0.160 (0.160)	Data 0.0150 (0.0178)	Loss 5.3548 (5.1151)	
Epoch: [4][30/345]	Time 0.164 (0.162)	Data 0.0150 (0.0174)	Loss 4.3195 (5.1178)	
Epoch: [4][40/345]	Time 0.162 (0.162)	Data 0.0189 (0.0176)	Loss 3.6588 (5.0039)	
Epoch: [4][50/345]	Time 0.153 (0.162)	Data 0.0200 (0.0176)	Loss 4.9878 (4.9515)	
Epoch: [4][60/345]	Time 0.156 (0.162)	Data 0.0190 (0.0175)	Loss 4.6430 (4.9725)	
Epoch: [4][70/345]	Time 0.181 (0.162)	Data 0.0209 (0.0175)	Loss 4.3366 (4.9362)	
Epoch: [4][80/345]	Time 0.156 (0.163)	Data 0.0150 (0.0173)	Loss 5.0177 (4.9162)	
Epoch: [4][90/345]	Time 0.167 (0.162)	Data 0.0150 (0.0172)	Loss 4.7558 (4.8556)	
Epoch: [4][100/345]	Time 0.156 (0.162)	Data 0.0140 (0.0171)	Loss 5.7159 (4.8164)	
Epoch: [4][110/345]	Time 0.170 (0.162)	Data 0.0130 (0.0169)	Loss 4.4000 (4.7803)	
Epoch: [4][120/345]	Time 0.168 (0.162)	Data 0.0289 (0.0169)	Loss 4.4762 (4.7530)	
Epoch: [4][130/345]	Time 0.168 (0.162)	Data 0.0269 (0.0172)	Loss 5.7886 (4.7498)	
Epoch: [4][140/345]	Time 0.158 (0.163)	Data 0.0130 (0.0171)	Loss 4.7809 (4.7387)	
Epoch: [4][150/345]	Time 0.170 (0.162)	Data 0.0259 (0.0171)	Loss 5.0124 (4.7188)	
Epoch: [4][160/345]	Time 0.165 (0.162)	Data 0.0219 (0.0171)	Loss 4.0485 (4.6973)	
Epoch: [4][170/345]	Time 0.161 (0.163)	Data 0.0180 (0.0172)	Loss 4.7855 (4.6846)	
Epoch: [4][180/345]	Time 0.170 (0.163)	Data 0.0269 (0.0173)	Loss 4.8300 (4.6634)	
Epoch: [4][190/345]	Time 0.166 (0.162)	Data 0.0140 (0.0173)	Loss 4.7193 (4.6656)	
Epoch: [4][200/345]	Time 0.182 (0.163)	Data 0.0249 (0.0174)	Loss 4.6088 (4.6460)	
Epoch: [4][210/345]	Time 0.174 (0.163)	Data 0.0180 (0.0173)	Loss 4.6460 (4.6293)	
Epoch: [4][220/345]	Time 0.165 (0.163)	Data 0.0170 (0.0173)	Loss 3.3393 (4.6054)	
Epoch: [4][230/345]	Time 0.155 (0.163)	Data 0.0140 (0.0173)	Loss 4.3457 (4.5761)	
Epoch: [4][240/345]	Time 0.156 (0.163)	Data 0.0130 (0.0174)	Loss 4.3713 (4.5681)	
Epoch: [4][250/345]	Time 0.172 (0.163)	Data 0.0229 (0.0174)	Loss 4.2099 (4.5446)	
Epoch: [4][260/345]	Time 0.171 (0.164)	Data 0.0279 (0.0175)	Loss 4.1247 (4.5170)	
Epoch: [4][270/345]	Time 0.172 (0.164)	Data 0.0150 (0.0175)	Loss 3.6506 (4.4933)	
Epoch: [4][280/345]	Time 0.161 (0.164)	Data 0.0150 (0.0175)	Loss 4.4486 (4.4638)	
Epoch: [4][290/345]	Time 0.160 (0.164)	Data 0.0180 (0.0175)	Loss 3.7783 (4.4328)	
Epoch: [4][300/345]	Time 0.167 (0.164)	Data 0.0150 (0.0174)	Loss 3.1698 (4.3973)	
Epoch: [4][310/345]	Time 0.163 (0.164)	Data 0.0170 (0.0177)	Loss 4.0135 (4.3574)	
Epoch: [4][320/345]	Time 0.162 (0.164)	Data 0.0199 (0.0177)	Loss 3.6975 (4.3231)	
Epoch: [4][330/345]	Time 0.158 (0.164)	Data 0.0180 (0.0177)	Loss 3.3888 (4.2916)	
Epoch: [4][340/345]	Time 0.156 (0.164)	Data 0.0130 (0.0177)	Loss 2.0780 (4.2521)	
4
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [5][10/345]	Time 0.154 (0.157)	Data 0.0190 (0.0175)	Loss 4.0077 (5.3919)	
Epoch: [5][20/345]	Time 0.162 (0.162)	Data 0.0140 (0.0168)	Loss 5.6575 (5.1674)	
Epoch: [5][30/345]	Time 0.172 (0.162)	Data 0.0189 (0.0165)	Loss 5.3999 (5.1065)	
Epoch: [5][40/345]	Time 0.160 (0.164)	Data 0.0150 (0.0174)	Loss 3.4325 (4.9975)	
Epoch: [5][50/345]	Time 0.169 (0.165)	Data 0.0180 (0.0177)	Loss 4.4974 (4.9451)	
Epoch: [5][60/345]	Time 0.152 (0.164)	Data 0.0180 (0.0174)	Loss 3.6016 (4.8833)	
Epoch: [5][70/345]	Time 0.158 (0.164)	Data 0.0140 (0.0175)	Loss 3.7304 (4.8169)	
Epoch: [5][80/345]	Time 0.159 (0.164)	Data 0.0160 (0.0175)	Loss 4.7234 (4.7450)	
Epoch: [5][90/345]	Time 0.156 (0.165)	Data 0.0140 (0.0172)	Loss 4.2961 (4.7103)	
Epoch: [5][100/345]	Time 0.169 (0.165)	Data 0.0219 (0.0172)	Loss 4.7240 (4.7101)	
Epoch: [5][110/345]	Time 0.165 (0.165)	Data 0.0219 (0.0174)	Loss 4.3515 (4.6964)	
Epoch: [5][120/345]	Time 0.176 (0.165)	Data 0.0289 (0.0176)	Loss 4.2037 (4.6866)	
Epoch: [5][130/345]	Time 0.161 (0.165)	Data 0.0190 (0.0175)	Loss 4.2658 (4.6644)	
Epoch: [5][140/345]	Time 0.189 (0.164)	Data 0.0309 (0.0175)	Loss 4.0917 (4.6492)	
Epoch: [5][150/345]	Time 0.157 (0.165)	Data 0.0189 (0.0178)	Loss 5.5198 (4.6244)	
Epoch: [5][160/345]	Time 0.191 (0.165)	Data 0.0229 (0.0177)	Loss 3.9300 (4.5821)	
Epoch: [5][170/345]	Time 0.171 (0.165)	Data 0.0140 (0.0177)	Loss 3.9808 (4.5430)	
Epoch: [5][180/345]	Time 0.167 (0.165)	Data 0.0160 (0.0177)	Loss 5.2693 (4.5325)	
Epoch: [5][190/345]	Time 0.152 (0.165)	Data 0.0140 (0.0177)	Loss 3.8627 (4.5063)	
Epoch: [5][200/345]	Time 0.155 (0.165)	Data 0.0170 (0.0176)	Loss 4.0032 (4.4862)	
Epoch: [5][210/345]	Time 0.159 (0.165)	Data 0.0150 (0.0176)	Loss 4.9573 (4.4714)	
Epoch: [5][220/345]	Time 0.170 (0.164)	Data 0.0199 (0.0176)	Loss 4.3533 (4.4461)	
Epoch: [5][230/345]	Time 0.172 (0.165)	Data 0.0140 (0.0176)	Loss 3.6427 (4.4247)	
Epoch: [5][240/345]	Time 0.157 (0.165)	Data 0.0189 (0.0177)	Loss 4.0017 (4.3967)	
Epoch: [5][250/345]	Time 0.157 (0.165)	Data 0.0229 (0.0177)	Loss 3.6441 (4.3725)	
Epoch: [5][260/345]	Time 0.184 (0.165)	Data 0.0369 (0.0177)	Loss 4.3184 (4.3470)	
Epoch: [5][270/345]	Time 0.166 (0.165)	Data 0.0150 (0.0177)	Loss 3.0267 (4.3125)	
Epoch: [5][280/345]	Time 0.150 (0.164)	Data 0.0150 (0.0177)	Loss 3.7710 (4.2866)	
Epoch: [5][290/345]	Time 0.159 (0.165)	Data 0.0160 (0.0177)	Loss 2.9903 (4.2610)	
Epoch: [5][300/345]	Time 0.170 (0.165)	Data 0.0289 (0.0177)	Loss 3.4798 (4.2318)	
Epoch: [5][310/345]	Time 0.157 (0.165)	Data 0.0180 (0.0177)	Loss 3.0766 (4.2079)	
Epoch: [5][320/345]	Time 0.168 (0.164)	Data 0.0199 (0.0176)	Loss 2.0817 (4.1713)	
Epoch: [5][330/345]	Time 0.160 (0.164)	Data 0.0189 (0.0176)	Loss 3.0324 (4.1420)	
Epoch: [5][340/345]	Time 0.164 (0.164)	Data 0.0170 (0.0175)	Loss 2.7928 (4.0999)	
5
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [6][10/345]	Time 0.166 (0.162)	Data 0.0160 (0.0182)	Loss 4.9529 (5.2220)	
Epoch: [6][20/345]	Time 0.155 (0.162)	Data 0.0140 (0.0170)	Loss 4.4207 (5.0301)	
Epoch: [6][30/345]	Time 0.174 (0.164)	Data 0.0170 (0.0170)	Loss 4.6300 (4.9108)	
Epoch: [6][40/345]	Time 0.175 (0.164)	Data 0.0249 (0.0173)	Loss 5.0577 (4.8316)	
Epoch: [6][50/345]	Time 0.168 (0.165)	Data 0.0150 (0.0172)	Loss 5.3188 (4.8324)	
Epoch: [6][60/345]	Time 0.172 (0.167)	Data 0.0170 (0.0183)	Loss 4.4354 (4.7753)	
Epoch: [6][70/345]	Time 0.172 (0.166)	Data 0.0249 (0.0183)	Loss 4.4563 (4.7446)	
Epoch: [6][80/345]	Time 0.167 (0.166)	Data 0.0209 (0.0182)	Loss 5.2600 (4.7074)	
Epoch: [6][90/345]	Time 0.158 (0.166)	Data 0.0170 (0.0182)	Loss 3.7681 (4.6884)	
Epoch: [6][100/345]	Time 0.171 (0.166)	Data 0.0170 (0.0183)	Loss 5.5299 (4.6791)	
Epoch: [6][110/345]	Time 0.159 (0.166)	Data 0.0160 (0.0183)	Loss 3.7828 (4.6507)	
Epoch: [6][120/345]	Time 0.164 (0.165)	Data 0.0140 (0.0180)	Loss 3.6522 (4.5911)	
Epoch: [6][130/345]	Time 0.163 (0.165)	Data 0.0150 (0.0179)	Loss 4.8030 (4.5663)	
Epoch: [6][140/345]	Time 0.169 (0.165)	Data 0.0150 (0.0181)	Loss 3.2051 (4.5533)	
Epoch: [6][150/345]	Time 0.175 (0.165)	Data 0.0229 (0.0180)	Loss 3.8246 (4.5465)	
Epoch: [6][160/345]	Time 0.169 (0.165)	Data 0.0259 (0.0180)	Loss 4.5294 (4.5078)	
Epoch: [6][170/345]	Time 0.164 (0.165)	Data 0.0180 (0.0180)	Loss 2.8654 (4.4687)	
Epoch: [6][180/345]	Time 0.173 (0.165)	Data 0.0160 (0.0181)	Loss 3.4485 (4.4261)	
Epoch: [6][190/345]	Time 0.170 (0.165)	Data 0.0189 (0.0180)	Loss 6.1017 (4.4027)	
Epoch: [6][200/345]	Time 0.176 (0.165)	Data 0.0170 (0.0179)	Loss 3.2081 (4.3603)	
Epoch: [6][210/345]	Time 0.152 (0.165)	Data 0.0120 (0.0179)	Loss 3.2018 (4.3287)	
Epoch: [6][220/345]	Time 0.168 (0.164)	Data 0.0150 (0.0178)	Loss 2.3596 (4.3010)	
Epoch: [6][230/345]	Time 0.156 (0.164)	Data 0.0140 (0.0178)	Loss 4.4032 (4.2711)	
Epoch: [6][240/345]	Time 0.173 (0.164)	Data 0.0160 (0.0178)	Loss 4.3632 (4.2366)	
Epoch: [6][250/345]	Time 0.179 (0.165)	Data 0.0239 (0.0179)	Loss 4.2264 (4.2013)	
Epoch: [6][260/345]	Time 0.156 (0.164)	Data 0.0170 (0.0179)	Loss 3.3334 (4.1702)	
Epoch: [6][270/345]	Time 0.154 (0.165)	Data 0.0140 (0.0180)	Loss 3.5002 (4.1479)	
Epoch: [6][280/345]	Time 0.174 (0.164)	Data 0.0140 (0.0179)	Loss 3.4853 (4.1263)	
Epoch: [6][290/345]	Time 0.162 (0.164)	Data 0.0150 (0.0179)	Loss 3.2204 (4.0957)	
Epoch: [6][300/345]	Time 0.172 (0.165)	Data 0.0209 (0.0180)	Loss 2.7415 (4.0626)	
Epoch: [6][310/345]	Time 0.181 (0.165)	Data 0.0319 (0.0181)	Loss 3.8757 (4.0260)	
Epoch: [6][320/345]	Time 0.155 (0.164)	Data 0.0160 (0.0181)	Loss 3.6466 (3.9919)	
Epoch: [6][330/345]	Time 0.153 (0.164)	Data 0.0140 (0.0181)	Loss 2.2811 (3.9487)	
Epoch: [6][340/345]	Time 0.161 (0.164)	Data 0.0199 (0.0180)	Loss 2.1885 (3.8941)	
6
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [7][10/345]	Time 0.155 (0.163)	Data 0.0180 (0.0182)	Loss 3.9626 (4.9052)	
Epoch: [7][20/345]	Time 0.186 (0.165)	Data 0.0219 (0.0184)	Loss 4.1759 (4.6878)	
Epoch: [7][30/345]	Time 0.164 (0.166)	Data 0.0199 (0.0185)	Loss 3.9141 (4.6033)	
Epoch: [7][40/345]	Time 0.169 (0.166)	Data 0.0180 (0.0184)	Loss 3.4535 (4.5702)	
Epoch: [7][50/345]	Time 0.173 (0.166)	Data 0.0150 (0.0180)	Loss 4.8472 (4.5306)	
Epoch: [7][60/345]	Time 0.154 (0.165)	Data 0.0150 (0.0178)	Loss 4.2275 (4.4246)	
Epoch: [7][70/345]	Time 0.162 (0.166)	Data 0.0140 (0.0177)	Loss 4.5526 (4.4388)	
Epoch: [7][80/345]	Time 0.164 (0.166)	Data 0.0160 (0.0175)	Loss 3.4839 (4.4310)	
Epoch: [7][90/345]	Time 0.187 (0.166)	Data 0.0259 (0.0177)	Loss 4.2575 (4.4260)	
Epoch: [7][100/345]	Time 0.177 (0.166)	Data 0.0180 (0.0177)	Loss 4.5053 (4.3888)	
Epoch: [7][110/345]	Time 0.159 (0.166)	Data 0.0140 (0.0177)	Loss 4.2598 (4.3338)	
Epoch: [7][120/345]	Time 0.166 (0.166)	Data 0.0189 (0.0177)	Loss 3.2758 (4.3282)	
Epoch: [7][130/345]	Time 0.171 (0.166)	Data 0.0229 (0.0177)	Loss 4.1508 (4.3174)	
Epoch: [7][140/345]	Time 0.159 (0.166)	Data 0.0140 (0.0177)	Loss 3.5208 (4.2746)	
Epoch: [7][150/345]	Time 0.164 (0.166)	Data 0.0219 (0.0178)	Loss 4.7614 (4.2501)	
Epoch: [7][160/345]	Time 0.166 (0.166)	Data 0.0269 (0.0177)	Loss 2.9878 (4.1988)	
Epoch: [7][170/345]	Time 0.162 (0.166)	Data 0.0190 (0.0177)	Loss 4.7740 (4.1736)	
Epoch: [7][180/345]	Time 0.148 (0.166)	Data 0.0140 (0.0177)	Loss 3.6360 (4.1549)	
Epoch: [7][190/345]	Time 0.166 (0.166)	Data 0.0150 (0.0176)	Loss 3.4224 (4.1480)	
Epoch: [7][200/345]	Time 0.168 (0.166)	Data 0.0219 (0.0177)	Loss 4.3753 (4.1463)	
Epoch: [7][210/345]	Time 0.161 (0.166)	Data 0.0199 (0.0176)	Loss 4.5229 (4.1484)	
Epoch: [7][220/345]	Time 0.170 (0.166)	Data 0.0190 (0.0177)	Loss 3.2251 (4.1386)	
Epoch: [7][230/345]	Time 0.165 (0.166)	Data 0.0279 (0.0178)	Loss 2.3351 (4.1018)	
Epoch: [7][240/345]	Time 0.165 (0.166)	Data 0.0239 (0.0178)	Loss 4.0354 (4.0987)	
Epoch: [7][250/345]	Time 0.187 (0.166)	Data 0.0170 (0.0178)	Loss 3.2621 (4.0682)	
Epoch: [7][260/345]	Time 0.158 (0.166)	Data 0.0160 (0.0177)	Loss 4.1414 (4.0408)	
Epoch: [7][270/345]	Time 0.171 (0.166)	Data 0.0150 (0.0177)	Loss 3.4337 (4.0145)	
Epoch: [7][280/345]	Time 0.164 (0.166)	Data 0.0140 (0.0177)	Loss 4.6085 (4.0050)	
Epoch: [7][290/345]	Time 0.183 (0.166)	Data 0.0229 (0.0177)	Loss 4.0180 (3.9810)	
Epoch: [7][300/345]	Time 0.154 (0.166)	Data 0.0180 (0.0177)	Loss 3.1393 (3.9580)	
Epoch: [7][310/345]	Time 0.155 (0.166)	Data 0.0150 (0.0177)	Loss 3.5931 (3.9350)	
Epoch: [7][320/345]	Time 0.173 (0.166)	Data 0.0150 (0.0176)	Loss 3.0594 (3.9041)	
Epoch: [7][330/345]	Time 0.156 (0.166)	Data 0.0160 (0.0176)	Loss 2.5006 (3.8683)	
Epoch: [7][340/345]	Time 0.188 (0.166)	Data 0.0190 (0.0176)	Loss 2.4308 (3.8299)	
7
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [8][10/345]	Time 0.156 (0.173)	Data 0.0140 (0.0176)	Loss 5.2933 (4.7110)	
Epoch: [8][20/345]	Time 0.159 (0.168)	Data 0.0180 (0.0177)	Loss 4.7201 (4.6508)	
Epoch: [8][30/345]	Time 0.168 (0.167)	Data 0.0150 (0.0173)	Loss 4.1131 (4.6351)	
Epoch: [8][40/345]	Time 0.161 (0.165)	Data 0.0219 (0.0175)	Loss 3.9032 (4.5080)	
Epoch: [8][50/345]	Time 0.165 (0.166)	Data 0.0180 (0.0178)	Loss 3.6565 (4.4965)	
Epoch: [8][60/345]	Time 0.171 (0.167)	Data 0.0150 (0.0178)	Loss 4.7003 (4.4089)	
Epoch: [8][70/345]	Time 0.167 (0.167)	Data 0.0160 (0.0178)	Loss 3.5541 (4.4035)	
Epoch: [8][80/345]	Time 0.174 (0.168)	Data 0.0279 (0.0183)	Loss 5.3149 (4.3542)	
Epoch: [8][90/345]	Time 0.165 (0.168)	Data 0.0170 (0.0182)	Loss 3.4563 (4.3372)	
Epoch: [8][100/345]	Time 0.159 (0.167)	Data 0.0130 (0.0183)	Loss 5.1789 (4.3146)	
Epoch: [8][110/345]	Time 0.156 (0.166)	Data 0.0156 (0.0179)	Loss 3.6046 (4.3081)	
Epoch: [8][120/345]	Time 0.156 (0.166)	Data 0.0156 (0.0180)	Loss 2.6887 (4.2601)	
Epoch: [8][130/345]	Time 0.187 (0.166)	Data 0.0472 (0.0181)	Loss 4.6919 (4.2471)	
Epoch: [8][140/345]	Time 0.172 (0.166)	Data 0.0316 (0.0182)	Loss 3.4787 (4.2468)	
Epoch: [8][150/345]	Time 0.172 (0.165)	Data 0.0312 (0.0179)	Loss 3.1983 (4.2232)	
Epoch: [8][160/345]	Time 0.141 (0.165)	Data 0.0156 (0.0178)	Loss 3.0735 (4.1897)	
Epoch: [8][170/345]	Time 0.141 (0.165)	Data 0.0156 (0.0176)	Loss 4.3007 (4.1786)	
Epoch: [8][180/345]	Time 0.156 (0.165)	Data 0.0156 (0.0177)	Loss 2.7965 (4.1512)	
Epoch: [8][190/345]	Time 0.187 (0.165)	Data 0.0313 (0.0179)	Loss 4.1253 (4.1281)	
Epoch: [8][200/345]	Time 0.156 (0.165)	Data 0.0156 (0.0178)	Loss 3.6597 (4.1011)	
Epoch: [8][210/345]	Time 0.156 (0.165)	Data 0.0156 (0.0178)	Loss 3.6366 (4.0830)	
Epoch: [8][220/345]	Time 0.156 (0.165)	Data 0.0156 (0.0178)	Loss 3.9156 (4.0632)	
Epoch: [8][230/345]	Time 0.157 (0.166)	Data 0.0156 (0.0179)	Loss 3.6111 (4.0389)	
Epoch: [8][240/345]	Time 0.172 (0.166)	Data 0.0156 (0.0178)	Loss 2.2445 (4.0130)	
Epoch: [8][250/345]	Time 0.172 (0.166)	Data 0.0156 (0.0178)	Loss 3.2637 (3.9997)	
Epoch: [8][260/345]	Time 0.156 (0.166)	Data 0.0160 (0.0178)	Loss 3.1098 (3.9731)	
Epoch: [8][270/345]	Time 0.156 (0.166)	Data 0.0156 (0.0179)	Loss 3.5916 (3.9548)	
Epoch: [8][280/345]	Time 0.156 (0.166)	Data 0.0156 (0.0179)	Loss 3.8738 (3.9326)	
Epoch: [8][290/345]	Time 0.141 (0.166)	Data 0.0000 (0.0177)	Loss 2.8012 (3.9208)	
Epoch: [8][300/345]	Time 0.172 (0.165)	Data 0.0156 (0.0176)	Loss 3.1201 (3.8896)	
Epoch: [8][310/345]	Time 0.219 (0.166)	Data 0.0316 (0.0175)	Loss 2.8673 (3.8580)	
Epoch: [8][320/345]	Time 0.157 (0.166)	Data 0.0156 (0.0175)	Loss 2.1312 (3.8342)	
Epoch: [8][330/345]	Time 0.172 (0.166)	Data 0.0156 (0.0176)	Loss 3.3878 (3.8177)	
Epoch: [8][340/345]	Time 0.156 (0.165)	Data 0.0000 (0.0175)	Loss 3.1749 (3.7890)	
8
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [9][10/345]	Time 0.219 (0.173)	Data 0.0312 (0.0172)	Loss 3.8761 (4.9860)	
Epoch: [9][20/345]	Time 0.172 (0.170)	Data 0.0156 (0.0188)	Loss 5.1550 (4.8809)	
Epoch: [9][30/345]	Time 0.156 (0.167)	Data 0.0000 (0.0177)	Loss 4.4947 (4.7617)	
Epoch: [9][40/345]	Time 0.172 (0.168)	Data 0.0156 (0.0172)	Loss 5.0339 (4.5591)	
Epoch: [9][50/345]	Time 0.172 (0.168)	Data 0.0156 (0.0175)	Loss 4.1630 (4.5323)	
Epoch: [9][60/345]	Time 0.156 (0.169)	Data 0.0156 (0.0177)	Loss 3.8950 (4.4714)	
Epoch: [9][70/345]	Time 0.141 (0.167)	Data 0.0156 (0.0172)	Loss 3.9679 (4.4113)	
Epoch: [9][80/345]	Time 0.156 (0.166)	Data 0.0160 (0.0168)	Loss 4.3893 (4.3993)	
Epoch: [9][90/345]	Time 0.141 (0.167)	Data 0.0000 (0.0167)	Loss 3.4609 (4.3640)	
Epoch: [9][100/345]	Time 0.156 (0.167)	Data 0.0157 (0.0166)	Loss 5.5959 (4.3668)	
Epoch: [9][110/345]	Time 0.172 (0.167)	Data 0.0156 (0.0163)	Loss 4.4804 (4.3528)	
Epoch: [9][120/345]	Time 0.156 (0.168)	Data 0.0156 (0.0162)	Loss 3.0228 (4.3195)	
Epoch: [9][130/345]	Time 0.140 (0.167)	Data 0.0155 (0.0160)	Loss 4.0599 (4.2971)	
Epoch: [9][140/345]	Time 0.187 (0.167)	Data 0.0156 (0.0161)	Loss 4.8615 (4.2741)	
Epoch: [9][150/345]	Time 0.172 (0.167)	Data 0.0156 (0.0162)	Loss 3.2656 (4.2243)	
Epoch: [9][160/345]	Time 0.172 (0.167)	Data 0.0156 (0.0163)	Loss 4.4394 (4.2128)	
Epoch: [9][170/345]	Time 0.156 (0.167)	Data 0.0156 (0.0163)	Loss 3.4708 (4.2012)	
Epoch: [9][180/345]	Time 0.172 (0.167)	Data 0.0156 (0.0162)	Loss 5.5995 (4.1836)	
Epoch: [9][190/345]	Time 0.156 (0.167)	Data 0.0153 (0.0163)	Loss 2.9711 (4.1463)	
Epoch: [9][200/345]	Time 0.187 (0.166)	Data 0.0156 (0.0163)	Loss 3.6808 (4.1166)	
Epoch: [9][210/345]	Time 0.187 (0.166)	Data 0.0312 (0.0162)	Loss 2.5302 (4.0988)	
Epoch: [9][220/345]	Time 0.141 (0.166)	Data 0.0157 (0.0161)	Loss 3.4897 (4.0723)	
Epoch: [9][230/345]	Time 0.156 (0.166)	Data 0.0156 (0.0161)	Loss 3.0222 (4.0397)	
Epoch: [9][240/345]	Time 0.172 (0.165)	Data 0.0312 (0.0162)	Loss 4.4301 (4.0102)	
Epoch: [9][250/345]	Time 0.172 (0.165)	Data 0.0312 (0.0162)	Loss 2.9976 (3.9807)	
Epoch: [9][260/345]	Time 0.172 (0.165)	Data 0.0156 (0.0162)	Loss 2.4893 (3.9570)	
Epoch: [9][270/345]	Time 0.172 (0.166)	Data 0.0156 (0.0163)	Loss 2.5790 (3.9190)	
Epoch: [9][280/345]	Time 0.172 (0.165)	Data 0.0156 (0.0163)	Loss 2.6175 (3.8858)	
Epoch: [9][290/345]	Time 0.203 (0.166)	Data 0.0156 (0.0163)	Loss 2.8758 (3.8543)	
Epoch: [9][300/345]	Time 0.156 (0.166)	Data 0.0156 (0.0164)	Loss 2.6822 (3.8172)	
Epoch: [9][310/345]	Time 0.172 (0.166)	Data 0.0156 (0.0164)	Loss 2.6242 (3.8090)	
Epoch: [9][320/345]	Time 0.172 (0.166)	Data 0.0156 (0.0167)	Loss 2.0608 (3.7863)	
Epoch: [9][330/345]	Time 0.172 (0.166)	Data 0.0156 (0.0168)	Loss 2.5035 (3.7562)	
Epoch: [9][340/345]	Time 0.172 (0.166)	Data 0.0156 (0.0168)	Loss 3.4266 (3.7225)	
9
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [10][10/345]	Time 0.156 (0.172)	Data 0.0156 (0.0187)	Loss 5.3589 (4.4537)	
Epoch: [10][20/345]	Time 0.156 (0.169)	Data 0.0156 (0.0179)	Loss 5.0498 (4.4171)	
Epoch: [10][30/345]	Time 0.172 (0.168)	Data 0.0156 (0.0172)	Loss 3.0599 (4.3002)	
Epoch: [10][40/345]	Time 0.156 (0.167)	Data 0.0156 (0.0168)	Loss 3.6206 (4.2986)	
Epoch: [10][50/345]	Time 0.187 (0.168)	Data 0.0316 (0.0172)	Loss 3.4870 (4.1935)	
Epoch: [10][60/345]	Time 0.156 (0.166)	Data 0.0312 (0.0174)	Loss 4.4456 (4.1877)	
Epoch: [10][70/345]	Time 0.188 (0.166)	Data 0.0156 (0.0174)	Loss 4.7014 (4.1348)	
Epoch: [10][80/345]	Time 0.187 (0.166)	Data 0.0316 (0.0176)	Loss 4.1619 (4.1133)	
Epoch: [10][90/345]	Time 0.157 (0.167)	Data 0.0156 (0.0172)	Loss 4.0965 (4.0867)	
Epoch: [10][100/345]	Time 0.172 (0.168)	Data 0.0156 (0.0172)	Loss 3.9402 (4.0982)	
Epoch: [10][110/345]	Time 0.172 (0.167)	Data 0.0156 (0.0172)	Loss 4.0828 (4.1000)	
Epoch: [10][120/345]	Time 0.172 (0.167)	Data 0.0156 (0.0173)	Loss 3.7748 (4.0937)	
Epoch: [10][130/345]	Time 0.174 (0.168)	Data 0.0312 (0.0174)	Loss 3.0109 (4.0259)	
Epoch: [10][140/345]	Time 0.172 (0.168)	Data 0.0156 (0.0172)	Loss 3.4775 (3.9911)	
Epoch: [10][150/345]	Time 0.172 (0.168)	Data 0.0313 (0.0175)	Loss 3.0338 (3.9851)	
Epoch: [10][160/345]	Time 0.187 (0.168)	Data 0.0156 (0.0172)	Loss 3.7733 (3.9693)	
Epoch: [10][170/345]	Time 0.203 (0.169)	Data 0.0312 (0.0172)	Loss 4.6574 (3.9719)	
Epoch: [10][180/345]	Time 0.187 (0.170)	Data 0.0156 (0.0175)	Loss 4.8400 (3.9369)	
Epoch: [10][190/345]	Time 0.172 (0.170)	Data 0.0156 (0.0175)	Loss 2.9991 (3.8994)	
Epoch: [10][200/345]	Time 0.187 (0.170)	Data 0.0313 (0.0177)	Loss 2.7024 (3.8745)	
Epoch: [10][210/345]	Time 0.172 (0.171)	Data 0.0156 (0.0177)	Loss 3.4406 (3.8606)	
Epoch: [10][220/345]	Time 0.187 (0.171)	Data 0.0312 (0.0177)	Loss 2.7863 (3.8321)	
Epoch: [10][230/345]	Time 0.187 (0.171)	Data 0.0156 (0.0176)	Loss 3.8838 (3.8129)	
Epoch: [10][240/345]	Time 0.172 (0.171)	Data 0.0156 (0.0176)	Loss 3.5432 (3.7969)	
Epoch: [10][250/345]	Time 0.187 (0.171)	Data 0.0156 (0.0176)	Loss 3.3918 (3.7702)	
Epoch: [10][260/345]	Time 0.172 (0.172)	Data 0.0156 (0.0177)	Loss 3.1642 (3.7590)	
Epoch: [10][270/345]	Time 0.203 (0.172)	Data 0.0153 (0.0177)	Loss 3.6499 (3.7429)	
Epoch: [10][280/345]	Time 0.187 (0.172)	Data 0.0156 (0.0178)	Loss 2.7860 (3.7239)	
Epoch: [10][290/345]	Time 0.203 (0.173)	Data 0.0156 (0.0179)	Loss 2.3853 (3.6911)	
Epoch: [10][300/345]	Time 0.172 (0.173)	Data 0.0156 (0.0178)	Loss 2.9444 (3.6625)	
Epoch: [10][310/345]	Time 0.187 (0.173)	Data 0.0312 (0.0178)	Loss 2.0859 (3.6247)	
Epoch: [10][320/345]	Time 0.172 (0.173)	Data 0.0156 (0.0178)	Loss 2.3232 (3.5883)	
Epoch: [10][330/345]	Time 0.188 (0.173)	Data 0.0156 (0.0179)	Loss 2.2449 (3.5617)	
Epoch: [10][340/345]	Time 0.172 (0.174)	Data 0.0156 (0.0179)	Loss 2.2583 (3.5258)	
10
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [11][10/345]	Time 0.203 (0.185)	Data 0.0156 (0.0188)	Loss 4.6558 (5.0041)	
Epoch: [11][20/345]	Time 0.173 (0.182)	Data 0.0153 (0.0172)	Loss 4.5163 (4.7259)	
Epoch: [11][30/345]	Time 0.219 (0.183)	Data 0.0316 (0.0183)	Loss 4.7486 (4.5823)	
Epoch: [11][40/345]	Time 0.188 (0.184)	Data 0.0156 (0.0180)	Loss 5.7246 (4.4237)	
Epoch: [11][50/345]	Time 0.187 (0.183)	Data 0.0155 (0.0178)	Loss 3.7581 (4.3893)	
Epoch: [11][60/345]	Time 0.156 (0.182)	Data 0.0000 (0.0169)	Loss 3.8180 (4.2789)	
Epoch: [11][70/345]	Time 0.172 (0.182)	Data 0.0156 (0.0177)	Loss 3.8847 (4.2352)	
Epoch: [11][80/345]	Time 0.187 (0.181)	Data 0.0312 (0.0176)	Loss 4.3282 (4.1658)	
Epoch: [11][90/345]	Time 0.172 (0.181)	Data 0.0316 (0.0177)	Loss 4.3917 (4.1198)	
Epoch: [11][100/345]	Time 0.172 (0.180)	Data 0.0156 (0.0180)	Loss 5.8523 (4.1244)	
Epoch: [11][110/345]	Time 0.156 (0.179)	Data 0.0157 (0.0178)	Loss 3.6965 (4.1219)	
Epoch: [11][120/345]	Time 0.172 (0.179)	Data 0.0000 (0.0179)	Loss 4.3024 (4.1212)	
Epoch: [11][130/345]	Time 0.187 (0.179)	Data 0.0156 (0.0178)	Loss 3.3635 (4.1018)	
Epoch: [11][140/345]	Time 0.187 (0.179)	Data 0.0312 (0.0179)	Loss 3.6836 (4.0788)	
Epoch: [11][150/345]	Time 0.156 (0.179)	Data 0.0000 (0.0176)	Loss 3.0638 (4.0493)	
Epoch: [11][160/345]	Time 0.187 (0.179)	Data 0.0156 (0.0177)	Loss 3.1372 (4.0076)	
Epoch: [11][170/345]	Time 0.172 (0.179)	Data 0.0156 (0.0177)	Loss 3.3018 (3.9847)	
Epoch: [11][180/345]	Time 0.187 (0.179)	Data 0.0156 (0.0176)	Loss 3.4496 (3.9541)	
Epoch: [11][190/345]	Time 0.219 (0.179)	Data 0.0156 (0.0175)	Loss 3.0826 (3.9135)	
Epoch: [11][200/345]	Time 0.188 (0.180)	Data 0.0156 (0.0176)	Loss 2.5137 (3.8913)	
Epoch: [11][210/345]	Time 0.140 (0.180)	Data 0.0153 (0.0176)	Loss 4.2960 (3.8662)	
Epoch: [11][220/345]	Time 0.188 (0.179)	Data 0.0312 (0.0176)	Loss 2.9800 (3.8510)	
Epoch: [11][230/345]	Time 0.187 (0.180)	Data 0.0156 (0.0176)	Loss 2.7783 (3.8357)	
Epoch: [11][240/345]	Time 0.187 (0.180)	Data 0.0153 (0.0174)	Loss 2.6832 (3.8134)	
Epoch: [11][250/345]	Time 0.187 (0.180)	Data 0.0312 (0.0175)	Loss 3.2979 (3.7833)	
Epoch: [11][260/345]	Time 0.203 (0.180)	Data 0.0316 (0.0174)	Loss 2.8229 (3.7613)	
Epoch: [11][270/345]	Time 0.156 (0.180)	Data 0.0156 (0.0175)	Loss 2.9188 (3.7392)	
Epoch: [11][280/345]	Time 0.187 (0.180)	Data 0.0156 (0.0174)	Loss 3.3639 (3.7097)	
Epoch: [11][290/345]	Time 0.172 (0.180)	Data 0.0154 (0.0176)	Loss 2.6962 (3.6766)	
Epoch: [11][300/345]	Time 0.172 (0.180)	Data 0.0316 (0.0178)	Loss 2.6938 (3.6524)	
Epoch: [11][310/345]	Time 0.187 (0.180)	Data 0.0312 (0.0178)	Loss 2.6392 (3.6326)	
Epoch: [11][320/345]	Time 0.188 (0.180)	Data 0.0156 (0.0176)	Loss 2.6345 (3.6027)	
Epoch: [11][330/345]	Time 0.172 (0.180)	Data 0.0000 (0.0175)	Loss 2.2213 (3.5668)	
Epoch: [11][340/345]	Time 0.188 (0.181)	Data 0.0156 (0.0176)	Loss 2.1427 (3.5268)	
11
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [12][10/345]	Time 0.172 (0.184)	Data 0.0156 (0.0188)	Loss 4.2423 (5.0461)	
Epoch: [12][20/345]	Time 0.172 (0.187)	Data 0.0156 (0.0188)	Loss 4.0549 (4.7309)	
Epoch: [12][30/345]	Time 0.187 (0.188)	Data 0.0156 (0.0167)	Loss 4.5736 (4.5602)	
Epoch: [12][40/345]	Time 0.203 (0.186)	Data 0.0156 (0.0160)	Loss 5.4178 (4.6000)	
Epoch: [12][50/345]	Time 0.156 (0.184)	Data 0.0156 (0.0163)	Loss 4.3112 (4.5303)	
Epoch: [12][60/345]	Time 0.156 (0.183)	Data 0.0157 (0.0167)	Loss 3.4704 (4.4650)	
Epoch: [12][70/345]	Time 0.172 (0.181)	Data 0.0156 (0.0163)	Loss 3.4101 (4.3292)	
Epoch: [12][80/345]	Time 0.203 (0.182)	Data 0.0312 (0.0168)	Loss 3.2142 (4.2545)	
Epoch: [12][90/345]	Time 0.156 (0.182)	Data 0.0156 (0.0172)	Loss 4.1898 (4.2412)	
Epoch: [12][100/345]	Time 0.203 (0.182)	Data 0.0156 (0.0175)	Loss 4.1236 (4.1770)	
Epoch: [12][110/345]	Time 0.203 (0.183)	Data 0.0316 (0.0175)	Loss 4.2709 (4.1268)	
Epoch: [12][120/345]	Time 0.203 (0.182)	Data 0.0156 (0.0173)	Loss 3.3131 (4.0737)	
Epoch: [12][130/345]	Time 0.172 (0.182)	Data 0.0156 (0.0172)	Loss 2.6680 (4.0148)	
Epoch: [12][140/345]	Time 0.203 (0.181)	Data 0.0156 (0.0171)	Loss 4.5834 (4.0250)	
Epoch: [12][150/345]	Time 0.187 (0.181)	Data 0.0312 (0.0175)	Loss 4.0197 (4.0011)	
Epoch: [12][160/345]	Time 0.172 (0.181)	Data 0.0155 (0.0175)	Loss 3.4047 (3.9739)	
Epoch: [12][170/345]	Time 0.203 (0.181)	Data 0.0312 (0.0175)	Loss 3.7576 (3.9243)	
Epoch: [12][180/345]	Time 0.188 (0.181)	Data 0.0000 (0.0174)	Loss 3.8385 (3.9018)	
Epoch: [12][190/345]	Time 0.172 (0.181)	Data 0.0156 (0.0172)	Loss 2.5119 (3.8712)	
Epoch: [12][200/345]	Time 0.187 (0.180)	Data 0.0156 (0.0174)	Loss 3.1403 (3.8379)	
Epoch: [12][210/345]	Time 0.187 (0.180)	Data 0.0156 (0.0173)	Loss 2.4670 (3.8093)	
Epoch: [12][220/345]	Time 0.187 (0.180)	Data 0.0155 (0.0172)	Loss 2.9471 (3.7874)	
Epoch: [12][230/345]	Time 0.172 (0.180)	Data 0.0156 (0.0171)	Loss 2.8161 (3.7636)	
Epoch: [12][240/345]	Time 0.156 (0.180)	Data 0.0156 (0.0171)	Loss 3.5360 (3.7383)	
Epoch: [12][250/345]	Time 0.156 (0.179)	Data 0.0156 (0.0171)	Loss 3.1222 (3.7069)	
Epoch: [12][260/345]	Time 0.156 (0.179)	Data 0.0156 (0.0170)	Loss 2.9184 (3.6969)	
Epoch: [12][270/345]	Time 0.172 (0.179)	Data 0.0316 (0.0172)	Loss 3.1955 (3.6767)	
Epoch: [12][280/345]	Time 0.187 (0.179)	Data 0.0154 (0.0170)	Loss 2.2124 (3.6552)	
Epoch: [12][290/345]	Time 0.187 (0.179)	Data 0.0156 (0.0172)	Loss 2.7257 (3.6343)	
Epoch: [12][300/345]	Time 0.187 (0.179)	Data 0.0156 (0.0171)	Loss 2.4186 (3.5976)	
Epoch: [12][310/345]	Time 0.172 (0.179)	Data 0.0156 (0.0171)	Loss 2.7362 (3.5614)	
Epoch: [12][320/345]	Time 0.141 (0.179)	Data 0.0156 (0.0170)	Loss 2.0842 (3.5211)	
Epoch: [12][330/345]	Time 0.156 (0.180)	Data 0.0156 (0.0170)	Loss 2.3786 (3.4815)	
Epoch: [12][340/345]	Time 0.172 (0.179)	Data 0.0156 (0.0169)	Loss 3.6214 (3.4467)	
12
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [13][10/345]	Time 0.203 (0.194)	Data 0.0156 (0.0172)	Loss 3.2757 (4.1534)	
Epoch: [13][20/345]	Time 0.172 (0.186)	Data 0.0312 (0.0172)	Loss 5.6233 (4.2700)	
Epoch: [13][30/345]	Time 0.187 (0.186)	Data 0.0156 (0.0188)	Loss 4.4848 (4.2680)	
Epoch: [13][40/345]	Time 0.188 (0.186)	Data 0.0156 (0.0192)	Loss 3.7827 (4.2302)	
Epoch: [13][50/345]	Time 0.172 (0.187)	Data 0.0156 (0.0188)	Loss 3.3400 (4.1361)	
Epoch: [13][60/345]	Time 0.172 (0.185)	Data 0.0000 (0.0183)	Loss 3.1993 (4.0726)	
Epoch: [13][70/345]	Time 0.172 (0.185)	Data 0.0156 (0.0182)	Loss 3.7237 (4.0692)	
Epoch: [13][80/345]	Time 0.187 (0.184)	Data 0.0156 (0.0178)	Loss 4.1022 (3.9963)	
Epoch: [13][90/345]	Time 0.172 (0.185)	Data 0.0157 (0.0179)	Loss 2.9847 (3.9562)	
Epoch: [13][100/345]	Time 0.187 (0.185)	Data 0.0156 (0.0180)	Loss 4.5249 (3.9517)	
Epoch: [13][110/345]	Time 0.172 (0.185)	Data 0.0156 (0.0178)	Loss 3.1171 (3.9251)	
Epoch: [13][120/345]	Time 0.172 (0.184)	Data 0.0156 (0.0179)	Loss 3.4438 (3.8828)	
Epoch: [13][130/345]	Time 0.187 (0.185)	Data 0.0156 (0.0181)	Loss 2.7915 (3.8314)	
Epoch: [13][140/345]	Time 0.156 (0.186)	Data 0.0156 (0.0182)	Loss 2.6421 (3.7989)	
Epoch: [13][150/345]	Time 0.203 (0.186)	Data 0.0316 (0.0183)	Loss 4.1498 (3.7902)	
Epoch: [13][160/345]	Time 0.187 (0.185)	Data 0.0156 (0.0179)	Loss 4.0459 (3.7684)	
Epoch: [13][170/345]	Time 0.187 (0.185)	Data 0.0156 (0.0180)	Loss 3.0204 (3.7370)	
Epoch: [13][180/345]	Time 0.172 (0.186)	Data 0.0156 (0.0182)	Loss 3.3550 (3.7308)	
Epoch: [13][190/345]	Time 0.187 (0.186)	Data 0.0153 (0.0180)	Loss 2.8282 (3.6908)	
Epoch: [13][200/345]	Time 0.187 (0.185)	Data 0.0156 (0.0179)	Loss 3.5981 (3.6813)	
Epoch: [13][210/345]	Time 0.172 (0.185)	Data 0.0156 (0.0179)	Loss 3.1399 (3.6719)	
Epoch: [13][220/345]	Time 0.203 (0.185)	Data 0.0313 (0.0179)	Loss 2.4705 (3.6416)	
Epoch: [13][230/345]	Time 0.187 (0.185)	Data 0.0155 (0.0177)	Loss 2.8543 (3.6285)	
Epoch: [13][240/345]	Time 0.187 (0.185)	Data 0.0153 (0.0176)	Loss 3.4921 (3.5997)	
Epoch: [13][250/345]	Time 0.188 (0.185)	Data 0.0156 (0.0176)	Loss 2.3308 (3.5557)	
Epoch: [13][260/345]	Time 0.203 (0.185)	Data 0.0312 (0.0176)	Loss 3.3636 (3.5387)	
Epoch: [13][270/345]	Time 0.172 (0.185)	Data 0.0313 (0.0177)	Loss 2.9311 (3.5161)	
Epoch: [13][280/345]	Time 0.188 (0.184)	Data 0.0312 (0.0178)	Loss 3.2136 (3.4888)	
Epoch: [13][290/345]	Time 0.187 (0.184)	Data 0.0156 (0.0178)	Loss 3.8131 (3.4689)	
Epoch: [13][300/345]	Time 0.156 (0.184)	Data 0.0156 (0.0177)	Loss 2.7189 (3.4481)	
Epoch: [13][310/345]	Time 0.203 (0.183)	Data 0.0316 (0.0178)	Loss 2.2622 (3.4174)	
Epoch: [13][320/345]	Time 0.172 (0.183)	Data 0.0156 (0.0177)	Loss 1.8054 (3.3833)	
Epoch: [13][330/345]	Time 0.156 (0.183)	Data 0.0160 (0.0179)	Loss 2.6267 (3.3584)	
Epoch: [13][340/345]	Time 0.172 (0.183)	Data 0.0156 (0.0179)	Loss 1.4038 (3.3237)	
13
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [14][10/345]	Time 0.156 (0.177)	Data 0.0156 (0.0188)	Loss 4.6144 (4.7177)	
Epoch: [14][20/345]	Time 0.188 (0.178)	Data 0.0156 (0.0180)	Loss 2.8426 (4.3035)	
Epoch: [14][30/345]	Time 0.172 (0.178)	Data 0.0156 (0.0177)	Loss 3.3305 (4.3176)	
Epoch: [14][40/345]	Time 0.172 (0.175)	Data 0.0000 (0.0164)	Loss 2.4492 (4.1788)	
Epoch: [14][50/345]	Time 0.156 (0.176)	Data 0.0156 (0.0166)	Loss 1.8601 (4.0987)	
Epoch: [14][60/345]	Time 0.172 (0.176)	Data 0.0316 (0.0159)	Loss 3.9889 (4.0788)	
Epoch: [14][70/345]	Time 0.141 (0.174)	Data 0.0000 (0.0152)	Loss 4.7802 (4.0577)	
Epoch: [14][80/345]	Time 0.187 (0.174)	Data 0.0000 (0.0152)	Loss 2.5399 (4.0302)	
Epoch: [14][90/345]	Time 0.188 (0.176)	Data 0.0000 (0.0158)	Loss 3.0926 (4.0139)	
Epoch: [14][100/345]	Time 0.187 (0.175)	Data 0.0156 (0.0163)	Loss 2.8371 (3.9778)	
Epoch: [14][110/345]	Time 0.172 (0.175)	Data 0.0156 (0.0161)	Loss 3.2670 (3.9391)	
Epoch: [14][120/345]	Time 0.172 (0.175)	Data 0.0312 (0.0162)	Loss 3.8142 (3.9401)	
Epoch: [14][130/345]	Time 0.187 (0.175)	Data 0.0156 (0.0166)	Loss 3.6307 (3.9143)	
Epoch: [14][140/345]	Time 0.188 (0.175)	Data 0.0156 (0.0165)	Loss 3.4502 (3.8654)	
Epoch: [14][150/345]	Time 0.172 (0.175)	Data 0.0312 (0.0166)	Loss 3.7107 (3.8422)	
Epoch: [14][160/345]	Time 0.172 (0.175)	Data 0.0156 (0.0166)	Loss 3.3271 (3.8148)	
Epoch: [14][170/345]	Time 0.203 (0.176)	Data 0.0156 (0.0168)	Loss 3.6685 (3.7971)	
Epoch: [14][180/345]	Time 0.203 (0.177)	Data 0.0156 (0.0169)	Loss 3.3684 (3.7788)	
Epoch: [14][190/345]	Time 0.172 (0.177)	Data 0.0156 (0.0166)	Loss 2.6996 (3.7438)	
Epoch: [14][200/345]	Time 0.172 (0.176)	Data 0.0156 (0.0167)	Loss 3.2006 (3.7189)	
Epoch: [14][210/345]	Time 0.156 (0.176)	Data 0.0156 (0.0166)	Loss 3.2959 (3.6923)	
Epoch: [14][220/345]	Time 0.156 (0.176)	Data 0.0156 (0.0166)	Loss 3.5170 (3.6692)	
Epoch: [14][230/345]	Time 0.205 (0.176)	Data 0.0156 (0.0168)	Loss 2.8630 (3.6307)	
Epoch: [14][240/345]	Time 0.188 (0.177)	Data 0.0156 (0.0167)	Loss 3.3559 (3.6030)	
Epoch: [14][250/345]	Time 0.156 (0.177)	Data 0.0156 (0.0169)	Loss 2.9864 (3.5837)	
Epoch: [14][260/345]	Time 0.203 (0.177)	Data 0.0312 (0.0170)	Loss 3.4627 (3.5673)	
Epoch: [14][270/345]	Time 0.203 (0.178)	Data 0.0156 (0.0171)	Loss 3.2011 (3.5453)	
Epoch: [14][280/345]	Time 0.187 (0.178)	Data 0.0312 (0.0172)	Loss 2.8789 (3.5205)	
Epoch: [14][290/345]	Time 0.187 (0.178)	Data 0.0156 (0.0172)	Loss 1.8123 (3.4940)	
Epoch: [14][300/345]	Time 0.188 (0.178)	Data 0.0156 (0.0172)	Loss 2.5289 (3.4664)	
Epoch: [14][310/345]	Time 0.172 (0.178)	Data 0.0156 (0.0173)	Loss 1.8534 (3.4352)	
Epoch: [14][320/345]	Time 0.172 (0.178)	Data 0.0156 (0.0173)	Loss 2.0362 (3.3967)	
Epoch: [14][330/345]	Time 0.172 (0.178)	Data 0.0156 (0.0172)	Loss 1.9665 (3.3747)	
Epoch: [14][340/345]	Time 0.172 (0.178)	Data 0.0156 (0.0172)	Loss 2.3563 (3.3446)	
14
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [15][10/345]	Time 0.172 (0.158)	Data 0.0156 (0.0171)	Loss 5.5430 (4.5797)	
Epoch: [15][20/345]	Time 0.156 (0.162)	Data 0.0156 (0.0172)	Loss 4.6955 (4.4663)	
Epoch: [15][30/345]	Time 0.158 (0.165)	Data 0.0156 (0.0172)	Loss 3.9531 (4.3491)	
Epoch: [15][40/345]	Time 0.156 (0.164)	Data 0.0000 (0.0164)	Loss 4.0266 (4.2209)	
Epoch: [15][50/345]	Time 0.156 (0.163)	Data 0.0156 (0.0165)	Loss 4.7864 (4.2099)	
Epoch: [15][60/345]	Time 0.156 (0.162)	Data 0.0000 (0.0161)	Loss 5.2339 (4.1885)	
Epoch: [15][70/345]	Time 0.156 (0.162)	Data 0.0156 (0.0165)	Loss 3.2841 (4.1108)	
Epoch: [15][80/345]	Time 0.172 (0.162)	Data 0.0156 (0.0164)	Loss 3.5576 (4.0901)	
Epoch: [15][90/345]	Time 0.156 (0.162)	Data 0.0155 (0.0165)	Loss 4.1710 (4.0478)	
Epoch: [15][100/345]	Time 0.156 (0.162)	Data 0.0156 (0.0167)	Loss 2.9047 (4.0310)	
Epoch: [15][110/345]	Time 0.156 (0.162)	Data 0.0313 (0.0168)	Loss 4.7989 (3.9925)	
Epoch: [15][120/345]	Time 0.172 (0.162)	Data 0.0156 (0.0165)	Loss 4.7043 (3.9374)	
Epoch: [15][130/345]	Time 0.172 (0.162)	Data 0.0156 (0.0166)	Loss 4.6218 (3.9147)	
Epoch: [15][140/345]	Time 0.156 (0.163)	Data 0.0156 (0.0167)	Loss 4.4069 (3.8797)	
Epoch: [15][150/345]	Time 0.172 (0.163)	Data 0.0156 (0.0171)	Loss 4.1370 (3.8310)	
Epoch: [15][160/345]	Time 0.141 (0.163)	Data 0.0156 (0.0171)	Loss 3.1828 (3.8099)	
Epoch: [15][170/345]	Time 0.156 (0.164)	Data 0.0156 (0.0172)	Loss 3.0341 (3.7702)	
Epoch: [15][180/345]	Time 0.172 (0.164)	Data 0.0316 (0.0171)	Loss 3.6342 (3.7441)	
Epoch: [15][190/345]	Time 0.156 (0.163)	Data 0.0000 (0.0171)	Loss 3.0112 (3.7121)	
Epoch: [15][200/345]	Time 0.156 (0.164)	Data 0.0313 (0.0173)	Loss 3.5949 (3.6868)	
Epoch: [15][210/345]	Time 0.156 (0.165)	Data 0.0156 (0.0176)	Loss 2.8586 (3.6536)	
Epoch: [15][220/345]	Time 0.188 (0.165)	Data 0.0156 (0.0175)	Loss 2.3646 (3.6206)	
Epoch: [15][230/345]	Time 0.203 (0.166)	Data 0.0156 (0.0174)	Loss 1.9547 (3.5938)	
Epoch: [15][240/345]	Time 0.172 (0.166)	Data 0.0156 (0.0175)	Loss 2.6073 (3.5638)	
Epoch: [15][250/345]	Time 0.156 (0.166)	Data 0.0312 (0.0174)	Loss 2.8967 (3.5434)	
Epoch: [15][260/345]	Time 0.156 (0.166)	Data 0.0156 (0.0173)	Loss 2.7512 (3.5089)	
Epoch: [15][270/345]	Time 0.157 (0.166)	Data 0.0000 (0.0173)	Loss 2.1657 (3.4856)	
Epoch: [15][280/345]	Time 0.156 (0.166)	Data 0.0000 (0.0172)	Loss 2.8120 (3.4634)	
Epoch: [15][290/345]	Time 0.156 (0.166)	Data 0.0312 (0.0171)	Loss 3.0198 (3.4358)	
Epoch: [15][300/345]	Time 0.157 (0.166)	Data 0.0156 (0.0171)	Loss 1.9422 (3.4066)	
Epoch: [15][310/345]	Time 0.174 (0.166)	Data 0.0175 (0.0173)	Loss 1.9676 (3.3718)	
Epoch: [15][320/345]	Time 0.156 (0.166)	Data 0.0156 (0.0173)	Loss 1.7135 (3.3433)	
Epoch: [15][330/345]	Time 0.156 (0.166)	Data 0.0156 (0.0173)	Loss 2.0327 (3.3102)	
Epoch: [15][340/345]	Time 0.172 (0.166)	Data 0.0312 (0.0173)	Loss 1.9356 (3.2793)	
15
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [16][10/345]	Time 0.172 (0.166)	Data 0.0156 (0.0187)	Loss 4.0595 (4.9050)	
Epoch: [16][20/345]	Time 0.156 (0.163)	Data 0.0156 (0.0164)	Loss 3.2009 (4.3506)	
Epoch: [16][30/345]	Time 0.172 (0.163)	Data 0.0156 (0.0167)	Loss 4.2656 (4.2292)	
Epoch: [16][40/345]	Time 0.172 (0.165)	Data 0.0156 (0.0172)	Loss 4.4813 (4.1649)	
Epoch: [16][50/345]	Time 0.156 (0.166)	Data 0.0000 (0.0175)	Loss 3.8174 (4.0778)	
Epoch: [16][60/345]	Time 0.172 (0.168)	Data 0.0156 (0.0177)	Loss 3.8739 (4.0905)	
Epoch: [16][70/345]	Time 0.156 (0.167)	Data 0.0156 (0.0174)	Loss 3.0845 (4.0481)	
Epoch: [16][80/345]	Time 0.156 (0.167)	Data 0.0156 (0.0172)	Loss 4.1426 (3.9600)	
Epoch: [16][90/345]	Time 0.172 (0.167)	Data 0.0156 (0.0170)	Loss 2.8877 (3.9101)	
Epoch: [16][100/345]	Time 0.172 (0.168)	Data 0.0156 (0.0174)	Loss 2.6078 (3.8644)	
Epoch: [16][110/345]	Time 0.189 (0.169)	Data 0.0156 (0.0172)	Loss 4.1061 (3.8600)	
Epoch: [16][120/345]	Time 0.141 (0.168)	Data 0.0156 (0.0169)	Loss 3.9843 (3.8206)	
Epoch: [16][130/345]	Time 0.172 (0.169)	Data 0.0156 (0.0170)	Loss 3.4265 (3.7769)	
Epoch: [16][140/345]	Time 0.187 (0.169)	Data 0.0156 (0.0171)	Loss 3.0511 (3.7669)	
Epoch: [16][150/345]	Time 0.187 (0.170)	Data 0.0156 (0.0171)	Loss 3.9970 (3.6998)	
Epoch: [16][160/345]	Time 0.172 (0.170)	Data 0.0156 (0.0172)	Loss 3.0663 (3.6799)	
Epoch: [16][170/345]	Time 0.188 (0.171)	Data 0.0156 (0.0173)	Loss 2.9515 (3.6455)	
Epoch: [16][180/345]	Time 0.172 (0.171)	Data 0.0156 (0.0172)	Loss 2.5499 (3.6107)	
Epoch: [16][190/345]	Time 0.188 (0.172)	Data 0.0154 (0.0171)	Loss 3.9291 (3.5934)	
Epoch: [16][200/345]	Time 0.172 (0.172)	Data 0.0156 (0.0173)	Loss 2.5617 (3.5514)	
Epoch: [16][210/345]	Time 0.187 (0.173)	Data 0.0156 (0.0175)	Loss 3.3726 (3.5228)	
Epoch: [16][220/345]	Time 0.189 (0.173)	Data 0.0316 (0.0175)	Loss 3.2138 (3.5020)	
Epoch: [16][230/345]	Time 0.172 (0.174)	Data 0.0156 (0.0174)	Loss 2.5847 (3.4759)	
Epoch: [16][240/345]	Time 0.156 (0.173)	Data 0.0156 (0.0173)	Loss 2.5873 (3.4590)	
Epoch: [16][250/345]	Time 0.187 (0.174)	Data 0.0153 (0.0173)	Loss 3.1937 (3.4473)	
Epoch: [16][260/345]	Time 0.156 (0.174)	Data 0.0156 (0.0173)	Loss 2.8209 (3.4257)	
Epoch: [16][270/345]	Time 0.172 (0.174)	Data 0.0156 (0.0173)	Loss 1.9044 (3.4009)	
Epoch: [16][280/345]	Time 0.188 (0.174)	Data 0.0156 (0.0173)	Loss 2.1658 (3.3595)	
Epoch: [16][290/345]	Time 0.203 (0.175)	Data 0.0316 (0.0172)	Loss 2.4081 (3.3303)	
Epoch: [16][300/345]	Time 0.187 (0.175)	Data 0.0156 (0.0173)	Loss 2.9675 (3.3067)	
Epoch: [16][310/345]	Time 0.187 (0.175)	Data 0.0156 (0.0172)	Loss 2.1835 (3.2693)	
Epoch: [16][320/345]	Time 0.187 (0.175)	Data 0.0154 (0.0172)	Loss 2.6558 (3.2395)	
Epoch: [16][330/345]	Time 0.187 (0.175)	Data 0.0316 (0.0172)	Loss 1.8778 (3.2035)	
Epoch: [16][340/345]	Time 0.203 (0.175)	Data 0.0156 (0.0172)	Loss 1.5632 (3.1591)	
16
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [17][10/345]	Time 0.203 (0.183)	Data 0.0312 (0.0140)	Loss 2.0407 (3.8708)	
Epoch: [17][20/345]	Time 0.172 (0.181)	Data 0.0156 (0.0156)	Loss 4.8486 (4.1342)	
Epoch: [17][30/345]	Time 0.172 (0.182)	Data 0.0156 (0.0156)	Loss 3.4580 (3.9946)	
Epoch: [17][40/345]	Time 0.156 (0.179)	Data 0.0000 (0.0148)	Loss 3.2011 (3.9174)	
Epoch: [17][50/345]	Time 0.187 (0.177)	Data 0.0316 (0.0153)	Loss 2.7597 (3.8475)	
Epoch: [17][60/345]	Time 0.156 (0.176)	Data 0.0156 (0.0156)	Loss 3.4323 (3.7851)	
Epoch: [17][70/345]	Time 0.156 (0.174)	Data 0.0156 (0.0161)	Loss 3.6660 (3.7996)	
Epoch: [17][80/345]	Time 0.172 (0.173)	Data 0.0313 (0.0166)	Loss 3.2593 (3.7641)	
Epoch: [17][90/345]	Time 0.172 (0.173)	Data 0.0156 (0.0167)	Loss 5.6947 (3.7267)	
Epoch: [17][100/345]	Time 0.172 (0.173)	Data 0.0156 (0.0166)	Loss 2.7355 (3.6739)	
Epoch: [17][110/345]	Time 0.172 (0.173)	Data 0.0156 (0.0168)	Loss 4.0832 (3.6417)	
Epoch: [17][120/345]	Time 0.187 (0.173)	Data 0.0316 (0.0168)	Loss 3.0538 (3.6355)	
Epoch: [17][130/345]	Time 0.156 (0.174)	Data 0.0156 (0.0167)	Loss 2.1658 (3.6240)	
Epoch: [17][140/345]	Time 0.187 (0.174)	Data 0.0156 (0.0168)	Loss 2.7305 (3.6100)	
Epoch: [17][150/345]	Time 0.156 (0.175)	Data 0.0156 (0.0168)	Loss 3.5549 (3.6021)	
Epoch: [17][160/345]	Time 0.172 (0.174)	Data 0.0156 (0.0166)	Loss 4.6211 (3.5922)	
Epoch: [17][170/345]	Time 0.188 (0.175)	Data 0.0156 (0.0167)	Loss 3.2865 (3.5662)	
Epoch: [17][180/345]	Time 0.156 (0.175)	Data 0.0156 (0.0168)	Loss 1.6279 (3.5469)	
Epoch: [17][190/345]	Time 0.187 (0.175)	Data 0.0316 (0.0169)	Loss 2.4441 (3.5185)	
Epoch: [17][200/345]	Time 0.190 (0.176)	Data 0.0156 (0.0170)	Loss 3.6070 (3.4851)	
Epoch: [17][210/345]	Time 0.156 (0.175)	Data 0.0156 (0.0170)	Loss 3.4010 (3.4749)	
Epoch: [17][220/345]	Time 0.172 (0.176)	Data 0.0156 (0.0172)	Loss 4.4886 (3.4668)	
Epoch: [17][230/345]	Time 0.156 (0.176)	Data 0.0156 (0.0173)	Loss 2.4954 (3.4333)	
Epoch: [17][240/345]	Time 0.156 (0.177)	Data 0.0156 (0.0175)	Loss 3.1333 (3.4225)	
Epoch: [17][250/345]	Time 0.219 (0.177)	Data 0.0312 (0.0176)	Loss 4.2345 (3.4233)	
Epoch: [17][260/345]	Time 0.156 (0.177)	Data 0.0154 (0.0177)	Loss 3.0416 (3.3988)	
Epoch: [17][270/345]	Time 0.172 (0.177)	Data 0.0156 (0.0178)	Loss 2.1808 (3.3847)	
Epoch: [17][280/345]	Time 0.172 (0.177)	Data 0.0156 (0.0179)	Loss 2.5792 (3.3626)	
Epoch: [17][290/345]	Time 0.219 (0.177)	Data 0.0316 (0.0179)	Loss 2.9329 (3.3421)	
Epoch: [17][300/345]	Time 0.172 (0.177)	Data 0.0156 (0.0178)	Loss 2.2314 (3.3201)	
Epoch: [17][310/345]	Time 0.188 (0.177)	Data 0.0316 (0.0179)	Loss 2.2004 (3.2868)	
Epoch: [17][320/345]	Time 0.203 (0.177)	Data 0.0312 (0.0177)	Loss 2.1255 (3.2580)	
Epoch: [17][330/345]	Time 0.187 (0.177)	Data 0.0000 (0.0177)	Loss 2.4186 (3.2306)	
Epoch: [17][340/345]	Time 0.172 (0.177)	Data 0.0156 (0.0177)	Loss 2.3344 (3.1911)	
17
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [18][10/345]	Time 0.187 (0.184)	Data 0.0156 (0.0172)	Loss 4.5839 (4.2750)	
Epoch: [18][20/345]	Time 0.156 (0.181)	Data 0.0156 (0.0164)	Loss 3.2352 (4.1151)	
Epoch: [18][30/345]	Time 0.187 (0.181)	Data 0.0316 (0.0162)	Loss 4.3019 (4.0329)	
Epoch: [18][40/345]	Time 0.188 (0.182)	Data 0.0156 (0.0161)	Loss 3.3324 (3.8953)	
Epoch: [18][50/345]	Time 0.156 (0.181)	Data 0.0155 (0.0153)	Loss 2.5184 (3.9194)	
Epoch: [18][60/345]	Time 0.187 (0.182)	Data 0.0156 (0.0162)	Loss 4.2220 (3.8672)	
Epoch: [18][70/345]	Time 0.203 (0.182)	Data 0.0156 (0.0166)	Loss 4.3609 (3.8971)	
Epoch: [18][80/345]	Time 0.172 (0.182)	Data 0.0157 (0.0164)	Loss 3.3642 (3.8441)	
Epoch: [18][90/345]	Time 0.156 (0.183)	Data 0.0156 (0.0167)	Loss 3.6931 (3.8502)	
Epoch: [18][100/345]	Time 0.187 (0.182)	Data 0.0156 (0.0166)	Loss 2.7272 (3.8311)	
Epoch: [18][110/345]	Time 0.156 (0.183)	Data 0.0000 (0.0166)	Loss 2.7180 (3.8156)	
Epoch: [18][120/345]	Time 0.172 (0.182)	Data 0.0156 (0.0168)	Loss 3.3282 (3.8013)	
Epoch: [18][130/345]	Time 0.172 (0.182)	Data 0.0156 (0.0169)	Loss 2.3297 (3.7772)	
Epoch: [18][140/345]	Time 0.172 (0.182)	Data 0.0156 (0.0170)	Loss 3.7119 (3.7512)	
Epoch: [18][150/345]	Time 0.172 (0.182)	Data 0.0156 (0.0168)	Loss 3.3629 (3.6929)	
Epoch: [18][160/345]	Time 0.187 (0.182)	Data 0.0156 (0.0167)	Loss 3.8492 (3.6745)	
Epoch: [18][170/345]	Time 0.188 (0.182)	Data 0.0156 (0.0168)	Loss 3.1332 (3.6344)	
Epoch: [18][180/345]	Time 0.172 (0.181)	Data 0.0156 (0.0168)	Loss 3.5808 (3.6229)	
Epoch: [18][190/345]	Time 0.187 (0.181)	Data 0.0156 (0.0166)	Loss 2.5177 (3.5787)	
Epoch: [18][200/345]	Time 0.187 (0.182)	Data 0.0316 (0.0167)	Loss 3.3719 (3.5510)	
Epoch: [18][210/345]	Time 0.203 (0.182)	Data 0.0156 (0.0171)	Loss 1.9732 (3.5231)	
Epoch: [18][220/345]	Time 0.203 (0.182)	Data 0.0156 (0.0171)	Loss 2.2557 (3.4882)	
Epoch: [18][230/345]	Time 0.187 (0.182)	Data 0.0316 (0.0171)	Loss 2.4009 (3.4557)	
Epoch: [18][240/345]	Time 0.172 (0.182)	Data 0.0156 (0.0172)	Loss 2.3403 (3.4260)	
Epoch: [18][250/345]	Time 0.187 (0.182)	Data 0.0316 (0.0173)	Loss 1.8942 (3.3945)	
Epoch: [18][260/345]	Time 0.203 (0.182)	Data 0.0312 (0.0172)	Loss 2.8551 (3.3702)	
Epoch: [18][270/345]	Time 0.156 (0.182)	Data 0.0156 (0.0172)	Loss 2.1714 (3.3354)	
Epoch: [18][280/345]	Time 0.187 (0.182)	Data 0.0156 (0.0172)	Loss 2.1283 (3.3021)	
Epoch: [18][290/345]	Time 0.158 (0.182)	Data 0.0156 (0.0172)	Loss 2.3196 (3.2731)	
Epoch: [18][300/345]	Time 0.187 (0.182)	Data 0.0156 (0.0174)	Loss 3.3242 (3.2521)	
Epoch: [18][310/345]	Time 0.219 (0.182)	Data 0.0156 (0.0176)	Loss 2.6064 (3.2258)	
Epoch: [18][320/345]	Time 0.156 (0.182)	Data 0.0156 (0.0176)	Loss 2.3336 (3.1908)	
Epoch: [18][330/345]	Time 0.203 (0.182)	Data 0.0156 (0.0175)	Loss 1.5409 (3.1542)	
Epoch: [18][340/345]	Time 0.156 (0.182)	Data 0.0156 (0.0175)	Loss 1.8191 (3.1174)	
18
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [19][10/345]	Time 0.156 (0.177)	Data 0.0156 (0.0203)	Loss 3.9532 (4.1529)	
Epoch: [19][20/345]	Time 0.172 (0.180)	Data 0.0312 (0.0188)	Loss 4.3377 (4.1032)	
Epoch: [19][30/345]	Time 0.157 (0.180)	Data 0.0156 (0.0182)	Loss 3.3183 (3.9766)	
Epoch: [19][40/345]	Time 0.187 (0.182)	Data 0.0156 (0.0176)	Loss 5.6419 (3.8856)	
Epoch: [19][50/345]	Time 0.203 (0.182)	Data 0.0156 (0.0166)	Loss 3.7400 (3.8248)	
Epoch: [19][60/345]	Time 0.203 (0.182)	Data 0.0316 (0.0172)	Loss 4.0027 (3.7964)	
Epoch: [19][70/345]	Time 0.172 (0.182)	Data 0.0156 (0.0172)	Loss 2.4879 (3.7523)	
Epoch: [19][80/345]	Time 0.172 (0.181)	Data 0.0156 (0.0172)	Loss 3.2941 (3.7675)	
Epoch: [19][90/345]	Time 0.187 (0.181)	Data 0.0316 (0.0172)	Loss 3.1797 (3.6948)	
Epoch: [19][100/345]	Time 0.187 (0.181)	Data 0.0156 (0.0170)	Loss 2.8177 (3.6504)	
Epoch: [19][110/345]	Time 0.187 (0.181)	Data 0.0156 (0.0169)	Loss 2.9948 (3.6386)	
Epoch: [19][120/345]	Time 0.156 (0.180)	Data 0.0156 (0.0168)	Loss 2.4032 (3.5917)	
Epoch: [19][130/345]	Time 0.156 (0.179)	Data 0.0156 (0.0167)	Loss 4.1806 (3.5754)	
Epoch: [19][140/345]	Time 0.187 (0.180)	Data 0.0313 (0.0166)	Loss 2.6366 (3.5316)	
Epoch: [19][150/345]	Time 0.187 (0.179)	Data 0.0156 (0.0166)	Loss 3.4070 (3.4933)	
Epoch: [19][160/345]	Time 0.188 (0.179)	Data 0.0154 (0.0164)	Loss 2.1666 (3.4430)	
Epoch: [19][170/345]	Time 0.187 (0.179)	Data 0.0156 (0.0165)	Loss 3.4460 (3.4191)	
Epoch: [19][180/345]	Time 0.187 (0.179)	Data 0.0156 (0.0166)	Loss 3.6077 (3.3888)	
Epoch: [19][190/345]	Time 0.172 (0.180)	Data 0.0156 (0.0165)	Loss 3.1508 (3.3951)	
Epoch: [19][200/345]	Time 0.187 (0.180)	Data 0.0312 (0.0166)	Loss 2.3049 (3.3586)	
Epoch: [19][210/345]	Time 0.172 (0.180)	Data 0.0156 (0.0168)	Loss 3.9569 (3.3389)	
Epoch: [19][220/345]	Time 0.172 (0.180)	Data 0.0156 (0.0168)	Loss 2.5937 (3.3376)	
Epoch: [19][230/345]	Time 0.187 (0.180)	Data 0.0156 (0.0168)	Loss 1.6063 (3.3165)	
Epoch: [19][240/345]	Time 0.187 (0.180)	Data 0.0156 (0.0168)	Loss 2.3459 (3.3047)	
Epoch: [19][250/345]	Time 0.187 (0.180)	Data 0.0156 (0.0170)	Loss 3.5923 (3.2819)	
Epoch: [19][260/345]	Time 0.187 (0.180)	Data 0.0312 (0.0171)	Loss 2.3320 (3.2531)	
Epoch: [19][270/345]	Time 0.172 (0.180)	Data 0.0156 (0.0170)	Loss 3.0563 (3.2335)	
Epoch: [19][280/345]	Time 0.172 (0.179)	Data 0.0156 (0.0170)	Loss 2.3187 (3.2056)	
Epoch: [19][290/345]	Time 0.187 (0.179)	Data 0.0156 (0.0169)	Loss 2.3758 (3.1907)	
Epoch: [19][300/345]	Time 0.203 (0.180)	Data 0.0156 (0.0169)	Loss 2.6455 (3.1731)	
Epoch: [19][310/345]	Time 0.187 (0.180)	Data 0.0312 (0.0169)	Loss 2.0835 (3.1514)	
Epoch: [19][320/345]	Time 0.187 (0.180)	Data 0.0157 (0.0171)	Loss 3.4205 (3.1298)	
Epoch: [19][330/345]	Time 0.188 (0.180)	Data 0.0156 (0.0170)	Loss 2.4517 (3.1020)	
Epoch: [19][340/345]	Time 0.172 (0.180)	Data 0.0313 (0.0171)	Loss 1.7408 (3.0706)	
19
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [20][10/345]	Time 0.172 (0.178)	Data 0.0156 (0.0172)	Loss 2.8081 (4.0794)	
Epoch: [20][20/345]	Time 0.156 (0.176)	Data 0.0160 (0.0164)	Loss 5.4447 (4.0116)	
Epoch: [20][30/345]	Time 0.156 (0.177)	Data 0.0156 (0.0167)	Loss 4.3008 (3.8909)	
Epoch: [20][40/345]	Time 0.172 (0.177)	Data 0.0156 (0.0164)	Loss 4.2506 (3.7456)	
Epoch: [20][50/345]	Time 0.203 (0.179)	Data 0.0312 (0.0175)	Loss 4.3912 (3.6533)	
Epoch: [20][60/345]	Time 0.172 (0.180)	Data 0.0156 (0.0175)	Loss 2.7728 (3.6470)	
Epoch: [20][70/345]	Time 0.172 (0.182)	Data 0.0156 (0.0177)	Loss 3.0008 (3.6518)	
Epoch: [20][80/345]	Time 0.187 (0.181)	Data 0.0156 (0.0176)	Loss 3.3976 (3.6573)	
Epoch: [20][90/345]	Time 0.187 (0.182)	Data 0.0316 (0.0179)	Loss 3.6181 (3.6290)	
Epoch: [20][100/345]	Time 0.203 (0.182)	Data 0.0312 (0.0178)	Loss 3.5331 (3.6215)	
Epoch: [20][110/345]	Time 0.172 (0.181)	Data 0.0156 (0.0175)	Loss 3.0333 (3.6016)	
Epoch: [20][120/345]	Time 0.187 (0.182)	Data 0.0153 (0.0175)	Loss 2.6261 (3.5622)	
Epoch: [20][130/345]	Time 0.203 (0.182)	Data 0.0156 (0.0176)	Loss 3.1167 (3.5268)	
Epoch: [20][140/345]	Time 0.172 (0.183)	Data 0.0000 (0.0174)	Loss 2.8185 (3.4891)	
Epoch: [20][150/345]	Time 0.187 (0.183)	Data 0.0156 (0.0173)	Loss 2.9188 (3.4536)	
Epoch: [20][160/345]	Time 0.203 (0.182)	Data 0.0156 (0.0172)	Loss 3.4386 (3.4167)	
Epoch: [20][170/345]	Time 0.203 (0.182)	Data 0.0156 (0.0172)	Loss 3.0921 (3.3736)	
Epoch: [20][180/345]	Time 0.172 (0.182)	Data 0.0156 (0.0169)	Loss 2.3521 (3.3339)	
Epoch: [20][190/345]	Time 0.203 (0.182)	Data 0.0156 (0.0170)	Loss 2.8325 (3.3018)	
Epoch: [20][200/345]	Time 0.187 (0.182)	Data 0.0156 (0.0168)	Loss 2.7054 (3.2792)	
Epoch: [20][210/345]	Time 0.172 (0.181)	Data 0.0156 (0.0168)	Loss 4.0751 (3.2729)	
Epoch: [20][220/345]	Time 0.187 (0.181)	Data 0.0156 (0.0168)	Loss 3.6557 (3.2518)	
Epoch: [20][230/345]	Time 0.172 (0.181)	Data 0.0312 (0.0169)	Loss 3.1339 (3.2331)	
Epoch: [20][240/345]	Time 0.187 (0.180)	Data 0.0156 (0.0169)	Loss 2.5213 (3.2153)	
Epoch: [20][250/345]	Time 0.156 (0.180)	Data 0.0000 (0.0167)	Loss 1.8447 (3.1889)	
Epoch: [20][260/345]	Time 0.156 (0.180)	Data 0.0156 (0.0167)	Loss 1.9549 (3.1714)	
Epoch: [20][270/345]	Time 0.187 (0.180)	Data 0.0316 (0.0167)	Loss 1.7748 (3.1431)	
Epoch: [20][280/345]	Time 0.187 (0.179)	Data 0.0156 (0.0167)	Loss 2.2003 (3.1221)	
Epoch: [20][290/345]	Time 0.172 (0.179)	Data 0.0156 (0.0167)	Loss 1.4748 (3.1007)	
Epoch: [20][300/345]	Time 0.141 (0.179)	Data 0.0156 (0.0167)	Loss 2.5607 (3.0732)	
Epoch: [20][310/345]	Time 0.172 (0.178)	Data 0.0312 (0.0168)	Loss 2.2553 (3.0486)	
Epoch: [20][320/345]	Time 0.172 (0.179)	Data 0.0156 (0.0169)	Loss 2.5999 (3.0264)	
Epoch: [20][330/345]	Time 0.172 (0.178)	Data 0.0000 (0.0167)	Loss 2.1255 (3.0074)	
Epoch: [20][340/345]	Time 0.188 (0.178)	Data 0.0156 (0.0167)	Loss 1.8960 (2.9776)	
20
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [21][10/345]	Time 0.203 (0.180)	Data 0.0156 (0.0172)	Loss 4.2520 (4.6236)	
Epoch: [21][20/345]	Time 0.156 (0.173)	Data 0.0156 (0.0172)	Loss 2.1570 (4.4006)	
Epoch: [21][30/345]	Time 0.172 (0.173)	Data 0.0156 (0.0182)	Loss 2.4969 (4.1714)	
Epoch: [21][40/345]	Time 0.188 (0.173)	Data 0.0156 (0.0172)	Loss 4.5008 (4.1370)	
Epoch: [21][50/345]	Time 0.187 (0.174)	Data 0.0156 (0.0175)	Loss 3.0346 (3.9999)	
Epoch: [21][60/345]	Time 0.172 (0.173)	Data 0.0156 (0.0174)	Loss 4.9605 (3.9676)	
Epoch: [21][70/345]	Time 0.172 (0.172)	Data 0.0313 (0.0172)	Loss 3.6118 (3.8879)	
Epoch: [21][80/345]	Time 0.187 (0.173)	Data 0.0156 (0.0168)	Loss 4.5818 (3.8495)	
Epoch: [21][90/345]	Time 0.172 (0.173)	Data 0.0156 (0.0170)	Loss 3.2236 (3.8230)	
Epoch: [21][100/345]	Time 0.172 (0.172)	Data 0.0157 (0.0169)	Loss 3.3937 (3.7654)	
Epoch: [21][110/345]	Time 0.157 (0.171)	Data 0.0156 (0.0168)	Loss 2.5955 (3.7100)	
Epoch: [21][120/345]	Time 0.156 (0.171)	Data 0.0000 (0.0165)	Loss 2.3162 (3.6345)	
Epoch: [21][130/345]	Time 0.156 (0.171)	Data 0.0153 (0.0168)	Loss 1.7561 (3.5815)	
Epoch: [21][140/345]	Time 0.156 (0.171)	Data 0.0156 (0.0170)	Loss 2.3724 (3.5187)	
Epoch: [21][150/345]	Time 0.172 (0.171)	Data 0.0156 (0.0168)	Loss 2.0078 (3.4619)	
Epoch: [21][160/345]	Time 0.172 (0.171)	Data 0.0156 (0.0167)	Loss 2.6560 (3.4169)	
Epoch: [21][170/345]	Time 0.156 (0.170)	Data 0.0156 (0.0168)	Loss 2.5289 (3.3689)	
Epoch: [21][180/345]	Time 0.156 (0.171)	Data 0.0156 (0.0169)	Loss 1.8922 (3.3208)	
Epoch: [21][190/345]	Time 0.156 (0.171)	Data 0.0156 (0.0170)	Loss 2.8396 (3.2771)	
Epoch: [21][200/345]	Time 0.172 (0.171)	Data 0.0312 (0.0173)	Loss 2.0203 (3.2385)	
Epoch: [21][210/345]	Time 0.156 (0.171)	Data 0.0156 (0.0173)	Loss 1.7614 (3.2039)	
Epoch: [21][220/345]	Time 0.203 (0.171)	Data 0.0156 (0.0175)	Loss 2.3291 (3.1795)	
Epoch: [21][230/345]	Time 0.172 (0.171)	Data 0.0156 (0.0173)	Loss 2.7194 (3.1338)	
Epoch: [21][240/345]	Time 0.172 (0.171)	Data 0.0156 (0.0174)	Loss 2.3855 (3.1045)	
Epoch: [21][250/345]	Time 0.172 (0.171)	Data 0.0156 (0.0174)	Loss 2.4102 (3.0745)	
Epoch: [21][260/345]	Time 0.187 (0.172)	Data 0.0312 (0.0174)	Loss 2.0117 (3.0435)	
Epoch: [21][270/345]	Time 0.172 (0.172)	Data 0.0156 (0.0174)	Loss 1.3218 (2.9976)	
Epoch: [21][280/345]	Time 0.172 (0.171)	Data 0.0316 (0.0174)	Loss 2.7017 (2.9674)	
Epoch: [21][290/345]	Time 0.156 (0.171)	Data 0.0157 (0.0174)	Loss 1.4700 (2.9293)	
Epoch: [21][300/345]	Time 0.187 (0.171)	Data 0.0156 (0.0175)	Loss 1.9327 (2.8982)	
Epoch: [21][310/345]	Time 0.172 (0.172)	Data 0.0156 (0.0175)	Loss 1.7015 (2.8716)	
Epoch: [21][320/345]	Time 0.172 (0.172)	Data 0.0156 (0.0176)	Loss 1.6827 (2.8464)	
Epoch: [21][330/345]	Time 0.172 (0.172)	Data 0.0156 (0.0177)	Loss 2.1888 (2.8232)	
Epoch: [21][340/345]	Time 0.187 (0.173)	Data 0.0156 (0.0178)	Loss 2.1141 (2.7931)	
21
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [22][10/345]	Time 0.156 (0.170)	Data 0.0156 (0.0187)	Loss 3.3085 (3.7039)	
Epoch: [22][20/345]	Time 0.172 (0.175)	Data 0.0312 (0.0195)	Loss 3.1190 (3.5458)	
Epoch: [22][30/345]	Time 0.156 (0.173)	Data 0.0156 (0.0198)	Loss 2.2660 (3.6303)	
Epoch: [22][40/345]	Time 0.187 (0.171)	Data 0.0156 (0.0195)	Loss 1.4912 (3.4590)	
Epoch: [22][50/345]	Time 0.156 (0.171)	Data 0.0157 (0.0191)	Loss 2.1456 (3.3288)	
Epoch: [22][60/345]	Time 0.172 (0.172)	Data 0.0156 (0.0196)	Loss 2.5635 (3.2696)	
Epoch: [22][70/345]	Time 0.172 (0.172)	Data 0.0156 (0.0192)	Loss 3.6919 (3.2577)	
Epoch: [22][80/345]	Time 0.188 (0.172)	Data 0.0000 (0.0188)	Loss 2.8040 (3.1737)	
Epoch: [22][90/345]	Time 0.172 (0.173)	Data 0.0156 (0.0188)	Loss 2.4241 (3.1462)	
Epoch: [22][100/345]	Time 0.203 (0.173)	Data 0.0156 (0.0185)	Loss 2.5864 (3.0884)	
Epoch: [22][110/345]	Time 0.156 (0.173)	Data 0.0156 (0.0183)	Loss 3.5809 (3.0785)	
Epoch: [22][120/345]	Time 0.156 (0.173)	Data 0.0000 (0.0183)	Loss 2.9845 (3.0658)	
Epoch: [22][130/345]	Time 0.187 (0.173)	Data 0.0156 (0.0182)	Loss 4.1019 (3.0742)	
Epoch: [22][140/345]	Time 0.172 (0.174)	Data 0.0156 (0.0182)	Loss 2.7593 (3.0435)	
Epoch: [22][150/345]	Time 0.172 (0.174)	Data 0.0156 (0.0182)	Loss 3.3901 (3.0310)	
Epoch: [22][160/345]	Time 0.219 (0.174)	Data 0.0312 (0.0182)	Loss 2.9955 (2.9975)	
Epoch: [22][170/345]	Time 0.172 (0.174)	Data 0.0156 (0.0180)	Loss 2.5444 (2.9577)	
Epoch: [22][180/345]	Time 0.156 (0.174)	Data 0.0156 (0.0180)	Loss 2.4612 (2.9274)	
Epoch: [22][190/345]	Time 0.172 (0.174)	Data 0.0156 (0.0180)	Loss 1.7846 (2.9006)	
Epoch: [22][200/345]	Time 0.156 (0.174)	Data 0.0156 (0.0182)	Loss 2.9374 (2.8993)	
Epoch: [22][210/345]	Time 0.172 (0.174)	Data 0.0154 (0.0180)	Loss 2.2196 (2.8674)	
Epoch: [22][220/345]	Time 0.156 (0.174)	Data 0.0156 (0.0181)	Loss 1.8691 (2.8427)	
Epoch: [22][230/345]	Time 0.156 (0.173)	Data 0.0156 (0.0180)	Loss 1.8128 (2.8176)	
Epoch: [22][240/345]	Time 0.156 (0.173)	Data 0.0156 (0.0180)	Loss 3.7510 (2.7913)	
Epoch: [22][250/345]	Time 0.172 (0.173)	Data 0.0156 (0.0180)	Loss 2.3753 (2.7690)	
Epoch: [22][260/345]	Time 0.172 (0.173)	Data 0.0156 (0.0179)	Loss 2.0767 (2.7410)	
Epoch: [22][270/345]	Time 0.172 (0.173)	Data 0.0312 (0.0178)	Loss 2.3115 (2.7286)	
Epoch: [22][280/345]	Time 0.156 (0.173)	Data 0.0156 (0.0179)	Loss 3.6110 (2.7135)	
Epoch: [22][290/345]	Time 0.187 (0.173)	Data 0.0156 (0.0179)	Loss 2.1868 (2.6943)	
Epoch: [22][300/345]	Time 0.203 (0.174)	Data 0.0156 (0.0177)	Loss 2.0526 (2.6846)	
Epoch: [22][310/345]	Time 0.172 (0.174)	Data 0.0156 (0.0177)	Loss 1.9407 (2.6632)	
Epoch: [22][320/345]	Time 0.187 (0.174)	Data 0.0160 (0.0176)	Loss 2.1781 (2.6380)	
Epoch: [22][330/345]	Time 0.156 (0.174)	Data 0.0156 (0.0176)	Loss 1.8744 (2.6097)	
Epoch: [22][340/345]	Time 0.172 (0.174)	Data 0.0316 (0.0175)	Loss 2.0661 (2.5874)	
22
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Epoch: [23][10/345]	Time 0.156 (0.180)	Data 0.0156 (0.0187)	Loss 2.6878 (3.4145)	
Epoch: [23][20/345]	Time 0.219 (0.178)	Data 0.0160 (0.0164)	Loss 3.5381 (3.4350)	
Epoch: [23][30/345]	Time 0.172 (0.177)	Data 0.0000 (0.0156)	Loss 2.6899 (3.1976)	
Epoch: [23][40/345]	Time 0.172 (0.180)	Data 0.0316 (0.0172)	Loss 2.1071 (3.1589)	
Epoch: [23][50/345]	Time 0.174 (0.181)	Data 0.0156 (0.0178)	Loss 2.5180 (3.1521)	
Epoch: [23][60/345]	Time 0.187 (0.181)	Data 0.0156 (0.0177)	Loss 2.9451 (3.1840)	
Epoch: [23][70/345]	Time 0.156 (0.180)	Data 0.0156 (0.0174)	Loss 3.0028 (3.0923)	
Epoch: [23][80/345]	Time 0.172 (0.179)	Data 0.0312 (0.0174)	Loss 2.8781 (3.1494)	
Epoch: [23][90/345]	Time 0.156 (0.178)	Data 0.0156 (0.0169)	Loss 1.6633 (3.1202)	
Epoch: [23][100/345]	Time 0.172 (0.178)	Data 0.0156 (0.0172)	Loss 3.5073 (3.1128)	
Epoch: [23][110/345]	Time 0.187 (0.179)	Data 0.0156 (0.0174)	Loss 3.9237 (3.1178)	
Epoch: [23][120/345]	Time 0.187 (0.179)	Data 0.0156 (0.0173)	Loss 3.0401 (3.0640)	
Epoch: [23][130/345]	Time 0.172 (0.179)	Data 0.0156 (0.0176)	Loss 1.8316 (3.0099)	
Epoch: [23][140/345]	Time 0.172 (0.179)	Data 0.0156 (0.0175)	Loss 2.5216 (2.9914)	
Epoch: [23][150/345]	Time 0.171 (0.179)	Data 0.0153 (0.0174)	Loss 2.9665 (2.9619)	
Epoch: [23][160/345]	Time 0.156 (0.179)	Data 0.0156 (0.0173)	Loss 2.1534 (2.9156)	
Epoch: [23][170/345]	Time 0.172 (0.179)	Data 0.0156 (0.0173)	Loss 2.7116 (2.9005)	
Epoch: [23][180/345]	Time 0.156 (0.179)	Data 0.0156 (0.0172)	Loss 2.1165 (2.8578)	
Epoch: [23][190/345]	Time 0.203 (0.180)	Data 0.0156 (0.0171)	Loss 2.2948 (2.8260)	
Epoch: [23][200/345]	Time 0.187 (0.180)	Data 0.0156 (0.0170)	Loss 2.2844 (2.8065)	
Epoch: [23][210/345]	Time 0.187 (0.180)	Data 0.0156 (0.0171)	Loss 2.1204 (2.7813)	
Epoch: [23][220/345]	Time 0.188 (0.180)	Data 0.0156 (0.0172)	Loss 3.0898 (2.7549)	
Epoch: [23][230/345]	Time 0.188 (0.181)	Data 0.0156 (0.0172)	Loss 2.1982 (2.7240)	
Epoch: [23][240/345]	Time 0.203 (0.181)	Data 0.0155 (0.0174)	Loss 2.4734 (2.7181)	
Epoch: [23][250/345]	Time 0.190 (0.181)	Data 0.0156 (0.0173)	Loss 2.4504 (2.7057)	
Epoch: [23][260/345]	Time 0.172 (0.182)	Data 0.0156 (0.0173)	Loss 1.7451 (2.6863)	
Epoch: [23][270/345]	Time 0.188 (0.182)	Data 0.0156 (0.0173)	Loss 1.4462 (2.6637)	
Epoch: [23][280/345]	Time 0.187 (0.182)	Data 0.0156 (0.0173)	Loss 2.7732 (2.6400)	
Epoch: [23][290/345]	Time 0.187 (0.182)	Data 0.0154 (0.0173)	Loss 2.3700 (2.6200)	
Epoch: [23][300/345]	Time 0.172 (0.182)	Data 0.0156 (0.0173)	Loss 2.2353 (2.6023)	
Epoch: [23][310/345]	Time 0.188 (0.182)	Data 0.0156 (0.0173)	Loss 1.3789 (2.5773)	
Epoch: [23][320/345]	Time 0.187 (0.182)	Data 0.0156 (0.0173)	Loss 1.6667 (2.5668)	
Epoch: [23][330/345]	Time 0.172 (0.182)	Data 0.0312 (0.0174)	Loss 1.6724 (2.5479)	
Epoch: [23][340/345]	Time 0.172 (0.182)	Data 0.0000 (0.0172)	Loss 2.0825 (2.5242)	
23
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [24][10/345]	Time 0.406 (0.381)	Data 0.0313 (0.0172)	Loss 4.4144 (4.4103)	
Epoch: [24][20/345]	Time 0.345 (0.377)	Data 0.0156 (0.0172)	Loss 3.0718 (3.9216)	
Epoch: [24][30/345]	Time 0.391 (0.379)	Data 0.0156 (0.0167)	Loss 4.9496 (3.8888)	
Epoch: [24][40/345]	Time 0.359 (0.380)	Data 0.0156 (0.0176)	Loss 2.0098 (3.7682)	
Epoch: [24][50/345]	Time 0.375 (0.380)	Data 0.0156 (0.0175)	Loss 2.7707 (3.7061)	
Epoch: [24][60/345]	Time 0.359 (0.380)	Data 0.0156 (0.0180)	Loss 3.0846 (3.6841)	
Epoch: [24][70/345]	Time 0.377 (0.382)	Data 0.0472 (0.0188)	Loss 3.6359 (3.6914)	
Epoch: [24][80/345]	Time 0.391 (0.382)	Data 0.0156 (0.0190)	Loss 3.6868 (3.6648)	
Epoch: [24][90/345]	Time 0.391 (0.381)	Data 0.0156 (0.0193)	Loss 3.6447 (3.6066)	
Epoch: [24][100/345]	Time 0.375 (0.381)	Data 0.0316 (0.0191)	Loss 2.3820 (3.5876)	
Epoch: [24][110/345]	Time 0.375 (0.380)	Data 0.0156 (0.0192)	Loss 2.4349 (3.5654)	
Epoch: [24][120/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 3.5219 (3.5329)	
Epoch: [24][130/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 4.2139 (3.5238)	
Epoch: [24][140/345]	Time 0.375 (0.378)	Data 0.0156 (0.0194)	Loss 3.3260 (3.4986)	
Epoch: [24][150/345]	Time 0.391 (0.378)	Data 0.0316 (0.0196)	Loss 3.1038 (3.4653)	
Epoch: [24][160/345]	Time 0.328 (0.378)	Data 0.0156 (0.0198)	Loss 2.3593 (3.4246)	
Epoch: [24][170/345]	Time 0.391 (0.378)	Data 0.0156 (0.0196)	Loss 2.3055 (3.3819)	
Epoch: [24][180/345]	Time 0.359 (0.377)	Data 0.0156 (0.0193)	Loss 3.7264 (3.3456)	
Epoch: [24][190/345]	Time 0.359 (0.377)	Data 0.0156 (0.0193)	Loss 3.7956 (3.3277)	
Epoch: [24][200/345]	Time 0.422 (0.377)	Data 0.0156 (0.0194)	Loss 2.2086 (3.3044)	
Epoch: [24][210/345]	Time 0.375 (0.377)	Data 0.0156 (0.0193)	Loss 2.2835 (3.2684)	
Epoch: [24][220/345]	Time 0.423 (0.377)	Data 0.0156 (0.0193)	Loss 2.1294 (3.2277)	
Epoch: [24][230/345]	Time 0.375 (0.376)	Data 0.0156 (0.0192)	Loss 3.3934 (3.2143)	
Epoch: [24][240/345]	Time 0.391 (0.376)	Data 0.0472 (0.0194)	Loss 2.5763 (3.1900)	
Epoch: [24][250/345]	Time 0.375 (0.375)	Data 0.0312 (0.0194)	Loss 2.2029 (3.1625)	
Epoch: [24][260/345]	Time 0.359 (0.375)	Data 0.0156 (0.0194)	Loss 2.0524 (3.1365)	
Epoch: [24][270/345]	Time 0.344 (0.375)	Data 0.0156 (0.0196)	Loss 2.1187 (3.1084)	
Epoch: [24][280/345]	Time 0.359 (0.374)	Data 0.0156 (0.0197)	Loss 2.7415 (3.0864)	
Epoch: [24][290/345]	Time 0.359 (0.374)	Data 0.0316 (0.0199)	Loss 2.3009 (3.0686)	
Epoch: [24][300/345]	Time 0.360 (0.374)	Data 0.0156 (0.0199)	Loss 2.3459 (3.0465)	
Epoch: [24][310/345]	Time 0.359 (0.374)	Data 0.0316 (0.0200)	Loss 2.2372 (3.0194)	
Epoch: [24][320/345]	Time 0.359 (0.373)	Data 0.0156 (0.0199)	Loss 2.6417 (2.9921)	
Epoch: [24][330/345]	Time 0.361 (0.373)	Data 0.0000 (0.0198)	Loss 2.2215 (2.9643)	
Epoch: [24][340/345]	Time 0.360 (0.373)	Data 0.0316 (0.0199)	Loss 1.8488 (2.9423)	
24
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [25][10/345]	Time 0.359 (0.381)	Data 0.0156 (0.0203)	Loss 4.4352 (3.2559)	
Epoch: [25][20/345]	Time 0.406 (0.374)	Data 0.0156 (0.0187)	Loss 4.5650 (3.5426)	
Epoch: [25][30/345]	Time 0.344 (0.374)	Data 0.0156 (0.0203)	Loss 3.5108 (3.4119)	
Epoch: [25][40/345]	Time 0.391 (0.378)	Data 0.0156 (0.0203)	Loss 3.6518 (3.5293)	
Epoch: [25][50/345]	Time 0.375 (0.377)	Data 0.0312 (0.0197)	Loss 3.3583 (3.5365)	
Epoch: [25][60/345]	Time 0.406 (0.378)	Data 0.0156 (0.0195)	Loss 3.5629 (3.4504)	
Epoch: [25][70/345]	Time 0.375 (0.378)	Data 0.0156 (0.0194)	Loss 2.6223 (3.4271)	
Epoch: [25][80/345]	Time 0.359 (0.378)	Data 0.0156 (0.0195)	Loss 3.9803 (3.4231)	
Epoch: [25][90/345]	Time 0.375 (0.377)	Data 0.0156 (0.0198)	Loss 2.3758 (3.4029)	
Epoch: [25][100/345]	Time 0.375 (0.378)	Data 0.0312 (0.0203)	Loss 3.8344 (3.3807)	
Epoch: [25][110/345]	Time 0.344 (0.379)	Data 0.0156 (0.0206)	Loss 3.1760 (3.3789)	
Epoch: [25][120/345]	Time 0.375 (0.379)	Data 0.0156 (0.0206)	Loss 3.1514 (3.3512)	
Epoch: [25][130/345]	Time 0.328 (0.378)	Data 0.0000 (0.0208)	Loss 3.1793 (3.3435)	
Epoch: [25][140/345]	Time 0.360 (0.377)	Data 0.0156 (0.0206)	Loss 4.0603 (3.3093)	
Epoch: [25][150/345]	Time 0.422 (0.377)	Data 0.0312 (0.0204)	Loss 2.9843 (3.2656)	
Epoch: [25][160/345]	Time 0.375 (0.378)	Data 0.0156 (0.0202)	Loss 2.6118 (3.2357)	
Epoch: [25][170/345]	Time 0.375 (0.378)	Data 0.0156 (0.0202)	Loss 1.9844 (3.2471)	
Epoch: [25][180/345]	Time 0.360 (0.377)	Data 0.0156 (0.0203)	Loss 2.5206 (3.2267)	
Epoch: [25][190/345]	Time 0.328 (0.377)	Data 0.0156 (0.0201)	Loss 3.3697 (3.1904)	
Epoch: [25][200/345]	Time 0.406 (0.377)	Data 0.0316 (0.0202)	Loss 2.7319 (3.1594)	
Epoch: [25][210/345]	Time 0.359 (0.377)	Data 0.0156 (0.0202)	Loss 2.1543 (3.1276)	
Epoch: [25][220/345]	Time 0.360 (0.377)	Data 0.0156 (0.0202)	Loss 2.7189 (3.0882)	
Epoch: [25][230/345]	Time 0.375 (0.377)	Data 0.0156 (0.0202)	Loss 2.1202 (3.0653)	
Epoch: [25][240/345]	Time 0.344 (0.376)	Data 0.0156 (0.0202)	Loss 2.4174 (3.0432)	
Epoch: [25][250/345]	Time 0.391 (0.376)	Data 0.0156 (0.0202)	Loss 3.0030 (3.0133)	
Epoch: [25][260/345]	Time 0.359 (0.376)	Data 0.0316 (0.0202)	Loss 2.8199 (2.9976)	
Epoch: [25][270/345]	Time 0.360 (0.376)	Data 0.0156 (0.0202)	Loss 2.1334 (2.9741)	
Epoch: [25][280/345]	Time 0.375 (0.375)	Data 0.0312 (0.0203)	Loss 1.8262 (2.9564)	
Epoch: [25][290/345]	Time 0.359 (0.375)	Data 0.0156 (0.0203)	Loss 1.9343 (2.9299)	
Epoch: [25][300/345]	Time 0.344 (0.375)	Data 0.0316 (0.0203)	Loss 2.2151 (2.9142)	
Epoch: [25][310/345]	Time 0.375 (0.374)	Data 0.0156 (0.0202)	Loss 2.9076 (2.8947)	
Epoch: [25][320/345]	Time 0.328 (0.374)	Data 0.0156 (0.0203)	Loss 1.8921 (2.8754)	
Epoch: [25][330/345]	Time 0.359 (0.374)	Data 0.0316 (0.0205)	Loss 2.0984 (2.8472)	
Epoch: [25][340/345]	Time 0.406 (0.374)	Data 0.0472 (0.0206)	Loss 1.8735 (2.8216)	
25
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [26][10/345]	Time 0.359 (0.380)	Data 0.0156 (0.0251)	Loss 2.2550 (3.0874)	
Epoch: [26][20/345]	Time 0.344 (0.379)	Data 0.0156 (0.0243)	Loss 2.2316 (3.2737)	
Epoch: [26][30/345]	Time 0.359 (0.375)	Data 0.0156 (0.0219)	Loss 4.1440 (3.3836)	
Epoch: [26][40/345]	Time 0.375 (0.374)	Data 0.0156 (0.0211)	Loss 2.8978 (3.4519)	
Epoch: [26][50/345]	Time 0.359 (0.372)	Data 0.0157 (0.0206)	Loss 3.4939 (3.4645)	
Epoch: [26][60/345]	Time 0.359 (0.373)	Data 0.0156 (0.0203)	Loss 3.7648 (3.4260)	
Epoch: [26][70/345]	Time 0.375 (0.374)	Data 0.0156 (0.0201)	Loss 3.0086 (3.3914)	
Epoch: [26][80/345]	Time 0.391 (0.375)	Data 0.0156 (0.0199)	Loss 2.7915 (3.3250)	
Epoch: [26][90/345]	Time 0.375 (0.376)	Data 0.0312 (0.0203)	Loss 2.4315 (3.2669)	
Epoch: [26][100/345]	Time 0.391 (0.375)	Data 0.0312 (0.0202)	Loss 2.5808 (3.2418)	
Epoch: [26][110/345]	Time 0.391 (0.376)	Data 0.0156 (0.0200)	Loss 3.4047 (3.2054)	
Epoch: [26][120/345]	Time 0.359 (0.376)	Data 0.0156 (0.0203)	Loss 2.6187 (3.1914)	
Epoch: [26][130/345]	Time 0.375 (0.375)	Data 0.0156 (0.0201)	Loss 3.0294 (3.1728)	
Epoch: [26][140/345]	Time 0.440 (0.376)	Data 0.0312 (0.0201)	Loss 3.3994 (3.1597)	
Epoch: [26][150/345]	Time 0.391 (0.376)	Data 0.0156 (0.0199)	Loss 1.6329 (3.1311)	
Epoch: [26][160/345]	Time 0.328 (0.376)	Data 0.0156 (0.0197)	Loss 2.7358 (3.1217)	
Epoch: [26][170/345]	Time 0.406 (0.375)	Data 0.0316 (0.0199)	Loss 2.3213 (3.1115)	
Epoch: [26][180/345]	Time 0.359 (0.375)	Data 0.0160 (0.0197)	Loss 2.6716 (3.0939)	
Epoch: [26][190/345]	Time 0.359 (0.375)	Data 0.0156 (0.0199)	Loss 2.1770 (3.0887)	
Epoch: [26][200/345]	Time 0.328 (0.374)	Data 0.0156 (0.0197)	Loss 3.2527 (3.0807)	
Epoch: [26][210/345]	Time 0.359 (0.374)	Data 0.0312 (0.0198)	Loss 3.6355 (3.0632)	
Epoch: [26][220/345]	Time 0.328 (0.373)	Data 0.0156 (0.0198)	Loss 2.8073 (3.0412)	
Epoch: [26][230/345]	Time 0.375 (0.374)	Data 0.0312 (0.0197)	Loss 2.0912 (3.0123)	
Epoch: [26][240/345]	Time 0.359 (0.374)	Data 0.0156 (0.0197)	Loss 2.0554 (2.9870)	
Epoch: [26][250/345]	Time 0.375 (0.374)	Data 0.0156 (0.0197)	Loss 2.9306 (2.9630)	
Epoch: [26][260/345]	Time 0.359 (0.374)	Data 0.0156 (0.0196)	Loss 2.8665 (2.9479)	
Epoch: [26][270/345]	Time 0.377 (0.374)	Data 0.0313 (0.0195)	Loss 2.4206 (2.9217)	
Epoch: [26][280/345]	Time 0.391 (0.375)	Data 0.0156 (0.0195)	Loss 2.8898 (2.9066)	
Epoch: [26][290/345]	Time 0.360 (0.374)	Data 0.0156 (0.0194)	Loss 3.0168 (2.8910)	
Epoch: [26][300/345]	Time 0.406 (0.374)	Data 0.0312 (0.0195)	Loss 1.9732 (2.8687)	
Epoch: [26][310/345]	Time 0.360 (0.374)	Data 0.0156 (0.0193)	Loss 2.0593 (2.8484)	
Epoch: [26][320/345]	Time 0.406 (0.374)	Data 0.0156 (0.0193)	Loss 1.8910 (2.8192)	
Epoch: [26][330/345]	Time 0.406 (0.374)	Data 0.0312 (0.0194)	Loss 2.5268 (2.7968)	
Epoch: [26][340/345]	Time 0.328 (0.374)	Data 0.0156 (0.0192)	Loss 2.1428 (2.7746)	
26
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [27][10/345]	Time 0.376 (0.388)	Data 0.0156 (0.0235)	Loss 1.8391 (3.3412)	
Epoch: [27][20/345]	Time 0.391 (0.383)	Data 0.0156 (0.0219)	Loss 4.0131 (3.4822)	
Epoch: [27][30/345]	Time 0.343 (0.381)	Data 0.0154 (0.0198)	Loss 2.2787 (3.4329)	
Epoch: [27][40/345]	Time 0.375 (0.382)	Data 0.0156 (0.0199)	Loss 4.3184 (3.4263)	
Epoch: [27][50/345]	Time 0.359 (0.380)	Data 0.0156 (0.0203)	Loss 3.3915 (3.4256)	
Epoch: [27][60/345]	Time 0.360 (0.378)	Data 0.0316 (0.0203)	Loss 3.2756 (3.4315)	
Epoch: [27][70/345]	Time 0.375 (0.378)	Data 0.0160 (0.0194)	Loss 4.0413 (3.4539)	
Epoch: [27][80/345]	Time 0.359 (0.378)	Data 0.0156 (0.0203)	Loss 2.9437 (3.3720)	
Epoch: [27][90/345]	Time 0.391 (0.379)	Data 0.0156 (0.0200)	Loss 2.4886 (3.3593)	
Epoch: [27][100/345]	Time 0.375 (0.379)	Data 0.0156 (0.0200)	Loss 3.3488 (3.3038)	
Epoch: [27][110/345]	Time 0.422 (0.379)	Data 0.0312 (0.0199)	Loss 3.1071 (3.3030)	
Epoch: [27][120/345]	Time 0.344 (0.379)	Data 0.0156 (0.0196)	Loss 3.4120 (3.2737)	
Epoch: [27][130/345]	Time 0.391 (0.379)	Data 0.0156 (0.0196)	Loss 3.3327 (3.2470)	
Epoch: [27][140/345]	Time 0.390 (0.379)	Data 0.0312 (0.0192)	Loss 2.9582 (3.2252)	
Epoch: [27][150/345]	Time 0.359 (0.378)	Data 0.0160 (0.0190)	Loss 3.1365 (3.2038)	
Epoch: [27][160/345]	Time 0.406 (0.379)	Data 0.0156 (0.0194)	Loss 2.1430 (3.1802)	
Epoch: [27][170/345]	Time 0.391 (0.379)	Data 0.0316 (0.0192)	Loss 2.6065 (3.1511)	
Epoch: [27][180/345]	Time 0.376 (0.379)	Data 0.0156 (0.0192)	Loss 2.1592 (3.1154)	
Epoch: [27][190/345]	Time 0.375 (0.379)	Data 0.0157 (0.0193)	Loss 2.6844 (3.0864)	
Epoch: [27][200/345]	Time 0.375 (0.379)	Data 0.0156 (0.0193)	Loss 1.9239 (3.0587)	
Epoch: [27][210/345]	Time 0.375 (0.379)	Data 0.0156 (0.0192)	Loss 2.0473 (3.0281)	
Epoch: [27][220/345]	Time 0.359 (0.379)	Data 0.0156 (0.0194)	Loss 2.0349 (2.9984)	
Epoch: [27][230/345]	Time 0.438 (0.380)	Data 0.0156 (0.0193)	Loss 2.2632 (2.9781)	
Epoch: [27][240/345]	Time 0.375 (0.380)	Data 0.0156 (0.0193)	Loss 1.9237 (2.9535)	
Epoch: [27][250/345]	Time 0.437 (0.381)	Data 0.0156 (0.0194)	Loss 2.3095 (2.9297)	
Epoch: [27][260/345]	Time 0.375 (0.381)	Data 0.0153 (0.0193)	Loss 2.2600 (2.9088)	
Epoch: [27][270/345]	Time 0.391 (0.381)	Data 0.0316 (0.0193)	Loss 2.7665 (2.8866)	
Epoch: [27][280/345]	Time 0.344 (0.380)	Data 0.0156 (0.0193)	Loss 2.7882 (2.8753)	
Epoch: [27][290/345]	Time 0.359 (0.380)	Data 0.0156 (0.0193)	Loss 2.1016 (2.8585)	
Epoch: [27][300/345]	Time 0.406 (0.380)	Data 0.0156 (0.0193)	Loss 2.3221 (2.8374)	
Epoch: [27][310/345]	Time 0.391 (0.380)	Data 0.0156 (0.0193)	Loss 3.3964 (2.8140)	
Epoch: [27][320/345]	Time 0.406 (0.380)	Data 0.0312 (0.0193)	Loss 1.8225 (2.7887)	
Epoch: [27][330/345]	Time 0.375 (0.380)	Data 0.0156 (0.0194)	Loss 2.0412 (2.7666)	
Epoch: [27][340/345]	Time 0.391 (0.380)	Data 0.0000 (0.0193)	Loss 1.7252 (2.7412)	
27
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [28][10/345]	Time 0.406 (0.386)	Data 0.0156 (0.0219)	Loss 2.9289 (3.6242)	
Epoch: [28][20/345]	Time 0.391 (0.383)	Data 0.0000 (0.0203)	Loss 3.5015 (3.5832)	
Epoch: [28][30/345]	Time 0.391 (0.382)	Data 0.0157 (0.0204)	Loss 3.9914 (3.5485)	
Epoch: [28][40/345]	Time 0.375 (0.381)	Data 0.0000 (0.0192)	Loss 3.2263 (3.4870)	
Epoch: [28][50/345]	Time 0.375 (0.380)	Data 0.0156 (0.0191)	Loss 2.4695 (3.4218)	
Epoch: [28][60/345]	Time 0.406 (0.381)	Data 0.0156 (0.0191)	Loss 3.6873 (3.3893)	
Epoch: [28][70/345]	Time 0.391 (0.382)	Data 0.0000 (0.0188)	Loss 3.7946 (3.4191)	
Epoch: [28][80/345]	Time 0.360 (0.381)	Data 0.0156 (0.0186)	Loss 2.2313 (3.3385)	
Epoch: [28][90/345]	Time 0.375 (0.380)	Data 0.0156 (0.0191)	Loss 2.2408 (3.2848)	
Epoch: [28][100/345]	Time 0.359 (0.380)	Data 0.0156 (0.0194)	Loss 3.1636 (3.2732)	
Epoch: [28][110/345]	Time 0.328 (0.380)	Data 0.0156 (0.0196)	Loss 4.1688 (3.2393)	
Epoch: [28][120/345]	Time 0.391 (0.380)	Data 0.0312 (0.0194)	Loss 3.5756 (3.2107)	
Epoch: [28][130/345]	Time 0.344 (0.379)	Data 0.0156 (0.0194)	Loss 3.4367 (3.1741)	
Epoch: [28][140/345]	Time 0.344 (0.379)	Data 0.0156 (0.0195)	Loss 3.3420 (3.1357)	
Epoch: [28][150/345]	Time 0.375 (0.378)	Data 0.0156 (0.0193)	Loss 3.6355 (3.1102)	
Epoch: [28][160/345]	Time 0.422 (0.379)	Data 0.0312 (0.0197)	Loss 3.5889 (3.0878)	
Epoch: [28][170/345]	Time 0.406 (0.379)	Data 0.0156 (0.0197)	Loss 2.1158 (3.0598)	
Epoch: [28][180/345]	Time 0.375 (0.379)	Data 0.0312 (0.0197)	Loss 3.0475 (3.0407)	
Epoch: [28][190/345]	Time 0.406 (0.378)	Data 0.0156 (0.0195)	Loss 2.0787 (3.0144)	
Epoch: [28][200/345]	Time 0.344 (0.379)	Data 0.0156 (0.0197)	Loss 2.5404 (2.9884)	
Epoch: [28][210/345]	Time 0.422 (0.378)	Data 0.0313 (0.0197)	Loss 2.3309 (2.9609)	
Epoch: [28][220/345]	Time 0.375 (0.378)	Data 0.0156 (0.0196)	Loss 1.9194 (2.9427)	
Epoch: [28][230/345]	Time 0.359 (0.378)	Data 0.0156 (0.0198)	Loss 1.9728 (2.9202)	
Epoch: [28][240/345]	Time 0.360 (0.378)	Data 0.0156 (0.0199)	Loss 1.6977 (2.8917)	
Epoch: [28][250/345]	Time 0.359 (0.377)	Data 0.0000 (0.0198)	Loss 1.7574 (2.8807)	
Epoch: [28][260/345]	Time 0.392 (0.377)	Data 0.0156 (0.0197)	Loss 2.3763 (2.8630)	
Epoch: [28][270/345]	Time 0.375 (0.377)	Data 0.0000 (0.0198)	Loss 2.4155 (2.8438)	
Epoch: [28][280/345]	Time 0.391 (0.377)	Data 0.0156 (0.0197)	Loss 2.4455 (2.8243)	
Epoch: [28][290/345]	Time 0.406 (0.377)	Data 0.0156 (0.0196)	Loss 1.7047 (2.8022)	
Epoch: [28][300/345]	Time 0.375 (0.377)	Data 0.0156 (0.0195)	Loss 1.9804 (2.7814)	
Epoch: [28][310/345]	Time 0.359 (0.377)	Data 0.0156 (0.0195)	Loss 1.8112 (2.7579)	
Epoch: [28][320/345]	Time 0.391 (0.377)	Data 0.0156 (0.0197)	Loss 1.9962 (2.7323)	
Epoch: [28][330/345]	Time 0.422 (0.378)	Data 0.0316 (0.0197)	Loss 1.8861 (2.7050)	
Epoch: [28][340/345]	Time 0.375 (0.378)	Data 0.0316 (0.0197)	Loss 1.7756 (2.6842)	
28
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [29][10/345]	Time 0.376 (0.380)	Data 0.0000 (0.0219)	Loss 3.8442 (3.5251)	
Epoch: [29][20/345]	Time 0.375 (0.377)	Data 0.0156 (0.0188)	Loss 2.6085 (3.6294)	
Epoch: [29][30/345]	Time 0.437 (0.380)	Data 0.0156 (0.0193)	Loss 1.7675 (3.5023)	
Epoch: [29][40/345]	Time 0.391 (0.378)	Data 0.0156 (0.0192)	Loss 2.3909 (3.5352)	
Epoch: [29][50/345]	Time 0.360 (0.378)	Data 0.0312 (0.0194)	Loss 2.9127 (3.4157)	
Epoch: [29][60/345]	Time 0.391 (0.378)	Data 0.0156 (0.0196)	Loss 2.0639 (3.3289)	
Epoch: [29][70/345]	Time 0.360 (0.378)	Data 0.0156 (0.0199)	Loss 2.6249 (3.2960)	
Epoch: [29][80/345]	Time 0.422 (0.378)	Data 0.0156 (0.0200)	Loss 4.4731 (3.2678)	
Epoch: [29][90/345]	Time 0.375 (0.379)	Data 0.0469 (0.0200)	Loss 3.6200 (3.2646)	
Epoch: [29][100/345]	Time 0.328 (0.378)	Data 0.0156 (0.0199)	Loss 3.9530 (3.2837)	
Epoch: [29][110/345]	Time 0.360 (0.376)	Data 0.0316 (0.0200)	Loss 2.6240 (3.2387)	
Epoch: [29][120/345]	Time 0.391 (0.378)	Data 0.0156 (0.0199)	Loss 2.4839 (3.1936)	
Epoch: [29][130/345]	Time 0.344 (0.377)	Data 0.0156 (0.0197)	Loss 3.0598 (3.1850)	
Epoch: [29][140/345]	Time 0.344 (0.376)	Data 0.0312 (0.0200)	Loss 2.6187 (3.1425)	
Epoch: [29][150/345]	Time 0.391 (0.377)	Data 0.0472 (0.0202)	Loss 2.3890 (3.1096)	
Epoch: [29][160/345]	Time 0.406 (0.378)	Data 0.0156 (0.0202)	Loss 2.2516 (3.0970)	
Epoch: [29][170/345]	Time 0.359 (0.377)	Data 0.0316 (0.0202)	Loss 2.4896 (3.0653)	
Epoch: [29][180/345]	Time 0.377 (0.377)	Data 0.0160 (0.0199)	Loss 1.8877 (3.0318)	
Epoch: [29][190/345]	Time 0.359 (0.377)	Data 0.0153 (0.0201)	Loss 2.6849 (3.0084)	
Epoch: [29][200/345]	Time 0.328 (0.377)	Data 0.0156 (0.0201)	Loss 2.0729 (2.9848)	
Epoch: [29][210/345]	Time 0.391 (0.377)	Data 0.0312 (0.0202)	Loss 2.4294 (2.9533)	
Epoch: [29][220/345]	Time 0.375 (0.377)	Data 0.0156 (0.0201)	Loss 3.4739 (2.9359)	
Epoch: [29][230/345]	Time 0.344 (0.376)	Data 0.0157 (0.0200)	Loss 2.0502 (2.9114)	
Epoch: [29][240/345]	Time 0.375 (0.376)	Data 0.0156 (0.0201)	Loss 2.1253 (2.8853)	
Epoch: [29][250/345]	Time 0.360 (0.376)	Data 0.0000 (0.0201)	Loss 2.0237 (2.8709)	
Epoch: [29][260/345]	Time 0.406 (0.376)	Data 0.0312 (0.0201)	Loss 2.5496 (2.8435)	
Epoch: [29][270/345]	Time 0.422 (0.376)	Data 0.0155 (0.0202)	Loss 2.0700 (2.8292)	
Epoch: [29][280/345]	Time 0.391 (0.376)	Data 0.0316 (0.0201)	Loss 2.4319 (2.8088)	
Epoch: [29][290/345]	Time 0.375 (0.376)	Data 0.0312 (0.0202)	Loss 2.3155 (2.7889)	
Epoch: [29][300/345]	Time 0.391 (0.376)	Data 0.0312 (0.0202)	Loss 1.8681 (2.7671)	
Epoch: [29][310/345]	Time 0.390 (0.376)	Data 0.0155 (0.0201)	Loss 1.8022 (2.7429)	
Epoch: [29][320/345]	Time 0.376 (0.376)	Data 0.0156 (0.0201)	Loss 2.4255 (2.7218)	
Epoch: [29][330/345]	Time 0.375 (0.376)	Data 0.0156 (0.0200)	Loss 1.9499 (2.6968)	
Epoch: [29][340/345]	Time 0.391 (0.376)	Data 0.0156 (0.0199)	Loss 1.6022 (2.6724)	
29
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [30][10/345]	Time 0.437 (0.399)	Data 0.0316 (0.0219)	Loss 2.9614 (3.5521)	
Epoch: [30][20/345]	Time 0.406 (0.391)	Data 0.0156 (0.0211)	Loss 3.5504 (3.4548)	
Epoch: [30][30/345]	Time 0.375 (0.386)	Data 0.0312 (0.0209)	Loss 3.9206 (3.3992)	
Epoch: [30][40/345]	Time 0.375 (0.383)	Data 0.0156 (0.0207)	Loss 2.4186 (3.2279)	
Epoch: [30][50/345]	Time 0.406 (0.381)	Data 0.0312 (0.0203)	Loss 1.8891 (3.1750)	
Epoch: [30][60/345]	Time 0.345 (0.382)	Data 0.0156 (0.0203)	Loss 3.3480 (3.1275)	
Epoch: [30][70/345]	Time 0.359 (0.381)	Data 0.0156 (0.0201)	Loss 3.5289 (3.1611)	
Epoch: [30][80/345]	Time 0.375 (0.380)	Data 0.0000 (0.0197)	Loss 3.9340 (3.1698)	
Epoch: [30][90/345]	Time 0.375 (0.381)	Data 0.0156 (0.0200)	Loss 2.8050 (3.1702)	
Epoch: [30][100/345]	Time 0.375 (0.380)	Data 0.0156 (0.0195)	Loss 2.4248 (3.1549)	
Epoch: [30][110/345]	Time 0.344 (0.379)	Data 0.0156 (0.0193)	Loss 3.1379 (3.1027)	
Epoch: [30][120/345]	Time 0.359 (0.379)	Data 0.0156 (0.0191)	Loss 2.1884 (3.0537)	
Epoch: [30][130/345]	Time 0.391 (0.380)	Data 0.0316 (0.0195)	Loss 3.4874 (3.0478)	
Epoch: [30][140/345]	Time 0.359 (0.379)	Data 0.0156 (0.0192)	Loss 2.0119 (3.0115)	
Epoch: [30][150/345]	Time 0.359 (0.378)	Data 0.0156 (0.0192)	Loss 2.1566 (2.9947)	
Epoch: [30][160/345]	Time 0.375 (0.379)	Data 0.0312 (0.0191)	Loss 2.5293 (2.9746)	
Epoch: [30][170/345]	Time 0.390 (0.379)	Data 0.0155 (0.0190)	Loss 1.8561 (2.9441)	
Epoch: [30][180/345]	Time 0.391 (0.380)	Data 0.0156 (0.0189)	Loss 1.9587 (2.9421)	
Epoch: [30][190/345]	Time 0.360 (0.380)	Data 0.0156 (0.0189)	Loss 3.0498 (2.9104)	
Epoch: [30][200/345]	Time 0.360 (0.379)	Data 0.0156 (0.0188)	Loss 3.0095 (2.8880)	
Epoch: [30][210/345]	Time 0.406 (0.379)	Data 0.0316 (0.0189)	Loss 2.3613 (2.8591)	
Epoch: [30][220/345]	Time 0.359 (0.379)	Data 0.0156 (0.0190)	Loss 2.1946 (2.8527)	
Epoch: [30][230/345]	Time 0.407 (0.379)	Data 0.0312 (0.0190)	Loss 1.8463 (2.8428)	
Epoch: [30][240/345]	Time 0.344 (0.378)	Data 0.0156 (0.0191)	Loss 2.4920 (2.8177)	
Epoch: [30][250/345]	Time 0.328 (0.378)	Data 0.0156 (0.0191)	Loss 2.1036 (2.8048)	
Epoch: [30][260/345]	Time 0.359 (0.378)	Data 0.0156 (0.0191)	Loss 1.8321 (2.7723)	
Epoch: [30][270/345]	Time 0.359 (0.377)	Data 0.0156 (0.0192)	Loss 2.6865 (2.7517)	
Epoch: [30][280/345]	Time 0.375 (0.377)	Data 0.0312 (0.0193)	Loss 2.4151 (2.7321)	
Epoch: [30][290/345]	Time 0.328 (0.377)	Data 0.0156 (0.0194)	Loss 1.9066 (2.7151)	
Epoch: [30][300/345]	Time 0.391 (0.377)	Data 0.0156 (0.0192)	Loss 3.3305 (2.6980)	
Epoch: [30][310/345]	Time 0.406 (0.377)	Data 0.0156 (0.0192)	Loss 1.9281 (2.6818)	
Epoch: [30][320/345]	Time 0.422 (0.377)	Data 0.0316 (0.0193)	Loss 1.6117 (2.6653)	
Epoch: [30][330/345]	Time 0.375 (0.378)	Data 0.0156 (0.0193)	Loss 1.8312 (2.6422)	
Epoch: [30][340/345]	Time 0.359 (0.377)	Data 0.0156 (0.0193)	Loss 1.6221 (2.6193)	
30
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [31][10/345]	Time 0.359 (0.386)	Data 0.0156 (0.0266)	Loss 2.8001 (3.5582)	
Epoch: [31][20/345]	Time 0.359 (0.381)	Data 0.0316 (0.0219)	Loss 2.2444 (3.3781)	
Epoch: [31][30/345]	Time 0.359 (0.379)	Data 0.0157 (0.0214)	Loss 4.0344 (3.4167)	
Epoch: [31][40/345]	Time 0.391 (0.381)	Data 0.0156 (0.0203)	Loss 2.6387 (3.4747)	
Epoch: [31][50/345]	Time 0.375 (0.379)	Data 0.0156 (0.0197)	Loss 3.3164 (3.4658)	
Epoch: [31][60/345]	Time 0.375 (0.381)	Data 0.0312 (0.0198)	Loss 3.1227 (3.3754)	
Epoch: [31][70/345]	Time 0.359 (0.380)	Data 0.0156 (0.0201)	Loss 2.5287 (3.2602)	
Epoch: [31][80/345]	Time 0.344 (0.378)	Data 0.0156 (0.0197)	Loss 2.4612 (3.2314)	
Epoch: [31][90/345]	Time 0.406 (0.378)	Data 0.0313 (0.0200)	Loss 3.9774 (3.1879)	
Epoch: [31][100/345]	Time 0.375 (0.377)	Data 0.0156 (0.0197)	Loss 3.3348 (3.1764)	
Epoch: [31][110/345]	Time 0.359 (0.377)	Data 0.0153 (0.0202)	Loss 2.7017 (3.1226)	
Epoch: [31][120/345]	Time 0.361 (0.377)	Data 0.0156 (0.0199)	Loss 3.5165 (3.0839)	
Epoch: [31][130/345]	Time 0.344 (0.376)	Data 0.0000 (0.0197)	Loss 2.4283 (3.0269)	
Epoch: [31][140/345]	Time 0.375 (0.377)	Data 0.0156 (0.0198)	Loss 2.6343 (3.0001)	
Epoch: [31][150/345]	Time 0.375 (0.377)	Data 0.0157 (0.0196)	Loss 3.0836 (2.9827)	
Epoch: [31][160/345]	Time 0.391 (0.377)	Data 0.0316 (0.0197)	Loss 2.2669 (2.9515)	
Epoch: [31][170/345]	Time 0.406 (0.376)	Data 0.0156 (0.0198)	Loss 2.7570 (2.9314)	
Epoch: [31][180/345]	Time 0.344 (0.377)	Data 0.0156 (0.0197)	Loss 1.8831 (2.9109)	
Epoch: [31][190/345]	Time 0.391 (0.377)	Data 0.0312 (0.0197)	Loss 2.3079 (2.9109)	
Epoch: [31][200/345]	Time 0.375 (0.377)	Data 0.0316 (0.0197)	Loss 2.5548 (2.8911)	
Epoch: [31][210/345]	Time 0.359 (0.377)	Data 0.0156 (0.0197)	Loss 1.9221 (2.8685)	
Epoch: [31][220/345]	Time 0.391 (0.377)	Data 0.0156 (0.0196)	Loss 2.4940 (2.8651)	
Epoch: [31][230/345]	Time 0.375 (0.377)	Data 0.0312 (0.0194)	Loss 2.5231 (2.8499)	
Epoch: [31][240/345]	Time 0.375 (0.377)	Data 0.0156 (0.0194)	Loss 2.4436 (2.8324)	
Epoch: [31][250/345]	Time 0.375 (0.377)	Data 0.0312 (0.0195)	Loss 1.5356 (2.8089)	
Epoch: [31][260/345]	Time 0.406 (0.377)	Data 0.0156 (0.0196)	Loss 2.1856 (2.7839)	
Epoch: [31][270/345]	Time 0.392 (0.376)	Data 0.0312 (0.0193)	Loss 2.2586 (2.7636)	
Epoch: [31][280/345]	Time 0.391 (0.376)	Data 0.0156 (0.0193)	Loss 2.0384 (2.7411)	
Epoch: [31][290/345]	Time 0.375 (0.376)	Data 0.0316 (0.0194)	Loss 1.8592 (2.7159)	
Epoch: [31][300/345]	Time 0.391 (0.376)	Data 0.0312 (0.0196)	Loss 1.9664 (2.6929)	
Epoch: [31][310/345]	Time 0.406 (0.375)	Data 0.0312 (0.0197)	Loss 2.6206 (2.6707)	
Epoch: [31][320/345]	Time 0.359 (0.375)	Data 0.0156 (0.0197)	Loss 1.7833 (2.6427)	
Epoch: [31][330/345]	Time 0.359 (0.375)	Data 0.0156 (0.0197)	Loss 1.5788 (2.6178)	
Epoch: [31][340/345]	Time 0.391 (0.375)	Data 0.0312 (0.0198)	Loss 1.6367 (2.5960)	
31
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [32][10/345]	Time 0.361 (0.372)	Data 0.0000 (0.0156)	Loss 3.7097 (3.9152)	
Epoch: [32][20/345]	Time 0.406 (0.375)	Data 0.0316 (0.0196)	Loss 3.5645 (3.6946)	
Epoch: [32][30/345]	Time 0.437 (0.378)	Data 0.0316 (0.0188)	Loss 4.0625 (3.5100)	
Epoch: [32][40/345]	Time 0.360 (0.375)	Data 0.0156 (0.0188)	Loss 4.2693 (3.4891)	
Epoch: [32][50/345]	Time 0.375 (0.374)	Data 0.0316 (0.0191)	Loss 3.2762 (3.3029)	
Epoch: [32][60/345]	Time 0.359 (0.376)	Data 0.0000 (0.0183)	Loss 2.1728 (3.2717)	
Epoch: [32][70/345]	Time 0.391 (0.376)	Data 0.0316 (0.0177)	Loss 2.5413 (3.1768)	
Epoch: [32][80/345]	Time 0.360 (0.377)	Data 0.0312 (0.0184)	Loss 3.5187 (3.1654)	
Epoch: [32][90/345]	Time 0.344 (0.376)	Data 0.0156 (0.0184)	Loss 2.7314 (3.1434)	
Epoch: [32][100/345]	Time 0.359 (0.375)	Data 0.0156 (0.0183)	Loss 2.5280 (3.1457)	
Epoch: [32][110/345]	Time 0.359 (0.376)	Data 0.0312 (0.0189)	Loss 2.0440 (3.1159)	
Epoch: [32][120/345]	Time 0.375 (0.376)	Data 0.0156 (0.0190)	Loss 2.9786 (3.0844)	
Epoch: [32][130/345]	Time 0.375 (0.376)	Data 0.0312 (0.0191)	Loss 2.6019 (3.0482)	
Epoch: [32][140/345]	Time 0.359 (0.375)	Data 0.0156 (0.0191)	Loss 2.0733 (3.0255)	
Epoch: [32][150/345]	Time 0.375 (0.375)	Data 0.0156 (0.0191)	Loss 2.4354 (2.9884)	
Epoch: [32][160/345]	Time 0.344 (0.373)	Data 0.0000 (0.0190)	Loss 2.6992 (2.9775)	
Epoch: [32][170/345]	Time 0.359 (0.373)	Data 0.0156 (0.0189)	Loss 2.6628 (2.9533)	
Epoch: [32][180/345]	Time 0.360 (0.373)	Data 0.0156 (0.0191)	Loss 2.3897 (2.9367)	
Epoch: [32][190/345]	Time 0.344 (0.372)	Data 0.0156 (0.0190)	Loss 1.9080 (2.8917)	
Epoch: [32][200/345]	Time 0.343 (0.372)	Data 0.0153 (0.0192)	Loss 1.9572 (2.8669)	
Epoch: [32][210/345]	Time 0.344 (0.372)	Data 0.0156 (0.0192)	Loss 2.2713 (2.8461)	
Epoch: [32][220/345]	Time 0.375 (0.372)	Data 0.0312 (0.0193)	Loss 3.0596 (2.8156)	
Epoch: [32][230/345]	Time 0.360 (0.372)	Data 0.0316 (0.0194)	Loss 1.8545 (2.7964)	
Epoch: [32][240/345]	Time 0.344 (0.372)	Data 0.0156 (0.0195)	Loss 2.5953 (2.7785)	
Epoch: [32][250/345]	Time 0.359 (0.371)	Data 0.0156 (0.0194)	Loss 2.0537 (2.7558)	
Epoch: [32][260/345]	Time 0.438 (0.372)	Data 0.0312 (0.0196)	Loss 2.0754 (2.7297)	
Epoch: [32][270/345]	Time 0.375 (0.372)	Data 0.0472 (0.0198)	Loss 1.9519 (2.7044)	
Epoch: [32][280/345]	Time 0.376 (0.372)	Data 0.0156 (0.0196)	Loss 1.6054 (2.6835)	
Epoch: [32][290/345]	Time 0.391 (0.372)	Data 0.0156 (0.0196)	Loss 1.9590 (2.6600)	
Epoch: [32][300/345]	Time 0.328 (0.371)	Data 0.0156 (0.0199)	Loss 1.9304 (2.6465)	
Epoch: [32][310/345]	Time 0.390 (0.371)	Data 0.0309 (0.0199)	Loss 1.7128 (2.6237)	
Epoch: [32][320/345]	Time 0.375 (0.371)	Data 0.0160 (0.0200)	Loss 1.7832 (2.6041)	
Epoch: [32][330/345]	Time 0.328 (0.371)	Data 0.0156 (0.0199)	Loss 1.6582 (2.5794)	
Epoch: [32][340/345]	Time 0.406 (0.371)	Data 0.0156 (0.0198)	Loss 1.4130 (2.5538)	
32
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [33][10/345]	Time 0.359 (0.358)	Data 0.0156 (0.0204)	Loss 3.2200 (3.5207)	
Epoch: [33][20/345]	Time 0.422 (0.366)	Data 0.0309 (0.0227)	Loss 3.4301 (3.3718)	
Epoch: [33][30/345]	Time 0.359 (0.367)	Data 0.0156 (0.0230)	Loss 3.9285 (3.4277)	
Epoch: [33][40/345]	Time 0.375 (0.368)	Data 0.0312 (0.0231)	Loss 3.1977 (3.3669)	
Epoch: [33][50/345]	Time 0.359 (0.367)	Data 0.0156 (0.0219)	Loss 3.3386 (3.3195)	
Epoch: [33][60/345]	Time 0.360 (0.369)	Data 0.0156 (0.0222)	Loss 2.6003 (3.2796)	
Epoch: [33][70/345]	Time 0.375 (0.371)	Data 0.0156 (0.0214)	Loss 2.7591 (3.2350)	
Epoch: [33][80/345]	Time 0.375 (0.373)	Data 0.0156 (0.0215)	Loss 2.3767 (3.1943)	
Epoch: [33][90/345]	Time 0.422 (0.376)	Data 0.0312 (0.0219)	Loss 2.9093 (3.1170)	
Epoch: [33][100/345]	Time 0.406 (0.377)	Data 0.0312 (0.0222)	Loss 5.0483 (3.1169)	
Epoch: [33][110/345]	Time 0.359 (0.376)	Data 0.0000 (0.0215)	Loss 3.5079 (3.0837)	
Epoch: [33][120/345]	Time 0.375 (0.376)	Data 0.0155 (0.0214)	Loss 2.7294 (3.0254)	
Epoch: [33][130/345]	Time 0.391 (0.377)	Data 0.0312 (0.0214)	Loss 2.0048 (2.9847)	
Epoch: [33][140/345]	Time 0.375 (0.376)	Data 0.0156 (0.0211)	Loss 1.8389 (2.9672)	
Epoch: [33][150/345]	Time 0.391 (0.375)	Data 0.0312 (0.0211)	Loss 2.7850 (2.9391)	
Epoch: [33][160/345]	Time 0.391 (0.377)	Data 0.0156 (0.0210)	Loss 1.9303 (2.9081)	
Epoch: [33][170/345]	Time 0.359 (0.376)	Data 0.0156 (0.0211)	Loss 2.6482 (2.8821)	
Epoch: [33][180/345]	Time 0.375 (0.377)	Data 0.0156 (0.0208)	Loss 3.3673 (2.8488)	
Epoch: [33][190/345]	Time 0.375 (0.377)	Data 0.0156 (0.0207)	Loss 2.7208 (2.8238)	
Epoch: [33][200/345]	Time 0.360 (0.377)	Data 0.0160 (0.0206)	Loss 2.6716 (2.8044)	
Epoch: [33][210/345]	Time 0.359 (0.377)	Data 0.0156 (0.0206)	Loss 3.8316 (2.8014)	
Epoch: [33][220/345]	Time 0.344 (0.377)	Data 0.0156 (0.0205)	Loss 2.1517 (2.7801)	
Epoch: [33][230/345]	Time 0.360 (0.377)	Data 0.0156 (0.0203)	Loss 3.3591 (2.7626)	
Epoch: [33][240/345]	Time 0.359 (0.377)	Data 0.0156 (0.0203)	Loss 1.8361 (2.7494)	
Epoch: [33][250/345]	Time 0.359 (0.377)	Data 0.0156 (0.0202)	Loss 1.9957 (2.7295)	
Epoch: [33][260/345]	Time 0.375 (0.377)	Data 0.0156 (0.0202)	Loss 2.5212 (2.7124)	
Epoch: [33][270/345]	Time 0.390 (0.377)	Data 0.0153 (0.0202)	Loss 1.6930 (2.6897)	
Epoch: [33][280/345]	Time 0.360 (0.377)	Data 0.0156 (0.0202)	Loss 1.8067 (2.6696)	
Epoch: [33][290/345]	Time 0.344 (0.377)	Data 0.0156 (0.0201)	Loss 2.0180 (2.6456)	
Epoch: [33][300/345]	Time 0.406 (0.377)	Data 0.0156 (0.0200)	Loss 1.9281 (2.6254)	
Epoch: [33][310/345]	Time 0.359 (0.377)	Data 0.0156 (0.0199)	Loss 1.7394 (2.6067)	
Epoch: [33][320/345]	Time 0.375 (0.377)	Data 0.0312 (0.0200)	Loss 1.7432 (2.5852)	
Epoch: [33][330/345]	Time 0.376 (0.377)	Data 0.0156 (0.0200)	Loss 1.9848 (2.5619)	
Epoch: [33][340/345]	Time 0.375 (0.377)	Data 0.0156 (0.0199)	Loss 1.8074 (2.5339)	
33
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [34][10/345]	Time 0.359 (0.386)	Data 0.0156 (0.0172)	Loss 3.3289 (3.4953)	
Epoch: [34][20/345]	Time 0.375 (0.380)	Data 0.0156 (0.0172)	Loss 4.5499 (3.4114)	
Epoch: [34][30/345]	Time 0.359 (0.380)	Data 0.0156 (0.0182)	Loss 2.3659 (3.2104)	
Epoch: [34][40/345]	Time 0.422 (0.383)	Data 0.0156 (0.0184)	Loss 2.3257 (3.0699)	
Epoch: [34][50/345]	Time 0.422 (0.384)	Data 0.0156 (0.0185)	Loss 2.3559 (3.0969)	
Epoch: [34][60/345]	Time 0.360 (0.382)	Data 0.0000 (0.0182)	Loss 3.7138 (3.0787)	
Epoch: [34][70/345]	Time 0.375 (0.384)	Data 0.0157 (0.0183)	Loss 3.8413 (3.0565)	
Epoch: [34][80/345]	Time 0.361 (0.384)	Data 0.0156 (0.0186)	Loss 2.0872 (3.0533)	
Epoch: [34][90/345]	Time 0.375 (0.384)	Data 0.0156 (0.0186)	Loss 2.6366 (3.0322)	
Epoch: [34][100/345]	Time 0.406 (0.384)	Data 0.0156 (0.0185)	Loss 2.7901 (3.0046)	
Epoch: [34][110/345]	Time 0.375 (0.384)	Data 0.0156 (0.0188)	Loss 1.6099 (2.9651)	
Epoch: [34][120/345]	Time 0.392 (0.383)	Data 0.0312 (0.0190)	Loss 2.4962 (2.9665)	
Epoch: [34][130/345]	Time 0.391 (0.382)	Data 0.0312 (0.0189)	Loss 3.7367 (2.9370)	
Epoch: [34][140/345]	Time 0.391 (0.382)	Data 0.0156 (0.0187)	Loss 4.2565 (2.9272)	
Epoch: [34][150/345]	Time 0.359 (0.382)	Data 0.0156 (0.0189)	Loss 2.3747 (2.9129)	
Epoch: [34][160/345]	Time 0.375 (0.382)	Data 0.0156 (0.0188)	Loss 2.6167 (2.9052)	
Epoch: [34][170/345]	Time 0.360 (0.381)	Data 0.0312 (0.0189)	Loss 2.5689 (2.8947)	
Epoch: [34][180/345]	Time 0.328 (0.381)	Data 0.0156 (0.0190)	Loss 1.6173 (2.8566)	
Epoch: [34][190/345]	Time 0.359 (0.380)	Data 0.0156 (0.0190)	Loss 2.0810 (2.8334)	
Epoch: [34][200/345]	Time 0.375 (0.380)	Data 0.0312 (0.0191)	Loss 2.5793 (2.8161)	
Epoch: [34][210/345]	Time 0.344 (0.380)	Data 0.0156 (0.0190)	Loss 2.0958 (2.7935)	
Epoch: [34][220/345]	Time 0.391 (0.379)	Data 0.0157 (0.0188)	Loss 2.6068 (2.7760)	
Epoch: [34][230/345]	Time 0.359 (0.379)	Data 0.0156 (0.0188)	Loss 1.9075 (2.7454)	
Epoch: [34][240/345]	Time 0.375 (0.379)	Data 0.0312 (0.0188)	Loss 1.6685 (2.7148)	
Epoch: [34][250/345]	Time 0.406 (0.379)	Data 0.0156 (0.0188)	Loss 1.9497 (2.6946)	
Epoch: [34][260/345]	Time 0.360 (0.379)	Data 0.0156 (0.0187)	Loss 1.9961 (2.6786)	
Epoch: [34][270/345]	Time 0.392 (0.379)	Data 0.0156 (0.0190)	Loss 2.1867 (2.6603)	
Epoch: [34][280/345]	Time 0.422 (0.379)	Data 0.0316 (0.0191)	Loss 2.0777 (2.6380)	
Epoch: [34][290/345]	Time 0.391 (0.379)	Data 0.0312 (0.0191)	Loss 2.0458 (2.6223)	
Epoch: [34][300/345]	Time 0.360 (0.379)	Data 0.0156 (0.0193)	Loss 2.0542 (2.5983)	
Epoch: [34][310/345]	Time 0.328 (0.379)	Data 0.0156 (0.0192)	Loss 1.7352 (2.5745)	
Epoch: [34][320/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 1.7661 (2.5549)	
Epoch: [34][330/345]	Time 0.359 (0.379)	Data 0.0156 (0.0194)	Loss 1.5608 (2.5301)	
Epoch: [34][340/345]	Time 0.375 (0.378)	Data 0.0309 (0.0196)	Loss 1.6925 (2.5010)	
34
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [35][10/345]	Time 0.390 (0.373)	Data 0.0153 (0.0171)	Loss 5.1007 (4.0021)	
Epoch: [35][20/345]	Time 0.375 (0.373)	Data 0.0156 (0.0164)	Loss 3.7871 (3.3910)	
Epoch: [35][30/345]	Time 0.375 (0.371)	Data 0.0156 (0.0161)	Loss 3.3530 (3.3057)	
Epoch: [35][40/345]	Time 0.359 (0.373)	Data 0.0156 (0.0160)	Loss 3.2334 (3.2767)	
Epoch: [35][50/345]	Time 0.375 (0.373)	Data 0.0156 (0.0169)	Loss 3.0046 (3.2626)	
Epoch: [35][60/345]	Time 0.359 (0.375)	Data 0.0156 (0.0172)	Loss 2.5987 (3.2619)	
Epoch: [35][70/345]	Time 0.391 (0.375)	Data 0.0156 (0.0179)	Loss 2.5089 (3.2172)	
Epoch: [35][80/345]	Time 0.375 (0.376)	Data 0.0312 (0.0182)	Loss 2.8642 (3.1844)	
Epoch: [35][90/345]	Time 0.359 (0.376)	Data 0.0153 (0.0184)	Loss 2.6297 (3.1750)	
Epoch: [35][100/345]	Time 0.375 (0.378)	Data 0.0316 (0.0188)	Loss 3.4752 (3.1317)	
Epoch: [35][110/345]	Time 0.375 (0.378)	Data 0.0156 (0.0183)	Loss 2.3042 (3.1211)	
Epoch: [35][120/345]	Time 0.375 (0.377)	Data 0.0000 (0.0180)	Loss 2.5056 (3.0730)	
Epoch: [35][130/345]	Time 0.344 (0.376)	Data 0.0000 (0.0178)	Loss 2.9538 (3.0446)	
Epoch: [35][140/345]	Time 0.406 (0.376)	Data 0.0156 (0.0178)	Loss 2.2418 (3.0140)	
Epoch: [35][150/345]	Time 0.359 (0.376)	Data 0.0156 (0.0177)	Loss 2.7106 (2.9773)	
Epoch: [35][160/345]	Time 0.422 (0.377)	Data 0.0156 (0.0178)	Loss 2.3018 (2.9394)	
Epoch: [35][170/345]	Time 0.406 (0.377)	Data 0.0316 (0.0179)	Loss 2.0081 (2.8992)	
Epoch: [35][180/345]	Time 0.359 (0.376)	Data 0.0156 (0.0178)	Loss 2.2293 (2.8543)	
Epoch: [35][190/345]	Time 0.406 (0.377)	Data 0.0312 (0.0179)	Loss 3.1542 (2.8271)	
Epoch: [35][200/345]	Time 0.359 (0.377)	Data 0.0156 (0.0181)	Loss 3.3286 (2.8067)	
Epoch: [35][210/345]	Time 0.378 (0.378)	Data 0.0156 (0.0182)	Loss 1.7996 (2.7832)	
Epoch: [35][220/345]	Time 0.375 (0.377)	Data 0.0312 (0.0182)	Loss 1.7705 (2.7505)	
Epoch: [35][230/345]	Time 0.406 (0.377)	Data 0.0316 (0.0182)	Loss 1.8336 (2.7259)	
Epoch: [35][240/345]	Time 0.359 (0.377)	Data 0.0156 (0.0184)	Loss 2.4332 (2.7107)	
Epoch: [35][250/345]	Time 0.359 (0.377)	Data 0.0156 (0.0185)	Loss 3.3079 (2.6978)	
Epoch: [35][260/345]	Time 0.375 (0.376)	Data 0.0312 (0.0185)	Loss 2.2315 (2.6717)	
Epoch: [35][270/345]	Time 0.375 (0.376)	Data 0.0156 (0.0186)	Loss 2.0236 (2.6472)	
Epoch: [35][280/345]	Time 0.359 (0.376)	Data 0.0156 (0.0186)	Loss 1.8329 (2.6213)	
Epoch: [35][290/345]	Time 0.391 (0.375)	Data 0.0316 (0.0186)	Loss 2.1500 (2.5981)	
Epoch: [35][300/345]	Time 0.360 (0.375)	Data 0.0156 (0.0186)	Loss 2.4444 (2.5782)	
Epoch: [35][310/345]	Time 0.344 (0.375)	Data 0.0156 (0.0186)	Loss 1.6149 (2.5511)	
Epoch: [35][320/345]	Time 0.375 (0.375)	Data 0.0156 (0.0187)	Loss 1.4693 (2.5261)	
Epoch: [35][330/345]	Time 0.344 (0.375)	Data 0.0156 (0.0186)	Loss 2.0181 (2.5047)	
Epoch: [35][340/345]	Time 0.360 (0.375)	Data 0.0156 (0.0186)	Loss 1.6598 (2.4784)	
35
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [36][10/345]	Time 0.344 (0.364)	Data 0.0156 (0.0203)	Loss 4.3129 (3.1366)	
Epoch: [36][20/345]	Time 0.391 (0.370)	Data 0.0156 (0.0195)	Loss 4.8295 (3.2935)	
Epoch: [36][30/345]	Time 0.359 (0.373)	Data 0.0156 (0.0192)	Loss 3.0449 (3.2500)	
Epoch: [36][40/345]	Time 0.406 (0.376)	Data 0.0472 (0.0199)	Loss 4.6442 (3.2897)	
Epoch: [36][50/345]	Time 0.391 (0.376)	Data 0.0312 (0.0207)	Loss 3.4633 (3.2340)	
Epoch: [36][60/345]	Time 0.375 (0.377)	Data 0.0316 (0.0206)	Loss 4.4080 (3.2004)	
Epoch: [36][70/345]	Time 0.360 (0.379)	Data 0.0156 (0.0204)	Loss 3.1458 (3.1883)	
Epoch: [36][80/345]	Time 0.375 (0.379)	Data 0.0156 (0.0204)	Loss 2.5000 (3.1729)	
Epoch: [36][90/345]	Time 0.361 (0.378)	Data 0.0156 (0.0202)	Loss 3.3077 (3.1093)	
Epoch: [36][100/345]	Time 0.375 (0.378)	Data 0.0156 (0.0202)	Loss 3.0109 (3.0628)	
Epoch: [36][110/345]	Time 0.437 (0.379)	Data 0.0312 (0.0201)	Loss 2.0290 (2.9990)	
Epoch: [36][120/345]	Time 0.423 (0.378)	Data 0.0312 (0.0200)	Loss 2.1923 (2.9482)	
Epoch: [36][130/345]	Time 0.392 (0.379)	Data 0.0156 (0.0200)	Loss 2.6325 (2.9285)	
Epoch: [36][140/345]	Time 0.406 (0.379)	Data 0.0156 (0.0199)	Loss 2.3852 (2.8968)	
Epoch: [36][150/345]	Time 0.375 (0.379)	Data 0.0316 (0.0203)	Loss 1.7077 (2.8476)	
Epoch: [36][160/345]	Time 0.375 (0.379)	Data 0.0312 (0.0205)	Loss 1.8076 (2.8173)	
Epoch: [36][170/345]	Time 0.375 (0.379)	Data 0.0156 (0.0204)	Loss 2.1600 (2.7797)	
Epoch: [36][180/345]	Time 0.344 (0.378)	Data 0.0156 (0.0204)	Loss 2.0645 (2.7579)	
Epoch: [36][190/345]	Time 0.375 (0.378)	Data 0.0156 (0.0204)	Loss 1.7582 (2.7440)	
Epoch: [36][200/345]	Time 0.312 (0.378)	Data 0.0153 (0.0204)	Loss 1.9505 (2.7278)	
Epoch: [36][210/345]	Time 0.359 (0.378)	Data 0.0156 (0.0201)	Loss 2.2343 (2.7094)	
Epoch: [36][220/345]	Time 0.391 (0.378)	Data 0.0156 (0.0202)	Loss 2.1580 (2.6900)	
Epoch: [36][230/345]	Time 0.359 (0.377)	Data 0.0316 (0.0201)	Loss 2.7472 (2.6636)	
Epoch: [36][240/345]	Time 0.391 (0.378)	Data 0.0316 (0.0202)	Loss 1.7009 (2.6546)	
Epoch: [36][250/345]	Time 0.375 (0.378)	Data 0.0156 (0.0202)	Loss 1.9635 (2.6361)	
Epoch: [36][260/345]	Time 0.375 (0.378)	Data 0.0156 (0.0202)	Loss 2.1842 (2.6154)	
Epoch: [36][270/345]	Time 0.406 (0.378)	Data 0.0156 (0.0202)	Loss 2.0755 (2.5954)	
Epoch: [36][280/345]	Time 0.359 (0.378)	Data 0.0156 (0.0202)	Loss 1.6973 (2.5741)	
Epoch: [36][290/345]	Time 0.453 (0.378)	Data 0.0156 (0.0202)	Loss 2.0057 (2.5597)	
Epoch: [36][300/345]	Time 0.391 (0.379)	Data 0.0156 (0.0202)	Loss 1.8514 (2.5431)	
Epoch: [36][310/345]	Time 0.391 (0.379)	Data 0.0156 (0.0202)	Loss 1.8173 (2.5157)	
Epoch: [36][320/345]	Time 0.375 (0.379)	Data 0.0156 (0.0203)	Loss 1.5126 (2.4945)	
Epoch: [36][330/345]	Time 0.359 (0.379)	Data 0.0155 (0.0203)	Loss 1.4433 (2.4734)	
Epoch: [36][340/345]	Time 0.359 (0.379)	Data 0.0156 (0.0204)	Loss 2.0631 (2.4530)	
36
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [37][10/345]	Time 0.360 (0.389)	Data 0.0000 (0.0187)	Loss 1.8401 (3.0818)	
Epoch: [37][20/345]	Time 0.406 (0.387)	Data 0.0156 (0.0195)	Loss 3.2611 (3.0116)	
Epoch: [37][30/345]	Time 0.391 (0.383)	Data 0.0156 (0.0177)	Loss 3.8619 (3.0143)	
Epoch: [37][40/345]	Time 0.391 (0.383)	Data 0.0156 (0.0184)	Loss 3.7526 (3.0875)	
Epoch: [37][50/345]	Time 0.375 (0.384)	Data 0.0312 (0.0191)	Loss 3.5452 (3.0339)	
Epoch: [37][60/345]	Time 0.344 (0.382)	Data 0.0156 (0.0193)	Loss 3.3824 (3.0964)	
Epoch: [37][70/345]	Time 0.375 (0.379)	Data 0.0154 (0.0192)	Loss 2.0922 (3.0393)	
Epoch: [37][80/345]	Time 0.375 (0.378)	Data 0.0156 (0.0193)	Loss 2.7056 (2.9880)	
Epoch: [37][90/345]	Time 0.391 (0.377)	Data 0.0156 (0.0193)	Loss 2.8623 (2.9798)	
Epoch: [37][100/345]	Time 0.344 (0.377)	Data 0.0000 (0.0189)	Loss 3.4409 (2.9842)	
Epoch: [37][110/345]	Time 0.391 (0.376)	Data 0.0156 (0.0188)	Loss 2.9097 (2.9660)	
Epoch: [37][120/345]	Time 0.359 (0.376)	Data 0.0312 (0.0192)	Loss 2.5544 (2.9367)	
Epoch: [37][130/345]	Time 0.359 (0.375)	Data 0.0316 (0.0191)	Loss 2.7254 (2.9375)	
Epoch: [37][140/345]	Time 0.375 (0.375)	Data 0.0316 (0.0194)	Loss 2.5931 (2.9038)	
Epoch: [37][150/345]	Time 0.375 (0.375)	Data 0.0156 (0.0194)	Loss 1.7364 (2.8720)	
Epoch: [37][160/345]	Time 0.375 (0.375)	Data 0.0156 (0.0194)	Loss 1.8653 (2.8574)	
Epoch: [37][170/345]	Time 0.375 (0.376)	Data 0.0156 (0.0192)	Loss 2.2777 (2.8361)	
Epoch: [37][180/345]	Time 0.438 (0.376)	Data 0.0316 (0.0192)	Loss 2.0195 (2.8115)	
Epoch: [37][190/345]	Time 0.361 (0.377)	Data 0.0312 (0.0193)	Loss 1.6370 (2.7766)	
Epoch: [37][200/345]	Time 0.376 (0.377)	Data 0.0156 (0.0194)	Loss 1.8123 (2.7580)	
Epoch: [37][210/345]	Time 0.359 (0.377)	Data 0.0000 (0.0197)	Loss 3.1736 (2.7348)	
Epoch: [37][220/345]	Time 0.375 (0.377)	Data 0.0156 (0.0196)	Loss 1.8480 (2.7093)	
Epoch: [37][230/345]	Time 0.422 (0.378)	Data 0.0312 (0.0197)	Loss 2.3819 (2.6799)	
Epoch: [37][240/345]	Time 0.344 (0.378)	Data 0.0000 (0.0196)	Loss 1.9918 (2.6622)	
Epoch: [37][250/345]	Time 0.359 (0.377)	Data 0.0156 (0.0195)	Loss 2.0801 (2.6434)	
Epoch: [37][260/345]	Time 0.391 (0.377)	Data 0.0156 (0.0193)	Loss 1.8321 (2.6171)	
Epoch: [37][270/345]	Time 0.359 (0.378)	Data 0.0156 (0.0192)	Loss 1.9756 (2.5940)	
Epoch: [37][280/345]	Time 0.375 (0.378)	Data 0.0156 (0.0191)	Loss 3.0344 (2.5741)	
Epoch: [37][290/345]	Time 0.375 (0.378)	Data 0.0156 (0.0190)	Loss 1.6333 (2.5446)	
Epoch: [37][300/345]	Time 0.391 (0.378)	Data 0.0312 (0.0190)	Loss 1.9516 (2.5259)	
Epoch: [37][310/345]	Time 0.406 (0.379)	Data 0.0156 (0.0190)	Loss 1.8767 (2.5036)	
Epoch: [37][320/345]	Time 0.375 (0.379)	Data 0.0156 (0.0190)	Loss 1.8238 (2.4799)	
Epoch: [37][330/345]	Time 0.375 (0.379)	Data 0.0156 (0.0191)	Loss 1.4755 (2.4542)	
Epoch: [37][340/345]	Time 0.375 (0.379)	Data 0.0156 (0.0191)	Loss 1.5447 (2.4301)	
37
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [38][10/345]	Time 0.422 (0.391)	Data 0.0156 (0.0188)	Loss 1.5335 (2.9406)	
Epoch: [38][20/345]	Time 0.406 (0.385)	Data 0.0312 (0.0188)	Loss 4.4310 (2.8762)	
Epoch: [38][30/345]	Time 0.391 (0.389)	Data 0.0316 (0.0188)	Loss 3.7714 (2.8365)	
Epoch: [38][40/345]	Time 0.359 (0.386)	Data 0.0156 (0.0196)	Loss 2.1052 (2.7725)	
Epoch: [38][50/345]	Time 0.375 (0.388)	Data 0.0153 (0.0210)	Loss 4.1220 (2.8418)	
Epoch: [38][60/345]	Time 0.391 (0.386)	Data 0.0156 (0.0206)	Loss 3.3752 (2.9300)	
Epoch: [38][70/345]	Time 0.375 (0.386)	Data 0.0312 (0.0210)	Loss 2.8160 (2.9413)	
Epoch: [38][80/345]	Time 0.375 (0.385)	Data 0.0156 (0.0215)	Loss 3.6849 (2.9394)	
Epoch: [38][90/345]	Time 0.375 (0.384)	Data 0.0155 (0.0214)	Loss 4.9787 (2.9728)	
Epoch: [38][100/345]	Time 0.375 (0.384)	Data 0.0156 (0.0210)	Loss 3.0192 (2.9236)	
Epoch: [38][110/345]	Time 0.406 (0.381)	Data 0.0156 (0.0205)	Loss 2.7389 (2.8900)	
Epoch: [38][120/345]	Time 0.375 (0.381)	Data 0.0156 (0.0208)	Loss 3.0137 (2.8601)	
Epoch: [38][130/345]	Time 0.375 (0.381)	Data 0.0156 (0.0208)	Loss 2.1183 (2.8324)	
Epoch: [38][140/345]	Time 0.359 (0.381)	Data 0.0156 (0.0205)	Loss 1.9756 (2.8016)	
Epoch: [38][150/345]	Time 0.393 (0.380)	Data 0.0156 (0.0204)	Loss 3.3104 (2.7858)	
Epoch: [38][160/345]	Time 0.359 (0.379)	Data 0.0156 (0.0204)	Loss 2.2511 (2.7652)	
Epoch: [38][170/345]	Time 0.359 (0.379)	Data 0.0156 (0.0204)	Loss 2.6625 (2.7294)	
Epoch: [38][180/345]	Time 0.406 (0.380)	Data 0.0156 (0.0206)	Loss 2.6708 (2.7222)	
Epoch: [38][190/345]	Time 0.375 (0.380)	Data 0.0156 (0.0206)	Loss 1.5870 (2.6891)	
Epoch: [38][200/345]	Time 0.391 (0.380)	Data 0.0156 (0.0203)	Loss 2.5558 (2.6692)	
Epoch: [38][210/345]	Time 0.328 (0.379)	Data 0.0000 (0.0200)	Loss 1.9065 (2.6541)	
Epoch: [38][220/345]	Time 0.406 (0.378)	Data 0.0312 (0.0199)	Loss 1.9467 (2.6400)	
Epoch: [38][230/345]	Time 0.375 (0.379)	Data 0.0312 (0.0203)	Loss 1.8300 (2.6138)	
Epoch: [38][240/345]	Time 0.359 (0.378)	Data 0.0156 (0.0203)	Loss 2.0638 (2.5914)	
Epoch: [38][250/345]	Time 0.344 (0.378)	Data 0.0156 (0.0204)	Loss 1.8379 (2.5713)	
Epoch: [38][260/345]	Time 0.375 (0.378)	Data 0.0156 (0.0204)	Loss 1.7011 (2.5511)	
Epoch: [38][270/345]	Time 0.344 (0.378)	Data 0.0156 (0.0205)	Loss 1.6880 (2.5351)	
Epoch: [38][280/345]	Time 0.359 (0.378)	Data 0.0156 (0.0204)	Loss 2.4247 (2.5187)	
Epoch: [38][290/345]	Time 0.359 (0.377)	Data 0.0000 (0.0203)	Loss 1.8986 (2.5001)	
Epoch: [38][300/345]	Time 0.376 (0.378)	Data 0.0155 (0.0204)	Loss 2.3912 (2.4844)	
Epoch: [38][310/345]	Time 0.361 (0.378)	Data 0.0316 (0.0205)	Loss 1.4215 (2.4636)	
Epoch: [38][320/345]	Time 0.344 (0.378)	Data 0.0160 (0.0203)	Loss 1.4390 (2.4425)	
Epoch: [38][330/345]	Time 0.391 (0.378)	Data 0.0316 (0.0202)	Loss 1.6241 (2.4274)	
Epoch: [38][340/345]	Time 0.406 (0.378)	Data 0.0156 (0.0202)	Loss 1.5425 (2.4029)	
38
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [39][10/345]	Time 0.359 (0.385)	Data 0.0156 (0.0235)	Loss 3.5138 (3.2582)	
Epoch: [39][20/345]	Time 0.359 (0.376)	Data 0.0156 (0.0212)	Loss 2.5015 (3.2308)	
Epoch: [39][30/345]	Time 0.375 (0.378)	Data 0.0156 (0.0209)	Loss 3.3824 (3.1120)	
Epoch: [39][40/345]	Time 0.375 (0.381)	Data 0.0156 (0.0196)	Loss 3.7031 (3.1279)	
Epoch: [39][50/345]	Time 0.437 (0.382)	Data 0.0156 (0.0194)	Loss 1.8565 (3.0649)	
Epoch: [39][60/345]	Time 0.375 (0.382)	Data 0.0316 (0.0196)	Loss 1.6490 (2.9745)	
Epoch: [39][70/345]	Time 0.375 (0.384)	Data 0.0156 (0.0206)	Loss 2.1184 (2.9658)	
Epoch: [39][80/345]	Time 0.391 (0.383)	Data 0.0316 (0.0206)	Loss 2.5918 (2.9401)	
Epoch: [39][90/345]	Time 0.391 (0.383)	Data 0.0312 (0.0207)	Loss 4.8993 (2.9098)	
Epoch: [39][100/345]	Time 0.375 (0.383)	Data 0.0156 (0.0208)	Loss 3.3863 (2.8795)	
Epoch: [39][110/345]	Time 0.375 (0.382)	Data 0.0000 (0.0204)	Loss 2.5035 (2.8317)	
Epoch: [39][120/345]	Time 0.359 (0.382)	Data 0.0000 (0.0200)	Loss 4.7594 (2.8446)	
Epoch: [39][130/345]	Time 0.391 (0.383)	Data 0.0156 (0.0196)	Loss 2.8067 (2.8131)	
Epoch: [39][140/345]	Time 0.391 (0.383)	Data 0.0312 (0.0200)	Loss 3.0531 (2.8134)	
Epoch: [39][150/345]	Time 0.391 (0.382)	Data 0.0156 (0.0198)	Loss 3.1604 (2.7982)	
Epoch: [39][160/345]	Time 0.343 (0.381)	Data 0.0153 (0.0198)	Loss 2.2811 (2.7871)	
Epoch: [39][170/345]	Time 0.391 (0.382)	Data 0.0156 (0.0200)	Loss 1.8403 (2.7595)	
Epoch: [39][180/345]	Time 0.375 (0.382)	Data 0.0153 (0.0201)	Loss 2.3042 (2.7318)	
Epoch: [39][190/345]	Time 0.391 (0.382)	Data 0.0156 (0.0199)	Loss 2.0978 (2.7116)	
Epoch: [39][200/345]	Time 0.359 (0.381)	Data 0.0312 (0.0198)	Loss 2.3334 (2.6798)	
Epoch: [39][210/345]	Time 0.375 (0.382)	Data 0.0154 (0.0197)	Loss 2.3020 (2.6540)	
Epoch: [39][220/345]	Time 0.406 (0.381)	Data 0.0156 (0.0197)	Loss 2.7977 (2.6318)	
Epoch: [39][230/345]	Time 0.359 (0.381)	Data 0.0156 (0.0197)	Loss 2.2873 (2.6053)	
Epoch: [39][240/345]	Time 0.375 (0.381)	Data 0.0156 (0.0197)	Loss 1.8956 (2.5818)	
Epoch: [39][250/345]	Time 0.377 (0.381)	Data 0.0170 (0.0194)	Loss 1.9518 (2.5540)	
Epoch: [39][260/345]	Time 0.375 (0.381)	Data 0.0156 (0.0196)	Loss 2.2424 (2.5317)	
Epoch: [39][270/345]	Time 0.391 (0.380)	Data 0.0156 (0.0195)	Loss 2.4436 (2.5175)	
Epoch: [39][280/345]	Time 0.359 (0.380)	Data 0.0000 (0.0196)	Loss 1.9953 (2.4976)	
Epoch: [39][290/345]	Time 0.391 (0.380)	Data 0.0157 (0.0195)	Loss 1.5767 (2.4720)	
Epoch: [39][300/345]	Time 0.391 (0.380)	Data 0.0156 (0.0195)	Loss 2.5066 (2.4533)	
Epoch: [39][310/345]	Time 0.359 (0.380)	Data 0.0154 (0.0194)	Loss 1.8688 (2.4356)	
Epoch: [39][320/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 1.7370 (2.4189)	
Epoch: [39][330/345]	Time 0.359 (0.379)	Data 0.0156 (0.0193)	Loss 1.5099 (2.4011)	
Epoch: [39][340/345]	Time 0.375 (0.379)	Data 0.0156 (0.0192)	Loss 1.4849 (2.3816)	
39
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [40][10/345]	Time 0.391 (0.381)	Data 0.0312 (0.0235)	Loss 2.2872 (3.5453)	
Epoch: [40][20/345]	Time 0.425 (0.382)	Data 0.0316 (0.0219)	Loss 3.2235 (3.3764)	
Epoch: [40][30/345]	Time 0.406 (0.381)	Data 0.0156 (0.0208)	Loss 2.5322 (3.3072)	
Epoch: [40][40/345]	Time 0.375 (0.383)	Data 0.0156 (0.0211)	Loss 2.9014 (3.1669)	
Epoch: [40][50/345]	Time 0.391 (0.382)	Data 0.0312 (0.0210)	Loss 1.8498 (3.1028)	
Epoch: [40][60/345]	Time 0.391 (0.383)	Data 0.0316 (0.0216)	Loss 3.1198 (3.0900)	
Epoch: [40][70/345]	Time 0.375 (0.384)	Data 0.0312 (0.0215)	Loss 2.0127 (3.0580)	
Epoch: [40][80/345]	Time 0.344 (0.382)	Data 0.0156 (0.0213)	Loss 2.0927 (2.9972)	
Epoch: [40][90/345]	Time 0.422 (0.381)	Data 0.0156 (0.0209)	Loss 2.6557 (2.9820)	
Epoch: [40][100/345]	Time 0.359 (0.380)	Data 0.0156 (0.0208)	Loss 2.2442 (2.9522)	
Epoch: [40][110/345]	Time 0.360 (0.378)	Data 0.0000 (0.0206)	Loss 2.3875 (2.9380)	
Epoch: [40][120/345]	Time 0.391 (0.377)	Data 0.0312 (0.0207)	Loss 2.7837 (2.9194)	
Epoch: [40][130/345]	Time 0.375 (0.377)	Data 0.0312 (0.0208)	Loss 3.9018 (2.9015)	
Epoch: [40][140/345]	Time 0.328 (0.376)	Data 0.0311 (0.0211)	Loss 1.7734 (2.8538)	
Epoch: [40][150/345]	Time 0.344 (0.375)	Data 0.0156 (0.0210)	Loss 1.6200 (2.8242)	
Epoch: [40][160/345]	Time 0.375 (0.374)	Data 0.0154 (0.0209)	Loss 2.5682 (2.7932)	
Epoch: [40][170/345]	Time 0.360 (0.374)	Data 0.0156 (0.0208)	Loss 2.5020 (2.7611)	
Epoch: [40][180/345]	Time 0.344 (0.373)	Data 0.0156 (0.0206)	Loss 1.9334 (2.7258)	
Epoch: [40][190/345]	Time 0.406 (0.373)	Data 0.0312 (0.0203)	Loss 1.9799 (2.7022)	
Epoch: [40][200/345]	Time 0.406 (0.373)	Data 0.0156 (0.0202)	Loss 1.8219 (2.6688)	
Epoch: [40][210/345]	Time 0.359 (0.373)	Data 0.0000 (0.0203)	Loss 1.6726 (2.6445)	
Epoch: [40][220/345]	Time 0.375 (0.373)	Data 0.0156 (0.0202)	Loss 2.0867 (2.6314)	
Epoch: [40][230/345]	Time 0.375 (0.374)	Data 0.0156 (0.0203)	Loss 1.8143 (2.6056)	
Epoch: [40][240/345]	Time 0.375 (0.374)	Data 0.0156 (0.0203)	Loss 1.5085 (2.5779)	
Epoch: [40][250/345]	Time 0.406 (0.374)	Data 0.0156 (0.0203)	Loss 2.2712 (2.5603)	
Epoch: [40][260/345]	Time 0.344 (0.374)	Data 0.0156 (0.0203)	Loss 2.3177 (2.5358)	
Epoch: [40][270/345]	Time 0.359 (0.375)	Data 0.0000 (0.0202)	Loss 1.7280 (2.5130)	
Epoch: [40][280/345]	Time 0.375 (0.375)	Data 0.0312 (0.0203)	Loss 1.6653 (2.4906)	
Epoch: [40][290/345]	Time 0.422 (0.375)	Data 0.0316 (0.0203)	Loss 3.0878 (2.4736)	
Epoch: [40][300/345]	Time 0.361 (0.375)	Data 0.0332 (0.0204)	Loss 2.3729 (2.4563)	
Epoch: [40][310/345]	Time 0.337 (0.375)	Data 0.0156 (0.0205)	Loss 1.3924 (2.4333)	
Epoch: [40][320/345]	Time 0.359 (0.375)	Data 0.0313 (0.0206)	Loss 1.8428 (2.4150)	
Epoch: [40][330/345]	Time 0.375 (0.375)	Data 0.0156 (0.0207)	Loss 1.9235 (2.3923)	
Epoch: [40][340/345]	Time 0.360 (0.376)	Data 0.0156 (0.0207)	Loss 1.7805 (2.3693)	
40
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [41][10/345]	Time 0.391 (0.394)	Data 0.0316 (0.0235)	Loss 3.4657 (3.6338)	
Epoch: [41][20/345]	Time 0.391 (0.386)	Data 0.0312 (0.0196)	Loss 3.0094 (3.2941)	
Epoch: [41][30/345]	Time 0.375 (0.385)	Data 0.0312 (0.0203)	Loss 1.7320 (3.1949)	
Epoch: [41][40/345]	Time 0.375 (0.388)	Data 0.0156 (0.0211)	Loss 2.6320 (3.0737)	
Epoch: [41][50/345]	Time 0.375 (0.385)	Data 0.0156 (0.0200)	Loss 2.7769 (3.0398)	
Epoch: [41][60/345]	Time 0.391 (0.388)	Data 0.0316 (0.0203)	Loss 1.8162 (3.0034)	
Epoch: [41][70/345]	Time 0.361 (0.388)	Data 0.0312 (0.0208)	Loss 3.4098 (2.9821)	
Epoch: [41][80/345]	Time 0.360 (0.386)	Data 0.0156 (0.0203)	Loss 1.6641 (2.9458)	
Epoch: [41][90/345]	Time 0.375 (0.385)	Data 0.0153 (0.0207)	Loss 2.6364 (2.9104)	
Epoch: [41][100/345]	Time 0.359 (0.384)	Data 0.0156 (0.0200)	Loss 2.5006 (2.8670)	
Epoch: [41][110/345]	Time 0.359 (0.383)	Data 0.0312 (0.0203)	Loss 2.4610 (2.8266)	
Epoch: [41][120/345]	Time 0.344 (0.382)	Data 0.0156 (0.0201)	Loss 2.5597 (2.8199)	
Epoch: [41][130/345]	Time 0.359 (0.381)	Data 0.0156 (0.0198)	Loss 3.1021 (2.7993)	
Epoch: [41][140/345]	Time 0.359 (0.380)	Data 0.0316 (0.0198)	Loss 2.0526 (2.7637)	
Epoch: [41][150/345]	Time 0.375 (0.380)	Data 0.0156 (0.0198)	Loss 2.0354 (2.7373)	
Epoch: [41][160/345]	Time 0.375 (0.380)	Data 0.0156 (0.0201)	Loss 1.9835 (2.7077)	
Epoch: [41][170/345]	Time 0.359 (0.379)	Data 0.0156 (0.0201)	Loss 1.5997 (2.6735)	
Epoch: [41][180/345]	Time 0.360 (0.380)	Data 0.0156 (0.0203)	Loss 2.4956 (2.6529)	
Epoch: [41][190/345]	Time 0.437 (0.381)	Data 0.0156 (0.0201)	Loss 2.5024 (2.6365)	
Epoch: [41][200/345]	Time 0.375 (0.380)	Data 0.0156 (0.0199)	Loss 1.6237 (2.6092)	
Epoch: [41][210/345]	Time 0.391 (0.380)	Data 0.0156 (0.0197)	Loss 1.9186 (2.5809)	
Epoch: [41][220/345]	Time 0.344 (0.380)	Data 0.0312 (0.0197)	Loss 2.1374 (2.5513)	
Epoch: [41][230/345]	Time 0.361 (0.380)	Data 0.0156 (0.0198)	Loss 2.9076 (2.5418)	
Epoch: [41][240/345]	Time 0.375 (0.380)	Data 0.0156 (0.0198)	Loss 1.6448 (2.5192)	
Epoch: [41][250/345]	Time 0.375 (0.380)	Data 0.0156 (0.0199)	Loss 1.4430 (2.5015)	
Epoch: [41][260/345]	Time 0.343 (0.380)	Data 0.0154 (0.0199)	Loss 1.7139 (2.4772)	
Epoch: [41][270/345]	Time 0.359 (0.380)	Data 0.0156 (0.0198)	Loss 2.3500 (2.4619)	
Epoch: [41][280/345]	Time 0.375 (0.380)	Data 0.0156 (0.0198)	Loss 2.2963 (2.4517)	
Epoch: [41][290/345]	Time 0.344 (0.379)	Data 0.0000 (0.0195)	Loss 1.4624 (2.4285)	
Epoch: [41][300/345]	Time 0.360 (0.380)	Data 0.0156 (0.0195)	Loss 1.9035 (2.4091)	
Epoch: [41][310/345]	Time 0.359 (0.380)	Data 0.0316 (0.0196)	Loss 1.3883 (2.3835)	
Epoch: [41][320/345]	Time 0.406 (0.380)	Data 0.0156 (0.0194)	Loss 1.9510 (2.3604)	
Epoch: [41][330/345]	Time 0.391 (0.380)	Data 0.0156 (0.0194)	Loss 1.5818 (2.3356)	
Epoch: [41][340/345]	Time 0.359 (0.379)	Data 0.0156 (0.0194)	Loss 1.5381 (2.3164)	
41
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [42][10/345]	Time 0.422 (0.386)	Data 0.0156 (0.0203)	Loss 4.5474 (3.4941)	
Epoch: [42][20/345]	Time 0.391 (0.387)	Data 0.0000 (0.0203)	Loss 2.9731 (3.1742)	
Epoch: [42][30/345]	Time 0.375 (0.390)	Data 0.0156 (0.0203)	Loss 2.4844 (3.1696)	
Epoch: [42][40/345]	Time 0.359 (0.388)	Data 0.0156 (0.0211)	Loss 2.2132 (3.1087)	
Epoch: [42][50/345]	Time 0.375 (0.386)	Data 0.0156 (0.0207)	Loss 3.7713 (3.0849)	
Epoch: [42][60/345]	Time 0.406 (0.387)	Data 0.0156 (0.0203)	Loss 2.5481 (3.0093)	
Epoch: [42][70/345]	Time 0.375 (0.386)	Data 0.0156 (0.0201)	Loss 4.2680 (2.9967)	
Epoch: [42][80/345]	Time 0.375 (0.385)	Data 0.0156 (0.0199)	Loss 2.0908 (2.9560)	
Epoch: [42][90/345]	Time 0.391 (0.385)	Data 0.0156 (0.0200)	Loss 2.3483 (2.9135)	
Epoch: [42][100/345]	Time 0.359 (0.384)	Data 0.0156 (0.0196)	Loss 1.8445 (2.8788)	
Epoch: [42][110/345]	Time 0.375 (0.384)	Data 0.0316 (0.0199)	Loss 3.2353 (2.8227)	
Epoch: [42][120/345]	Time 0.375 (0.383)	Data 0.0156 (0.0201)	Loss 2.5652 (2.8036)	
Epoch: [42][130/345]	Time 0.362 (0.383)	Data 0.0000 (0.0199)	Loss 1.8161 (2.7548)	
Epoch: [42][140/345]	Time 0.375 (0.382)	Data 0.0156 (0.0200)	Loss 2.5502 (2.7225)	
Epoch: [42][150/345]	Time 0.375 (0.382)	Data 0.0156 (0.0198)	Loss 2.5154 (2.7036)	
Epoch: [42][160/345]	Time 0.391 (0.382)	Data 0.0156 (0.0199)	Loss 2.1274 (2.6914)	
Epoch: [42][170/345]	Time 0.375 (0.382)	Data 0.0153 (0.0196)	Loss 2.9609 (2.6635)	
Epoch: [42][180/345]	Time 0.359 (0.382)	Data 0.0156 (0.0195)	Loss 3.7947 (2.6474)	
Epoch: [42][190/345]	Time 0.391 (0.381)	Data 0.0156 (0.0193)	Loss 1.9347 (2.6104)	
Epoch: [42][200/345]	Time 0.359 (0.381)	Data 0.0156 (0.0193)	Loss 2.0120 (2.5774)	
Epoch: [42][210/345]	Time 0.359 (0.381)	Data 0.0156 (0.0192)	Loss 1.6659 (2.5497)	
Epoch: [42][220/345]	Time 0.359 (0.381)	Data 0.0156 (0.0193)	Loss 1.6713 (2.5257)	
Epoch: [42][230/345]	Time 0.391 (0.381)	Data 0.0312 (0.0194)	Loss 2.2723 (2.5230)	
Epoch: [42][240/345]	Time 0.359 (0.381)	Data 0.0316 (0.0196)	Loss 1.5102 (2.4989)	
Epoch: [42][250/345]	Time 0.359 (0.380)	Data 0.0156 (0.0195)	Loss 2.0318 (2.4832)	
Epoch: [42][260/345]	Time 0.375 (0.380)	Data 0.0156 (0.0195)	Loss 3.4188 (2.4662)	
Epoch: [42][270/345]	Time 0.375 (0.380)	Data 0.0000 (0.0195)	Loss 1.6558 (2.4459)	
Epoch: [42][280/345]	Time 0.359 (0.380)	Data 0.0156 (0.0195)	Loss 2.6921 (2.4275)	
Epoch: [42][290/345]	Time 0.392 (0.380)	Data 0.0156 (0.0195)	Loss 2.1180 (2.4148)	
Epoch: [42][300/345]	Time 0.391 (0.380)	Data 0.0472 (0.0194)	Loss 1.7894 (2.3908)	
Epoch: [42][310/345]	Time 0.359 (0.380)	Data 0.0155 (0.0194)	Loss 1.3187 (2.3672)	
Epoch: [42][320/345]	Time 0.375 (0.380)	Data 0.0316 (0.0195)	Loss 1.7539 (2.3455)	
Epoch: [42][330/345]	Time 0.391 (0.380)	Data 0.0312 (0.0195)	Loss 1.4857 (2.3237)	
Epoch: [42][340/345]	Time 0.391 (0.380)	Data 0.0316 (0.0195)	Loss 1.6394 (2.3023)	
42
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [43][10/345]	Time 0.391 (0.383)	Data 0.0316 (0.0188)	Loss 2.1725 (3.0031)	
Epoch: [43][20/345]	Time 0.359 (0.380)	Data 0.0316 (0.0211)	Loss 1.9767 (3.0630)	
Epoch: [43][30/345]	Time 0.391 (0.381)	Data 0.0156 (0.0214)	Loss 2.2700 (2.9291)	
Epoch: [43][40/345]	Time 0.359 (0.381)	Data 0.0156 (0.0215)	Loss 4.0039 (2.9913)	
Epoch: [43][50/345]	Time 0.406 (0.380)	Data 0.0156 (0.0207)	Loss 3.6726 (2.9963)	
Epoch: [43][60/345]	Time 0.375 (0.383)	Data 0.0156 (0.0201)	Loss 2.8048 (2.9760)	
Epoch: [43][70/345]	Time 0.359 (0.381)	Data 0.0155 (0.0190)	Loss 3.6957 (3.0125)	
Epoch: [43][80/345]	Time 0.359 (0.381)	Data 0.0157 (0.0190)	Loss 2.9222 (2.9703)	
Epoch: [43][90/345]	Time 0.422 (0.382)	Data 0.0312 (0.0191)	Loss 2.5775 (2.8935)	
Epoch: [43][100/345]	Time 0.375 (0.382)	Data 0.0156 (0.0191)	Loss 1.6660 (2.8763)	
Epoch: [43][110/345]	Time 0.438 (0.383)	Data 0.0156 (0.0196)	Loss 2.0944 (2.8270)	
Epoch: [43][120/345]	Time 0.375 (0.383)	Data 0.0156 (0.0195)	Loss 2.8958 (2.7826)	
Epoch: [43][130/345]	Time 0.359 (0.384)	Data 0.0156 (0.0194)	Loss 3.6961 (2.7583)	
Epoch: [43][140/345]	Time 0.375 (0.383)	Data 0.0156 (0.0194)	Loss 1.8275 (2.7300)	
Epoch: [43][150/345]	Time 0.359 (0.382)	Data 0.0312 (0.0197)	Loss 2.1749 (2.6896)	
Epoch: [43][160/345]	Time 0.391 (0.382)	Data 0.0156 (0.0198)	Loss 2.5960 (2.6682)	
Epoch: [43][170/345]	Time 0.344 (0.381)	Data 0.0316 (0.0197)	Loss 2.2236 (2.6341)	
Epoch: [43][180/345]	Time 0.328 (0.381)	Data 0.0157 (0.0197)	Loss 1.9343 (2.6102)	
Epoch: [43][190/345]	Time 0.344 (0.381)	Data 0.0156 (0.0197)	Loss 3.0229 (2.5906)	
Epoch: [43][200/345]	Time 0.375 (0.381)	Data 0.0000 (0.0196)	Loss 1.6752 (2.5700)	
Epoch: [43][210/345]	Time 0.344 (0.380)	Data 0.0156 (0.0197)	Loss 2.3987 (2.5469)	
Epoch: [43][220/345]	Time 0.408 (0.380)	Data 0.0158 (0.0197)	Loss 2.5446 (2.5260)	
Epoch: [43][230/345]	Time 0.391 (0.380)	Data 0.0312 (0.0197)	Loss 1.5561 (2.5058)	
Epoch: [43][240/345]	Time 0.359 (0.379)	Data 0.0313 (0.0196)	Loss 1.7378 (2.4801)	
Epoch: [43][250/345]	Time 0.375 (0.379)	Data 0.0153 (0.0195)	Loss 2.0391 (2.4562)	
Epoch: [43][260/345]	Time 0.375 (0.379)	Data 0.0156 (0.0196)	Loss 2.0406 (2.4350)	
Epoch: [43][270/345]	Time 0.391 (0.379)	Data 0.0313 (0.0196)	Loss 2.1257 (2.4169)	
Epoch: [43][280/345]	Time 0.344 (0.378)	Data 0.0157 (0.0196)	Loss 2.0840 (2.3975)	
Epoch: [43][290/345]	Time 0.344 (0.378)	Data 0.0160 (0.0197)	Loss 1.5945 (2.3795)	
Epoch: [43][300/345]	Time 0.360 (0.378)	Data 0.0312 (0.0197)	Loss 1.5095 (2.3591)	
Epoch: [43][310/345]	Time 0.391 (0.378)	Data 0.0316 (0.0197)	Loss 1.5484 (2.3377)	
Epoch: [43][320/345]	Time 0.391 (0.378)	Data 0.0312 (0.0198)	Loss 1.4962 (2.3224)	
Epoch: [43][330/345]	Time 0.406 (0.379)	Data 0.0312 (0.0198)	Loss 1.7149 (2.3030)	
Epoch: [43][340/345]	Time 0.359 (0.378)	Data 0.0156 (0.0198)	Loss 1.8984 (2.2813)	
43
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [44][10/345]	Time 0.391 (0.397)	Data 0.0156 (0.0234)	Loss 2.5773 (2.8360)	
Epoch: [44][20/345]	Time 0.391 (0.389)	Data 0.0156 (0.0227)	Loss 1.9702 (3.0681)	
Epoch: [44][30/345]	Time 0.391 (0.385)	Data 0.0156 (0.0214)	Loss 4.0570 (3.1823)	
Epoch: [44][40/345]	Time 0.344 (0.383)	Data 0.0156 (0.0211)	Loss 3.3897 (3.1937)	
Epoch: [44][50/345]	Time 0.375 (0.383)	Data 0.0156 (0.0203)	Loss 2.4294 (3.1613)	
Epoch: [44][60/345]	Time 0.422 (0.382)	Data 0.0312 (0.0203)	Loss 2.4603 (3.0256)	
Epoch: [44][70/345]	Time 0.360 (0.381)	Data 0.0156 (0.0194)	Loss 2.9534 (2.9859)	
Epoch: [44][80/345]	Time 0.375 (0.381)	Data 0.0000 (0.0190)	Loss 1.5039 (2.9169)	
Epoch: [44][90/345]	Time 0.375 (0.381)	Data 0.0156 (0.0189)	Loss 3.1927 (2.8945)	
Epoch: [44][100/345]	Time 0.391 (0.381)	Data 0.0156 (0.0191)	Loss 1.7174 (2.8570)	
Epoch: [44][110/345]	Time 0.391 (0.380)	Data 0.0156 (0.0191)	Loss 3.6658 (2.8173)	
Epoch: [44][120/345]	Time 0.375 (0.380)	Data 0.0313 (0.0193)	Loss 2.6502 (2.7926)	
Epoch: [44][130/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 2.7031 (2.7654)	
Epoch: [44][140/345]	Time 0.392 (0.379)	Data 0.0312 (0.0197)	Loss 2.6507 (2.7422)	
Epoch: [44][150/345]	Time 0.406 (0.380)	Data 0.0312 (0.0197)	Loss 2.1861 (2.7389)	
Epoch: [44][160/345]	Time 0.344 (0.379)	Data 0.0156 (0.0194)	Loss 1.9823 (2.7069)	
Epoch: [44][170/345]	Time 0.406 (0.379)	Data 0.0156 (0.0194)	Loss 2.0280 (2.6780)	
Epoch: [44][180/345]	Time 0.375 (0.379)	Data 0.0156 (0.0193)	Loss 2.0836 (2.6585)	
Epoch: [44][190/345]	Time 0.422 (0.379)	Data 0.0156 (0.0193)	Loss 1.9205 (2.6185)	
Epoch: [44][200/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 1.7772 (2.5915)	
Epoch: [44][210/345]	Time 0.359 (0.379)	Data 0.0316 (0.0196)	Loss 2.3152 (2.5614)	
Epoch: [44][220/345]	Time 0.359 (0.380)	Data 0.0156 (0.0198)	Loss 1.5248 (2.5400)	
Epoch: [44][230/345]	Time 0.375 (0.379)	Data 0.0156 (0.0197)	Loss 1.8383 (2.5097)	
Epoch: [44][240/345]	Time 0.360 (0.379)	Data 0.0156 (0.0197)	Loss 2.1100 (2.4943)	
Epoch: [44][250/345]	Time 0.375 (0.379)	Data 0.0156 (0.0196)	Loss 1.9350 (2.4704)	
Epoch: [44][260/345]	Time 0.390 (0.379)	Data 0.0153 (0.0196)	Loss 1.6988 (2.4506)	
Epoch: [44][270/345]	Time 0.391 (0.379)	Data 0.0312 (0.0195)	Loss 1.5345 (2.4288)	
Epoch: [44][280/345]	Time 0.406 (0.379)	Data 0.0316 (0.0195)	Loss 2.1675 (2.4102)	
Epoch: [44][290/345]	Time 0.375 (0.379)	Data 0.0156 (0.0195)	Loss 2.1637 (2.3887)	
Epoch: [44][300/345]	Time 0.375 (0.379)	Data 0.0316 (0.0195)	Loss 1.5076 (2.3676)	
Epoch: [44][310/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 1.9751 (2.3439)	
Epoch: [44][320/345]	Time 0.360 (0.379)	Data 0.0000 (0.0192)	Loss 1.7701 (2.3221)	
Epoch: [44][330/345]	Time 0.437 (0.379)	Data 0.0312 (0.0193)	Loss 1.8037 (2.3027)	
Epoch: [44][340/345]	Time 0.375 (0.379)	Data 0.0156 (0.0192)	Loss 1.6035 (2.2840)	
44
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [45][10/345]	Time 0.391 (0.394)	Data 0.0316 (0.0236)	Loss 3.1601 (3.2837)	
Epoch: [45][20/345]	Time 0.359 (0.388)	Data 0.0155 (0.0228)	Loss 3.1498 (3.2039)	
Epoch: [45][30/345]	Time 0.375 (0.383)	Data 0.0312 (0.0235)	Loss 2.6010 (3.0467)	
Epoch: [45][40/345]	Time 0.391 (0.384)	Data 0.0156 (0.0219)	Loss 2.5708 (3.0234)	
Epoch: [45][50/345]	Time 0.375 (0.383)	Data 0.0156 (0.0213)	Loss 3.7933 (3.0107)	
Epoch: [45][60/345]	Time 0.328 (0.381)	Data 0.0156 (0.0204)	Loss 3.2011 (2.9358)	
Epoch: [45][70/345]	Time 0.422 (0.382)	Data 0.0156 (0.0204)	Loss 3.3749 (2.9463)	
Epoch: [45][80/345]	Time 0.406 (0.382)	Data 0.0469 (0.0209)	Loss 2.7449 (2.9038)	
Epoch: [45][90/345]	Time 0.375 (0.382)	Data 0.0156 (0.0205)	Loss 1.6517 (2.8096)	
Epoch: [45][100/345]	Time 0.408 (0.382)	Data 0.0316 (0.0205)	Loss 2.1928 (2.8113)	
Epoch: [45][110/345]	Time 0.360 (0.382)	Data 0.0156 (0.0205)	Loss 2.2814 (2.7727)	
Epoch: [45][120/345]	Time 0.375 (0.382)	Data 0.0156 (0.0202)	Loss 2.0400 (2.7288)	
Epoch: [45][130/345]	Time 0.360 (0.381)	Data 0.0156 (0.0200)	Loss 1.5501 (2.6856)	
Epoch: [45][140/345]	Time 0.375 (0.381)	Data 0.0156 (0.0199)	Loss 2.3602 (2.6514)	
Epoch: [45][150/345]	Time 0.390 (0.380)	Data 0.0155 (0.0195)	Loss 1.7460 (2.6366)	
Epoch: [45][160/345]	Time 0.375 (0.380)	Data 0.0156 (0.0194)	Loss 2.3792 (2.6125)	
Epoch: [45][170/345]	Time 0.360 (0.379)	Data 0.0156 (0.0193)	Loss 1.7145 (2.5850)	
Epoch: [45][180/345]	Time 0.375 (0.379)	Data 0.0160 (0.0194)	Loss 1.5049 (2.5603)	
Epoch: [45][190/345]	Time 0.360 (0.379)	Data 0.0156 (0.0194)	Loss 1.6970 (2.5398)	
Epoch: [45][200/345]	Time 0.328 (0.378)	Data 0.0156 (0.0191)	Loss 1.7072 (2.5118)	
Epoch: [45][210/345]	Time 0.375 (0.378)	Data 0.0316 (0.0191)	Loss 2.4789 (2.4904)	
Epoch: [45][220/345]	Time 0.344 (0.378)	Data 0.0154 (0.0193)	Loss 2.0527 (2.4688)	
Epoch: [45][230/345]	Time 0.359 (0.378)	Data 0.0316 (0.0194)	Loss 2.5013 (2.4480)	
Epoch: [45][240/345]	Time 0.390 (0.378)	Data 0.0155 (0.0195)	Loss 2.0771 (2.4255)	
Epoch: [45][250/345]	Time 0.375 (0.378)	Data 0.0312 (0.0196)	Loss 1.9273 (2.4037)	
Epoch: [45][260/345]	Time 0.393 (0.378)	Data 0.0156 (0.0196)	Loss 1.6956 (2.3856)	
Epoch: [45][270/345]	Time 0.391 (0.378)	Data 0.0312 (0.0195)	Loss 1.6948 (2.3726)	
Epoch: [45][280/345]	Time 0.391 (0.378)	Data 0.0156 (0.0195)	Loss 1.6702 (2.3592)	
Epoch: [45][290/345]	Time 0.360 (0.378)	Data 0.0156 (0.0192)	Loss 2.2777 (2.3487)	
Epoch: [45][300/345]	Time 0.375 (0.378)	Data 0.0160 (0.0191)	Loss 2.1980 (2.3321)	
Epoch: [45][310/345]	Time 0.375 (0.378)	Data 0.0316 (0.0192)	Loss 1.4261 (2.3136)	
Epoch: [45][320/345]	Time 0.375 (0.378)	Data 0.0316 (0.0192)	Loss 1.6028 (2.2976)	
Epoch: [45][330/345]	Time 0.359 (0.378)	Data 0.0153 (0.0192)	Loss 1.3295 (2.2771)	
Epoch: [45][340/345]	Time 0.360 (0.378)	Data 0.0316 (0.0192)	Loss 1.4100 (2.2579)	
45
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [46][10/345]	Time 0.361 (0.361)	Data 0.0156 (0.0234)	Loss 2.0210 (2.8573)	
Epoch: [46][20/345]	Time 0.375 (0.365)	Data 0.0316 (0.0211)	Loss 3.5631 (2.9751)	
Epoch: [46][30/345]	Time 0.359 (0.366)	Data 0.0153 (0.0214)	Loss 3.0759 (2.8843)	
Epoch: [46][40/345]	Time 0.375 (0.364)	Data 0.0156 (0.0199)	Loss 3.8015 (2.8684)	
Epoch: [46][50/345]	Time 0.375 (0.367)	Data 0.0316 (0.0200)	Loss 3.4172 (2.9790)	
Epoch: [46][60/345]	Time 0.360 (0.366)	Data 0.0156 (0.0195)	Loss 1.6738 (2.9390)	
Epoch: [46][70/345]	Time 0.391 (0.368)	Data 0.0000 (0.0197)	Loss 2.5830 (2.9145)	
Epoch: [46][80/345]	Time 0.361 (0.368)	Data 0.0156 (0.0193)	Loss 3.1569 (2.9249)	
Epoch: [46][90/345]	Time 0.375 (0.370)	Data 0.0156 (0.0195)	Loss 3.3179 (2.8435)	
Epoch: [46][100/345]	Time 0.406 (0.369)	Data 0.0156 (0.0192)	Loss 2.5338 (2.8620)	
Epoch: [46][110/345]	Time 0.375 (0.371)	Data 0.0312 (0.0199)	Loss 2.0935 (2.8457)	
Epoch: [46][120/345]	Time 0.360 (0.370)	Data 0.0156 (0.0199)	Loss 1.6685 (2.7924)	
Epoch: [46][130/345]	Time 0.377 (0.370)	Data 0.0312 (0.0198)	Loss 1.7699 (2.7524)	
Epoch: [46][140/345]	Time 0.344 (0.370)	Data 0.0160 (0.0197)	Loss 2.3950 (2.7070)	
Epoch: [46][150/345]	Time 0.375 (0.370)	Data 0.0312 (0.0195)	Loss 2.2840 (2.6650)	
Epoch: [46][160/345]	Time 0.375 (0.371)	Data 0.0156 (0.0195)	Loss 1.5159 (2.6302)	
Epoch: [46][170/345]	Time 0.375 (0.371)	Data 0.0156 (0.0194)	Loss 3.3883 (2.6151)	
Epoch: [46][180/345]	Time 0.375 (0.371)	Data 0.0316 (0.0192)	Loss 1.9705 (2.6066)	
Epoch: [46][190/345]	Time 0.359 (0.372)	Data 0.0316 (0.0194)	Loss 1.9097 (2.5745)	
Epoch: [46][200/345]	Time 0.375 (0.372)	Data 0.0156 (0.0193)	Loss 1.7990 (2.5614)	
Epoch: [46][210/345]	Time 0.391 (0.372)	Data 0.0156 (0.0193)	Loss 2.0441 (2.5439)	
Epoch: [46][220/345]	Time 0.437 (0.372)	Data 0.0156 (0.0193)	Loss 1.6535 (2.5167)	
Epoch: [46][230/345]	Time 0.375 (0.372)	Data 0.0157 (0.0191)	Loss 2.4052 (2.4957)	
Epoch: [46][240/345]	Time 0.375 (0.372)	Data 0.0156 (0.0191)	Loss 2.0581 (2.4719)	
Epoch: [46][250/345]	Time 0.422 (0.372)	Data 0.0156 (0.0190)	Loss 1.6658 (2.4522)	
Epoch: [46][260/345]	Time 0.422 (0.372)	Data 0.0469 (0.0191)	Loss 1.7522 (2.4381)	
Epoch: [46][270/345]	Time 0.375 (0.372)	Data 0.0156 (0.0192)	Loss 1.9604 (2.4120)	
Epoch: [46][280/345]	Time 0.360 (0.372)	Data 0.0156 (0.0192)	Loss 1.8360 (2.3897)	
Epoch: [46][290/345]	Time 0.361 (0.372)	Data 0.0156 (0.0193)	Loss 2.3960 (2.3773)	
Epoch: [46][300/345]	Time 0.375 (0.372)	Data 0.0000 (0.0193)	Loss 1.9329 (2.3575)	
Epoch: [46][310/345]	Time 0.375 (0.372)	Data 0.0316 (0.0196)	Loss 2.3207 (2.3383)	
Epoch: [46][320/345]	Time 0.344 (0.373)	Data 0.0156 (0.0196)	Loss 1.4269 (2.3158)	
Epoch: [46][330/345]	Time 0.375 (0.373)	Data 0.0156 (0.0195)	Loss 1.4348 (2.2942)	
Epoch: [46][340/345]	Time 0.328 (0.373)	Data 0.0156 (0.0196)	Loss 1.5036 (2.2710)	
46
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [47][10/345]	Time 0.391 (0.378)	Data 0.0156 (0.0171)	Loss 1.9870 (2.8678)	
Epoch: [47][20/345]	Time 0.375 (0.380)	Data 0.0156 (0.0195)	Loss 2.9975 (3.0738)	
Epoch: [47][30/345]	Time 0.375 (0.381)	Data 0.0156 (0.0198)	Loss 2.1893 (3.0152)	
Epoch: [47][40/345]	Time 0.391 (0.380)	Data 0.0312 (0.0191)	Loss 4.3852 (3.0239)	
Epoch: [47][50/345]	Time 0.375 (0.381)	Data 0.0156 (0.0194)	Loss 2.4299 (2.9804)	
Epoch: [47][60/345]	Time 0.344 (0.381)	Data 0.0000 (0.0193)	Loss 2.1880 (2.9157)	
Epoch: [47][70/345]	Time 0.406 (0.382)	Data 0.0156 (0.0190)	Loss 2.8362 (2.8675)	
Epoch: [47][80/345]	Time 0.375 (0.381)	Data 0.0316 (0.0192)	Loss 3.6090 (2.8062)	
Epoch: [47][90/345]	Time 0.391 (0.381)	Data 0.0156 (0.0188)	Loss 3.1432 (2.7915)	
Epoch: [47][100/345]	Time 0.375 (0.381)	Data 0.0156 (0.0192)	Loss 3.0700 (2.7707)	
Epoch: [47][110/345]	Time 0.375 (0.380)	Data 0.0156 (0.0194)	Loss 2.1504 (2.7588)	
Epoch: [47][120/345]	Time 0.375 (0.380)	Data 0.0156 (0.0196)	Loss 1.9159 (2.7231)	
Epoch: [47][130/345]	Time 0.391 (0.380)	Data 0.0156 (0.0196)	Loss 2.0582 (2.7003)	
Epoch: [47][140/345]	Time 0.359 (0.379)	Data 0.0156 (0.0196)	Loss 4.2329 (2.6796)	
Epoch: [47][150/345]	Time 0.344 (0.379)	Data 0.0156 (0.0194)	Loss 3.1665 (2.6665)	
Epoch: [47][160/345]	Time 0.360 (0.379)	Data 0.0156 (0.0193)	Loss 1.6362 (2.6308)	
Epoch: [47][170/345]	Time 0.422 (0.379)	Data 0.0312 (0.0193)	Loss 2.6179 (2.5962)	
Epoch: [47][180/345]	Time 0.359 (0.380)	Data 0.0156 (0.0195)	Loss 1.9649 (2.5634)	
Epoch: [47][190/345]	Time 0.375 (0.380)	Data 0.0153 (0.0195)	Loss 2.3177 (2.5551)	
Epoch: [47][200/345]	Time 0.375 (0.379)	Data 0.0156 (0.0195)	Loss 1.8850 (2.5342)	
Epoch: [47][210/345]	Time 0.406 (0.380)	Data 0.0313 (0.0195)	Loss 1.3414 (2.5066)	
Epoch: [47][220/345]	Time 0.376 (0.379)	Data 0.0170 (0.0194)	Loss 1.9672 (2.4779)	
Epoch: [47][230/345]	Time 0.361 (0.379)	Data 0.0000 (0.0194)	Loss 2.3316 (2.4588)	
Epoch: [47][240/345]	Time 0.375 (0.380)	Data 0.0156 (0.0194)	Loss 2.1384 (2.4352)	
Epoch: [47][250/345]	Time 0.359 (0.379)	Data 0.0156 (0.0192)	Loss 1.7158 (2.4179)	
Epoch: [47][260/345]	Time 0.391 (0.380)	Data 0.0316 (0.0192)	Loss 2.0019 (2.4022)	
Epoch: [47][270/345]	Time 0.359 (0.379)	Data 0.0155 (0.0192)	Loss 1.8299 (2.3914)	
Epoch: [47][280/345]	Time 0.375 (0.380)	Data 0.0156 (0.0193)	Loss 2.1284 (2.3702)	
Epoch: [47][290/345]	Time 0.359 (0.380)	Data 0.0156 (0.0194)	Loss 1.7847 (2.3505)	
Epoch: [47][300/345]	Time 0.375 (0.380)	Data 0.0156 (0.0194)	Loss 1.4494 (2.3341)	
Epoch: [47][310/345]	Time 0.406 (0.380)	Data 0.0156 (0.0193)	Loss 1.8798 (2.3204)	
Epoch: [47][320/345]	Time 0.359 (0.380)	Data 0.0316 (0.0193)	Loss 1.7195 (2.3001)	
Epoch: [47][330/345]	Time 0.359 (0.379)	Data 0.0156 (0.0193)	Loss 1.5427 (2.2797)	
Epoch: [47][340/345]	Time 0.406 (0.379)	Data 0.0316 (0.0194)	Loss 2.0906 (2.2580)	
47
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [48][10/345]	Time 0.346 (0.392)	Data 0.0156 (0.0282)	Loss 4.1193 (3.1129)	
Epoch: [48][20/345]	Time 0.375 (0.385)	Data 0.0156 (0.0266)	Loss 3.1485 (2.9101)	
Epoch: [48][30/345]	Time 0.359 (0.378)	Data 0.0156 (0.0240)	Loss 1.5099 (2.8446)	
Epoch: [48][40/345]	Time 0.375 (0.380)	Data 0.0312 (0.0239)	Loss 2.3613 (2.8426)	
Epoch: [48][50/345]	Time 0.360 (0.380)	Data 0.0160 (0.0235)	Loss 3.2799 (2.7848)	
Epoch: [48][60/345]	Time 0.359 (0.379)	Data 0.0156 (0.0227)	Loss 1.9585 (2.8000)	
Epoch: [48][70/345]	Time 0.359 (0.378)	Data 0.0156 (0.0215)	Loss 4.2069 (2.7905)	
Epoch: [48][80/345]	Time 0.406 (0.378)	Data 0.0156 (0.0213)	Loss 2.2291 (2.7087)	
Epoch: [48][90/345]	Time 0.342 (0.377)	Data 0.0000 (0.0212)	Loss 2.8224 (2.6723)	
Epoch: [48][100/345]	Time 0.375 (0.377)	Data 0.0156 (0.0208)	Loss 3.1719 (2.7027)	
Epoch: [48][110/345]	Time 0.391 (0.377)	Data 0.0156 (0.0205)	Loss 4.1235 (2.6720)	
Epoch: [48][120/345]	Time 0.360 (0.378)	Data 0.0000 (0.0202)	Loss 2.9241 (2.6499)	
Epoch: [48][130/345]	Time 0.375 (0.377)	Data 0.0156 (0.0201)	Loss 2.3894 (2.6305)	
Epoch: [48][140/345]	Time 0.391 (0.378)	Data 0.0156 (0.0199)	Loss 2.9374 (2.6374)	
Epoch: [48][150/345]	Time 0.391 (0.378)	Data 0.0316 (0.0200)	Loss 1.8326 (2.6159)	
Epoch: [48][160/345]	Time 0.375 (0.377)	Data 0.0156 (0.0199)	Loss 1.5329 (2.5893)	
Epoch: [48][170/345]	Time 0.344 (0.377)	Data 0.0156 (0.0199)	Loss 3.1985 (2.5818)	
Epoch: [48][180/345]	Time 0.375 (0.376)	Data 0.0000 (0.0197)	Loss 2.0266 (2.5523)	
Epoch: [48][190/345]	Time 0.359 (0.375)	Data 0.0312 (0.0198)	Loss 1.7834 (2.5315)	
Epoch: [48][200/345]	Time 0.359 (0.375)	Data 0.0156 (0.0198)	Loss 1.9112 (2.5011)	
Epoch: [48][210/345]	Time 0.392 (0.374)	Data 0.0156 (0.0200)	Loss 2.2944 (2.4809)	
Epoch: [48][220/345]	Time 0.375 (0.374)	Data 0.0000 (0.0199)	Loss 1.9831 (2.4546)	
Epoch: [48][230/345]	Time 0.328 (0.373)	Data 0.0156 (0.0199)	Loss 1.3410 (2.4370)	
Epoch: [48][240/345]	Time 0.359 (0.373)	Data 0.0312 (0.0201)	Loss 1.4334 (2.4149)	
Epoch: [48][250/345]	Time 0.359 (0.373)	Data 0.0156 (0.0202)	Loss 2.6363 (2.3945)	
Epoch: [48][260/345]	Time 0.375 (0.372)	Data 0.0312 (0.0204)	Loss 2.5232 (2.3822)	
Epoch: [48][270/345]	Time 0.375 (0.372)	Data 0.0156 (0.0204)	Loss 2.1221 (2.3603)	
Epoch: [48][280/345]	Time 0.359 (0.372)	Data 0.0156 (0.0204)	Loss 2.1091 (2.3435)	
Epoch: [48][290/345]	Time 0.359 (0.372)	Data 0.0156 (0.0202)	Loss 1.3864 (2.3268)	
Epoch: [48][300/345]	Time 0.375 (0.372)	Data 0.0156 (0.0202)	Loss 1.9520 (2.3106)	
Epoch: [48][310/345]	Time 0.406 (0.372)	Data 0.0312 (0.0202)	Loss 1.4766 (2.2890)	
Epoch: [48][320/345]	Time 0.361 (0.372)	Data 0.0156 (0.0202)	Loss 1.7683 (2.2673)	
Epoch: [48][330/345]	Time 0.328 (0.372)	Data 0.0156 (0.0202)	Loss 1.7217 (2.2533)	
Epoch: [48][340/345]	Time 0.375 (0.373)	Data 0.0156 (0.0203)	Loss 1.5217 (2.2324)	
48
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [49][10/345]	Time 0.391 (0.378)	Data 0.0472 (0.0250)	Loss 2.8792 (3.1629)	
Epoch: [49][20/345]	Time 0.359 (0.370)	Data 0.0156 (0.0227)	Loss 2.6309 (2.9759)	
Epoch: [49][30/345]	Time 0.359 (0.369)	Data 0.0156 (0.0224)	Loss 3.9866 (2.9561)	
Epoch: [49][40/345]	Time 0.344 (0.368)	Data 0.0000 (0.0211)	Loss 3.4216 (2.9892)	
Epoch: [49][50/345]	Time 0.359 (0.368)	Data 0.0156 (0.0200)	Loss 3.0293 (2.9959)	
Epoch: [49][60/345]	Time 0.392 (0.369)	Data 0.0326 (0.0201)	Loss 2.9389 (2.9872)	
Epoch: [49][70/345]	Time 0.359 (0.368)	Data 0.0312 (0.0204)	Loss 1.7694 (2.9360)	
Epoch: [49][80/345]	Time 0.375 (0.369)	Data 0.0316 (0.0206)	Loss 1.8181 (2.8759)	
Epoch: [49][90/345]	Time 0.375 (0.369)	Data 0.0312 (0.0209)	Loss 2.7056 (2.8454)	
Epoch: [49][100/345]	Time 0.328 (0.370)	Data 0.0312 (0.0211)	Loss 1.6871 (2.7876)	
Epoch: [49][110/345]	Time 0.343 (0.369)	Data 0.0155 (0.0211)	Loss 2.9335 (2.7400)	
Epoch: [49][120/345]	Time 0.359 (0.369)	Data 0.0000 (0.0209)	Loss 1.8135 (2.7462)	
Epoch: [49][130/345]	Time 0.406 (0.370)	Data 0.0156 (0.0210)	Loss 1.9679 (2.7184)	
Epoch: [49][140/345]	Time 0.375 (0.370)	Data 0.0312 (0.0209)	Loss 1.5820 (2.7102)	
Epoch: [49][150/345]	Time 0.406 (0.370)	Data 0.0156 (0.0206)	Loss 1.6145 (2.6778)	
Epoch: [49][160/345]	Time 0.375 (0.370)	Data 0.0156 (0.0207)	Loss 1.6071 (2.6506)	
Epoch: [49][170/345]	Time 0.359 (0.370)	Data 0.0156 (0.0204)	Loss 2.1256 (2.6256)	
Epoch: [49][180/345]	Time 0.406 (0.371)	Data 0.0312 (0.0203)	Loss 2.0940 (2.6025)	
Epoch: [49][190/345]	Time 0.375 (0.371)	Data 0.0156 (0.0203)	Loss 2.1014 (2.5742)	
Epoch: [49][200/345]	Time 0.328 (0.371)	Data 0.0156 (0.0203)	Loss 2.1069 (2.5427)	
Epoch: [49][210/345]	Time 0.361 (0.371)	Data 0.0316 (0.0204)	Loss 2.4163 (2.5192)	
Epoch: [49][220/345]	Time 0.360 (0.372)	Data 0.0156 (0.0204)	Loss 2.9209 (2.4941)	
Epoch: [49][230/345]	Time 0.359 (0.372)	Data 0.0316 (0.0204)	Loss 2.0259 (2.4782)	
Epoch: [49][240/345]	Time 0.391 (0.372)	Data 0.0156 (0.0202)	Loss 2.0624 (2.4544)	
Epoch: [49][250/345]	Time 0.359 (0.372)	Data 0.0312 (0.0202)	Loss 1.2962 (2.4305)	
Epoch: [49][260/345]	Time 0.359 (0.371)	Data 0.0156 (0.0202)	Loss 1.9788 (2.4135)	
Epoch: [49][270/345]	Time 0.359 (0.371)	Data 0.0156 (0.0200)	Loss 2.4650 (2.3966)	
Epoch: [49][280/345]	Time 0.360 (0.371)	Data 0.0156 (0.0198)	Loss 1.7981 (2.3725)	
Epoch: [49][290/345]	Time 0.391 (0.371)	Data 0.0313 (0.0200)	Loss 1.6805 (2.3515)	
Epoch: [49][300/345]	Time 0.375 (0.372)	Data 0.0316 (0.0201)	Loss 1.5842 (2.3309)	
Epoch: [49][310/345]	Time 0.344 (0.371)	Data 0.0156 (0.0201)	Loss 1.7865 (2.3107)	
Epoch: [49][320/345]	Time 0.359 (0.371)	Data 0.0155 (0.0200)	Loss 1.8796 (2.2934)	
Epoch: [49][330/345]	Time 0.375 (0.371)	Data 0.0156 (0.0199)	Loss 1.5991 (2.2726)	
Epoch: [49][340/345]	Time 0.408 (0.371)	Data 0.0156 (0.0200)	Loss 1.4167 (2.2500)	
49
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [50][10/345]	Time 0.406 (0.384)	Data 0.0154 (0.0219)	Loss 2.4964 (3.1196)	
Epoch: [50][20/345]	Time 0.360 (0.376)	Data 0.0156 (0.0188)	Loss 3.0152 (3.1290)	
Epoch: [50][30/345]	Time 0.391 (0.376)	Data 0.0312 (0.0199)	Loss 3.4052 (3.1074)	
Epoch: [50][40/345]	Time 0.391 (0.378)	Data 0.0156 (0.0192)	Loss 1.8795 (2.9715)	
Epoch: [50][50/345]	Time 0.406 (0.380)	Data 0.0312 (0.0204)	Loss 3.1944 (2.8809)	
Epoch: [50][60/345]	Time 0.375 (0.379)	Data 0.0156 (0.0204)	Loss 4.0499 (2.8559)	
Epoch: [50][70/345]	Time 0.360 (0.379)	Data 0.0312 (0.0199)	Loss 1.8357 (2.8033)	
Epoch: [50][80/345]	Time 0.391 (0.378)	Data 0.0156 (0.0198)	Loss 1.6200 (2.7587)	
Epoch: [50][90/345]	Time 0.391 (0.378)	Data 0.0000 (0.0191)	Loss 2.8865 (2.7692)	
Epoch: [50][100/345]	Time 0.360 (0.377)	Data 0.0156 (0.0189)	Loss 2.2050 (2.7394)	
Epoch: [50][110/345]	Time 0.437 (0.378)	Data 0.0316 (0.0193)	Loss 2.6674 (2.7616)	
Epoch: [50][120/345]	Time 0.359 (0.377)	Data 0.0156 (0.0189)	Loss 1.8891 (2.7219)	
Epoch: [50][130/345]	Time 0.359 (0.376)	Data 0.0312 (0.0191)	Loss 2.2036 (2.6885)	
Epoch: [50][140/345]	Time 0.360 (0.377)	Data 0.0312 (0.0199)	Loss 1.9689 (2.6810)	
Epoch: [50][150/345]	Time 0.375 (0.377)	Data 0.0156 (0.0199)	Loss 2.4821 (2.6782)	
Epoch: [50][160/345]	Time 0.391 (0.377)	Data 0.0156 (0.0198)	Loss 1.7662 (2.6274)	
Epoch: [50][170/345]	Time 0.359 (0.378)	Data 0.0156 (0.0201)	Loss 2.6285 (2.5820)	
Epoch: [50][180/345]	Time 0.406 (0.378)	Data 0.0160 (0.0201)	Loss 1.8532 (2.5508)	
Epoch: [50][190/345]	Time 0.406 (0.378)	Data 0.0000 (0.0199)	Loss 1.7308 (2.5153)	
Epoch: [50][200/345]	Time 0.375 (0.377)	Data 0.0156 (0.0198)	Loss 1.6242 (2.4935)	
Epoch: [50][210/345]	Time 0.375 (0.377)	Data 0.0312 (0.0198)	Loss 1.5600 (2.4639)	
Epoch: [50][220/345]	Time 0.406 (0.377)	Data 0.0156 (0.0197)	Loss 2.4307 (2.4404)	
Epoch: [50][230/345]	Time 0.375 (0.377)	Data 0.0156 (0.0197)	Loss 2.1654 (2.4241)	
Epoch: [50][240/345]	Time 0.359 (0.377)	Data 0.0156 (0.0196)	Loss 1.6438 (2.4070)	
Epoch: [50][250/345]	Time 0.345 (0.377)	Data 0.0156 (0.0195)	Loss 1.5541 (2.3884)	
Epoch: [50][260/345]	Time 0.344 (0.376)	Data 0.0000 (0.0194)	Loss 2.0230 (2.3725)	
Epoch: [50][270/345]	Time 0.359 (0.376)	Data 0.0156 (0.0194)	Loss 2.1456 (2.3615)	
Epoch: [50][280/345]	Time 0.344 (0.377)	Data 0.0156 (0.0193)	Loss 1.5796 (2.3427)	
Epoch: [50][290/345]	Time 0.375 (0.376)	Data 0.0156 (0.0191)	Loss 1.5049 (2.3208)	
Epoch: [50][300/345]	Time 0.406 (0.377)	Data 0.0156 (0.0192)	Loss 1.7705 (2.3047)	
Epoch: [50][310/345]	Time 0.437 (0.377)	Data 0.0312 (0.0192)	Loss 1.5453 (2.2837)	
Epoch: [50][320/345]	Time 0.391 (0.377)	Data 0.0312 (0.0193)	Loss 1.5440 (2.2675)	
Epoch: [50][330/345]	Time 0.360 (0.377)	Data 0.0156 (0.0192)	Loss 1.6830 (2.2499)	
Epoch: [50][340/345]	Time 0.375 (0.377)	Data 0.0156 (0.0195)	Loss 2.2622 (2.2368)	
50
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [51][10/345]	Time 0.362 (0.374)	Data 0.0156 (0.0219)	Loss 3.7416 (2.7851)	
Epoch: [51][20/345]	Time 0.391 (0.379)	Data 0.0316 (0.0219)	Loss 4.4244 (2.8731)	
Epoch: [51][30/345]	Time 0.359 (0.378)	Data 0.0156 (0.0214)	Loss 3.2317 (2.7799)	
Epoch: [51][40/345]	Time 0.375 (0.379)	Data 0.0156 (0.0211)	Loss 2.5315 (2.7420)	
Epoch: [51][50/345]	Time 0.375 (0.378)	Data 0.0156 (0.0200)	Loss 2.8553 (2.7174)	
Epoch: [51][60/345]	Time 0.359 (0.380)	Data 0.0316 (0.0206)	Loss 1.6649 (2.7269)	
Epoch: [51][70/345]	Time 0.422 (0.381)	Data 0.0156 (0.0201)	Loss 3.0952 (2.7148)	
Epoch: [51][80/345]	Time 0.375 (0.381)	Data 0.0156 (0.0200)	Loss 2.5283 (2.7638)	
Epoch: [51][90/345]	Time 0.391 (0.381)	Data 0.0312 (0.0205)	Loss 1.8703 (2.7292)	
Epoch: [51][100/345]	Time 0.406 (0.379)	Data 0.0316 (0.0208)	Loss 3.2982 (2.6995)	
Epoch: [51][110/345]	Time 0.391 (0.379)	Data 0.0156 (0.0203)	Loss 2.4704 (2.6731)	
Epoch: [51][120/345]	Time 0.359 (0.379)	Data 0.0156 (0.0203)	Loss 2.3475 (2.6437)	
Epoch: [51][130/345]	Time 0.360 (0.378)	Data 0.0156 (0.0202)	Loss 2.0720 (2.6369)	
Epoch: [51][140/345]	Time 0.437 (0.377)	Data 0.0316 (0.0202)	Loss 2.4673 (2.6161)	
Epoch: [51][150/345]	Time 0.343 (0.377)	Data 0.0154 (0.0202)	Loss 2.4703 (2.6027)	
Epoch: [51][160/345]	Time 0.375 (0.376)	Data 0.0156 (0.0203)	Loss 2.4171 (2.6004)	
Epoch: [51][170/345]	Time 0.375 (0.375)	Data 0.0312 (0.0202)	Loss 2.3011 (2.5805)	
Epoch: [51][180/345]	Time 0.406 (0.375)	Data 0.0312 (0.0202)	Loss 1.7716 (2.5603)	
Epoch: [51][190/345]	Time 0.359 (0.375)	Data 0.0156 (0.0204)	Loss 1.9718 (2.5359)	
Epoch: [51][200/345]	Time 0.344 (0.375)	Data 0.0156 (0.0205)	Loss 2.6617 (2.5167)	
Epoch: [51][210/345]	Time 0.406 (0.375)	Data 0.0472 (0.0206)	Loss 2.2607 (2.4914)	
Epoch: [51][220/345]	Time 0.375 (0.375)	Data 0.0156 (0.0206)	Loss 1.8350 (2.4600)	
Epoch: [51][230/345]	Time 0.391 (0.376)	Data 0.0153 (0.0205)	Loss 2.2784 (2.4312)	
Epoch: [51][240/345]	Time 0.359 (0.376)	Data 0.0312 (0.0204)	Loss 1.5244 (2.4105)	
Epoch: [51][250/345]	Time 0.375 (0.376)	Data 0.0156 (0.0204)	Loss 2.3884 (2.3931)	
Epoch: [51][260/345]	Time 0.391 (0.376)	Data 0.0156 (0.0205)	Loss 1.4840 (2.3740)	
Epoch: [51][270/345]	Time 0.391 (0.376)	Data 0.0156 (0.0205)	Loss 2.0339 (2.3577)	
Epoch: [51][280/345]	Time 0.391 (0.376)	Data 0.0316 (0.0207)	Loss 1.6492 (2.3376)	
Epoch: [51][290/345]	Time 0.375 (0.376)	Data 0.0156 (0.0205)	Loss 1.7327 (2.3195)	
Epoch: [51][300/345]	Time 0.375 (0.376)	Data 0.0156 (0.0205)	Loss 1.7102 (2.2999)	
Epoch: [51][310/345]	Time 0.344 (0.376)	Data 0.0156 (0.0206)	Loss 1.8398 (2.2824)	
Epoch: [51][320/345]	Time 0.484 (0.376)	Data 0.0316 (0.0205)	Loss 2.0698 (2.2649)	
Epoch: [51][330/345]	Time 0.344 (0.376)	Data 0.0156 (0.0205)	Loss 1.3560 (2.2439)	
Epoch: [51][340/345]	Time 0.375 (0.376)	Data 0.0156 (0.0205)	Loss 1.5452 (2.2247)	
51
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [52][10/345]	Time 0.344 (0.361)	Data 0.0156 (0.0187)	Loss 3.7288 (2.6326)	
Epoch: [52][20/345]	Time 0.359 (0.363)	Data 0.0156 (0.0196)	Loss 2.0348 (2.8380)	
Epoch: [52][30/345]	Time 0.360 (0.366)	Data 0.0000 (0.0198)	Loss 2.0815 (2.9683)	
Epoch: [52][40/345]	Time 0.391 (0.369)	Data 0.0312 (0.0203)	Loss 3.7839 (2.8683)	
Epoch: [52][50/345]	Time 0.392 (0.369)	Data 0.0316 (0.0206)	Loss 3.5359 (2.8682)	
Epoch: [52][60/345]	Time 0.344 (0.368)	Data 0.0156 (0.0201)	Loss 2.8472 (2.8490)	
Epoch: [52][70/345]	Time 0.360 (0.368)	Data 0.0316 (0.0203)	Loss 2.6838 (2.7859)	
Epoch: [52][80/345]	Time 0.391 (0.369)	Data 0.0312 (0.0205)	Loss 3.1133 (2.8146)	
Epoch: [52][90/345]	Time 0.406 (0.370)	Data 0.0156 (0.0209)	Loss 3.9205 (2.7852)	
Epoch: [52][100/345]	Time 0.359 (0.371)	Data 0.0156 (0.0210)	Loss 2.5622 (2.7249)	
Epoch: [52][110/345]	Time 0.375 (0.371)	Data 0.0156 (0.0211)	Loss 2.4825 (2.7157)	
Epoch: [52][120/345]	Time 0.344 (0.371)	Data 0.0156 (0.0211)	Loss 2.5747 (2.6998)	
Epoch: [52][130/345]	Time 0.391 (0.371)	Data 0.0156 (0.0212)	Loss 1.8232 (2.6467)	
Epoch: [52][140/345]	Time 0.438 (0.372)	Data 0.0156 (0.0215)	Loss 2.8304 (2.6336)	
Epoch: [52][150/345]	Time 0.391 (0.372)	Data 0.0312 (0.0214)	Loss 2.5619 (2.5961)	
Epoch: [52][160/345]	Time 0.360 (0.371)	Data 0.0156 (0.0210)	Loss 2.2588 (2.5696)	
Epoch: [52][170/345]	Time 0.375 (0.372)	Data 0.0156 (0.0211)	Loss 2.1844 (2.5499)	
Epoch: [52][180/345]	Time 0.344 (0.372)	Data 0.0156 (0.0211)	Loss 2.4225 (2.5381)	
Epoch: [52][190/345]	Time 0.361 (0.372)	Data 0.0156 (0.0208)	Loss 1.5461 (2.5129)	
Epoch: [52][200/345]	Time 0.393 (0.373)	Data 0.0156 (0.0208)	Loss 1.7940 (2.4848)	
Epoch: [52][210/345]	Time 0.406 (0.373)	Data 0.0312 (0.0208)	Loss 1.6534 (2.4531)	
Epoch: [52][220/345]	Time 0.375 (0.373)	Data 0.0156 (0.0210)	Loss 2.4799 (2.4459)	
Epoch: [52][230/345]	Time 0.391 (0.374)	Data 0.0156 (0.0210)	Loss 1.7872 (2.4309)	
Epoch: [52][240/345]	Time 0.359 (0.374)	Data 0.0156 (0.0209)	Loss 1.5848 (2.4048)	
Epoch: [52][250/345]	Time 0.391 (0.374)	Data 0.0316 (0.0211)	Loss 1.6229 (2.3815)	
Epoch: [52][260/345]	Time 0.375 (0.374)	Data 0.0312 (0.0210)	Loss 3.0749 (2.3716)	
Epoch: [52][270/345]	Time 0.344 (0.374)	Data 0.0000 (0.0209)	Loss 1.6985 (2.3510)	
Epoch: [52][280/345]	Time 0.391 (0.374)	Data 0.0156 (0.0208)	Loss 2.3906 (2.3393)	
Epoch: [52][290/345]	Time 0.391 (0.374)	Data 0.0156 (0.0207)	Loss 1.9267 (2.3257)	
Epoch: [52][300/345]	Time 0.391 (0.374)	Data 0.0156 (0.0206)	Loss 2.0838 (2.3107)	
Epoch: [52][310/345]	Time 0.375 (0.375)	Data 0.0156 (0.0207)	Loss 1.9431 (2.2930)	
Epoch: [52][320/345]	Time 0.391 (0.375)	Data 0.0000 (0.0206)	Loss 1.5552 (2.2762)	
Epoch: [52][330/345]	Time 0.360 (0.375)	Data 0.0156 (0.0205)	Loss 1.5095 (2.2582)	
Epoch: [52][340/345]	Time 0.406 (0.375)	Data 0.0316 (0.0206)	Loss 1.6336 (2.2425)	
52
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [53][10/345]	Time 0.375 (0.384)	Data 0.0156 (0.0250)	Loss 2.8888 (3.0501)	
Epoch: [53][20/345]	Time 0.375 (0.381)	Data 0.0316 (0.0235)	Loss 2.3507 (3.0092)	
Epoch: [53][30/345]	Time 0.359 (0.384)	Data 0.0156 (0.0230)	Loss 2.0937 (2.8668)	
Epoch: [53][40/345]	Time 0.375 (0.382)	Data 0.0316 (0.0223)	Loss 2.6314 (2.8272)	
Epoch: [53][50/345]	Time 0.375 (0.380)	Data 0.0156 (0.0219)	Loss 2.0716 (2.7456)	
Epoch: [53][60/345]	Time 0.375 (0.382)	Data 0.0156 (0.0219)	Loss 2.9894 (2.7764)	
Epoch: [53][70/345]	Time 0.344 (0.381)	Data 0.0156 (0.0212)	Loss 2.6506 (2.7426)	
Epoch: [53][80/345]	Time 0.359 (0.380)	Data 0.0156 (0.0207)	Loss 3.0329 (2.7865)	
Epoch: [53][90/345]	Time 0.391 (0.380)	Data 0.0153 (0.0207)	Loss 1.4973 (2.7515)	
Epoch: [53][100/345]	Time 0.344 (0.376)	Data 0.0156 (0.0203)	Loss 3.1916 (2.7258)	
Epoch: [53][110/345]	Time 0.359 (0.376)	Data 0.0156 (0.0205)	Loss 2.2710 (2.7115)	
Epoch: [53][120/345]	Time 0.375 (0.375)	Data 0.0156 (0.0203)	Loss 1.4256 (2.6956)	
Epoch: [53][130/345]	Time 0.360 (0.374)	Data 0.0155 (0.0205)	Loss 1.9343 (2.6634)	
Epoch: [53][140/345]	Time 0.360 (0.374)	Data 0.0316 (0.0207)	Loss 1.5283 (2.6409)	
Epoch: [53][150/345]	Time 0.360 (0.374)	Data 0.0312 (0.0208)	Loss 1.8658 (2.6176)	
Epoch: [53][160/345]	Time 0.406 (0.374)	Data 0.0312 (0.0207)	Loss 1.8054 (2.5951)	
Epoch: [53][170/345]	Time 0.344 (0.373)	Data 0.0156 (0.0209)	Loss 2.4612 (2.5690)	
Epoch: [53][180/345]	Time 0.359 (0.372)	Data 0.0312 (0.0208)	Loss 1.8825 (2.5462)	
Epoch: [53][190/345]	Time 0.360 (0.372)	Data 0.0156 (0.0208)	Loss 2.4298 (2.5246)	
Epoch: [53][200/345]	Time 0.375 (0.371)	Data 0.0156 (0.0203)	Loss 1.8649 (2.5013)	
Epoch: [53][210/345]	Time 0.359 (0.370)	Data 0.0316 (0.0204)	Loss 2.4190 (2.4835)	
Epoch: [53][220/345]	Time 0.361 (0.370)	Data 0.0000 (0.0204)	Loss 2.2406 (2.4592)	
Epoch: [53][230/345]	Time 0.359 (0.370)	Data 0.0156 (0.0203)	Loss 2.3492 (2.4395)	
Epoch: [53][240/345]	Time 0.360 (0.369)	Data 0.0316 (0.0201)	Loss 2.2649 (2.4228)	
Epoch: [53][250/345]	Time 0.344 (0.369)	Data 0.0157 (0.0200)	Loss 1.5418 (2.4001)	
Epoch: [53][260/345]	Time 0.391 (0.369)	Data 0.0156 (0.0199)	Loss 2.0970 (2.3787)	
Epoch: [53][270/345]	Time 0.391 (0.369)	Data 0.0156 (0.0198)	Loss 1.7435 (2.3647)	
Epoch: [53][280/345]	Time 0.359 (0.369)	Data 0.0312 (0.0197)	Loss 2.0245 (2.3502)	
Epoch: [53][290/345]	Time 0.359 (0.368)	Data 0.0156 (0.0195)	Loss 1.8205 (2.3347)	
Epoch: [53][300/345]	Time 0.344 (0.368)	Data 0.0312 (0.0195)	Loss 2.3481 (2.3214)	
Epoch: [53][310/345]	Time 0.391 (0.368)	Data 0.0156 (0.0195)	Loss 1.6592 (2.2985)	
Epoch: [53][320/345]	Time 0.375 (0.368)	Data 0.0156 (0.0193)	Loss 1.3637 (2.2759)	
Epoch: [53][330/345]	Time 0.375 (0.368)	Data 0.0316 (0.0193)	Loss 1.6742 (2.2571)	
Epoch: [53][340/345]	Time 0.375 (0.368)	Data 0.0312 (0.0194)	Loss 1.5872 (2.2390)	
53
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [54][10/345]	Time 0.359 (0.383)	Data 0.0156 (0.0204)	Loss 3.3337 (2.7607)	
Epoch: [54][20/345]	Time 0.391 (0.379)	Data 0.0316 (0.0211)	Loss 3.6590 (2.7231)	
Epoch: [54][30/345]	Time 0.375 (0.376)	Data 0.0156 (0.0209)	Loss 3.6496 (2.8823)	
Epoch: [54][40/345]	Time 0.360 (0.375)	Data 0.0156 (0.0215)	Loss 2.8507 (2.9487)	
Epoch: [54][50/345]	Time 0.344 (0.374)	Data 0.0156 (0.0213)	Loss 3.4359 (2.9518)	
Epoch: [54][60/345]	Time 0.345 (0.376)	Data 0.0155 (0.0209)	Loss 3.1879 (2.8846)	
Epoch: [54][70/345]	Time 0.406 (0.377)	Data 0.0156 (0.0203)	Loss 3.0496 (2.8421)	
Epoch: [54][80/345]	Time 0.391 (0.377)	Data 0.0313 (0.0203)	Loss 2.6456 (2.8210)	
Epoch: [54][90/345]	Time 0.391 (0.379)	Data 0.0156 (0.0205)	Loss 2.0123 (2.7760)	
Epoch: [54][100/345]	Time 0.391 (0.380)	Data 0.0316 (0.0213)	Loss 2.9067 (2.7449)	
Epoch: [54][110/345]	Time 0.391 (0.380)	Data 0.0316 (0.0216)	Loss 2.3986 (2.7076)	
Epoch: [54][120/345]	Time 0.406 (0.380)	Data 0.0312 (0.0217)	Loss 2.2607 (2.6891)	
Epoch: [54][130/345]	Time 0.391 (0.381)	Data 0.0156 (0.0213)	Loss 2.0624 (2.6793)	
Epoch: [54][140/345]	Time 0.375 (0.380)	Data 0.0156 (0.0212)	Loss 2.8511 (2.6340)	
Epoch: [54][150/345]	Time 0.375 (0.379)	Data 0.0312 (0.0211)	Loss 2.2512 (2.5980)	
Epoch: [54][160/345]	Time 0.391 (0.379)	Data 0.0156 (0.0210)	Loss 1.8846 (2.5751)	
Epoch: [54][170/345]	Time 0.375 (0.379)	Data 0.0312 (0.0208)	Loss 1.8522 (2.5485)	
Epoch: [54][180/345]	Time 0.390 (0.379)	Data 0.0154 (0.0204)	Loss 2.2401 (2.5277)	
Epoch: [54][190/345]	Time 0.344 (0.378)	Data 0.0312 (0.0204)	Loss 2.3028 (2.5135)	
Epoch: [54][200/345]	Time 0.391 (0.378)	Data 0.0316 (0.0203)	Loss 2.0856 (2.4964)	
Epoch: [54][210/345]	Time 0.359 (0.378)	Data 0.0156 (0.0200)	Loss 1.8408 (2.4742)	
Epoch: [54][220/345]	Time 0.330 (0.377)	Data 0.0156 (0.0198)	Loss 1.9751 (2.4597)	
Epoch: [54][230/345]	Time 0.375 (0.377)	Data 0.0156 (0.0197)	Loss 1.4284 (2.4291)	
Epoch: [54][240/345]	Time 0.406 (0.377)	Data 0.0156 (0.0196)	Loss 1.7109 (2.4038)	
Epoch: [54][250/345]	Time 0.391 (0.377)	Data 0.0312 (0.0196)	Loss 1.8306 (2.3871)	
Epoch: [54][260/345]	Time 0.375 (0.377)	Data 0.0156 (0.0195)	Loss 2.0061 (2.3729)	
Epoch: [54][270/345]	Time 0.391 (0.377)	Data 0.0156 (0.0195)	Loss 1.9166 (2.3477)	
Epoch: [54][280/345]	Time 0.375 (0.377)	Data 0.0156 (0.0197)	Loss 1.5345 (2.3289)	
Epoch: [54][290/345]	Time 0.422 (0.377)	Data 0.0156 (0.0197)	Loss 2.0508 (2.3102)	
Epoch: [54][300/345]	Time 0.359 (0.377)	Data 0.0156 (0.0197)	Loss 2.6238 (2.2953)	
Epoch: [54][310/345]	Time 0.375 (0.377)	Data 0.0156 (0.0197)	Loss 1.2845 (2.2787)	
Epoch: [54][320/345]	Time 0.344 (0.377)	Data 0.0156 (0.0197)	Loss 1.8874 (2.2589)	
Epoch: [54][330/345]	Time 0.406 (0.377)	Data 0.0316 (0.0198)	Loss 1.6694 (2.2391)	
Epoch: [54][340/345]	Time 0.375 (0.377)	Data 0.0156 (0.0197)	Loss 1.5652 (2.2167)	
54
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [55][10/345]	Time 0.375 (0.375)	Data 0.0157 (0.0188)	Loss 3.5617 (3.2588)	
Epoch: [55][20/345]	Time 0.453 (0.376)	Data 0.0316 (0.0188)	Loss 2.0497 (3.1434)	
Epoch: [55][30/345]	Time 0.375 (0.379)	Data 0.0156 (0.0194)	Loss 1.8941 (3.0977)	
Epoch: [55][40/345]	Time 0.344 (0.376)	Data 0.0156 (0.0192)	Loss 2.5164 (3.0373)	
Epoch: [55][50/345]	Time 0.375 (0.378)	Data 0.0313 (0.0201)	Loss 1.6260 (3.0926)	
Epoch: [55][60/345]	Time 0.391 (0.376)	Data 0.0156 (0.0204)	Loss 2.1794 (2.9564)	
Epoch: [55][70/345]	Time 0.359 (0.376)	Data 0.0469 (0.0206)	Loss 2.2592 (2.9697)	
Epoch: [55][80/345]	Time 0.391 (0.377)	Data 0.0316 (0.0210)	Loss 2.3183 (2.9010)	
Epoch: [55][90/345]	Time 0.391 (0.377)	Data 0.0312 (0.0207)	Loss 2.3153 (2.8762)	
Epoch: [55][100/345]	Time 0.360 (0.377)	Data 0.0156 (0.0204)	Loss 3.0290 (2.8523)	
Epoch: [55][110/345]	Time 0.344 (0.375)	Data 0.0000 (0.0202)	Loss 2.8560 (2.8191)	
Epoch: [55][120/345]	Time 0.391 (0.375)	Data 0.0312 (0.0204)	Loss 1.9494 (2.7687)	
Epoch: [55][130/345]	Time 0.376 (0.374)	Data 0.0156 (0.0204)	Loss 2.9718 (2.7484)	
Epoch: [55][140/345]	Time 0.344 (0.375)	Data 0.0156 (0.0201)	Loss 1.6300 (2.7063)	
Epoch: [55][150/345]	Time 0.406 (0.376)	Data 0.0156 (0.0200)	Loss 1.5428 (2.6768)	
Epoch: [55][160/345]	Time 0.406 (0.376)	Data 0.0312 (0.0202)	Loss 2.4818 (2.6409)	
Epoch: [55][170/345]	Time 0.391 (0.376)	Data 0.0316 (0.0202)	Loss 1.8359 (2.6143)	
Epoch: [55][180/345]	Time 0.375 (0.376)	Data 0.0153 (0.0201)	Loss 2.5594 (2.5842)	
Epoch: [55][190/345]	Time 0.391 (0.375)	Data 0.0313 (0.0201)	Loss 2.3187 (2.5601)	
Epoch: [55][200/345]	Time 0.359 (0.375)	Data 0.0156 (0.0200)	Loss 1.5973 (2.5323)	
Epoch: [55][210/345]	Time 0.375 (0.375)	Data 0.0312 (0.0200)	Loss 1.6578 (2.5043)	
Epoch: [55][220/345]	Time 0.359 (0.374)	Data 0.0156 (0.0201)	Loss 1.7119 (2.4767)	
Epoch: [55][230/345]	Time 0.359 (0.374)	Data 0.0156 (0.0200)	Loss 1.3234 (2.4473)	
Epoch: [55][240/345]	Time 0.375 (0.374)	Data 0.0313 (0.0199)	Loss 2.3881 (2.4308)	
Epoch: [55][250/345]	Time 0.391 (0.375)	Data 0.0156 (0.0198)	Loss 1.6754 (2.4061)	
Epoch: [55][260/345]	Time 0.362 (0.374)	Data 0.0156 (0.0199)	Loss 2.1969 (2.3843)	
Epoch: [55][270/345]	Time 0.391 (0.374)	Data 0.0156 (0.0197)	Loss 1.4455 (2.3601)	
Epoch: [55][280/345]	Time 0.375 (0.373)	Data 0.0156 (0.0196)	Loss 1.6398 (2.3419)	
Epoch: [55][290/345]	Time 0.344 (0.373)	Data 0.0156 (0.0197)	Loss 1.7946 (2.3227)	
Epoch: [55][300/345]	Time 0.406 (0.373)	Data 0.0312 (0.0196)	Loss 1.5268 (2.3036)	
Epoch: [55][310/345]	Time 0.406 (0.373)	Data 0.0156 (0.0196)	Loss 1.6032 (2.2847)	
Epoch: [55][320/345]	Time 0.406 (0.373)	Data 0.0312 (0.0196)	Loss 1.7083 (2.2663)	
Epoch: [55][330/345]	Time 0.360 (0.373)	Data 0.0156 (0.0195)	Loss 1.5268 (2.2526)	
Epoch: [55][340/345]	Time 0.375 (0.374)	Data 0.0153 (0.0196)	Loss 1.5299 (2.2307)	
55
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [56][10/345]	Time 0.391 (0.386)	Data 0.0316 (0.0267)	Loss 3.0977 (3.0919)	
Epoch: [56][20/345]	Time 0.360 (0.379)	Data 0.0156 (0.0219)	Loss 3.6742 (2.9754)	
Epoch: [56][30/345]	Time 0.391 (0.378)	Data 0.0160 (0.0224)	Loss 2.6600 (3.0446)	
Epoch: [56][40/345]	Time 0.375 (0.380)	Data 0.0156 (0.0219)	Loss 3.1620 (2.9351)	
Epoch: [56][50/345]	Time 0.391 (0.380)	Data 0.0156 (0.0210)	Loss 3.4860 (2.9213)	
Epoch: [56][60/345]	Time 0.406 (0.379)	Data 0.0316 (0.0206)	Loss 1.9571 (2.8736)	
Epoch: [56][70/345]	Time 0.406 (0.380)	Data 0.0156 (0.0206)	Loss 2.1659 (2.8204)	
Epoch: [56][80/345]	Time 0.391 (0.382)	Data 0.0312 (0.0211)	Loss 2.8982 (2.7961)	
Epoch: [56][90/345]	Time 0.391 (0.381)	Data 0.0312 (0.0205)	Loss 2.7870 (2.7514)	
Epoch: [56][100/345]	Time 0.375 (0.380)	Data 0.0316 (0.0205)	Loss 2.0644 (2.7355)	
Epoch: [56][110/345]	Time 0.359 (0.379)	Data 0.0156 (0.0204)	Loss 2.0783 (2.6981)	
Epoch: [56][120/345]	Time 0.391 (0.379)	Data 0.0156 (0.0201)	Loss 1.7790 (2.6562)	
Epoch: [56][130/345]	Time 0.344 (0.378)	Data 0.0156 (0.0201)	Loss 2.3795 (2.6238)	
Epoch: [56][140/345]	Time 0.359 (0.377)	Data 0.0312 (0.0202)	Loss 2.6204 (2.5811)	
Epoch: [56][150/345]	Time 0.361 (0.377)	Data 0.0156 (0.0201)	Loss 1.8964 (2.5589)	
Epoch: [56][160/345]	Time 0.375 (0.377)	Data 0.0156 (0.0202)	Loss 1.9951 (2.5381)	
Epoch: [56][170/345]	Time 0.344 (0.377)	Data 0.0156 (0.0203)	Loss 1.5972 (2.5148)	
Epoch: [56][180/345]	Time 0.391 (0.377)	Data 0.0156 (0.0200)	Loss 2.1557 (2.4987)	
Epoch: [56][190/345]	Time 0.391 (0.377)	Data 0.0316 (0.0198)	Loss 3.0527 (2.4831)	
Epoch: [56][200/345]	Time 0.344 (0.377)	Data 0.0156 (0.0200)	Loss 2.4371 (2.4566)	
Epoch: [56][210/345]	Time 0.375 (0.376)	Data 0.0156 (0.0197)	Loss 2.4820 (2.4338)	
Epoch: [56][220/345]	Time 0.359 (0.376)	Data 0.0156 (0.0198)	Loss 2.0528 (2.4243)	
Epoch: [56][230/345]	Time 0.359 (0.376)	Data 0.0156 (0.0197)	Loss 2.3631 (2.4110)	
Epoch: [56][240/345]	Time 0.375 (0.376)	Data 0.0156 (0.0196)	Loss 1.5002 (2.3913)	
Epoch: [56][250/345]	Time 0.359 (0.376)	Data 0.0153 (0.0197)	Loss 1.9285 (2.3729)	
Epoch: [56][260/345]	Time 0.391 (0.376)	Data 0.0316 (0.0197)	Loss 1.5834 (2.3578)	
Epoch: [56][270/345]	Time 0.359 (0.376)	Data 0.0156 (0.0199)	Loss 1.4680 (2.3373)	
Epoch: [56][280/345]	Time 0.375 (0.376)	Data 0.0156 (0.0201)	Loss 2.0220 (2.3187)	
Epoch: [56][290/345]	Time 0.360 (0.377)	Data 0.0000 (0.0200)	Loss 1.6685 (2.3008)	
Epoch: [56][300/345]	Time 0.375 (0.376)	Data 0.0156 (0.0200)	Loss 1.6295 (2.2768)	
Epoch: [56][310/345]	Time 0.375 (0.376)	Data 0.0160 (0.0199)	Loss 1.5936 (2.2600)	
Epoch: [56][320/345]	Time 0.359 (0.376)	Data 0.0156 (0.0197)	Loss 1.4933 (2.2399)	
Epoch: [56][330/345]	Time 0.359 (0.376)	Data 0.0156 (0.0198)	Loss 1.7474 (2.2203)	
Epoch: [56][340/345]	Time 0.406 (0.376)	Data 0.0316 (0.0198)	Loss 1.3807 (2.2028)	
56
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [57][10/345]	Time 0.359 (0.385)	Data 0.0156 (0.0204)	Loss 1.5787 (3.1500)	
Epoch: [57][20/345]	Time 0.391 (0.384)	Data 0.0312 (0.0227)	Loss 2.5247 (2.9501)	
Epoch: [57][30/345]	Time 0.375 (0.384)	Data 0.0156 (0.0235)	Loss 2.0782 (3.0202)	
Epoch: [57][40/345]	Time 0.360 (0.387)	Data 0.0156 (0.0235)	Loss 1.4077 (2.8326)	
Epoch: [57][50/345]	Time 0.377 (0.385)	Data 0.0156 (0.0232)	Loss 2.7837 (2.8301)	
Epoch: [57][60/345]	Time 0.375 (0.385)	Data 0.0312 (0.0225)	Loss 2.4074 (2.7720)	
Epoch: [57][70/345]	Time 0.391 (0.384)	Data 0.0156 (0.0215)	Loss 3.7825 (2.7505)	
Epoch: [57][80/345]	Time 0.391 (0.383)	Data 0.0312 (0.0217)	Loss 2.1984 (2.7313)	
Epoch: [57][90/345]	Time 0.391 (0.381)	Data 0.0312 (0.0217)	Loss 2.9500 (2.7035)	
Epoch: [57][100/345]	Time 0.360 (0.379)	Data 0.0312 (0.0216)	Loss 3.6911 (2.6878)	
Epoch: [57][110/345]	Time 0.359 (0.377)	Data 0.0156 (0.0209)	Loss 2.0658 (2.6698)	
Epoch: [57][120/345]	Time 0.406 (0.376)	Data 0.0156 (0.0207)	Loss 2.3635 (2.6677)	
Epoch: [57][130/345]	Time 0.391 (0.376)	Data 0.0312 (0.0209)	Loss 1.7293 (2.6262)	
Epoch: [57][140/345]	Time 0.344 (0.375)	Data 0.0156 (0.0209)	Loss 2.6710 (2.6077)	
Epoch: [57][150/345]	Time 0.375 (0.374)	Data 0.0156 (0.0208)	Loss 1.8932 (2.5817)	
Epoch: [57][160/345]	Time 0.361 (0.373)	Data 0.0338 (0.0207)	Loss 1.9493 (2.5464)	
Epoch: [57][170/345]	Time 0.375 (0.372)	Data 0.0156 (0.0206)	Loss 2.2998 (2.5121)	
Epoch: [57][180/345]	Time 0.359 (0.372)	Data 0.0156 (0.0208)	Loss 2.6575 (2.4931)	
Epoch: [57][190/345]	Time 0.391 (0.373)	Data 0.0156 (0.0206)	Loss 2.0463 (2.4708)	
Epoch: [57][200/345]	Time 0.375 (0.373)	Data 0.0156 (0.0205)	Loss 1.9159 (2.4480)	
Epoch: [57][210/345]	Time 0.359 (0.372)	Data 0.0156 (0.0203)	Loss 1.7310 (2.4337)	
Epoch: [57][220/345]	Time 0.359 (0.372)	Data 0.0156 (0.0202)	Loss 2.4422 (2.4154)	
Epoch: [57][230/345]	Time 0.438 (0.373)	Data 0.0155 (0.0201)	Loss 1.5476 (2.3936)	
Epoch: [57][240/345]	Time 0.344 (0.373)	Data 0.0156 (0.0200)	Loss 1.7328 (2.3674)	
Epoch: [57][250/345]	Time 0.375 (0.372)	Data 0.0156 (0.0200)	Loss 2.0195 (2.3552)	
Epoch: [57][260/345]	Time 0.344 (0.372)	Data 0.0313 (0.0199)	Loss 1.4759 (2.3370)	
Epoch: [57][270/345]	Time 0.375 (0.373)	Data 0.0156 (0.0201)	Loss 1.5828 (2.3221)	
Epoch: [57][280/345]	Time 0.359 (0.372)	Data 0.0316 (0.0200)	Loss 1.6848 (2.3041)	
Epoch: [57][290/345]	Time 0.359 (0.372)	Data 0.0156 (0.0200)	Loss 1.5051 (2.2850)	
Epoch: [57][300/345]	Time 0.375 (0.372)	Data 0.0156 (0.0199)	Loss 1.2713 (2.2647)	
Epoch: [57][310/345]	Time 0.375 (0.372)	Data 0.0156 (0.0198)	Loss 1.5541 (2.2513)	
Epoch: [57][320/345]	Time 0.375 (0.373)	Data 0.0000 (0.0198)	Loss 1.5028 (2.2333)	
Epoch: [57][330/345]	Time 0.360 (0.373)	Data 0.0156 (0.0197)	Loss 1.5957 (2.2179)	
Epoch: [57][340/345]	Time 0.375 (0.373)	Data 0.0156 (0.0197)	Loss 1.3932 (2.2067)	
57
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [58][10/345]	Time 0.359 (0.394)	Data 0.0156 (0.0266)	Loss 2.7362 (3.0582)	
Epoch: [58][20/345]	Time 0.375 (0.390)	Data 0.0312 (0.0274)	Loss 3.6475 (3.1669)	
Epoch: [58][30/345]	Time 0.406 (0.387)	Data 0.0156 (0.0261)	Loss 2.8583 (3.0853)	
Epoch: [58][40/345]	Time 0.360 (0.388)	Data 0.0312 (0.0239)	Loss 4.2958 (2.9885)	
Epoch: [58][50/345]	Time 0.391 (0.384)	Data 0.0313 (0.0235)	Loss 2.1150 (2.9051)	
Epoch: [58][60/345]	Time 0.391 (0.384)	Data 0.0312 (0.0232)	Loss 2.7781 (2.8671)	
Epoch: [58][70/345]	Time 0.375 (0.381)	Data 0.0156 (0.0224)	Loss 2.3497 (2.8219)	
Epoch: [58][80/345]	Time 0.360 (0.380)	Data 0.0156 (0.0221)	Loss 1.5970 (2.7957)	
Epoch: [58][90/345]	Time 0.359 (0.379)	Data 0.0156 (0.0214)	Loss 2.5941 (2.7517)	
Epoch: [58][100/345]	Time 0.360 (0.379)	Data 0.0000 (0.0210)	Loss 1.8469 (2.7408)	
Epoch: [58][110/345]	Time 0.375 (0.378)	Data 0.0156 (0.0203)	Loss 1.6944 (2.7021)	
Epoch: [58][120/345]	Time 0.375 (0.378)	Data 0.0469 (0.0206)	Loss 2.6569 (2.6726)	
Epoch: [58][130/345]	Time 0.375 (0.378)	Data 0.0156 (0.0205)	Loss 1.9280 (2.6762)	
Epoch: [58][140/345]	Time 0.359 (0.378)	Data 0.0156 (0.0206)	Loss 1.4948 (2.6281)	
Epoch: [58][150/345]	Time 0.422 (0.378)	Data 0.0312 (0.0208)	Loss 2.1113 (2.5934)	
Epoch: [58][160/345]	Time 0.344 (0.377)	Data 0.0156 (0.0208)	Loss 2.0027 (2.5664)	
Epoch: [58][170/345]	Time 0.406 (0.377)	Data 0.0156 (0.0207)	Loss 2.8062 (2.5405)	
Epoch: [58][180/345]	Time 0.375 (0.376)	Data 0.0157 (0.0205)	Loss 1.7691 (2.5030)	
Epoch: [58][190/345]	Time 0.328 (0.375)	Data 0.0156 (0.0203)	Loss 1.5758 (2.4816)	
Epoch: [58][200/345]	Time 0.345 (0.374)	Data 0.0156 (0.0202)	Loss 1.6588 (2.4620)	
Epoch: [58][210/345]	Time 0.375 (0.374)	Data 0.0312 (0.0203)	Loss 1.8853 (2.4325)	
Epoch: [58][220/345]	Time 0.375 (0.374)	Data 0.0156 (0.0202)	Loss 2.1794 (2.4189)	
Epoch: [58][230/345]	Time 0.422 (0.374)	Data 0.0316 (0.0203)	Loss 1.6852 (2.4024)	
Epoch: [58][240/345]	Time 0.391 (0.375)	Data 0.0156 (0.0203)	Loss 1.7474 (2.3865)	
Epoch: [58][250/345]	Time 0.359 (0.375)	Data 0.0316 (0.0203)	Loss 1.7017 (2.3660)	
Epoch: [58][260/345]	Time 0.391 (0.375)	Data 0.0156 (0.0203)	Loss 1.9799 (2.3418)	
Epoch: [58][270/345]	Time 0.375 (0.375)	Data 0.0156 (0.0201)	Loss 1.5772 (2.3273)	
Epoch: [58][280/345]	Time 0.359 (0.375)	Data 0.0156 (0.0202)	Loss 1.6060 (2.3116)	
Epoch: [58][290/345]	Time 0.375 (0.375)	Data 0.0316 (0.0203)	Loss 1.6864 (2.2989)	
Epoch: [58][300/345]	Time 0.359 (0.375)	Data 0.0156 (0.0203)	Loss 2.1701 (2.2839)	
Epoch: [58][310/345]	Time 0.344 (0.375)	Data 0.0156 (0.0201)	Loss 1.6578 (2.2626)	
Epoch: [58][320/345]	Time 0.375 (0.375)	Data 0.0156 (0.0200)	Loss 2.1990 (2.2430)	
Epoch: [58][330/345]	Time 0.359 (0.375)	Data 0.0156 (0.0200)	Loss 1.4367 (2.2236)	
Epoch: [58][340/345]	Time 0.359 (0.375)	Data 0.0156 (0.0199)	Loss 1.2939 (2.2089)	
58
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [59][10/345]	Time 0.375 (0.373)	Data 0.0156 (0.0172)	Loss 3.1544 (2.8322)	
Epoch: [59][20/345]	Time 0.344 (0.371)	Data 0.0156 (0.0196)	Loss 2.1949 (2.7364)	
Epoch: [59][30/345]	Time 0.344 (0.375)	Data 0.0000 (0.0188)	Loss 3.1484 (2.8369)	
Epoch: [59][40/345]	Time 0.344 (0.377)	Data 0.0156 (0.0196)	Loss 2.2768 (2.8841)	
Epoch: [59][50/345]	Time 0.391 (0.378)	Data 0.0156 (0.0191)	Loss 1.9669 (2.9071)	
Epoch: [59][60/345]	Time 0.359 (0.378)	Data 0.0156 (0.0185)	Loss 2.1838 (2.8696)	
Epoch: [59][70/345]	Time 0.422 (0.379)	Data 0.0316 (0.0190)	Loss 3.0975 (2.8468)	
Epoch: [59][80/345]	Time 0.328 (0.378)	Data 0.0156 (0.0184)	Loss 3.1126 (2.8337)	
Epoch: [59][90/345]	Time 0.359 (0.377)	Data 0.0156 (0.0182)	Loss 2.8959 (2.8546)	
Epoch: [59][100/345]	Time 0.408 (0.376)	Data 0.0173 (0.0183)	Loss 2.4655 (2.8603)	
Epoch: [59][110/345]	Time 0.408 (0.377)	Data 0.0156 (0.0185)	Loss 3.6315 (2.8023)	
Epoch: [59][120/345]	Time 0.422 (0.378)	Data 0.0156 (0.0187)	Loss 2.5043 (2.7434)	
Epoch: [59][130/345]	Time 0.422 (0.378)	Data 0.0312 (0.0188)	Loss 2.3822 (2.7095)	
Epoch: [59][140/345]	Time 0.391 (0.379)	Data 0.0156 (0.0191)	Loss 1.7117 (2.6819)	
Epoch: [59][150/345]	Time 0.391 (0.379)	Data 0.0312 (0.0192)	Loss 1.4459 (2.6435)	
Epoch: [59][160/345]	Time 0.422 (0.379)	Data 0.0156 (0.0194)	Loss 3.0749 (2.6139)	
Epoch: [59][170/345]	Time 0.391 (0.379)	Data 0.0312 (0.0193)	Loss 2.3936 (2.5757)	
Epoch: [59][180/345]	Time 0.391 (0.379)	Data 0.0316 (0.0195)	Loss 1.6971 (2.5346)	
Epoch: [59][190/345]	Time 0.359 (0.379)	Data 0.0312 (0.0193)	Loss 2.3551 (2.5177)	
Epoch: [59][200/345]	Time 0.406 (0.378)	Data 0.0000 (0.0191)	Loss 1.7204 (2.4842)	
Epoch: [59][210/345]	Time 0.375 (0.378)	Data 0.0156 (0.0192)	Loss 1.8768 (2.4563)	
Epoch: [59][220/345]	Time 0.391 (0.379)	Data 0.0156 (0.0193)	Loss 1.7224 (2.4314)	
Epoch: [59][230/345]	Time 0.391 (0.379)	Data 0.0316 (0.0194)	Loss 2.1484 (2.4138)	
Epoch: [59][240/345]	Time 0.406 (0.379)	Data 0.0316 (0.0194)	Loss 2.2157 (2.3920)	
Epoch: [59][250/345]	Time 0.359 (0.378)	Data 0.0156 (0.0194)	Loss 2.0848 (2.3756)	
Epoch: [59][260/345]	Time 0.391 (0.378)	Data 0.0316 (0.0194)	Loss 1.8440 (2.3540)	
Epoch: [59][270/345]	Time 0.375 (0.378)	Data 0.0312 (0.0194)	Loss 1.7450 (2.3323)	
Epoch: [59][280/345]	Time 0.406 (0.378)	Data 0.0156 (0.0193)	Loss 1.6116 (2.3136)	
Epoch: [59][290/345]	Time 0.406 (0.378)	Data 0.0156 (0.0193)	Loss 1.8224 (2.2950)	
Epoch: [59][300/345]	Time 0.359 (0.378)	Data 0.0156 (0.0195)	Loss 1.7642 (2.2766)	
Epoch: [59][310/345]	Time 0.359 (0.378)	Data 0.0156 (0.0194)	Loss 1.8271 (2.2587)	
Epoch: [59][320/345]	Time 0.391 (0.378)	Data 0.0156 (0.0194)	Loss 1.3539 (2.2417)	
Epoch: [59][330/345]	Time 0.422 (0.378)	Data 0.0156 (0.0194)	Loss 1.7291 (2.2265)	
Epoch: [59][340/345]	Time 0.391 (0.378)	Data 0.0316 (0.0193)	Loss 1.5569 (2.2058)	
59
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [60][10/345]	Time 0.391 (0.380)	Data 0.0156 (0.0187)	Loss 3.4174 (2.9015)	
Epoch: [60][20/345]	Time 0.391 (0.380)	Data 0.0156 (0.0187)	Loss 2.1054 (3.0528)	
Epoch: [60][30/345]	Time 0.391 (0.381)	Data 0.0312 (0.0193)	Loss 3.7630 (3.0714)	
Epoch: [60][40/345]	Time 0.359 (0.379)	Data 0.0000 (0.0180)	Loss 1.9270 (3.0069)	
Epoch: [60][50/345]	Time 0.375 (0.377)	Data 0.0160 (0.0184)	Loss 2.3112 (2.8941)	
Epoch: [60][60/345]	Time 0.437 (0.380)	Data 0.0316 (0.0190)	Loss 2.3279 (2.8533)	
Epoch: [60][70/345]	Time 0.391 (0.381)	Data 0.0156 (0.0188)	Loss 2.1545 (2.8104)	
Epoch: [60][80/345]	Time 0.391 (0.381)	Data 0.0156 (0.0186)	Loss 2.7788 (2.7725)	
Epoch: [60][90/345]	Time 0.406 (0.381)	Data 0.0312 (0.0189)	Loss 1.5258 (2.7317)	
Epoch: [60][100/345]	Time 0.375 (0.381)	Data 0.0154 (0.0189)	Loss 4.5954 (2.7226)	
Epoch: [60][110/345]	Time 0.375 (0.381)	Data 0.0156 (0.0193)	Loss 1.9199 (2.7064)	
Epoch: [60][120/345]	Time 0.391 (0.380)	Data 0.0156 (0.0195)	Loss 2.4415 (2.6821)	
Epoch: [60][130/345]	Time 0.375 (0.380)	Data 0.0312 (0.0194)	Loss 2.1813 (2.6396)	
Epoch: [60][140/345]	Time 0.359 (0.379)	Data 0.0156 (0.0193)	Loss 2.8281 (2.5951)	
Epoch: [60][150/345]	Time 0.375 (0.379)	Data 0.0313 (0.0196)	Loss 3.3373 (2.5737)	
Epoch: [60][160/345]	Time 0.391 (0.380)	Data 0.0156 (0.0195)	Loss 2.3242 (2.5507)	
Epoch: [60][170/345]	Time 0.391 (0.379)	Data 0.0156 (0.0194)	Loss 2.0543 (2.5204)	
Epoch: [60][180/345]	Time 0.359 (0.379)	Data 0.0156 (0.0195)	Loss 1.9327 (2.4977)	
Epoch: [60][190/345]	Time 0.360 (0.379)	Data 0.0156 (0.0195)	Loss 1.7644 (2.4822)	
Epoch: [60][200/345]	Time 0.359 (0.379)	Data 0.0156 (0.0195)	Loss 1.8354 (2.4561)	
Epoch: [60][210/345]	Time 0.359 (0.379)	Data 0.0156 (0.0195)	Loss 1.9032 (2.4287)	
Epoch: [60][220/345]	Time 0.361 (0.379)	Data 0.0316 (0.0198)	Loss 1.9400 (2.4179)	
Epoch: [60][230/345]	Time 0.375 (0.379)	Data 0.0312 (0.0198)	Loss 1.7714 (2.3936)	
Epoch: [60][240/345]	Time 0.375 (0.379)	Data 0.0312 (0.0198)	Loss 2.1860 (2.3678)	
Epoch: [60][250/345]	Time 0.359 (0.379)	Data 0.0154 (0.0198)	Loss 1.7474 (2.3536)	
Epoch: [60][260/345]	Time 0.375 (0.379)	Data 0.0312 (0.0197)	Loss 1.8542 (2.3364)	
Epoch: [60][270/345]	Time 0.344 (0.378)	Data 0.0156 (0.0196)	Loss 1.5785 (2.3179)	
Epoch: [60][280/345]	Time 0.359 (0.378)	Data 0.0156 (0.0197)	Loss 2.0684 (2.3028)	
Epoch: [60][290/345]	Time 0.344 (0.378)	Data 0.0156 (0.0196)	Loss 1.8404 (2.2908)	
Epoch: [60][300/345]	Time 0.391 (0.377)	Data 0.0156 (0.0196)	Loss 1.7111 (2.2739)	
Epoch: [60][310/345]	Time 0.359 (0.377)	Data 0.0156 (0.0195)	Loss 1.6122 (2.2688)	
Epoch: [60][320/345]	Time 0.359 (0.377)	Data 0.0156 (0.0194)	Loss 1.8211 (2.2571)	
Epoch: [60][330/345]	Time 0.375 (0.377)	Data 0.0156 (0.0195)	Loss 1.6293 (2.2364)	
Epoch: [60][340/345]	Time 0.359 (0.377)	Data 0.0156 (0.0194)	Loss 1.4866 (2.2183)	
60
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [61][10/345]	Time 0.390 (0.378)	Data 0.0156 (0.0251)	Loss 1.7850 (2.8643)	
Epoch: [61][20/345]	Time 0.406 (0.383)	Data 0.0156 (0.0219)	Loss 2.7766 (3.0235)	
Epoch: [61][30/345]	Time 0.375 (0.381)	Data 0.0312 (0.0214)	Loss 4.3329 (3.0930)	
Epoch: [61][40/345]	Time 0.391 (0.381)	Data 0.0316 (0.0211)	Loss 2.8260 (3.0383)	
Epoch: [61][50/345]	Time 0.391 (0.383)	Data 0.0155 (0.0216)	Loss 2.3666 (2.9094)	
Epoch: [61][60/345]	Time 0.375 (0.384)	Data 0.0156 (0.0214)	Loss 2.7078 (2.8518)	
Epoch: [61][70/345]	Time 0.406 (0.386)	Data 0.0156 (0.0212)	Loss 1.7920 (2.8299)	
Epoch: [61][80/345]	Time 0.391 (0.384)	Data 0.0156 (0.0213)	Loss 2.3474 (2.8093)	
Epoch: [61][90/345]	Time 0.375 (0.383)	Data 0.0156 (0.0216)	Loss 3.1415 (2.7934)	
Epoch: [61][100/345]	Time 0.375 (0.383)	Data 0.0156 (0.0213)	Loss 2.3051 (2.7308)	
Epoch: [61][110/345]	Time 0.359 (0.381)	Data 0.0156 (0.0212)	Loss 2.7507 (2.7233)	
Epoch: [61][120/345]	Time 0.376 (0.380)	Data 0.0000 (0.0210)	Loss 2.1168 (2.6749)	
Epoch: [61][130/345]	Time 0.376 (0.381)	Data 0.0156 (0.0211)	Loss 1.8530 (2.6502)	
Epoch: [61][140/345]	Time 0.375 (0.380)	Data 0.0156 (0.0208)	Loss 1.4136 (2.6315)	
Epoch: [61][150/345]	Time 0.375 (0.381)	Data 0.0156 (0.0208)	Loss 2.2989 (2.6113)	
Epoch: [61][160/345]	Time 0.359 (0.381)	Data 0.0156 (0.0208)	Loss 1.6351 (2.5700)	
Epoch: [61][170/345]	Time 0.391 (0.381)	Data 0.0316 (0.0209)	Loss 2.0489 (2.5405)	
Epoch: [61][180/345]	Time 0.359 (0.381)	Data 0.0153 (0.0207)	Loss 1.9433 (2.5093)	
Epoch: [61][190/345]	Time 0.375 (0.380)	Data 0.0156 (0.0205)	Loss 1.8746 (2.4843)	
Epoch: [61][200/345]	Time 0.391 (0.381)	Data 0.0312 (0.0208)	Loss 1.9950 (2.4667)	
Epoch: [61][210/345]	Time 0.391 (0.380)	Data 0.0312 (0.0210)	Loss 1.8972 (2.4432)	
Epoch: [61][220/345]	Time 0.375 (0.380)	Data 0.0156 (0.0207)	Loss 2.1675 (2.4243)	
Epoch: [61][230/345]	Time 0.437 (0.380)	Data 0.0153 (0.0205)	Loss 1.8833 (2.4056)	
Epoch: [61][240/345]	Time 0.344 (0.379)	Data 0.0156 (0.0204)	Loss 2.4831 (2.3825)	
Epoch: [61][250/345]	Time 0.375 (0.379)	Data 0.0316 (0.0203)	Loss 1.9567 (2.3661)	
Epoch: [61][260/345]	Time 0.359 (0.379)	Data 0.0153 (0.0201)	Loss 2.0905 (2.3475)	
Epoch: [61][270/345]	Time 0.344 (0.379)	Data 0.0156 (0.0200)	Loss 1.8389 (2.3287)	
Epoch: [61][280/345]	Time 0.392 (0.378)	Data 0.0325 (0.0199)	Loss 1.6598 (2.3119)	
Epoch: [61][290/345]	Time 0.344 (0.378)	Data 0.0156 (0.0197)	Loss 1.7840 (2.2919)	
Epoch: [61][300/345]	Time 0.375 (0.378)	Data 0.0312 (0.0197)	Loss 1.7955 (2.2713)	
Epoch: [61][310/345]	Time 0.375 (0.378)	Data 0.0312 (0.0197)	Loss 1.7272 (2.2522)	
Epoch: [61][320/345]	Time 0.359 (0.377)	Data 0.0156 (0.0197)	Loss 1.5612 (2.2332)	
Epoch: [61][330/345]	Time 0.375 (0.377)	Data 0.0156 (0.0196)	Loss 1.6222 (2.2161)	
Epoch: [61][340/345]	Time 0.406 (0.377)	Data 0.0156 (0.0195)	Loss 1.4615 (2.1986)	
61
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [62][10/345]	Time 0.375 (0.375)	Data 0.0156 (0.0188)	Loss 2.3020 (2.5389)	
Epoch: [62][20/345]	Time 0.344 (0.373)	Data 0.0312 (0.0196)	Loss 3.1985 (2.7416)	
Epoch: [62][30/345]	Time 0.391 (0.374)	Data 0.0316 (0.0193)	Loss 3.4333 (2.7672)	
Epoch: [62][40/345]	Time 0.422 (0.375)	Data 0.0469 (0.0203)	Loss 4.1288 (2.7922)	
Epoch: [62][50/345]	Time 0.406 (0.379)	Data 0.0153 (0.0203)	Loss 1.8285 (2.8669)	
Epoch: [62][60/345]	Time 0.391 (0.378)	Data 0.0156 (0.0193)	Loss 2.1914 (2.7913)	
Epoch: [62][70/345]	Time 0.422 (0.379)	Data 0.0154 (0.0195)	Loss 4.5492 (2.7857)	
Epoch: [62][80/345]	Time 0.391 (0.379)	Data 0.0156 (0.0194)	Loss 2.6980 (2.7644)	
Epoch: [62][90/345]	Time 0.375 (0.378)	Data 0.0156 (0.0195)	Loss 2.5401 (2.7696)	
Epoch: [62][100/345]	Time 0.391 (0.377)	Data 0.0157 (0.0193)	Loss 2.5323 (2.7411)	
Epoch: [62][110/345]	Time 0.344 (0.377)	Data 0.0156 (0.0192)	Loss 1.9646 (2.7257)	
Epoch: [62][120/345]	Time 0.422 (0.377)	Data 0.0156 (0.0187)	Loss 1.9046 (2.6778)	
Epoch: [62][130/345]	Time 0.375 (0.378)	Data 0.0156 (0.0189)	Loss 1.8402 (2.6343)	
Epoch: [62][140/345]	Time 0.360 (0.377)	Data 0.0313 (0.0190)	Loss 2.1835 (2.5963)	
Epoch: [62][150/345]	Time 0.359 (0.377)	Data 0.0156 (0.0192)	Loss 1.9825 (2.5743)	
Epoch: [62][160/345]	Time 0.391 (0.377)	Data 0.0312 (0.0194)	Loss 3.6001 (2.5568)	
Epoch: [62][170/345]	Time 0.376 (0.377)	Data 0.0156 (0.0192)	Loss 2.2873 (2.5341)	
Epoch: [62][180/345]	Time 0.375 (0.377)	Data 0.0156 (0.0192)	Loss 1.6059 (2.5139)	
Epoch: [62][190/345]	Time 0.359 (0.376)	Data 0.0156 (0.0191)	Loss 2.0450 (2.5021)	
Epoch: [62][200/345]	Time 0.406 (0.377)	Data 0.0312 (0.0192)	Loss 2.6730 (2.4843)	
Epoch: [62][210/345]	Time 0.375 (0.377)	Data 0.0156 (0.0192)	Loss 1.6566 (2.4582)	
Epoch: [62][220/345]	Time 0.375 (0.377)	Data 0.0312 (0.0193)	Loss 1.8781 (2.4443)	
Epoch: [62][230/345]	Time 0.391 (0.377)	Data 0.0156 (0.0192)	Loss 2.1170 (2.4237)	
Epoch: [62][240/345]	Time 0.375 (0.377)	Data 0.0156 (0.0192)	Loss 1.7927 (2.3972)	
Epoch: [62][250/345]	Time 0.359 (0.377)	Data 0.0156 (0.0193)	Loss 2.0060 (2.3708)	
Epoch: [62][260/345]	Time 0.391 (0.377)	Data 0.0316 (0.0193)	Loss 1.7480 (2.3560)	
Epoch: [62][270/345]	Time 0.391 (0.377)	Data 0.0312 (0.0193)	Loss 1.7572 (2.3403)	
Epoch: [62][280/345]	Time 0.375 (0.378)	Data 0.0156 (0.0192)	Loss 2.1256 (2.3207)	
Epoch: [62][290/345]	Time 0.375 (0.378)	Data 0.0156 (0.0191)	Loss 1.4872 (2.3002)	
Epoch: [62][300/345]	Time 0.391 (0.378)	Data 0.0316 (0.0191)	Loss 1.8697 (2.2786)	
Epoch: [62][310/345]	Time 0.375 (0.377)	Data 0.0156 (0.0190)	Loss 2.4063 (2.2634)	
Epoch: [62][320/345]	Time 0.406 (0.377)	Data 0.0312 (0.0190)	Loss 1.6519 (2.2467)	
Epoch: [62][330/345]	Time 0.437 (0.377)	Data 0.0316 (0.0190)	Loss 1.3152 (2.2247)	
Epoch: [62][340/345]	Time 0.359 (0.377)	Data 0.0156 (0.0190)	Loss 1.5246 (2.2032)	
62
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [63][10/345]	Time 0.437 (0.387)	Data 0.0312 (0.0282)	Loss 4.4709 (2.9158)	
Epoch: [63][20/345]	Time 0.375 (0.383)	Data 0.0156 (0.0243)	Loss 2.6340 (2.9293)	
Epoch: [63][30/345]	Time 0.391 (0.383)	Data 0.0316 (0.0230)	Loss 2.0538 (2.7269)	
Epoch: [63][40/345]	Time 0.391 (0.382)	Data 0.0156 (0.0216)	Loss 2.2007 (2.7153)	
Epoch: [63][50/345]	Time 0.390 (0.383)	Data 0.0153 (0.0213)	Loss 2.8371 (2.7045)	
Epoch: [63][60/345]	Time 0.375 (0.383)	Data 0.0156 (0.0206)	Loss 3.4082 (2.7408)	
Epoch: [63][70/345]	Time 0.375 (0.381)	Data 0.0156 (0.0199)	Loss 2.2765 (2.7434)	
Epoch: [63][80/345]	Time 0.359 (0.380)	Data 0.0156 (0.0192)	Loss 1.8114 (2.7324)	
Epoch: [63][90/345]	Time 0.376 (0.380)	Data 0.0312 (0.0186)	Loss 1.8343 (2.6815)	
Epoch: [63][100/345]	Time 0.375 (0.379)	Data 0.0000 (0.0183)	Loss 2.1490 (2.6967)	
Epoch: [63][110/345]	Time 0.360 (0.379)	Data 0.0156 (0.0182)	Loss 2.0624 (2.6549)	
Epoch: [63][120/345]	Time 0.344 (0.379)	Data 0.0156 (0.0183)	Loss 2.2522 (2.6014)	
Epoch: [63][130/345]	Time 0.360 (0.378)	Data 0.0157 (0.0187)	Loss 1.6779 (2.5925)	
Epoch: [63][140/345]	Time 0.422 (0.378)	Data 0.0316 (0.0189)	Loss 2.9333 (2.5859)	
Epoch: [63][150/345]	Time 0.328 (0.378)	Data 0.0156 (0.0190)	Loss 2.2025 (2.5629)	
Epoch: [63][160/345]	Time 0.360 (0.378)	Data 0.0156 (0.0189)	Loss 2.4598 (2.5393)	
Epoch: [63][170/345]	Time 0.375 (0.378)	Data 0.0156 (0.0189)	Loss 2.0078 (2.5366)	
Epoch: [63][180/345]	Time 0.375 (0.378)	Data 0.0160 (0.0188)	Loss 2.2086 (2.5171)	
Epoch: [63][190/345]	Time 0.375 (0.377)	Data 0.0000 (0.0188)	Loss 2.1717 (2.4943)	
Epoch: [63][200/345]	Time 0.359 (0.378)	Data 0.0154 (0.0189)	Loss 1.7522 (2.4772)	
Epoch: [63][210/345]	Time 0.391 (0.378)	Data 0.0312 (0.0188)	Loss 1.9075 (2.4593)	
Epoch: [63][220/345]	Time 0.375 (0.377)	Data 0.0156 (0.0188)	Loss 2.4517 (2.4399)	
Epoch: [63][230/345]	Time 0.375 (0.377)	Data 0.0156 (0.0189)	Loss 1.9590 (2.4169)	
Epoch: [63][240/345]	Time 0.391 (0.377)	Data 0.0312 (0.0189)	Loss 1.6298 (2.3903)	
Epoch: [63][250/345]	Time 0.375 (0.377)	Data 0.0312 (0.0190)	Loss 1.5115 (2.3693)	
Epoch: [63][260/345]	Time 0.391 (0.378)	Data 0.0156 (0.0190)	Loss 2.0469 (2.3506)	
Epoch: [63][270/345]	Time 0.406 (0.378)	Data 0.0156 (0.0190)	Loss 1.6221 (2.3309)	
Epoch: [63][280/345]	Time 0.391 (0.378)	Data 0.0156 (0.0191)	Loss 1.7559 (2.3091)	
Epoch: [63][290/345]	Time 0.328 (0.378)	Data 0.0156 (0.0191)	Loss 1.9786 (2.2919)	
Epoch: [63][300/345]	Time 0.359 (0.378)	Data 0.0156 (0.0190)	Loss 1.4130 (2.2695)	
Epoch: [63][310/345]	Time 0.437 (0.378)	Data 0.0316 (0.0189)	Loss 1.6349 (2.2478)	
Epoch: [63][320/345]	Time 0.375 (0.378)	Data 0.0156 (0.0188)	Loss 1.4965 (2.2294)	
Epoch: [63][330/345]	Time 0.359 (0.378)	Data 0.0156 (0.0189)	Loss 1.7075 (2.2105)	
Epoch: [63][340/345]	Time 0.375 (0.378)	Data 0.0156 (0.0189)	Loss 1.4251 (2.1955)	
63
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [64][10/345]	Time 0.408 (0.380)	Data 0.0316 (0.0204)	Loss 2.5220 (2.5314)	
Epoch: [64][20/345]	Time 0.359 (0.381)	Data 0.0156 (0.0211)	Loss 2.2198 (2.7390)	
Epoch: [64][30/345]	Time 0.375 (0.377)	Data 0.0469 (0.0219)	Loss 2.0389 (2.7789)	
Epoch: [64][40/345]	Time 0.406 (0.381)	Data 0.0156 (0.0219)	Loss 2.4304 (2.8445)	
Epoch: [64][50/345]	Time 0.359 (0.382)	Data 0.0156 (0.0219)	Loss 2.1927 (2.7517)	
Epoch: [64][60/345]	Time 0.359 (0.383)	Data 0.0156 (0.0217)	Loss 1.8835 (2.7188)	
Epoch: [64][70/345]	Time 0.391 (0.381)	Data 0.0312 (0.0213)	Loss 2.5853 (2.7175)	
Epoch: [64][80/345]	Time 0.344 (0.382)	Data 0.0000 (0.0211)	Loss 1.8802 (2.6842)	
Epoch: [64][90/345]	Time 0.375 (0.381)	Data 0.0156 (0.0210)	Loss 1.6436 (2.6536)	
Epoch: [64][100/345]	Time 0.328 (0.379)	Data 0.0156 (0.0213)	Loss 2.4568 (2.6106)	
Epoch: [64][110/345]	Time 0.359 (0.378)	Data 0.0156 (0.0209)	Loss 3.2660 (2.5842)	
Epoch: [64][120/345]	Time 0.359 (0.378)	Data 0.0153 (0.0205)	Loss 2.4985 (2.5841)	
Epoch: [64][130/345]	Time 0.344 (0.378)	Data 0.0156 (0.0206)	Loss 1.9826 (2.5650)	
Epoch: [64][140/345]	Time 0.391 (0.377)	Data 0.0156 (0.0206)	Loss 1.8463 (2.5500)	
Epoch: [64][150/345]	Time 0.344 (0.376)	Data 0.0156 (0.0203)	Loss 1.6345 (2.5245)	
Epoch: [64][160/345]	Time 0.344 (0.376)	Data 0.0156 (0.0203)	Loss 1.7199 (2.5088)	
Epoch: [64][170/345]	Time 0.406 (0.375)	Data 0.0312 (0.0202)	Loss 2.5178 (2.4927)	
Epoch: [64][180/345]	Time 0.406 (0.375)	Data 0.0156 (0.0201)	Loss 3.5633 (2.4742)	
Epoch: [64][190/345]	Time 0.344 (0.374)	Data 0.0156 (0.0199)	Loss 3.2954 (2.4566)	
Epoch: [64][200/345]	Time 0.359 (0.374)	Data 0.0156 (0.0201)	Loss 1.3775 (2.4360)	
Epoch: [64][210/345]	Time 0.360 (0.375)	Data 0.0156 (0.0201)	Loss 1.5814 (2.4128)	
Epoch: [64][220/345]	Time 0.453 (0.375)	Data 0.0316 (0.0203)	Loss 1.7895 (2.3915)	
Epoch: [64][230/345]	Time 0.359 (0.375)	Data 0.0156 (0.0201)	Loss 2.2709 (2.3689)	
Epoch: [64][240/345]	Time 0.406 (0.375)	Data 0.0156 (0.0199)	Loss 1.8799 (2.3469)	
Epoch: [64][250/345]	Time 0.344 (0.375)	Data 0.0156 (0.0198)	Loss 1.6571 (2.3245)	
Epoch: [64][260/345]	Time 0.375 (0.375)	Data 0.0156 (0.0199)	Loss 1.7966 (2.3084)	
Epoch: [64][270/345]	Time 0.391 (0.375)	Data 0.0312 (0.0199)	Loss 1.6682 (2.2942)	
Epoch: [64][280/345]	Time 0.375 (0.375)	Data 0.0153 (0.0198)	Loss 1.7277 (2.2814)	
Epoch: [64][290/345]	Time 0.406 (0.375)	Data 0.0316 (0.0199)	Loss 1.3351 (2.2620)	
Epoch: [64][300/345]	Time 0.359 (0.375)	Data 0.0156 (0.0200)	Loss 1.5048 (2.2542)	
Epoch: [64][310/345]	Time 0.391 (0.375)	Data 0.0313 (0.0201)	Loss 1.8869 (2.2366)	
Epoch: [64][320/345]	Time 0.359 (0.375)	Data 0.0312 (0.0202)	Loss 1.8298 (2.2182)	
Epoch: [64][330/345]	Time 0.359 (0.375)	Data 0.0312 (0.0203)	Loss 1.5902 (2.2015)	
Epoch: [64][340/345]	Time 0.375 (0.375)	Data 0.0316 (0.0203)	Loss 2.0130 (2.1850)	
64
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [65][10/345]	Time 0.375 (0.379)	Data 0.0157 (0.0188)	Loss 4.7994 (3.0163)	
Epoch: [65][20/345]	Time 0.438 (0.381)	Data 0.0316 (0.0204)	Loss 2.6207 (2.6923)	
Epoch: [65][30/345]	Time 0.406 (0.377)	Data 0.0156 (0.0199)	Loss 2.1483 (2.8223)	
Epoch: [65][40/345]	Time 0.346 (0.375)	Data 0.0156 (0.0192)	Loss 1.5500 (2.8455)	
Epoch: [65][50/345]	Time 0.375 (0.374)	Data 0.0154 (0.0185)	Loss 3.6888 (2.9010)	
Epoch: [65][60/345]	Time 0.375 (0.374)	Data 0.0312 (0.0188)	Loss 4.0908 (2.9249)	
Epoch: [65][70/345]	Time 0.406 (0.375)	Data 0.0312 (0.0192)	Loss 2.3045 (2.8606)	
Epoch: [65][80/345]	Time 0.391 (0.375)	Data 0.0156 (0.0192)	Loss 2.2771 (2.7950)	
Epoch: [65][90/345]	Time 0.359 (0.374)	Data 0.0156 (0.0188)	Loss 2.3750 (2.7640)	
Epoch: [65][100/345]	Time 0.375 (0.374)	Data 0.0312 (0.0188)	Loss 1.7399 (2.6840)	
Epoch: [65][110/345]	Time 0.391 (0.374)	Data 0.0156 (0.0188)	Loss 1.8446 (2.6497)	
Epoch: [65][120/345]	Time 0.344 (0.372)	Data 0.0156 (0.0187)	Loss 1.6770 (2.6425)	
Epoch: [65][130/345]	Time 0.375 (0.372)	Data 0.0156 (0.0187)	Loss 1.6844 (2.6013)	
Epoch: [65][140/345]	Time 0.360 (0.372)	Data 0.0156 (0.0187)	Loss 3.4366 (2.5843)	
Epoch: [65][150/345]	Time 0.360 (0.371)	Data 0.0156 (0.0189)	Loss 1.6131 (2.5677)	
Epoch: [65][160/345]	Time 0.391 (0.372)	Data 0.0156 (0.0189)	Loss 1.7228 (2.5280)	
Epoch: [65][170/345]	Time 0.408 (0.373)	Data 0.0156 (0.0192)	Loss 3.0250 (2.5109)	
Epoch: [65][180/345]	Time 0.391 (0.373)	Data 0.0316 (0.0192)	Loss 1.8929 (2.4975)	
Epoch: [65][190/345]	Time 0.375 (0.373)	Data 0.0312 (0.0192)	Loss 1.7358 (2.4677)	
Epoch: [65][200/345]	Time 0.375 (0.373)	Data 0.0316 (0.0194)	Loss 2.5408 (2.4503)	
Epoch: [65][210/345]	Time 0.406 (0.374)	Data 0.0156 (0.0192)	Loss 2.0438 (2.4218)	
Epoch: [65][220/345]	Time 0.375 (0.374)	Data 0.0156 (0.0192)	Loss 1.9860 (2.4030)	
Epoch: [65][230/345]	Time 0.359 (0.374)	Data 0.0156 (0.0192)	Loss 1.7335 (2.3875)	
Epoch: [65][240/345]	Time 0.375 (0.374)	Data 0.0156 (0.0193)	Loss 2.3581 (2.3629)	
Epoch: [65][250/345]	Time 0.359 (0.374)	Data 0.0156 (0.0192)	Loss 2.1558 (2.3497)	
Epoch: [65][260/345]	Time 0.344 (0.375)	Data 0.0156 (0.0190)	Loss 2.1812 (2.3343)	
Epoch: [65][270/345]	Time 0.375 (0.374)	Data 0.0316 (0.0189)	Loss 1.8832 (2.3203)	
Epoch: [65][280/345]	Time 0.344 (0.374)	Data 0.0156 (0.0189)	Loss 2.6081 (2.3013)	
Epoch: [65][290/345]	Time 0.359 (0.374)	Data 0.0156 (0.0188)	Loss 1.8957 (2.2788)	
Epoch: [65][300/345]	Time 0.391 (0.375)	Data 0.0156 (0.0189)	Loss 1.3230 (2.2586)	
Epoch: [65][310/345]	Time 0.359 (0.375)	Data 0.0156 (0.0188)	Loss 1.6591 (2.2440)	
Epoch: [65][320/345]	Time 0.375 (0.374)	Data 0.0156 (0.0187)	Loss 1.8933 (2.2218)	
Epoch: [65][330/345]	Time 0.328 (0.374)	Data 0.0156 (0.0188)	Loss 1.6386 (2.2089)	
Epoch: [65][340/345]	Time 0.391 (0.375)	Data 0.0156 (0.0189)	Loss 1.3111 (2.1931)	
65
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [66][10/345]	Time 0.344 (0.391)	Data 0.0155 (0.0235)	Loss 2.8117 (2.7458)	
Epoch: [66][20/345]	Time 0.406 (0.384)	Data 0.0312 (0.0227)	Loss 3.7572 (2.7752)	
Epoch: [66][30/345]	Time 0.328 (0.381)	Data 0.0156 (0.0229)	Loss 2.0146 (2.9037)	
Epoch: [66][40/345]	Time 0.391 (0.379)	Data 0.0312 (0.0219)	Loss 3.3255 (2.8230)	
Epoch: [66][50/345]	Time 0.360 (0.379)	Data 0.0312 (0.0216)	Loss 2.7831 (2.8070)	
Epoch: [66][60/345]	Time 0.344 (0.379)	Data 0.0156 (0.0219)	Loss 2.0417 (2.7842)	
Epoch: [66][70/345]	Time 0.360 (0.379)	Data 0.0156 (0.0215)	Loss 4.2459 (2.7023)	
Epoch: [66][80/345]	Time 0.406 (0.380)	Data 0.0156 (0.0209)	Loss 3.2809 (2.6806)	
Epoch: [66][90/345]	Time 0.391 (0.380)	Data 0.0312 (0.0209)	Loss 2.8625 (2.6383)	
Epoch: [66][100/345]	Time 0.375 (0.380)	Data 0.0156 (0.0210)	Loss 1.4918 (2.6206)	
Epoch: [66][110/345]	Time 0.391 (0.380)	Data 0.0156 (0.0209)	Loss 2.6333 (2.5958)	
Epoch: [66][120/345]	Time 0.406 (0.381)	Data 0.0316 (0.0209)	Loss 3.7596 (2.5979)	
Epoch: [66][130/345]	Time 0.377 (0.380)	Data 0.0156 (0.0206)	Loss 1.9582 (2.5832)	
Epoch: [66][140/345]	Time 0.344 (0.380)	Data 0.0000 (0.0203)	Loss 1.9311 (2.5795)	
Epoch: [66][150/345]	Time 0.375 (0.379)	Data 0.0156 (0.0202)	Loss 2.1716 (2.5538)	
Epoch: [66][160/345]	Time 0.359 (0.379)	Data 0.0156 (0.0200)	Loss 2.0060 (2.5256)	
Epoch: [66][170/345]	Time 0.391 (0.379)	Data 0.0312 (0.0202)	Loss 2.2259 (2.5010)	
Epoch: [66][180/345]	Time 0.391 (0.378)	Data 0.0156 (0.0201)	Loss 1.9885 (2.4765)	
Epoch: [66][190/345]	Time 0.391 (0.378)	Data 0.0156 (0.0199)	Loss 2.2000 (2.4446)	
Epoch: [66][200/345]	Time 0.375 (0.377)	Data 0.0156 (0.0199)	Loss 2.3697 (2.4282)	
Epoch: [66][210/345]	Time 0.391 (0.378)	Data 0.0156 (0.0201)	Loss 1.3574 (2.4081)	
Epoch: [66][220/345]	Time 0.375 (0.378)	Data 0.0156 (0.0201)	Loss 2.0749 (2.3855)	
Epoch: [66][230/345]	Time 0.391 (0.378)	Data 0.0156 (0.0202)	Loss 1.9963 (2.3623)	
Epoch: [66][240/345]	Time 0.375 (0.378)	Data 0.0000 (0.0201)	Loss 1.8772 (2.3415)	
Epoch: [66][250/345]	Time 0.391 (0.378)	Data 0.0312 (0.0200)	Loss 2.0972 (2.3309)	
Epoch: [66][260/345]	Time 0.360 (0.377)	Data 0.0312 (0.0201)	Loss 2.3436 (2.3178)	
Epoch: [66][270/345]	Time 0.375 (0.378)	Data 0.0156 (0.0202)	Loss 2.0421 (2.2969)	
Epoch: [66][280/345]	Time 0.375 (0.378)	Data 0.0156 (0.0203)	Loss 2.0614 (2.2792)	
Epoch: [66][290/345]	Time 0.359 (0.378)	Data 0.0313 (0.0204)	Loss 1.3068 (2.2586)	
Epoch: [66][300/345]	Time 0.422 (0.377)	Data 0.0156 (0.0203)	Loss 1.4603 (2.2417)	
Epoch: [66][310/345]	Time 0.375 (0.377)	Data 0.0156 (0.0201)	Loss 2.2931 (2.2249)	
Epoch: [66][320/345]	Time 0.406 (0.377)	Data 0.0472 (0.0203)	Loss 1.6452 (2.2145)	
Epoch: [66][330/345]	Time 0.344 (0.377)	Data 0.0316 (0.0203)	Loss 1.8177 (2.1982)	
Epoch: [66][340/345]	Time 0.375 (0.377)	Data 0.0316 (0.0205)	Loss 1.6522 (2.1799)	
66
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [67][10/345]	Time 0.406 (0.383)	Data 0.0312 (0.0234)	Loss 3.2131 (2.7985)	
Epoch: [67][20/345]	Time 0.375 (0.383)	Data 0.0158 (0.0251)	Loss 1.2973 (2.7989)	
Epoch: [67][30/345]	Time 0.359 (0.381)	Data 0.0000 (0.0224)	Loss 3.3831 (2.7994)	
Epoch: [67][40/345]	Time 0.345 (0.381)	Data 0.0156 (0.0207)	Loss 3.5519 (2.8548)	
Epoch: [67][50/345]	Time 0.391 (0.380)	Data 0.0156 (0.0206)	Loss 2.2687 (2.8546)	
Epoch: [67][60/345]	Time 0.359 (0.381)	Data 0.0153 (0.0198)	Loss 2.3353 (2.8865)	
Epoch: [67][70/345]	Time 0.359 (0.380)	Data 0.0156 (0.0199)	Loss 1.9000 (2.9101)	
Epoch: [67][80/345]	Time 0.406 (0.381)	Data 0.0316 (0.0200)	Loss 2.0322 (2.8713)	
Epoch: [67][90/345]	Time 0.391 (0.381)	Data 0.0316 (0.0200)	Loss 3.7805 (2.8070)	
Epoch: [67][100/345]	Time 0.406 (0.380)	Data 0.0156 (0.0199)	Loss 2.2214 (2.7643)	
Epoch: [67][110/345]	Time 0.391 (0.380)	Data 0.0155 (0.0196)	Loss 1.7008 (2.7307)	
Epoch: [67][120/345]	Time 0.375 (0.379)	Data 0.0000 (0.0194)	Loss 2.4452 (2.6868)	
Epoch: [67][130/345]	Time 0.375 (0.379)	Data 0.0156 (0.0189)	Loss 3.1375 (2.6571)	
Epoch: [67][140/345]	Time 0.376 (0.378)	Data 0.0316 (0.0188)	Loss 1.6445 (2.6208)	
Epoch: [67][150/345]	Time 0.406 (0.378)	Data 0.0312 (0.0189)	Loss 2.4389 (2.6032)	
Epoch: [67][160/345]	Time 0.391 (0.378)	Data 0.0000 (0.0190)	Loss 1.8632 (2.5779)	
Epoch: [67][170/345]	Time 0.391 (0.378)	Data 0.0156 (0.0190)	Loss 1.4590 (2.5539)	
Epoch: [67][180/345]	Time 0.360 (0.378)	Data 0.0156 (0.0189)	Loss 1.6570 (2.5271)	
Epoch: [67][190/345]	Time 0.375 (0.378)	Data 0.0312 (0.0190)	Loss 1.7153 (2.5025)	
Epoch: [67][200/345]	Time 0.328 (0.378)	Data 0.0156 (0.0193)	Loss 2.0044 (2.4649)	
Epoch: [67][210/345]	Time 0.359 (0.378)	Data 0.0316 (0.0194)	Loss 1.6548 (2.4365)	
Epoch: [67][220/345]	Time 0.375 (0.378)	Data 0.0316 (0.0193)	Loss 2.0362 (2.4181)	
Epoch: [67][230/345]	Time 0.375 (0.378)	Data 0.0312 (0.0192)	Loss 1.8991 (2.3980)	
Epoch: [67][240/345]	Time 0.375 (0.378)	Data 0.0156 (0.0193)	Loss 1.9766 (2.3720)	
Epoch: [67][250/345]	Time 0.469 (0.378)	Data 0.0316 (0.0194)	Loss 1.8169 (2.3504)	
Epoch: [67][260/345]	Time 0.359 (0.378)	Data 0.0156 (0.0193)	Loss 1.6299 (2.3313)	
Epoch: [67][270/345]	Time 0.375 (0.378)	Data 0.0316 (0.0194)	Loss 1.4942 (2.3162)	
Epoch: [67][280/345]	Time 0.360 (0.378)	Data 0.0156 (0.0194)	Loss 1.7869 (2.2995)	
Epoch: [67][290/345]	Time 0.391 (0.378)	Data 0.0156 (0.0191)	Loss 2.1958 (2.2793)	
Epoch: [67][300/345]	Time 0.406 (0.378)	Data 0.0312 (0.0191)	Loss 1.5540 (2.2599)	
Epoch: [67][310/345]	Time 0.375 (0.378)	Data 0.0316 (0.0192)	Loss 1.4194 (2.2369)	
Epoch: [67][320/345]	Time 0.375 (0.378)	Data 0.0313 (0.0192)	Loss 1.5699 (2.2185)	
Epoch: [67][330/345]	Time 0.406 (0.377)	Data 0.0313 (0.0192)	Loss 1.6624 (2.2009)	
Epoch: [67][340/345]	Time 0.359 (0.377)	Data 0.0311 (0.0193)	Loss 1.6895 (2.1923)	
67
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [68][10/345]	Time 0.390 (0.377)	Data 0.0154 (0.0219)	Loss 3.2154 (3.6040)	
Epoch: [68][20/345]	Time 0.406 (0.382)	Data 0.0316 (0.0219)	Loss 2.7118 (3.3249)	
Epoch: [68][30/345]	Time 0.391 (0.380)	Data 0.0316 (0.0214)	Loss 1.6431 (3.2557)	
Epoch: [68][40/345]	Time 0.391 (0.381)	Data 0.0313 (0.0223)	Loss 1.9325 (3.0853)	
Epoch: [68][50/345]	Time 0.391 (0.380)	Data 0.0312 (0.0228)	Loss 3.4117 (2.9928)	
Epoch: [68][60/345]	Time 0.391 (0.380)	Data 0.0000 (0.0222)	Loss 3.2902 (2.9217)	
Epoch: [68][70/345]	Time 0.344 (0.378)	Data 0.0157 (0.0221)	Loss 2.1285 (2.8606)	
Epoch: [68][80/345]	Time 0.375 (0.378)	Data 0.0156 (0.0219)	Loss 3.9600 (2.8141)	
Epoch: [68][90/345]	Time 0.375 (0.378)	Data 0.0313 (0.0221)	Loss 2.4738 (2.7365)	
Epoch: [68][100/345]	Time 0.391 (0.377)	Data 0.0316 (0.0216)	Loss 2.6828 (2.6692)	
Epoch: [68][110/345]	Time 0.361 (0.378)	Data 0.0156 (0.0216)	Loss 1.5785 (2.6335)	
Epoch: [68][120/345]	Time 0.375 (0.378)	Data 0.0312 (0.0219)	Loss 3.1341 (2.6029)	
Epoch: [68][130/345]	Time 0.359 (0.376)	Data 0.0156 (0.0218)	Loss 2.7479 (2.5711)	
Epoch: [68][140/345]	Time 0.359 (0.375)	Data 0.0156 (0.0215)	Loss 3.5173 (2.5496)	
Epoch: [68][150/345]	Time 0.375 (0.375)	Data 0.0156 (0.0215)	Loss 2.3186 (2.5594)	
Epoch: [68][160/345]	Time 0.422 (0.376)	Data 0.0156 (0.0215)	Loss 1.9925 (2.5346)	
Epoch: [68][170/345]	Time 0.375 (0.376)	Data 0.0156 (0.0216)	Loss 1.6413 (2.5061)	
Epoch: [68][180/345]	Time 0.375 (0.375)	Data 0.0156 (0.0214)	Loss 2.4550 (2.4902)	
Epoch: [68][190/345]	Time 0.344 (0.375)	Data 0.0156 (0.0214)	Loss 1.5161 (2.4596)	
Epoch: [68][200/345]	Time 0.360 (0.375)	Data 0.0156 (0.0211)	Loss 2.5853 (2.4410)	
Epoch: [68][210/345]	Time 0.359 (0.375)	Data 0.0156 (0.0210)	Loss 1.8152 (2.4272)	
Epoch: [68][220/345]	Time 0.375 (0.376)	Data 0.0156 (0.0209)	Loss 2.0612 (2.4079)	
Epoch: [68][230/345]	Time 0.375 (0.377)	Data 0.0156 (0.0210)	Loss 1.6407 (2.3878)	
Epoch: [68][240/345]	Time 0.391 (0.377)	Data 0.0312 (0.0209)	Loss 1.7139 (2.3705)	
Epoch: [68][250/345]	Time 0.359 (0.377)	Data 0.0000 (0.0207)	Loss 1.6637 (2.3440)	
Epoch: [68][260/345]	Time 0.344 (0.377)	Data 0.0156 (0.0209)	Loss 2.4899 (2.3376)	
Epoch: [68][270/345]	Time 0.375 (0.377)	Data 0.0153 (0.0207)	Loss 2.5950 (2.3200)	
Epoch: [68][280/345]	Time 0.359 (0.377)	Data 0.0156 (0.0206)	Loss 1.8847 (2.3004)	
Epoch: [68][290/345]	Time 0.375 (0.377)	Data 0.0153 (0.0205)	Loss 1.4218 (2.2782)	
Epoch: [68][300/345]	Time 0.422 (0.377)	Data 0.0156 (0.0205)	Loss 1.8399 (2.2597)	
Epoch: [68][310/345]	Time 0.359 (0.378)	Data 0.0156 (0.0205)	Loss 1.6541 (2.2424)	
Epoch: [68][320/345]	Time 0.391 (0.378)	Data 0.0312 (0.0204)	Loss 1.6539 (2.2227)	
Epoch: [68][330/345]	Time 0.406 (0.378)	Data 0.0000 (0.0202)	Loss 1.5303 (2.2038)	
Epoch: [68][340/345]	Time 0.359 (0.378)	Data 0.0156 (0.0202)	Loss 1.9990 (2.1879)	
68
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [69][10/345]	Time 0.343 (0.383)	Data 0.0154 (0.0172)	Loss 3.8195 (3.4358)	
Epoch: [69][20/345]	Time 0.391 (0.383)	Data 0.0156 (0.0172)	Loss 1.9946 (3.3310)	
Epoch: [69][30/345]	Time 0.359 (0.376)	Data 0.0316 (0.0182)	Loss 2.5918 (3.1202)	
Epoch: [69][40/345]	Time 0.359 (0.377)	Data 0.0156 (0.0199)	Loss 2.3357 (2.8887)	
Epoch: [69][50/345]	Time 0.376 (0.379)	Data 0.0156 (0.0197)	Loss 2.6993 (2.8358)	
Epoch: [69][60/345]	Time 0.391 (0.377)	Data 0.0312 (0.0193)	Loss 1.6481 (2.8464)	
Epoch: [69][70/345]	Time 0.437 (0.378)	Data 0.0156 (0.0201)	Loss 3.4061 (2.8314)	
Epoch: [69][80/345]	Time 0.375 (0.378)	Data 0.0156 (0.0198)	Loss 2.1008 (2.8340)	
Epoch: [69][90/345]	Time 0.422 (0.378)	Data 0.0156 (0.0195)	Loss 1.2885 (2.7954)	
Epoch: [69][100/345]	Time 0.328 (0.377)	Data 0.0156 (0.0197)	Loss 1.4508 (2.7507)	
Epoch: [69][110/345]	Time 0.375 (0.377)	Data 0.0154 (0.0198)	Loss 1.9621 (2.7087)	
Epoch: [69][120/345]	Time 0.406 (0.377)	Data 0.0156 (0.0197)	Loss 1.7608 (2.6607)	
Epoch: [69][130/345]	Time 0.375 (0.377)	Data 0.0156 (0.0197)	Loss 2.6247 (2.6162)	
Epoch: [69][140/345]	Time 0.406 (0.377)	Data 0.0312 (0.0196)	Loss 2.5807 (2.6004)	
Epoch: [69][150/345]	Time 0.406 (0.377)	Data 0.0312 (0.0196)	Loss 1.7087 (2.5668)	
Epoch: [69][160/345]	Time 0.375 (0.378)	Data 0.0312 (0.0198)	Loss 2.0673 (2.5456)	
Epoch: [69][170/345]	Time 0.375 (0.378)	Data 0.0156 (0.0196)	Loss 1.7486 (2.5177)	
Epoch: [69][180/345]	Time 0.359 (0.378)	Data 0.0156 (0.0194)	Loss 2.4485 (2.5041)	
Epoch: [69][190/345]	Time 0.375 (0.378)	Data 0.0156 (0.0194)	Loss 1.8028 (2.4755)	
Epoch: [69][200/345]	Time 0.391 (0.378)	Data 0.0156 (0.0195)	Loss 3.1678 (2.4501)	
Epoch: [69][210/345]	Time 0.391 (0.378)	Data 0.0316 (0.0197)	Loss 1.7996 (2.4295)	
Epoch: [69][220/345]	Time 0.359 (0.378)	Data 0.0156 (0.0197)	Loss 2.0766 (2.4043)	
Epoch: [69][230/345]	Time 0.362 (0.378)	Data 0.0156 (0.0197)	Loss 2.1275 (2.3781)	
Epoch: [69][240/345]	Time 0.375 (0.378)	Data 0.0156 (0.0197)	Loss 2.2371 (2.3605)	
Epoch: [69][250/345]	Time 0.344 (0.378)	Data 0.0156 (0.0197)	Loss 1.5848 (2.3358)	
Epoch: [69][260/345]	Time 0.469 (0.378)	Data 0.0312 (0.0198)	Loss 1.5687 (2.3167)	
Epoch: [69][270/345]	Time 0.375 (0.378)	Data 0.0156 (0.0197)	Loss 1.5496 (2.2970)	
Epoch: [69][280/345]	Time 0.359 (0.377)	Data 0.0156 (0.0195)	Loss 2.2347 (2.2813)	
Epoch: [69][290/345]	Time 0.360 (0.378)	Data 0.0156 (0.0196)	Loss 2.0021 (2.2626)	
Epoch: [69][300/345]	Time 0.406 (0.378)	Data 0.0156 (0.0196)	Loss 1.9371 (2.2503)	
Epoch: [69][310/345]	Time 0.375 (0.378)	Data 0.0156 (0.0195)	Loss 1.4616 (2.2285)	
Epoch: [69][320/345]	Time 0.406 (0.378)	Data 0.0312 (0.0194)	Loss 1.4441 (2.2148)	
Epoch: [69][330/345]	Time 0.375 (0.379)	Data 0.0312 (0.0194)	Loss 1.4774 (2.1963)	
Epoch: [69][340/345]	Time 0.391 (0.378)	Data 0.0156 (0.0193)	Loss 1.3724 (2.1794)	
69
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [70][10/345]	Time 0.376 (0.375)	Data 0.0156 (0.0156)	Loss 2.7882 (2.7908)	
Epoch: [70][20/345]	Time 0.470 (0.381)	Data 0.0156 (0.0172)	Loss 4.6761 (2.9404)	
Epoch: [70][30/345]	Time 0.359 (0.376)	Data 0.0156 (0.0177)	Loss 2.2003 (2.8526)	
Epoch: [70][40/345]	Time 0.375 (0.375)	Data 0.0156 (0.0172)	Loss 3.0213 (2.8337)	
Epoch: [70][50/345]	Time 0.375 (0.375)	Data 0.0156 (0.0175)	Loss 2.3892 (2.8322)	
Epoch: [70][60/345]	Time 0.406 (0.376)	Data 0.0155 (0.0182)	Loss 1.5566 (2.7462)	
Epoch: [70][70/345]	Time 0.375 (0.376)	Data 0.0156 (0.0185)	Loss 3.6989 (2.7821)	
Epoch: [70][80/345]	Time 0.375 (0.376)	Data 0.0156 (0.0186)	Loss 2.7574 (2.7842)	
Epoch: [70][90/345]	Time 0.375 (0.378)	Data 0.0312 (0.0197)	Loss 2.3942 (2.7813)	
Epoch: [70][100/345]	Time 0.406 (0.378)	Data 0.0312 (0.0199)	Loss 1.7362 (2.7263)	
Epoch: [70][110/345]	Time 0.375 (0.378)	Data 0.0155 (0.0198)	Loss 2.4088 (2.6898)	
Epoch: [70][120/345]	Time 0.437 (0.380)	Data 0.0316 (0.0198)	Loss 3.5828 (2.6606)	
Epoch: [70][130/345]	Time 0.391 (0.380)	Data 0.0156 (0.0196)	Loss 2.4784 (2.6500)	
Epoch: [70][140/345]	Time 0.360 (0.380)	Data 0.0156 (0.0198)	Loss 2.4091 (2.6025)	
Epoch: [70][150/345]	Time 0.360 (0.379)	Data 0.0157 (0.0196)	Loss 1.3407 (2.5632)	
Epoch: [70][160/345]	Time 0.406 (0.380)	Data 0.0312 (0.0198)	Loss 2.6204 (2.5462)	
Epoch: [70][170/345]	Time 0.359 (0.379)	Data 0.0156 (0.0196)	Loss 3.0400 (2.5234)	
Epoch: [70][180/345]	Time 0.375 (0.380)	Data 0.0156 (0.0197)	Loss 2.6743 (2.4948)	
Epoch: [70][190/345]	Time 0.359 (0.379)	Data 0.0156 (0.0198)	Loss 1.9556 (2.4687)	
Epoch: [70][200/345]	Time 0.375 (0.380)	Data 0.0156 (0.0196)	Loss 1.6502 (2.4431)	
Epoch: [70][210/345]	Time 0.359 (0.379)	Data 0.0156 (0.0195)	Loss 1.8541 (2.4222)	
Epoch: [70][220/345]	Time 0.359 (0.379)	Data 0.0156 (0.0193)	Loss 2.5699 (2.4077)	
Epoch: [70][230/345]	Time 0.360 (0.379)	Data 0.0156 (0.0195)	Loss 1.4707 (2.3819)	
Epoch: [70][240/345]	Time 0.422 (0.379)	Data 0.0312 (0.0198)	Loss 1.5390 (2.3596)	
Epoch: [70][250/345]	Time 0.422 (0.379)	Data 0.0156 (0.0197)	Loss 1.4786 (2.3434)	
Epoch: [70][260/345]	Time 0.360 (0.378)	Data 0.0156 (0.0196)	Loss 2.0875 (2.3274)	
Epoch: [70][270/345]	Time 0.391 (0.377)	Data 0.0312 (0.0195)	Loss 1.9856 (2.3148)	
Epoch: [70][280/345]	Time 0.359 (0.377)	Data 0.0312 (0.0194)	Loss 1.4154 (2.2964)	
Epoch: [70][290/345]	Time 0.406 (0.377)	Data 0.0156 (0.0193)	Loss 1.8947 (2.2818)	
Epoch: [70][300/345]	Time 0.359 (0.377)	Data 0.0316 (0.0193)	Loss 1.5682 (2.2586)	
Epoch: [70][310/345]	Time 0.360 (0.376)	Data 0.0312 (0.0193)	Loss 1.4452 (2.2360)	
Epoch: [70][320/345]	Time 0.344 (0.376)	Data 0.0000 (0.0192)	Loss 1.6776 (2.2212)	
Epoch: [70][330/345]	Time 0.375 (0.376)	Data 0.0156 (0.0192)	Loss 1.7153 (2.2005)	
Epoch: [70][340/345]	Time 0.328 (0.375)	Data 0.0312 (0.0193)	Loss 1.5348 (2.1828)	
70
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [71][10/345]	Time 0.406 (0.375)	Data 0.0156 (0.0203)	Loss 3.2585 (3.0126)	
Epoch: [71][20/345]	Time 0.375 (0.380)	Data 0.0156 (0.0172)	Loss 3.4935 (3.0154)	
Epoch: [71][30/345]	Time 0.344 (0.376)	Data 0.0155 (0.0177)	Loss 2.9983 (2.8758)	
Epoch: [71][40/345]	Time 0.391 (0.376)	Data 0.0316 (0.0188)	Loss 4.0059 (2.8120)	
Epoch: [71][50/345]	Time 0.359 (0.376)	Data 0.0156 (0.0191)	Loss 1.9904 (2.7979)	
Epoch: [71][60/345]	Time 0.345 (0.374)	Data 0.0156 (0.0185)	Loss 1.6968 (2.7363)	
Epoch: [71][70/345]	Time 0.375 (0.372)	Data 0.0156 (0.0185)	Loss 1.9435 (2.7218)	
Epoch: [71][80/345]	Time 0.391 (0.372)	Data 0.0156 (0.0188)	Loss 1.8246 (2.7323)	
Epoch: [71][90/345]	Time 0.359 (0.373)	Data 0.0316 (0.0191)	Loss 2.8382 (2.7017)	
Epoch: [71][100/345]	Time 0.328 (0.372)	Data 0.0156 (0.0188)	Loss 2.2141 (2.6496)	
Epoch: [71][110/345]	Time 0.359 (0.373)	Data 0.0153 (0.0186)	Loss 2.3686 (2.6142)	
Epoch: [71][120/345]	Time 0.375 (0.373)	Data 0.0156 (0.0187)	Loss 1.8065 (2.5686)	
Epoch: [71][130/345]	Time 0.422 (0.375)	Data 0.0156 (0.0187)	Loss 1.5804 (2.5398)	
Epoch: [71][140/345]	Time 0.375 (0.375)	Data 0.0156 (0.0188)	Loss 1.7051 (2.5011)	
Epoch: [71][150/345]	Time 0.422 (0.375)	Data 0.0156 (0.0190)	Loss 2.8434 (2.5111)	
Epoch: [71][160/345]	Time 0.406 (0.374)	Data 0.0312 (0.0189)	Loss 1.7648 (2.5073)	
Epoch: [71][170/345]	Time 0.391 (0.375)	Data 0.0156 (0.0188)	Loss 3.9425 (2.5077)	
Epoch: [71][180/345]	Time 0.375 (0.376)	Data 0.0156 (0.0191)	Loss 1.6039 (2.4876)	
Epoch: [71][190/345]	Time 0.359 (0.375)	Data 0.0156 (0.0191)	Loss 2.2427 (2.4669)	
Epoch: [71][200/345]	Time 0.359 (0.376)	Data 0.0312 (0.0191)	Loss 1.3552 (2.4523)	
Epoch: [71][210/345]	Time 0.375 (0.376)	Data 0.0472 (0.0193)	Loss 2.7691 (2.4298)	
Epoch: [71][220/345]	Time 0.361 (0.376)	Data 0.0156 (0.0194)	Loss 1.6970 (2.4014)	
Epoch: [71][230/345]	Time 0.391 (0.376)	Data 0.0316 (0.0193)	Loss 3.3047 (2.3910)	
Epoch: [71][240/345]	Time 0.343 (0.376)	Data 0.0153 (0.0193)	Loss 1.8263 (2.3713)	
Epoch: [71][250/345]	Time 0.375 (0.376)	Data 0.0312 (0.0193)	Loss 1.8808 (2.3457)	
Epoch: [71][260/345]	Time 0.344 (0.376)	Data 0.0000 (0.0193)	Loss 1.5433 (2.3259)	
Epoch: [71][270/345]	Time 0.359 (0.376)	Data 0.0156 (0.0193)	Loss 2.0074 (2.3034)	
Epoch: [71][280/345]	Time 0.422 (0.376)	Data 0.0156 (0.0193)	Loss 1.9613 (2.2919)	
Epoch: [71][290/345]	Time 0.391 (0.376)	Data 0.0000 (0.0193)	Loss 1.9582 (2.2727)	
Epoch: [71][300/345]	Time 0.391 (0.376)	Data 0.0312 (0.0193)	Loss 1.3054 (2.2545)	
Epoch: [71][310/345]	Time 0.360 (0.375)	Data 0.0156 (0.0191)	Loss 1.7111 (2.2329)	
Epoch: [71][320/345]	Time 0.406 (0.375)	Data 0.0313 (0.0192)	Loss 1.8011 (2.2150)	
Epoch: [71][330/345]	Time 0.344 (0.375)	Data 0.0156 (0.0192)	Loss 1.5517 (2.1987)	
Epoch: [71][340/345]	Time 0.375 (0.374)	Data 0.0156 (0.0192)	Loss 1.6232 (2.1783)	
71
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [72][10/345]	Time 0.406 (0.375)	Data 0.0156 (0.0219)	Loss 4.4895 (3.2617)	
Epoch: [72][20/345]	Time 0.391 (0.378)	Data 0.0156 (0.0196)	Loss 2.3957 (3.0018)	
Epoch: [72][30/345]	Time 0.359 (0.374)	Data 0.0156 (0.0188)	Loss 2.2586 (2.8924)	
Epoch: [72][40/345]	Time 0.391 (0.371)	Data 0.0156 (0.0184)	Loss 3.9998 (2.9352)	
Epoch: [72][50/345]	Time 0.344 (0.370)	Data 0.0156 (0.0185)	Loss 2.4861 (2.8971)	
Epoch: [72][60/345]	Time 0.344 (0.370)	Data 0.0156 (0.0185)	Loss 2.7268 (2.8524)	
Epoch: [72][70/345]	Time 0.391 (0.370)	Data 0.0313 (0.0185)	Loss 2.1199 (2.8264)	
Epoch: [72][80/345]	Time 0.344 (0.369)	Data 0.0156 (0.0188)	Loss 2.0778 (2.8182)	
Epoch: [72][90/345]	Time 0.422 (0.370)	Data 0.0312 (0.0193)	Loss 2.4470 (2.7485)	
Epoch: [72][100/345]	Time 0.361 (0.370)	Data 0.0156 (0.0197)	Loss 2.5052 (2.7109)	
Epoch: [72][110/345]	Time 0.344 (0.370)	Data 0.0156 (0.0195)	Loss 1.5838 (2.6528)	
Epoch: [72][120/345]	Time 0.359 (0.370)	Data 0.0156 (0.0193)	Loss 2.6624 (2.6018)	
Epoch: [72][130/345]	Time 0.375 (0.370)	Data 0.0156 (0.0189)	Loss 2.1027 (2.5675)	
Epoch: [72][140/345]	Time 0.375 (0.370)	Data 0.0156 (0.0188)	Loss 2.5975 (2.5591)	
Epoch: [72][150/345]	Time 0.422 (0.371)	Data 0.0156 (0.0186)	Loss 1.7616 (2.5454)	
Epoch: [72][160/345]	Time 0.391 (0.371)	Data 0.0156 (0.0185)	Loss 2.0302 (2.5113)	
Epoch: [72][170/345]	Time 0.375 (0.372)	Data 0.0156 (0.0185)	Loss 1.8052 (2.4818)	
Epoch: [72][180/345]	Time 0.344 (0.372)	Data 0.0156 (0.0186)	Loss 1.7573 (2.4445)	
Epoch: [72][190/345]	Time 0.344 (0.372)	Data 0.0316 (0.0187)	Loss 2.3303 (2.4251)	
Epoch: [72][200/345]	Time 0.375 (0.371)	Data 0.0156 (0.0186)	Loss 2.1634 (2.3997)	
Epoch: [72][210/345]	Time 0.344 (0.372)	Data 0.0160 (0.0187)	Loss 2.4611 (2.3775)	
Epoch: [72][220/345]	Time 0.391 (0.372)	Data 0.0156 (0.0186)	Loss 2.2133 (2.3608)	
Epoch: [72][230/345]	Time 0.438 (0.373)	Data 0.0156 (0.0187)	Loss 1.8460 (2.3514)	
Epoch: [72][240/345]	Time 0.391 (0.372)	Data 0.0157 (0.0187)	Loss 1.8897 (2.3334)	
Epoch: [72][250/345]	Time 0.361 (0.373)	Data 0.0156 (0.0188)	Loss 1.6055 (2.3133)	
Epoch: [72][260/345]	Time 0.375 (0.373)	Data 0.0316 (0.0190)	Loss 1.7368 (2.2894)	
Epoch: [72][270/345]	Time 0.344 (0.373)	Data 0.0156 (0.0189)	Loss 1.9085 (2.2711)	
Epoch: [72][280/345]	Time 0.390 (0.373)	Data 0.0154 (0.0191)	Loss 1.6860 (2.2468)	
Epoch: [72][290/345]	Time 0.375 (0.373)	Data 0.0156 (0.0192)	Loss 1.8665 (2.2390)	
Epoch: [72][300/345]	Time 0.360 (0.373)	Data 0.0156 (0.0192)	Loss 2.0977 (2.2215)	
Epoch: [72][310/345]	Time 0.375 (0.373)	Data 0.0156 (0.0191)	Loss 1.6243 (2.2052)	
Epoch: [72][320/345]	Time 0.422 (0.373)	Data 0.0000 (0.0191)	Loss 1.5956 (2.1857)	
Epoch: [72][330/345]	Time 0.391 (0.374)	Data 0.0156 (0.0191)	Loss 1.4697 (2.1665)	
Epoch: [72][340/345]	Time 0.359 (0.373)	Data 0.0156 (0.0190)	Loss 1.7367 (2.1532)	
72
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [73][10/345]	Time 0.359 (0.367)	Data 0.0156 (0.0172)	Loss 3.1161 (2.7491)	
Epoch: [73][20/345]	Time 0.391 (0.370)	Data 0.0316 (0.0204)	Loss 2.8561 (2.7688)	
Epoch: [73][30/345]	Time 0.359 (0.371)	Data 0.0156 (0.0204)	Loss 3.1600 (2.7932)	
Epoch: [73][40/345]	Time 0.391 (0.374)	Data 0.0156 (0.0196)	Loss 1.4928 (2.7178)	
Epoch: [73][50/345]	Time 0.438 (0.376)	Data 0.0313 (0.0201)	Loss 1.8467 (2.6675)	
Epoch: [73][60/345]	Time 0.359 (0.378)	Data 0.0156 (0.0198)	Loss 2.0179 (2.6878)	
Epoch: [73][70/345]	Time 0.391 (0.378)	Data 0.0312 (0.0199)	Loss 2.5809 (2.6143)	
Epoch: [73][80/345]	Time 0.375 (0.379)	Data 0.0156 (0.0200)	Loss 2.1224 (2.6759)	
Epoch: [73][90/345]	Time 0.391 (0.379)	Data 0.0156 (0.0200)	Loss 3.8375 (2.6967)	
Epoch: [73][100/345]	Time 0.359 (0.379)	Data 0.0153 (0.0197)	Loss 3.4531 (2.6494)	
Epoch: [73][110/345]	Time 0.375 (0.378)	Data 0.0312 (0.0196)	Loss 1.8022 (2.6088)	
Epoch: [73][120/345]	Time 0.375 (0.378)	Data 0.0154 (0.0196)	Loss 2.5882 (2.6053)	
Epoch: [73][130/345]	Time 0.422 (0.378)	Data 0.0312 (0.0197)	Loss 1.6806 (2.5834)	
Epoch: [73][140/345]	Time 0.359 (0.378)	Data 0.0156 (0.0197)	Loss 1.9405 (2.5398)	
Epoch: [73][150/345]	Time 0.359 (0.378)	Data 0.0156 (0.0195)	Loss 2.7419 (2.5131)	
Epoch: [73][160/345]	Time 0.376 (0.377)	Data 0.0312 (0.0196)	Loss 1.7677 (2.4773)	
Epoch: [73][170/345]	Time 0.438 (0.377)	Data 0.0156 (0.0195)	Loss 1.8594 (2.4606)	
Epoch: [73][180/345]	Time 0.359 (0.377)	Data 0.0156 (0.0194)	Loss 1.9293 (2.4322)	
Epoch: [73][190/345]	Time 0.359 (0.378)	Data 0.0312 (0.0194)	Loss 2.4158 (2.4096)	
Epoch: [73][200/345]	Time 0.375 (0.378)	Data 0.0156 (0.0194)	Loss 2.9038 (2.3862)	
Epoch: [73][210/345]	Time 0.391 (0.377)	Data 0.0156 (0.0192)	Loss 1.5775 (2.3680)	
Epoch: [73][220/345]	Time 0.375 (0.377)	Data 0.0472 (0.0194)	Loss 1.5705 (2.3550)	
Epoch: [73][230/345]	Time 0.359 (0.377)	Data 0.0156 (0.0195)	Loss 2.1032 (2.3411)	
Epoch: [73][240/345]	Time 0.359 (0.377)	Data 0.0156 (0.0194)	Loss 1.8890 (2.3295)	
Epoch: [73][250/345]	Time 0.344 (0.377)	Data 0.0156 (0.0194)	Loss 1.8459 (2.3186)	
Epoch: [73][260/345]	Time 0.359 (0.377)	Data 0.0312 (0.0193)	Loss 1.5659 (2.2949)	
Epoch: [73][270/345]	Time 0.437 (0.377)	Data 0.0156 (0.0193)	Loss 2.3305 (2.2830)	
Epoch: [73][280/345]	Time 0.391 (0.377)	Data 0.0156 (0.0193)	Loss 3.2511 (2.2696)	
Epoch: [73][290/345]	Time 0.359 (0.378)	Data 0.0156 (0.0193)	Loss 1.6901 (2.2501)	
Epoch: [73][300/345]	Time 0.359 (0.378)	Data 0.0156 (0.0194)	Loss 1.4912 (2.2424)	
Epoch: [73][310/345]	Time 0.359 (0.378)	Data 0.0156 (0.0194)	Loss 1.3834 (2.2209)	
Epoch: [73][320/345]	Time 0.391 (0.377)	Data 0.0154 (0.0195)	Loss 1.6238 (2.2056)	
Epoch: [73][330/345]	Time 0.408 (0.378)	Data 0.0156 (0.0196)	Loss 1.7949 (2.1900)	
Epoch: [73][340/345]	Time 0.360 (0.377)	Data 0.0156 (0.0197)	Loss 1.6103 (2.1707)	
73
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [74][10/345]	Time 0.359 (0.375)	Data 0.0156 (0.0203)	Loss 3.1166 (3.0500)	
Epoch: [74][20/345]	Time 0.375 (0.371)	Data 0.0312 (0.0203)	Loss 4.7656 (3.0372)	
Epoch: [74][30/345]	Time 0.360 (0.373)	Data 0.0160 (0.0198)	Loss 1.9502 (2.9101)	
Epoch: [74][40/345]	Time 0.344 (0.374)	Data 0.0156 (0.0187)	Loss 2.1947 (2.8795)	
Epoch: [74][50/345]	Time 0.391 (0.374)	Data 0.0156 (0.0188)	Loss 2.2799 (2.8574)	
Epoch: [74][60/345]	Time 0.375 (0.377)	Data 0.0316 (0.0193)	Loss 2.6504 (2.8549)	
Epoch: [74][70/345]	Time 0.391 (0.378)	Data 0.0156 (0.0197)	Loss 1.7500 (2.8369)	
Epoch: [74][80/345]	Time 0.359 (0.377)	Data 0.0156 (0.0198)	Loss 2.7519 (2.7827)	
Epoch: [74][90/345]	Time 0.359 (0.378)	Data 0.0156 (0.0198)	Loss 2.5343 (2.7222)	
Epoch: [74][100/345]	Time 0.392 (0.379)	Data 0.0156 (0.0199)	Loss 2.9609 (2.7208)	
Epoch: [74][110/345]	Time 0.376 (0.380)	Data 0.0156 (0.0195)	Loss 2.0385 (2.6910)	
Epoch: [74][120/345]	Time 0.391 (0.381)	Data 0.0156 (0.0200)	Loss 1.9715 (2.6612)	
Epoch: [74][130/345]	Time 0.391 (0.381)	Data 0.0312 (0.0199)	Loss 2.0691 (2.6392)	
Epoch: [74][140/345]	Time 0.375 (0.381)	Data 0.0312 (0.0199)	Loss 1.9245 (2.6073)	
Epoch: [74][150/345]	Time 0.375 (0.380)	Data 0.0154 (0.0198)	Loss 2.8385 (2.5709)	
Epoch: [74][160/345]	Time 0.375 (0.379)	Data 0.0156 (0.0198)	Loss 1.9924 (2.5469)	
Epoch: [74][170/345]	Time 0.391 (0.379)	Data 0.0156 (0.0196)	Loss 1.7044 (2.5362)	
Epoch: [74][180/345]	Time 0.375 (0.379)	Data 0.0156 (0.0195)	Loss 2.2698 (2.5056)	
Epoch: [74][190/345]	Time 0.375 (0.380)	Data 0.0156 (0.0194)	Loss 1.8818 (2.4709)	
Epoch: [74][200/345]	Time 0.406 (0.380)	Data 0.0156 (0.0195)	Loss 1.6072 (2.4484)	
Epoch: [74][210/345]	Time 0.391 (0.380)	Data 0.0156 (0.0194)	Loss 1.5779 (2.4204)	
Epoch: [74][220/345]	Time 0.375 (0.380)	Data 0.0153 (0.0194)	Loss 1.7980 (2.4010)	
Epoch: [74][230/345]	Time 0.375 (0.380)	Data 0.0156 (0.0195)	Loss 1.9303 (2.3778)	
Epoch: [74][240/345]	Time 0.344 (0.380)	Data 0.0156 (0.0196)	Loss 1.5800 (2.3604)	
Epoch: [74][250/345]	Time 0.344 (0.380)	Data 0.0000 (0.0195)	Loss 1.9016 (2.3402)	
Epoch: [74][260/345]	Time 0.360 (0.380)	Data 0.0156 (0.0197)	Loss 3.0351 (2.3231)	
Epoch: [74][270/345]	Time 0.375 (0.380)	Data 0.0156 (0.0195)	Loss 2.1030 (2.3050)	
Epoch: [74][280/345]	Time 0.360 (0.379)	Data 0.0156 (0.0196)	Loss 1.9769 (2.2849)	
Epoch: [74][290/345]	Time 0.391 (0.380)	Data 0.0312 (0.0197)	Loss 1.8010 (2.2637)	
Epoch: [74][300/345]	Time 0.344 (0.379)	Data 0.0156 (0.0196)	Loss 1.3669 (2.2391)	
Epoch: [74][310/345]	Time 0.375 (0.379)	Data 0.0156 (0.0197)	Loss 1.7976 (2.2212)	
Epoch: [74][320/345]	Time 0.422 (0.379)	Data 0.0156 (0.0197)	Loss 1.8298 (2.2023)	
Epoch: [74][330/345]	Time 0.344 (0.379)	Data 0.0156 (0.0196)	Loss 1.7964 (2.1858)	
Epoch: [74][340/345]	Time 0.375 (0.379)	Data 0.0312 (0.0196)	Loss 1.5644 (2.1654)	
74
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [75][10/345]	Time 0.360 (0.385)	Data 0.0156 (0.0187)	Loss 1.6860 (3.1302)	
Epoch: [75][20/345]	Time 0.344 (0.379)	Data 0.0156 (0.0188)	Loss 3.3089 (3.0221)	
Epoch: [75][30/345]	Time 0.359 (0.383)	Data 0.0156 (0.0203)	Loss 1.7331 (2.9878)	
Epoch: [75][40/345]	Time 0.344 (0.380)	Data 0.0156 (0.0199)	Loss 2.4996 (2.7952)	
Epoch: [75][50/345]	Time 0.359 (0.380)	Data 0.0156 (0.0194)	Loss 3.4737 (2.9025)	
Epoch: [75][60/345]	Time 0.375 (0.380)	Data 0.0156 (0.0190)	Loss 2.2037 (2.8611)	
Epoch: [75][70/345]	Time 0.375 (0.378)	Data 0.0156 (0.0183)	Loss 1.7263 (2.8269)	
Epoch: [75][80/345]	Time 0.406 (0.379)	Data 0.0154 (0.0182)	Loss 1.6480 (2.7714)	
Epoch: [75][90/345]	Time 0.391 (0.379)	Data 0.0156 (0.0182)	Loss 2.1894 (2.7166)	
Epoch: [75][100/345]	Time 0.375 (0.379)	Data 0.0312 (0.0186)	Loss 2.2619 (2.6613)	
Epoch: [75][110/345]	Time 0.375 (0.378)	Data 0.0156 (0.0186)	Loss 2.5834 (2.6369)	
Epoch: [75][120/345]	Time 0.406 (0.378)	Data 0.0312 (0.0190)	Loss 1.7442 (2.6079)	
Epoch: [75][130/345]	Time 0.391 (0.378)	Data 0.0312 (0.0191)	Loss 1.8943 (2.5682)	
Epoch: [75][140/345]	Time 0.375 (0.378)	Data 0.0156 (0.0191)	Loss 2.0219 (2.5559)	
Epoch: [75][150/345]	Time 0.359 (0.377)	Data 0.0157 (0.0191)	Loss 1.9796 (2.5372)	
Epoch: [75][160/345]	Time 0.359 (0.377)	Data 0.0156 (0.0190)	Loss 2.4289 (2.5113)	
Epoch: [75][170/345]	Time 0.422 (0.378)	Data 0.0156 (0.0192)	Loss 1.7139 (2.4779)	
Epoch: [75][180/345]	Time 0.375 (0.378)	Data 0.0156 (0.0193)	Loss 1.9451 (2.4490)	
Epoch: [75][190/345]	Time 0.377 (0.378)	Data 0.0156 (0.0192)	Loss 2.1028 (2.4330)	
Epoch: [75][200/345]	Time 0.422 (0.378)	Data 0.0312 (0.0193)	Loss 2.6790 (2.4105)	
Epoch: [75][210/345]	Time 0.406 (0.378)	Data 0.0156 (0.0194)	Loss 1.8342 (2.3908)	
Epoch: [75][220/345]	Time 0.375 (0.378)	Data 0.0156 (0.0194)	Loss 2.0039 (2.3747)	
Epoch: [75][230/345]	Time 0.359 (0.378)	Data 0.0153 (0.0195)	Loss 2.3075 (2.3572)	
Epoch: [75][240/345]	Time 0.391 (0.378)	Data 0.0313 (0.0197)	Loss 1.9816 (2.3318)	
Epoch: [75][250/345]	Time 0.391 (0.378)	Data 0.0312 (0.0198)	Loss 1.8192 (2.3091)	
Epoch: [75][260/345]	Time 0.359 (0.378)	Data 0.0316 (0.0198)	Loss 2.1994 (2.2924)	
Epoch: [75][270/345]	Time 0.375 (0.378)	Data 0.0155 (0.0200)	Loss 1.8805 (2.2731)	
Epoch: [75][280/345]	Time 0.391 (0.378)	Data 0.0316 (0.0200)	Loss 1.6042 (2.2522)	
Epoch: [75][290/345]	Time 0.406 (0.378)	Data 0.0312 (0.0201)	Loss 1.7492 (2.2318)	
Epoch: [75][300/345]	Time 0.375 (0.378)	Data 0.0156 (0.0200)	Loss 1.8251 (2.2131)	
Epoch: [75][310/345]	Time 0.375 (0.378)	Data 0.0156 (0.0200)	Loss 2.2747 (2.1956)	
Epoch: [75][320/345]	Time 0.391 (0.378)	Data 0.0156 (0.0199)	Loss 1.6422 (2.1790)	
Epoch: [75][330/345]	Time 0.375 (0.378)	Data 0.0156 (0.0198)	Loss 1.4757 (2.1622)	
Epoch: [75][340/345]	Time 0.393 (0.378)	Data 0.0156 (0.0197)	Loss 1.5473 (2.1456)	
75
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [76][10/345]	Time 0.360 (0.378)	Data 0.0000 (0.0172)	Loss 1.6513 (3.0421)	
Epoch: [76][20/345]	Time 0.391 (0.377)	Data 0.0000 (0.0187)	Loss 4.6800 (3.1283)	
Epoch: [76][30/345]	Time 0.375 (0.378)	Data 0.0312 (0.0198)	Loss 2.7432 (2.9263)	
Epoch: [76][40/345]	Time 0.359 (0.378)	Data 0.0156 (0.0191)	Loss 2.9408 (2.8239)	
Epoch: [76][50/345]	Time 0.391 (0.376)	Data 0.0312 (0.0194)	Loss 1.6566 (2.7455)	
Epoch: [76][60/345]	Time 0.391 (0.376)	Data 0.0156 (0.0190)	Loss 3.0992 (2.7469)	
Epoch: [76][70/345]	Time 0.344 (0.377)	Data 0.0156 (0.0192)	Loss 2.6095 (2.6601)	
Epoch: [76][80/345]	Time 0.330 (0.374)	Data 0.0156 (0.0195)	Loss 1.8151 (2.6443)	
Epoch: [76][90/345]	Time 0.375 (0.375)	Data 0.0156 (0.0196)	Loss 1.7995 (2.6162)	
Epoch: [76][100/345]	Time 0.359 (0.374)	Data 0.0000 (0.0194)	Loss 3.0448 (2.6203)	
Epoch: [76][110/345]	Time 0.360 (0.374)	Data 0.0156 (0.0192)	Loss 1.5263 (2.5896)	
Epoch: [76][120/345]	Time 0.391 (0.374)	Data 0.0316 (0.0194)	Loss 2.3410 (2.5649)	
Epoch: [76][130/345]	Time 0.344 (0.374)	Data 0.0156 (0.0197)	Loss 2.5024 (2.5394)	
Epoch: [76][140/345]	Time 0.375 (0.374)	Data 0.0312 (0.0198)	Loss 2.1175 (2.5224)	
Epoch: [76][150/345]	Time 0.359 (0.374)	Data 0.0156 (0.0199)	Loss 2.4008 (2.5029)	
Epoch: [76][160/345]	Time 0.375 (0.374)	Data 0.0156 (0.0196)	Loss 1.9958 (2.4793)	
Epoch: [76][170/345]	Time 0.344 (0.375)	Data 0.0312 (0.0198)	Loss 1.9530 (2.4556)	
Epoch: [76][180/345]	Time 0.375 (0.374)	Data 0.0156 (0.0196)	Loss 2.0260 (2.4431)	
Epoch: [76][190/345]	Time 0.343 (0.374)	Data 0.0153 (0.0196)	Loss 1.8067 (2.4191)	
Epoch: [76][200/345]	Time 0.391 (0.374)	Data 0.0312 (0.0197)	Loss 1.6606 (2.4005)	
Epoch: [76][210/345]	Time 0.346 (0.374)	Data 0.0156 (0.0196)	Loss 1.8254 (2.3779)	
Epoch: [76][220/345]	Time 0.391 (0.374)	Data 0.0156 (0.0196)	Loss 1.9751 (2.3628)	
Epoch: [76][230/345]	Time 0.391 (0.374)	Data 0.0312 (0.0195)	Loss 1.9459 (2.3462)	
Epoch: [76][240/345]	Time 0.375 (0.373)	Data 0.0156 (0.0195)	Loss 2.2303 (2.3289)	
Epoch: [76][250/345]	Time 0.359 (0.373)	Data 0.0156 (0.0194)	Loss 1.8316 (2.3083)	
Epoch: [76][260/345]	Time 0.359 (0.373)	Data 0.0312 (0.0193)	Loss 1.5110 (2.2938)	
Epoch: [76][270/345]	Time 0.344 (0.373)	Data 0.0156 (0.0194)	Loss 2.1700 (2.2776)	
Epoch: [76][280/345]	Time 0.375 (0.373)	Data 0.0156 (0.0193)	Loss 1.9879 (2.2589)	
Epoch: [76][290/345]	Time 0.375 (0.373)	Data 0.0156 (0.0193)	Loss 2.1725 (2.2409)	
Epoch: [76][300/345]	Time 0.375 (0.373)	Data 0.0316 (0.0193)	Loss 1.6376 (2.2208)	
Epoch: [76][310/345]	Time 0.359 (0.373)	Data 0.0156 (0.0194)	Loss 1.6132 (2.2003)	
Epoch: [76][320/345]	Time 0.359 (0.373)	Data 0.0156 (0.0194)	Loss 1.6319 (2.1841)	
Epoch: [76][330/345]	Time 0.406 (0.373)	Data 0.0316 (0.0193)	Loss 1.4455 (2.1634)	
Epoch: [76][340/345]	Time 0.391 (0.373)	Data 0.0312 (0.0193)	Loss 1.5482 (2.1430)	
76
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [77][10/345]	Time 0.359 (0.375)	Data 0.0312 (0.0234)	Loss 2.0188 (2.6469)	
Epoch: [77][20/345]	Time 0.360 (0.369)	Data 0.0156 (0.0234)	Loss 2.5883 (2.7208)	
Epoch: [77][30/345]	Time 0.344 (0.367)	Data 0.0312 (0.0213)	Loss 4.4930 (2.7955)	
Epoch: [77][40/345]	Time 0.344 (0.368)	Data 0.0156 (0.0215)	Loss 2.8610 (2.6432)	
Epoch: [77][50/345]	Time 0.359 (0.366)	Data 0.0312 (0.0222)	Loss 3.3415 (2.5929)	
Epoch: [77][60/345]	Time 0.359 (0.366)	Data 0.0156 (0.0216)	Loss 3.7781 (2.6516)	
Epoch: [77][70/345]	Time 0.359 (0.367)	Data 0.0311 (0.0221)	Loss 3.4319 (2.6687)	
Epoch: [77][80/345]	Time 0.377 (0.368)	Data 0.0156 (0.0215)	Loss 3.4111 (2.6323)	
Epoch: [77][90/345]	Time 0.360 (0.368)	Data 0.0156 (0.0214)	Loss 2.7857 (2.6562)	
Epoch: [77][100/345]	Time 0.360 (0.368)	Data 0.0000 (0.0208)	Loss 3.5527 (2.6646)	
Epoch: [77][110/345]	Time 0.359 (0.368)	Data 0.0313 (0.0203)	Loss 1.5221 (2.6317)	
Epoch: [77][120/345]	Time 0.391 (0.367)	Data 0.0312 (0.0203)	Loss 3.6189 (2.6358)	
Epoch: [77][130/345]	Time 0.360 (0.367)	Data 0.0155 (0.0197)	Loss 2.5503 (2.6000)	
Epoch: [77][140/345]	Time 0.391 (0.367)	Data 0.0156 (0.0200)	Loss 1.8030 (2.5714)	
Epoch: [77][150/345]	Time 0.375 (0.367)	Data 0.0000 (0.0201)	Loss 2.1414 (2.5309)	
Epoch: [77][160/345]	Time 0.406 (0.367)	Data 0.0316 (0.0201)	Loss 1.5909 (2.5107)	
Epoch: [77][170/345]	Time 0.328 (0.367)	Data 0.0000 (0.0202)	Loss 1.9176 (2.4813)	
Epoch: [77][180/345]	Time 0.375 (0.368)	Data 0.0156 (0.0201)	Loss 2.2766 (2.4527)	
Epoch: [77][190/345]	Time 0.391 (0.368)	Data 0.0316 (0.0201)	Loss 1.7719 (2.4296)	
Epoch: [77][200/345]	Time 0.375 (0.369)	Data 0.0156 (0.0199)	Loss 1.9061 (2.4109)	
Epoch: [77][210/345]	Time 0.406 (0.369)	Data 0.0156 (0.0200)	Loss 1.5424 (2.3834)	
Epoch: [77][220/345]	Time 0.359 (0.369)	Data 0.0156 (0.0198)	Loss 2.2244 (2.3604)	
Epoch: [77][230/345]	Time 0.359 (0.369)	Data 0.0313 (0.0198)	Loss 1.5566 (2.3417)	
Epoch: [77][240/345]	Time 0.359 (0.370)	Data 0.0156 (0.0197)	Loss 1.9898 (2.3229)	
Epoch: [77][250/345]	Time 0.375 (0.370)	Data 0.0156 (0.0197)	Loss 1.7561 (2.3030)	
Epoch: [77][260/345]	Time 0.375 (0.370)	Data 0.0312 (0.0198)	Loss 1.6065 (2.2845)	
Epoch: [77][270/345]	Time 0.406 (0.371)	Data 0.0313 (0.0196)	Loss 1.9661 (2.2636)	
Epoch: [77][280/345]	Time 0.360 (0.371)	Data 0.0156 (0.0194)	Loss 1.7425 (2.2454)	
Epoch: [77][290/345]	Time 0.375 (0.371)	Data 0.0156 (0.0194)	Loss 2.3550 (2.2309)	
Epoch: [77][300/345]	Time 0.391 (0.371)	Data 0.0156 (0.0195)	Loss 1.2910 (2.2101)	
Epoch: [77][310/345]	Time 0.375 (0.372)	Data 0.0156 (0.0194)	Loss 1.5033 (2.1914)	
Epoch: [77][320/345]	Time 0.402 (0.372)	Data 0.0156 (0.0195)	Loss 1.6773 (2.1720)	
Epoch: [77][330/345]	Time 0.375 (0.372)	Data 0.0156 (0.0193)	Loss 1.6543 (2.1529)	
Epoch: [77][340/345]	Time 0.353 (0.371)	Data 0.0247 (0.0193)	Loss 1.4530 (2.1367)	
77
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [78][10/345]	Time 0.375 (0.373)	Data 0.0156 (0.0203)	Loss 4.4841 (3.2499)	
Epoch: [78][20/345]	Time 0.359 (0.373)	Data 0.0156 (0.0211)	Loss 1.6298 (3.1075)	
Epoch: [78][30/345]	Time 0.375 (0.379)	Data 0.0156 (0.0193)	Loss 2.3365 (2.9010)	
Epoch: [78][40/345]	Time 0.375 (0.378)	Data 0.0156 (0.0176)	Loss 2.3181 (2.8866)	
Epoch: [78][50/345]	Time 0.375 (0.378)	Data 0.0157 (0.0185)	Loss 2.0364 (2.7324)	
Epoch: [78][60/345]	Time 0.359 (0.378)	Data 0.0156 (0.0183)	Loss 2.0404 (2.6918)	
Epoch: [78][70/345]	Time 0.375 (0.380)	Data 0.0157 (0.0188)	Loss 1.9659 (2.6785)	
Epoch: [78][80/345]	Time 0.375 (0.381)	Data 0.0156 (0.0188)	Loss 3.0189 (2.6917)	
Epoch: [78][90/345]	Time 0.406 (0.381)	Data 0.0156 (0.0186)	Loss 3.3978 (2.6612)	
Epoch: [78][100/345]	Time 0.391 (0.381)	Data 0.0156 (0.0186)	Loss 3.5505 (2.6318)	
Epoch: [78][110/345]	Time 0.422 (0.381)	Data 0.0316 (0.0191)	Loss 1.8505 (2.5932)	
Epoch: [78][120/345]	Time 0.438 (0.382)	Data 0.0312 (0.0193)	Loss 2.7753 (2.5843)	
Epoch: [78][130/345]	Time 0.406 (0.383)	Data 0.0316 (0.0199)	Loss 2.0914 (2.5479)	
Epoch: [78][140/345]	Time 0.409 (0.383)	Data 0.0156 (0.0196)	Loss 1.7818 (2.5286)	
Epoch: [78][150/345]	Time 0.359 (0.383)	Data 0.0000 (0.0192)	Loss 2.0321 (2.5070)	
Epoch: [78][160/345]	Time 0.359 (0.382)	Data 0.0000 (0.0190)	Loss 2.0972 (2.4730)	
Epoch: [78][170/345]	Time 0.375 (0.382)	Data 0.0156 (0.0190)	Loss 1.5119 (2.4376)	
Epoch: [78][180/345]	Time 0.391 (0.382)	Data 0.0316 (0.0190)	Loss 1.7134 (2.4247)	
Epoch: [78][190/345]	Time 0.375 (0.382)	Data 0.0156 (0.0189)	Loss 1.4507 (2.3991)	
Epoch: [78][200/345]	Time 0.375 (0.382)	Data 0.0316 (0.0189)	Loss 3.0991 (2.3810)	
Epoch: [78][210/345]	Time 0.391 (0.381)	Data 0.0312 (0.0188)	Loss 1.4264 (2.3566)	
Epoch: [78][220/345]	Time 0.344 (0.381)	Data 0.0000 (0.0189)	Loss 1.4044 (2.3241)	
Epoch: [78][230/345]	Time 0.359 (0.381)	Data 0.0156 (0.0188)	Loss 2.4887 (2.3073)	
Epoch: [78][240/345]	Time 0.422 (0.381)	Data 0.0156 (0.0187)	Loss 2.3645 (2.2920)	
Epoch: [78][250/345]	Time 0.406 (0.381)	Data 0.0156 (0.0185)	Loss 1.5314 (2.2731)	
Epoch: [78][260/345]	Time 0.406 (0.381)	Data 0.0316 (0.0187)	Loss 1.6483 (2.2562)	
Epoch: [78][270/345]	Time 0.375 (0.380)	Data 0.0156 (0.0186)	Loss 1.7764 (2.2373)	
Epoch: [78][280/345]	Time 0.406 (0.380)	Data 0.0156 (0.0186)	Loss 1.9262 (2.2233)	
Epoch: [78][290/345]	Time 0.359 (0.380)	Data 0.0156 (0.0187)	Loss 1.6714 (2.2154)	
Epoch: [78][300/345]	Time 0.360 (0.380)	Data 0.0156 (0.0187)	Loss 1.4442 (2.1985)	
Epoch: [78][310/345]	Time 0.362 (0.380)	Data 0.0156 (0.0187)	Loss 2.3653 (2.1878)	
Epoch: [78][320/345]	Time 0.359 (0.379)	Data 0.0316 (0.0187)	Loss 2.5025 (2.1812)	
Epoch: [78][330/345]	Time 0.391 (0.380)	Data 0.0156 (0.0189)	Loss 1.5902 (2.1625)	
Epoch: [78][340/345]	Time 0.375 (0.380)	Data 0.0312 (0.0190)	Loss 1.4060 (2.1494)	
78
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [79][10/345]	Time 0.375 (0.369)	Data 0.0156 (0.0188)	Loss 2.7719 (3.0217)	
Epoch: [79][20/345]	Time 0.375 (0.380)	Data 0.0156 (0.0188)	Loss 3.0336 (2.8512)	
Epoch: [79][30/345]	Time 0.344 (0.381)	Data 0.0156 (0.0209)	Loss 1.7904 (2.7785)	
Epoch: [79][40/345]	Time 0.391 (0.381)	Data 0.0472 (0.0211)	Loss 2.0928 (2.7625)	
Epoch: [79][50/345]	Time 0.375 (0.380)	Data 0.0156 (0.0206)	Loss 3.0438 (2.7127)	
Epoch: [79][60/345]	Time 0.375 (0.379)	Data 0.0156 (0.0201)	Loss 2.8064 (2.6807)	
Epoch: [79][70/345]	Time 0.375 (0.381)	Data 0.0156 (0.0203)	Loss 2.1549 (2.6944)	
Epoch: [79][80/345]	Time 0.375 (0.380)	Data 0.0316 (0.0204)	Loss 1.9462 (2.6426)	
Epoch: [79][90/345]	Time 0.360 (0.379)	Data 0.0316 (0.0202)	Loss 3.4255 (2.6571)	
Epoch: [79][100/345]	Time 0.391 (0.379)	Data 0.0316 (0.0200)	Loss 3.7318 (2.6361)	
Epoch: [79][110/345]	Time 0.359 (0.380)	Data 0.0156 (0.0205)	Loss 2.6342 (2.6052)	
Epoch: [79][120/345]	Time 0.391 (0.380)	Data 0.0156 (0.0206)	Loss 2.4234 (2.5866)	
Epoch: [79][130/345]	Time 0.406 (0.381)	Data 0.0316 (0.0205)	Loss 1.8392 (2.5658)	
Epoch: [79][140/345]	Time 0.375 (0.380)	Data 0.0156 (0.0201)	Loss 2.6474 (2.5429)	
Epoch: [79][150/345]	Time 0.375 (0.379)	Data 0.0156 (0.0203)	Loss 2.3876 (2.5085)	
Epoch: [79][160/345]	Time 0.359 (0.379)	Data 0.0156 (0.0203)	Loss 3.0188 (2.4881)	
Epoch: [79][170/345]	Time 0.406 (0.379)	Data 0.0156 (0.0202)	Loss 2.0321 (2.4789)	
Epoch: [79][180/345]	Time 0.391 (0.379)	Data 0.0156 (0.0201)	Loss 1.6691 (2.4674)	
Epoch: [79][190/345]	Time 0.375 (0.379)	Data 0.0316 (0.0199)	Loss 1.7497 (2.4343)	
Epoch: [79][200/345]	Time 0.359 (0.379)	Data 0.0156 (0.0201)	Loss 2.3715 (2.4046)	
Epoch: [79][210/345]	Time 0.375 (0.379)	Data 0.0156 (0.0203)	Loss 1.7427 (2.3818)	
Epoch: [79][220/345]	Time 0.406 (0.379)	Data 0.0312 (0.0202)	Loss 1.8113 (2.3584)	
Epoch: [79][230/345]	Time 0.344 (0.379)	Data 0.0316 (0.0201)	Loss 1.4795 (2.3373)	
Epoch: [79][240/345]	Time 0.437 (0.379)	Data 0.0316 (0.0203)	Loss 1.6902 (2.3197)	
Epoch: [79][250/345]	Time 0.361 (0.379)	Data 0.0153 (0.0202)	Loss 1.8820 (2.3030)	
Epoch: [79][260/345]	Time 0.376 (0.379)	Data 0.0156 (0.0202)	Loss 1.8885 (2.2950)	
Epoch: [79][270/345]	Time 0.391 (0.379)	Data 0.0312 (0.0202)	Loss 1.9072 (2.2847)	
Epoch: [79][280/345]	Time 0.375 (0.379)	Data 0.0156 (0.0201)	Loss 2.1367 (2.2628)	
Epoch: [79][290/345]	Time 0.359 (0.379)	Data 0.0313 (0.0201)	Loss 2.1246 (2.2484)	
Epoch: [79][300/345]	Time 0.375 (0.379)	Data 0.0156 (0.0200)	Loss 1.6216 (2.2311)	
Epoch: [79][310/345]	Time 0.344 (0.379)	Data 0.0160 (0.0199)	Loss 1.4812 (2.2157)	
Epoch: [79][320/345]	Time 0.391 (0.378)	Data 0.0156 (0.0198)	Loss 1.4448 (2.1914)	
Epoch: [79][330/345]	Time 0.360 (0.378)	Data 0.0156 (0.0199)	Loss 1.4443 (2.1701)	
Epoch: [79][340/345]	Time 0.359 (0.378)	Data 0.0312 (0.0199)	Loss 1.7885 (2.1528)	
79
TripletLoss(
  (ranking_loss): MarginRankingLoss()
  (xent): CrossEntropyLoss(
    (logsoftmax): LogSoftmax(dim=1)
  )
)
Using OF
Epoch: [80][10/345]	Time 0.423 (0.374)	Data 0.0155 (0.0203)	Loss 1.7149 (2.8369)	
Epoch: [80][20/345]	Time 0.360 (0.370)	Data 0.0156 (0.0203)	Loss 2.5806 (2.7376)	
Epoch: [80][30/345]	Time 0.375 (0.370)	Data 0.0312 (0.0203)	Loss 3.6592 (2.7315)	
Epoch: [80][40/345]	Time 0.375 (0.371)	Data 0.0156 (0.0207)	Loss 1.7560 (2.7718)	
Epoch: [80][50/345]	Time 0.375 (0.372)	Data 0.0156 (0.0207)	Loss 1.9256 (2.7203)	
Epoch: [80][60/345]	Time 0.375 (0.372)	Data 0.0156 (0.0206)	Loss 2.2337 (2.6746)	
Epoch: [80][70/345]	Time 0.375 (0.373)	Data 0.0000 (0.0206)	Loss 3.0952 (2.6888)	
Epoch: [80][80/345]	Time 0.360 (0.372)	Data 0.0156 (0.0202)	Loss 2.7824 (2.6874)	
Epoch: [80][90/345]	Time 0.360 (0.372)	Data 0.0156 (0.0200)	Loss 1.9437 (2.6877)	
Epoch: [80][100/345]	Time 0.328 (0.371)	Data 0.0156 (0.0200)	Loss 2.3855 (2.6558)	
Epoch: [80][110/345]	Time 0.359 (0.372)	Data 0.0312 (0.0202)	Loss 3.1099 (2.6432)	
Epoch: [80][120/345]	Time 0.375 (0.372)	Data 0.0312 (0.0203)	Loss 2.1973 (2.6317)	
Epoch: [80][130/345]	Time 0.360 (0.371)	Data 0.0156 (0.0200)	Loss 2.2123 (2.5943)	
Epoch: [80][140/345]	Time 0.375 (0.372)	Data 0.0312 (0.0202)	Loss 3.0596 (2.5741)	
Epoch: [80][150/345]	Time 0.375 (0.372)	Data 0.0156 (0.0204)	Loss 1.9377 (2.5349)	
Epoch: [80][160/345]	Time 0.359 (0.371)	Data 0.0156 (0.0206)	Loss 1.7679 (2.5052)	
Epoch: [80][170/345]	Time 0.344 (0.371)	Data 0.0312 (0.0205)	Loss 1.8531 (2.4857)	
Epoch: [80][180/345]	Time 0.391 (0.371)	Data 0.0156 (0.0205)	Loss 1.6642 (2.4527)	
Epoch: [80][190/345]	Time 0.391 (0.371)	Data 0.0156 (0.0203)	Loss 1.9698 (2.4271)	
Epoch: [80][200/345]	Time 0.375 (0.371)	Data 0.0160 (0.0202)	Loss 1.7324 (2.3992)	
Epoch: [80][210/345]	Time 0.422 (0.372)	Data 0.0156 (0.0200)	Loss 1.7392 (2.3755)	
Epoch: [80][220/345]	Time 0.375 (0.372)	Data 0.0156 (0.0198)	Loss 1.7758 (2.3593)	
Epoch: [80][230/345]	Time 0.375 (0.372)	Data 0.0000 (0.0199)	Loss 1.8880 (2.3365)	
Epoch: [80][240/345]	Time 0.391 (0.373)	Data 0.0312 (0.0199)	Loss 1.6305 (2.3123)	
Epoch: [80][250/345]	Time 0.375 (0.373)	Data 0.0312 (0.0198)	Loss 1.6014 (2.2913)	
Epoch: [80][260/345]	Time 0.375 (0.374)	Data 0.0156 (0.0200)	Loss 1.2597 (2.2693)	
Epoch: [80][270/345]	Time 0.391 (0.374)	Data 0.0156 (0.0202)	Loss 1.7935 (2.2518)	
Epoch: [80][280/345]	Time 0.346 (0.374)	Data 0.0156 (0.0202)	Loss 1.9805 (2.2368)	
Epoch: [80][290/345]	Time 0.359 (0.374)	Data 0.0156 (0.0201)	Loss 1.7314 (2.2275)	
Epoch: [80][300/345]	Time 0.375 (0.374)	Data 0.0312 (0.0200)	Loss 1.6169 (2.2085)	
Epoch: [80][310/345]	Time 0.391 (0.374)	Data 0.0316 (0.0201)	Loss 1.3921 (2.1904)	
Epoch: [80][320/345]	Time 0.344 (0.374)	Data 0.0157 (0.0201)	Loss 1.4718 (2.1674)	
Epoch: [80][330/345]	Time 0.391 (0.375)	Data 0.0156 (0.0201)	Loss 1.5187 (2.1498)	
Epoch: [80][340/345]	Time 0.344 (0.375)	Data 0.0156 (0.0201)	Loss 1.5689 (2.1316)	
==> Test
Evaluating market1501 ...
# Using Flip Eval
Extracted features for query set, obtained 3368-by-3072 matrix
Extracted features for gallery set, obtained 15913-by-3072 matrix
==> BatchTime(s)/BatchSize(img): 0.066/100
Computing CMC and mAP
Results ----------
mAP: 39.05%
CMC curve
Rank-1  : 63.06%
Rank-5  : 81.89%
Rank-10 : 87.83%
Rank-20 : 91.75%
------------------
Save! 0 0.63064134
Finished. Total elapsed time (h:m:s): 3:28:20. Training time (h:m:s): 3:20:10.
=> Show summary
market1501 (source)
- epoch 80	 rank1 63.1%
